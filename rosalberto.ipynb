{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# -*- coding: utf-8 -*-\n", "# \n", "# # Copyright (c) 2019, NVIDIA Corporation. All rights reserved.\n", "#\n", "import os\n", "import io\n", "from io import StringIO\n", "import time\n", "import argparse\n", "import functools\n", "import errno\n", "import scipy\n", "import scipy.io\n", "import requests\n", "import zipfile\n", "import random\n", "import datetime\n", "#\n", "from functools import partial\n", "from importlib import import_module\n", "#\n", "import logging\n", "logging.getLogger('tensorflow').setLevel(logging.ERROR)\n", "#\n", "import numpy as np\n", "from numpy import *\n", "#\n", "import math\n", "from math import floor, log2\n", "from random import random\n", "from pylab import *\n", "from IPython.core.display import display\n", "import PIL\n", "from PIL import Image\n", "PIL.Image.MAX_IMAGE_PIXELS = 933120000\n", "#\n", "import scipy.ndimage as pyimg\n", "import cv2\n", "import imageio\n", "import glob\n", "import matplotlib as mpl\n", "import matplotlib.pyplot as plt \n", "import matplotlib.image as mgimg\n", "import matplotlib.animation as anim\n", "mpl.rcParams['figure.figsize'] = (12,12)\n", "mpl.rcParams['axes.grid'] = False\n", "#\n", "import shutil\n", "import gdown\n", "#\n", "import sys\n", "#\n", "import tensorflow as tf \n", "from tensorflow.keras import initializers, regularizers, constraints\n", "from tensorflow.keras import backend as K\n", "from tensorflow.keras import layers\n", "from tensorflow.keras.layers import Layer, InputSpec\n", "from tensorflow.keras.layers import BatchNormalization, Activation, ZeroPadding2D, UpSampling2D, Conv2D\n", "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout, LeakyReLU\n", "from tensorflow.keras.models import Sequential, Model\n", "from tensorflow.keras.optimizers import Adam\n", "from tensorflow.python.keras.utils import conv_utils\n", "#\n", "from tensorflow.keras.layers import Lambda\n", "from tensorflow.keras.layers import add\n", "from tensorflow.keras.layers import AveragePooling2D\n", "from tensorflow.keras.initializers import VarianceScaling\n", "from tensorflow.keras.models import clone_model\n", "from tensorflow.keras.models import model_from_json\n", "#\n", "from absl import app\n", "from absl import flags\n", "from absl import logging\n", "#\n", "tf.get_logger().setLevel('ERROR')\n", "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n", "#\n", "print(f'|===> {tf.__version__}')\n", "#\n", "if 1: # get base.py from github\n", "    cwd = os.getcwd()\n", "    base_path = os.path.join(cwd, 'base.py')\n", "    if not os.path.exists(base_path):\n", "        base_file = 'base.py'\n", "        urlfolder = 'https://raw.githubusercontent.com/sifbuilder/pylon/master/'\n", "        url = f'{urlfolder}{base_file}'\n", "        print(f\"|===> nnimg: get base file \\n \\\n", "            urlfolder: {urlfolder} \\n \\\n", "            url: {url} \\n \\\n", "            base_path: {base_path} \\n \\\n", "        \")\n", "        tofile = tf.keras.utils.get_file(f'{base_path}', origin=url, extract=True)\n", "    else:\n", "        print(f\"|===> base in cwd {cwd}\")\n", "#\n", "#\n", "#   FUNS\n", "#\n", "#\n", "# check if base.Onpyon is defined\n", "try:\n", "    var = Onpyon()\n", "except NameError:\n", "    sys.path.append('../')  # if called from eon, modules are in parallel folder\n", "    sys.path.append('./')  #  if called from dnns, modules are in folder\n", "    from base import *\n", "#\n", "onutil = Onutil()\n", "oncuda = Oncuda()\n", "onrosa = Onrosa()\n", "onplot = Onplot()\n", "onformat = Onformat()\n", "onfile = Onfile()\n", "onvid = Onvid()\n", "ondata = Ondata()\n", "onset = Onset()\n", "onrecord = Onrecord()\n", "ontree = Ontree()\n", "onlllyas = Onlllyas()\n", "onmoono = Onmoono()\n", "#\n", "#\n", "#   CONTEXT\n", "#\n", "#\n", "def getap():\n", "    cp = {\n", "        \"primecmd\": 'nntrain',    \n", "                \n", "        \"MNAME\": \"rosasalberto\",      \n", "        \"AUTHOR\": \"rosasalberto\",      \n", "        \"PROJECT\": \"rosalberto\",      \n", "        \"GITPOD\": \"StyleGAN2-TensorFlow-2.x\",      \n", "        \"DATASET\": \"ffhq\",        \n", "    \n", "        \"GDRIVE\": 1,            # mount gdrive: gdata, gwork    \n", "        \"TRAINDO\": 1,      \n", "        \"MAKEGIF\": 1,      \n", "        \"RUNGIF\": 0,      \n", "        \"CLEARTMP\": 0,      \n", "        \"REGET\": 0,             # get again data \n", "        \"ING\": 1,               # ckpt in gwork\n", "        \"MODITEM\": \"\",          # will look into module\n", "        \"RESETCODE\": False,\n", "        \"LOCALDATA\": False,\n", "        \"LOCALMODELS\": False,\n", "        \"LOCALLAB\": True,\n", "        \"grel_infix\": '../..',            # relative path to content \n", "        \"net_prefix\": '//enas/hdrive',     \n", "        \"gdrive_prefix\": '/content/drive/My Drive',     \n", "        \"gcloud_prefix\": '/content',     \n", "    }\n", "    local_prefix = os.path.abspath('')\n", "    try:\n", "        local_prefix = os.path.dirname(os.path.realpath(__file__)) # script dir\n", "    except:\n", "        pass\n", "    cp[\"local_prefix\"] = local_prefix\n", "    hp = {\n", "        \"verbose\": False,\n", "        \"visual\": True,\n", "    }\n", "    ap = {}\n", "    for key in cp.keys():\n", "        ap[key] = cp[key]\n", "    for key in hp.keys():\n", "        ap[key] = hp[key]\n", "    return ap\n", "#\n", "def getxp(cp):\n", "    yp={\n", "    }\n", "    xp={}\n", "    for key in cp.keys():\n", "        xp[key] = cp[key]\n", "    tree = ontree.tree(cp)\n", "    for key in tree.keys():\n", "        xp[key] = tree[key]\n", "    for key in yp.keys():\n", "        xp[key] = yp[key]\n", "   \n", "    return xp\n", "#\n", "#\n", "#\n", "#   NETS\n", "#\n", "#\n", "#\n", "#\n", "#   utils/weights_map\n", "#\n", "# import numpy as np\n", "#\n", "# weights      \n", "file_id = [\n", "    '1afMN3e_6UuTTPDL63WHaA0Fb9EQrZceE', \n", "    '1Av4p3JNWkmWsJx6s9Hq32JvlNWSW4kgk',\n", "    '1LCyHcKtqNs8NirJeSPq3fKAUZ-MLt_-8', \n", "    '1pEAeJTK_ZPfkUvV7VFDHq0O4tKYsslkX', \n", "    '16_QtKS2w9-40uxGZ02h3OtFhnJgNgdi_'\n", "    ]\n", "name = ['ffhq.npy', 'car.npy', 'cat.npy', 'church.npy', 'horse.npy']\n", "weights = {\n", "    \"ffhq\": '1afMN3e_6UuTTPDL63WHaA0Fb9EQrZceE',\n", "    \"car\": '1Av4p3JNWkmWsJx6s9Hq32JvlNWSW4kgk',\n", "    \"cat\": '1LCyHcKtqNs8NirJeSPq3fKAUZ-MLt_-8',\n", "    \"church\": '1pEAeJTK_ZPfkUvV7VFDHq0O4tKYsslkX',\n", "    \"horse\": '16_QtKS2w9-40uxGZ02h3OtFhnJgNgdi_',   \n", "}\n", "#\n", "resolutions = [  4,   8,  16,  32,  64, 128, 256, 512, 1024]\n", "featuremaps = [512, 512, 512, 512, 512, 256, 128,  64,   32]\n", "#\n", "available_weights = ['ffhq', 'car', 'cat', 'church', 'horse']\n", "weights_stylegan2_dir = 'weights/'\n", "#\n", "mapping_weights = [ 'Dense0/weight', 'Dense0/bias',\n", "                    'Dense1/weight', 'Dense1/bias',\n", "                    'Dense2/weight', 'Dense2/bias',\n", "                    'Dense3/weight', 'Dense3/bias',\n", "                    'Dense4/weight', 'Dense4/bias',\n", "                    'Dense5/weight', 'Dense5/bias',\n", "                    'Dense6/weight', 'Dense6/bias',\n", "                    'Dense7/weight', 'Dense7/bias']\n", "#\n", "def get_synthesis_name_weights(resolution):\n", "    synthesis_weights = ['4x4/Const/const',\n", "                         '4x4/Conv/noise_strength',\n", "                         '4x4/Conv/bias',\n", "                         '4x4/Conv/mod_bias',\n", "                         '4x4/Conv/mod_weight',\n", "                         '4x4/Conv/weight',\n", "                         '4x4/ToRGB/bias',\n", "                         '4x4/ToRGB/mod_bias',\n", "                         '4x4/ToRGB/mod_weight',\n", "                         '4x4/ToRGB/weight']\n", "    for res in range(3,int(np.log2(resolution)) + 1):\n", "        name = '{}x{}/'.format(2**res, 2**res)\n", "        for up in ['Conv0_up/', 'Conv1/', 'ToRGB/']:\n", "            for var in ['noise_strength', 'bias', 'mod_bias', 'mod_weight', 'weight']:\n", "                if up == 'ToRGB/' and var == 'noise_strength':\n", "                    continue\n", "                synthesis_weights.append(name+up+var)\n", "                \n", "    return synthesis_weights\n", "#\n", "synthesis_weights_1024 = get_synthesis_name_weights(1024)\n", "synthesis_weights_512 = get_synthesis_name_weights(512)\n", "synthesis_weights_256 = get_synthesis_name_weights(256)\n", "#\n", "discriminator_weights_1024 = ['disc_4x4/Conv/bias',\n", "                            'disc_1024x1024/FromRGB/bias',\n", "                            'disc_1024x1024/FromRGB/weight',\n", "                            'disc_1024x1024/Conv0/bias',\n", "                            'disc_1024x1024/Conv1_down/bias',\n", "                            'disc_1024x1024/Conv0/weight',\n", "                            'disc_1024x1024/Conv1_down/weight',\n", "                            'disc_1024x1024/Skip/weight',\n", "                            'disc_512x512/Conv0/bias',\n", "                            'disc_512x512/Conv1_down/bias',\n", "                            'disc_512x512/Conv0/weight',\n", "                            'disc_512x512/Conv1_down/weight',\n", "                            'disc_512x512/Skip/weight',\n", "                            'disc_256x256/Conv0/bias',\n", "                            'disc_256x256/Conv1_down/bias',\n", "                            'disc_256x256/Conv0/weight',\n", "                            'disc_256x256/Conv1_down/weight',\n", "                            'disc_256x256/Skip/weight',\n", "                            'disc_128x128/Conv0/bias',\n", "                            'disc_128x128/Conv1_down/bias',\n", "                            'disc_128x128/Conv0/weight',\n", "                            'disc_128x128/Conv1_down/weight',\n", "                            'disc_128x128/Skip/weight',\n", "                            'disc_64x64/Conv0/bias',\n", "                            'disc_64x64/Conv1_down/bias',\n", "                            'disc_64x64/Conv0/weight',\n", "                            'disc_64x64/Conv1_down/weight',\n", "                            'disc_64x64/Skip/weight',\n", "                            'disc_32x32/Conv0/bias',\n", "                            'disc_32x32/Conv1_down/bias',\n", "                            'disc_32x32/Conv0/weight',\n", "                            'disc_32x32/Conv1_down/weight',\n", "                            'disc_32x32/Skip/weight',\n", "                            'disc_16x16/Conv0/bias',\n", "                            'disc_16x16/Conv1_down/bias',\n", "                            'disc_16x16/Conv0/weight',\n", "                            'disc_16x16/Conv1_down/weight',\n", "                            'disc_16x16/Skip/weight',\n", "                            'disc_8x8/Conv0/bias',\n", "                            'disc_8x8/Conv1_down/bias',\n", "                            'disc_8x8/Conv0/weight',\n", "                            'disc_8x8/Conv1_down/weight',\n", "                            'disc_8x8/Skip/weight',\n", "                            'disc_4x4/Conv/weight',\n", "                            'disc_4x4/Dense0/weight',\n", "                            'disc_4x4/Dense0/bias',\n", "                            'disc_Output/weight',\n", "                            'disc_Output/bias']\n", "#\n", "discriminator_weights_512 = ['disc_4x4/Conv/bias',\n", "                            'disc_512x512/FromRGB/bias',\n", "                            'disc_512x512/FromRGB/weight',\n", "                            'disc_512x512/Conv0/bias',\n", "                            'disc_512x512/Conv1_down/bias',\n", "                            'disc_512x512/Conv0/weight',\n", "                            'disc_512x512/Conv1_down/weight',\n", "                            'disc_512x512/Skip/weight',\n", "                            'disc_256x256/Conv0/bias',\n", "                            'disc_256x256/Conv1_down/bias',\n", "                            'disc_256x256/Conv0/weight',\n", "                            'disc_256x256/Conv1_down/weight',\n", "                            'disc_256x256/Skip/weight',\n", "                            'disc_128x128/Conv0/bias',\n", "                            'disc_128x128/Conv1_down/bias',\n", "                            'disc_128x128/Conv0/weight',\n", "                            'disc_128x128/Conv1_down/weight',\n", "                            'disc_128x128/Skip/weight',\n", "                            'disc_64x64/Conv0/bias',\n", "                            'disc_64x64/Conv1_down/bias',\n", "                            'disc_64x64/Conv0/weight',\n", "                            'disc_64x64/Conv1_down/weight',\n", "                            'disc_64x64/Skip/weight',\n", "                            'disc_32x32/Conv0/bias',\n", "                            'disc_32x32/Conv1_down/bias',\n", "                            'disc_32x32/Conv0/weight',\n", "                            'disc_32x32/Conv1_down/weight',\n", "                            'disc_32x32/Skip/weight',\n", "                            'disc_16x16/Conv0/bias',\n", "                            'disc_16x16/Conv1_down/bias',\n", "                            'disc_16x16/Conv0/weight',\n", "                            'disc_16x16/Conv1_down/weight',\n", "                            'disc_16x16/Skip/weight',\n", "                            'disc_8x8/Conv0/bias',\n", "                            'disc_8x8/Conv1_down/bias',\n", "                            'disc_8x8/Conv0/weight',\n", "                            'disc_8x8/Conv1_down/weight',\n", "                            'disc_8x8/Skip/weight',\n", "                            'disc_4x4/Conv/weight',\n", "                            'disc_4x4/Dense0/weight',\n", "                            'disc_4x4/Dense0/bias',\n", "                            'disc_Output/weight',\n", "                            'disc_Output/bias']\n", "#\n", "discriminator_weights_256 =  ['disc_4x4/Conv/bias',\n", "                            'disc_256x256/FromRGB/bias',\n", "                            'disc_256x256/FromRGB/weight',\n", "                            'disc_256x256/Conv0/bias',\n", "                            'disc_256x256/Conv1_down/bias',\n", "                            'disc_256x256/Conv0/weight',\n", "                            'disc_256x256/Conv1_down/weight',\n", "                            'disc_256x256/Skip/weight',\n", "                            'disc_128x128/Conv0/bias',\n", "                            'disc_128x128/Conv1_down/bias',\n", "                            'disc_128x128/Conv0/weight',\n", "                            'disc_128x128/Conv1_down/weight',\n", "                            'disc_128x128/Skip/weight',\n", "                            'disc_64x64/Conv0/bias',\n", "                            'disc_64x64/Conv1_down/bias',\n", "                            'disc_64x64/Conv0/weight',\n", "                            'disc_64x64/Conv1_down/weight',\n", "                            'disc_64x64/Skip/weight',\n", "                            'disc_32x32/Conv0/bias',\n", "                            'disc_32x32/Conv1_down/bias',\n", "                            'disc_32x32/Conv0/weight',\n", "                            'disc_32x32/Conv1_down/weight',\n", "                            'disc_32x32/Skip/weight',\n", "                            'disc_16x16/Conv0/bias',\n", "                            'disc_16x16/Conv1_down/bias',\n", "                            'disc_16x16/Conv0/weight',\n", "                            'disc_16x16/Conv1_down/weight',\n", "                            'disc_16x16/Skip/weight',\n", "                            'disc_8x8/Conv0/bias',\n", "                            'disc_8x8/Conv1_down/bias',\n", "                            'disc_8x8/Conv0/weight',\n", "                            'disc_8x8/Conv1_down/weight',\n", "                            'disc_8x8/Skip/weight',\n", "                            'disc_4x4/Conv/weight',\n", "                            'disc_4x4/Dense0/weight',\n", "                            'disc_4x4/Dense0/bias',\n", "                            'disc_Output/weight',\n", "                            'disc_Output/bias']\n", "#\n", "synthesis_weights = {\n", "    'ffhq' : synthesis_weights_1024,\n", "    'car' : synthesis_weights_512,\n", "    'cat' : synthesis_weights_256,\n", "    'horse' : synthesis_weights_256,\n", "    'church' : synthesis_weights_256\n", "    }\n", "#\n", "discriminator_weights = {\n", "    'ffhq' : discriminator_weights_1024,\n", "    'car' : discriminator_weights_512,\n", "    'cat' : discriminator_weights_256,\n", "    'horse' : discriminator_weights_256,\n", "    'church' : discriminator_weights_256\n", "    }\n", "#\n", "#\n", "#\n", "#   NETS\n", "#\n", "#\n", "# from utils.utils_stylegan2 import get_weight_initializer_runtime_coef\n", "# from dnnlib.ops.upfirdn_2d import upsample_conv_2d, conv_downsample_2d\n", "#\n", "#   layers/block_layer.py\n", "#\n", "class BlockLayer(tf.keras.layers.Layer):\n", "    \"\"\"\n", "    StyleGan2 discriminator Block layer\n", "    \"\"\"\n", "    def __init__(self, res, impl='cuda', gpu=False, **kwargs):\n", "        \n", "        super(BlockLayer, self).__init__(**kwargs)\n", "        \n", "        self.res = res\n", "        self.impl = impl\n", "        self.gpu = gpu\n", "        self.resample_kernel = [1, 3, 3, 1]\n", "        \n", "    def build(self, input_shape):\n", "        \n", "        self.conv2d_0 = Conv2DLayer(fmaps=onrosa.nf(self.res-1), kernel=3, \n", "                                    impl=self.impl, gpu=self.gpu, name='Conv0')\n", "        \n", "        self.bias_0 = self.add_weight(name='Conv0/bias', shape=(onrosa.nf(self.res-1),), \n", "                                      initializer=tf.random_normal_initializer(0, 1), trainable=True)\n", "        \n", "        self.conv2d_1_down = Conv2DLayer(fmaps=onrosa.nf(self.res-2), kernel=3, down=True, \n", "                                         resample_kernel=self.resample_kernel, \n", "                                         impl=self.impl, gpu=self.gpu, name='Conv1_down')\n", "        \n", "        self.bias_1_down = self.add_weight(name='Conv1_down/bias', shape=(onrosa.nf(self.res-2),), \n", "                                           initializer=tf.random_normal_initializer(0, 1), trainable=True)\n", "        \n", "        self.conv2d_skip = Conv2DLayer(fmaps=onrosa.nf(self.res-2), kernel=1, down=True, \n", "                                       resample_kernel=self.resample_kernel, \n", "                                       impl=self.impl, gpu=self.gpu, name='Skip')\n", "        \n", "    def call(self, x):\n", "        t = x\n", "        \n", "        x = self.conv2d_0(x)\n", "        x += tf.reshape(self.bias_0, [-1 if i == 1 else 1 for i in range(x.shape.rank)])\n", "        x = tf.math.multiply(tf.nn.leaky_relu(x, 0.2), tf.math.sqrt(2.))\n", "        \n", "        x = self.conv2d_1_down(x)\n", "        x += tf.reshape(self.bias_1_down, [-1 if i == 1 else 1 for i in range(x.shape.rank)])\n", "        x = tf.math.multiply(tf.nn.leaky_relu(x, 0.2), tf.math.sqrt(2.))\n", " \n", "        t = self.conv2d_skip(t)\n", "        x = (x + t) * (1 / np.sqrt(2))\n", "        \n", "        return x\n", "#\n", "#\n", "#   layers/conv_2d_layer.py\n", "#\n", "class Conv2DLayer(tf.keras.layers.Layer):\n", "    \"\"\"\n", "    StyleGan2 discriminator convolutional layer\n", "    \"\"\"\n", "    def __init__(self, fmaps, kernel, up=False, down=False, \n", "                               demodulate=True, resample_kernel=None, gain=1, use_wscale=True, lrmul=1, \n", "                               impl='cuda', gpu=True, **kwargs):\n", "                \n", "        super(Conv2DLayer, self).__init__(**kwargs)\n", "        \n", "        self.fmaps = fmaps\n", "        self.kernel = kernel\n", "        \n", "        self.up = up\n", "        self.down = down\n", "        self.resample_kernel = resample_kernel\n", "        self.gain = gain\n", "        self.use_wscale = use_wscale\n", "        self.lrmul = lrmul\n", "        self.impl = impl\n", "        self.gpu = gpu\n", "        \n", "    def build(self, input_shape):\n", "        \n", "        self.init_std_w, self.runtime_coef_w = onrosa.get_weight_initializer_runtime_coef(shape=[self.kernel, self.kernel, input_shape[1], self.fmaps],\n", "                                    gain=self.gain, use_wscale=self.use_wscale, lrmul=self.lrmul)\n", "        \n", "        self.weight = self.add_weight(name='weight', shape=(self.kernel,self.kernel, input_shape[1], self.fmaps), \n", "                                    initializer=tf.random_normal_initializer(0, self.init_std_w), trainable=True)\n", "    \n", "    def call(self, x):\n", "        \n", "        # multiply weight per runtime_coef\n", "        w = tf.math.multiply(self.weight, self.runtime_coef_w)\n", "        \n", "        # Convolution with optional up/downsampling.\n", "        if self.up:\n", "            if self.gpu:\n", "                x = oncuda.upsample_conv_2d(x, tf.cast(w, x.dtype), data_format='NCHW', k=self.resample_kernel, impl=self.impl)\n", "            else:\n", "                x = tf.transpose(x, [0, 2, 3, 1])\n", "                x = oncuda.upsample_conv_2d(x, tf.cast(w, x.dtype), data_format='NHWC', k=self.resample_kernel, impl=self.impl, gpu=False)\n", "                x = tf.transpose(x, [0, 3, 1, 2]) \n", "        elif self.down:\n", "            if self.gpu:\n", "                x = oncuda.conv_downsample_2d(x, tf.cast(w, x.dtype), data_format='NCHW', k=self.resample_kernel, impl=self.impl)\n", "            else:\n", "                x = tf.transpose(x, [0, 2, 3, 1])\n", "                x = oncuda.conv_downsample_2d(x, tf.cast(w, x.dtype), data_format='NHWC', k=self.resample_kernel, impl=self.impl, gpu=False)\n", "                x = tf.transpose(x, [0, 3, 1, 2]) \n", "        else:\n", "            if self.gpu:\n", "                x = tf.nn.conv2d(x, tf.cast(w, x.dtype), data_format='NCHW', strides=[1,1,1,1], padding='SAME')\n", "            else:\n", "                x = tf.transpose(x, [0, 2, 3, 1])\n", "                x = tf.nn.conv2d(x, tf.cast(w, x.dtype), data_format='NHWC', strides=[1,1,1,1], padding='SAME')\n", "                x = tf.transpose(x, [0, 3, 1, 2])  \n", "        return x\n", "#\n", "#\n", "#   layers/dense_layer.py\n", "#\n", "class DenseLayer(tf.keras.layers.Layer):\n", "    \"\"\"\n", "    StyleGan2 Dense layer, including weights multiplication per runtime coef, and bias multiplication per lrmul\n", "    \"\"\"\n", "    def __init__(self, fmaps, lrmul=1, **kwargs):\n", "        \n", "        super(DenseLayer, self).__init__(**kwargs)\n", "        \n", "        self.fmaps = fmaps\n", "        self.lrmul = lrmul\n", "        \n", "    def build(self, input_shape):\n", "        \n", "        init_std, self.runtime_coef = onrosa.get_weight_initializer_runtime_coef(shape=[input_shape[1], self.fmaps], \n", "                                                                              gain=1, use_wscale=True, lrmul=self.lrmul)\n", "        \n", "        self.dense_weight = self.add_weight(name='weight', shape=(input_shape[1],self.fmaps),\n", "                                            initializer=tf.random_normal_initializer(0,init_std), trainable=True)\n", "        self.dense_bias = self.add_weight(name='bias', shape=(self.fmaps,),\n", "                                          initializer=tf.random_normal_initializer(0,init_std), trainable=True)\n", "        \n", "    def call(self, x):\n", "        \n", "        x = tf.matmul(x, tf.math.multiply(self.dense_weight, self.runtime_coef)) \n", "        x += tf.reshape(tf.math.multiply(self.dense_bias, self.lrmul), [-1 if i == 1 else 1 for i in range(x.shape.rank)])\n", "        \n", "        return x\n", "#\n", "#\n", "#   layers/from_rgb_layer.py\n", "#\n", "class FromRgbLayer(tf.keras.layers.Layer):\n", "    \"\"\"\n", "    StyleGan2 discriminator From RGB layer\n", "    \"\"\"\n", "    def __init__(self, fmaps, impl='cuda', gpu=True, **kwargs):\n", "        \n", "        super(FromRgbLayer, self).__init__(**kwargs)\n", "        \n", "        self.fmaps = fmaps\n", "        self.impl = impl\n", "        self.gpu = gpu\n", "        \n", "    def build(self, input_shape):\n", "        \n", "        self.conv2d_rgb = Conv2DLayer(fmaps=self.fmaps, kernel=1, impl=self.impl, gpu=self.gpu, name='FromRGB')\n", "        \n", "        self.rgb_bias = self.add_weight(name='FromRGB/bias', shape=(self.fmaps,), \n", "                                        initializer=tf.random_normal_initializer(0,1), trainable=True)\n", "        \n", "    def call(self, x, y):\n", "        \n", "        t = self.conv2d_rgb(y)\n\n", "        #add bias and lrelu activation\n", "        t += tf.reshape(self.rgb_bias, [-1 if i == 1 else 1 for i in range(t.shape.rank)])\n", "        t = tf.math.multiply(tf.nn.leaky_relu(t, 0.2), tf.math.sqrt(2.))\n", "        \n", "        return t if x is None else x + t\n", "#\n", "#\n", "#   layers/mini_batch_std_layer.py\n", "#\n", "class MinibatchStdLayer(tf.keras.layers.Layer):\n", "    \"\"\"\n", "    StyleGan2 discriminator MinibatchStdLayer\n", "    \"\"\"\n", "    def __init__(self, group_size=4, num_new_features=1, **kwargs):\n", "        \n", "        super(MinibatchStdLayer, self).__init__(**kwargs)\n", "        \n", "        self.group_size = group_size\n", "        self.num_new_features = num_new_features\n", "        \n", "    def call(self, x):\n", "        \n", "        group_size = tf.minimum(self.group_size, x.shape[0])     # Minibatch must be divisible by (or smaller than) group_size.\n", "        s = x.shape                                             # [NCHW]  Input shape.\n", "        y = tf.reshape(x, [group_size, -1, self.num_new_features, s[1]//self.num_new_features, s[2], s[3]])   # [GMncHW] Split minibatch into M groups of size G. Split channels into n channel groups c.\n", "        y = tf.cast(y, tf.float32)                              # [GMncHW] Cast to FP32.\n", "        y -= tf.reduce_mean(y, axis=0, keepdims=True)           # [GMncHW] Subtract mean over group.\n", "        y = tf.reduce_mean(tf.square(y), axis=0)                # [MncHW]  Calc variance over group.\n", "        y = tf.sqrt(y + 1e-8)                                   # [MncHW]  Calc stddev over group.\n", "        y = tf.reduce_mean(y, axis=[2,3,4], keepdims=True)      # [Mn111]  Take average over fmaps and pixels.\n", "        y = tf.reduce_mean(y, axis=[2])                         # [Mn11] Split channels into c channel groups\n", "        y = tf.cast(y, x.dtype)                                 # [Mn11]  Cast back to original data type.\n", "        y = tf.tile(y, [group_size, 1, s[2], s[3]])             # [NnHW]  Replicate over group and pixels.\n", "    \n", "        return tf.concat([x, y], axis=1)\n", "#\n", "#\n", "#   layers/modulated_conv_2d_layer.py\n", "#\n", "class ModulatedConv2DLayer(tf.keras.layers.Layer):\n", "    \"\"\"\n", "    StyleGan2 generator modulated convolution layer\n", "    \"\"\"\n", "    def __init__(self, fmaps, kernel, up=False, down=False, \n", "                               demodulate=True, resample_kernel=None, gain=1, use_wscale=True, lrmul=1, \n", "                               fused_modconv=True, impl='cuda', gpu=True, **kwargs):\n", "                \n", "        super(ModulatedConv2DLayer, self).__init__(**kwargs)\n", "        \n", "        self.fmaps = fmaps\n", "        self.kernel = kernel\n", "        \n", "        self.up = up\n", "        self.down = down\n", "        self.demodulate = demodulate\n", "        self.resample_kernel = resample_kernel\n", "        self.gain = gain\n", "        self.use_wscale = use_wscale\n", "        self.lrmul = lrmul\n", "        self.fused_modconv = fused_modconv\n", "        self.latent_size = 512\n", "        self.impl = impl\n", "        self.gpu = gpu\n", "        \n", "    def build(self, input_shape):\n", "        \n", "        self.init_std_w, self.runtime_coef_w = onrosa.get_weight_initializer_runtime_coef(shape=[self.kernel, self.kernel, input_shape[1], self.fmaps],\n", "                gain=self.gain, use_wscale=self.use_wscale, lrmul=self.lrmul)\n", "        \n", "        self.init_std_s, self.runtime_coef_s = onrosa.get_weight_initializer_runtime_coef(shape=[self.latent_size, input_shape[1]],\n", "                gain=self.gain, use_wscale=self.use_wscale, lrmul=self.lrmul)\n", "        \n", "        self.mod_bias = self.add_weight(name='mod_bias', shape=(input_shape[1],), \n", "                initializer=tf.random_normal_initializer(0, self.init_std_s), trainable=True)\n", "        self.mod_weight = self.add_weight(name='mod_weight', shape=(self.latent_size, input_shape[1]), \n", "                initializer=tf.random_normal_initializer(0, self.init_std_s), trainable=True)\n", "        self.weight = self.add_weight(name='weight', shape=(self.kernel,self.kernel, input_shape[1], self.fmaps), \n", "                initializer=tf.random_normal_initializer(0, self.init_std_w), trainable=True)\n", "    \n", "    def call(self, x, dlatent_vect):\n", "        \n", "        # multiply weight per runtime_coef\n", "        w = tf.math.multiply(self.weight, self.runtime_coef_w)\n", "        ww = w[np.newaxis] # [BkkIO] Introduce minibatch dimension.\n", "        \n", "        # Modulate.\n", "        s = tf.matmul(dlatent_vect, tf.math.multiply(self.mod_weight, self.runtime_coef_s)) # [BI] Transform incoming W to style.\n", "        s = tf.nn.bias_add(s, tf.math.multiply(self.mod_bias, self.lrmul)) + 1 # [BI] Add bias (initially 1).\n", "        ww = tf.math.multiply(ww, tf.cast(s[:, np.newaxis, np.newaxis, :, np.newaxis], w.dtype)) # [BkkIO] Scale input feature maps.\n", "        \n", "        # Demodulate.\n", "        if self.demodulate:\n", "            d = tf.math.rsqrt(tf.reduce_sum(tf.square(ww), axis=[1,2,3]) + 1e-8) # [BO] Scaling factor.\n", "            ww = tf.math.multiply(ww, d[:, np.newaxis, np.newaxis, np.newaxis, :]) # [BkkIO] Scale output feature maps.\n", "        \n", "        # Reshape/scale input.\n", "        if self.fused_modconv:\n", "            x = tf.reshape(x, [1, -1, x.shape[2], x.shape[3]]) # Fused => reshape minibatch to convolution groups.\n", "            w = tf.reshape(tf.transpose(ww, [1, 2, 3, 0, 4]), [ww.shape[1], ww.shape[2], ww.shape[3], -1])\n", "        else:\n", "            x = tf.math.multiply(x, tf.cast(s[:, :, np.newaxis, np.newaxis], x.dtype)) # [BIhw] Not fused => scale input activations.\n", "        \n", "        # Convolution with optional up/downsampling.\n", "        if self.up:\n", "            if self.gpu:\n", "                x = oncuda.upsample_conv_2d(x, tf.cast(w, x.dtype), data_format='NCHW', k=self.resample_kernel, impl=self.impl)\n", "            else:\n", "                x = tf.transpose(x, [0, 2, 3, 1])\n", "                x = oncuda.upsample_conv_2d(x, tf.cast(w, x.dtype), data_format='NHWC', k=self.resample_kernel, impl=self.impl, gpu=False)\n", "                x = tf.transpose(x, [0, 3, 1, 2]) \n", "        elif self.down:\n", "            if self.gpu:\n", "                x = oncuda.conv_downsample_2d(x, tf.cast(w, x.dtype), data_format='NCHW', k=self.resample_kernel, impl=self.impl)\n", "            else:\n", "                x = tf.transpose(x, [0, 2, 3, 1])\n", "                x = oncuda.conv_downsample_2d(x, tf.cast(w, x.dtype), data_format='NHWC', k=self.resample_kernel, impl=self.impl, gpu=False)\n", "                x = tf.transpose(x, [0, 3, 1, 2]) \n", "        else:\n", "            if self.gpu:\n", "                x = tf.nn.conv2d(x, tf.cast(w, x.dtype), data_format='NCHW', strides=[1,1,1,1], padding='SAME')\n", "            else:\n", "                x = tf.transpose(x, [0, 2, 3, 1])\n", "                x = tf.nn.conv2d(x, tf.cast(w, x.dtype), data_format='NHWC', strides=[1,1,1,1], padding='SAME')\n", "                x = tf.transpose(x, [0, 3, 1, 2])  \n", "                  \n", "        # Reshape/scale output.\n", "        if self.fused_modconv:\n", "            x = tf.reshape(x, [-1, self.fmaps, x.shape[2], x.shape[3]]) # Fused => reshape convolution groups back to minibatch.\n", "        elif self.demodulate:\n", "            x = tf.math.multiply(x, tf.cast(d[:, :, np.newaxis, np.newaxis], x.dtype)) # [BOhw] Not fused => scale output activations.\n", "        return x\n", "#\n", "#\n", "#   layers/synthesis_main_layer.py\n", "#\n", "class SynthesisMainLayer(tf.keras.layers.Layer):\n", "    \"\"\"\n", "    StyleGan2 synthesis network main layer\n", "    \"\"\"\n", "    def __init__(self, fmaps, up=False, impl='cuda', gpu=True,**kwargs):\n", "        \n", "        super(SynthesisMainLayer, self).__init__(**kwargs)\n", "        \n", "        self.fmaps = fmaps\n", "        self.up = up\n", "        self.impl = impl\n", "        self.gpu = gpu\n", "        \n", "        self.resample_kernel = [1,3,3,1]\n", "        self.kernel = 3\n", "        \n", "        if self.up:\n", "            self.l_name = 'Conv0_up'\n", "        else:\n", "            self.l_name = 'Conv1'\n", "        \n", "    def build(self, input_shape):\n", "        \n", "        self.noise_strength = self.add_weight(name=self.l_name+'/noise_strength', shape=[], initializer=tf.initializers.zeros(), trainable=True)\n", "        self.bias = self.add_weight(name=self.l_name+'/bias', shape=(self.fmaps,), initializer=tf.random_normal_initializer(0,1), trainable=True)\n", "        \n", "        self.mod_conv2d_layer = ModulatedConv2DLayer(fmaps=self.fmaps, kernel=self.kernel, \n", "                                                up=self.up, resample_kernel=self.resample_kernel,\n", "                                                 impl=self.impl, gpu=self.gpu, name=self.l_name)\n", "        \n", "    def call(self, x, dlatent_vect):\n", "                \n", "        x = self.mod_conv2d_layer(x, dlatent_vect)\n", "        \n", "        #randomize noise\n", "        noise = tf.random.normal([tf.shape(x)[0], 1, x.shape[2], x.shape[3]], dtype=x.dtype)\n", "        \n", "        # adding noise to layer\n", "        x += tf.math.multiply(noise, tf.cast(self.noise_strength, x.dtype))\n", "        \n", "        # adding bias and lrelu activation\n", "        x += tf.reshape(self.bias, [-1 if i == 1 else 1 for i in range(x.shape.rank)])\n", "        x = tf.math.multiply(tf.nn.leaky_relu(x, 0.2), tf.math.sqrt(2.))\n", "        \n", "        return x\n", "#\n", "#\n", "#   layers/to_rgb_layer.py\n", "#\n", "class ToRgbLayer(tf.keras.layers.Layer):\n", "    \"\"\"\n", "    StyleGan2 generator To RGB layer\n", "    \"\"\"\n", "    def __init__(self, impl='cuda', gpu=True,**kwargs):\n", "        \n", "        super(ToRgbLayer, self).__init__(**kwargs)\n", "        \n", "        self.impl = impl\n", "        self.gpu = gpu\n", "        \n", "    def build(self, input_shape):\n", "        \n", "        self.mod_conv2d_rgb = ModulatedConv2DLayer(fmaps=3, kernel=1, demodulate=False, \n", "                                              impl=self.impl, gpu=self.gpu, name='ToRGB')\n", "        \n", "        self.rgb_bias = self.add_weight(name='ToRGB/bias', shape=(3,), \n", "                                        initializer=tf.random_normal_initializer(0, 1), trainable=True)\n", "        \n", "    def call(self, x, dlatent_vect, y):\n", "        \n", "        u = self.mod_conv2d_rgb(x, dlatent_vect)\n", "        t = u + tf.reshape(self.rgb_bias, [-1 if i == 1 else 1 for i in range(x.shape.rank)])\n", "        \n", "        return t if y is None else y + t\n", "#\n", "#\n", "#   stylegan2_discriminator.py\n", "#\n", "class StyleGan2Discriminator(tf.keras.layers.Layer):\n", "    \"\"\"\n", "    StyleGan2 discriminator config f for tensorflow 2.x \n", "    \"\"\"\n", "    def __init__(self, resolution=1024, weights=None, impl='cuda', gpu=True, **kwargs):\n", "        \"\"\"\n", "        Parameters\n", "        ----------\n", "        resolution : int, optional\n", "            Resolution output of the synthesis network, will be parsed \n", "            to the floor integer power of 2. \n", "            The default is 1024.\n", "        weights : string, optional\n", "            weights name in weights dir to be loaded. The default is None.\n", "        impl : str, optional\n", "            Wether to run some convolutions in custom tensorflow \n", "            operations or cuda operations. 'ref' and 'cuda' available.\n", "            The default is 'cuda'.\n", "        gpu : boolean, optional\n", "            Wether to use gpu. The default is True.\n", "        \"\"\"\n", "        super(StyleGan2Discriminator, self).__init__(**kwargs)\n", "    \n", "        self.gpu = gpu\n", "        self.impl = impl\n", "    \n", "        self.resolution = resolution\n", "        if weights is not None: self.__adjust_resolution(weights)\n", "        self.resolution_log2 = int(np.log2(resolution))\n", "        \n", "        # load weights\n", "        if weights is not None:\n", "            _ = self(tf.zeros(shape=(1, 3, self.resolution, self.resolution)))\n", "            self.__load_weights(weights)\n", "             \n", "    def build(self, input_shape):\n", "        \n", "        self.mini_btch_std_layer = MinibatchStdLayer()\n", "        self.from_rgb = FromRgbLayer(fmaps=onrosa.nf(self.resolution_log2-1), \n", "                                     name='{}x{}'.format(self.resolution, self.resolution),\n", "                                     impl=self.impl, gpu=self.gpu)\n", "        \n", "        for res in range(self.resolution_log2, 2, -1):\n", "            res_str = str(2**res)\n", "            setattr(self, 'block_{}_{}'.format(res_str, res_str), \n", "                    BlockLayer(res=res, name='{}x{}'.format(res_str, res_str), \n", "                               impl=self.impl, gpu=self.gpu))\n", "        \n", "        #last layers\n", "        self.conv_4_4 = Conv2DLayer(fmaps=onrosa.nf(1), kernel=3, impl=self.impl, \n", "                                    gpu=self.gpu, name='4x4/Conv')\n", "        self.conv_4_4_bias = self.add_weight(name='4x4/Conv/bias', shape=(512,),\n", "                                             initializer=tf.random_normal_initializer(0,1), trainable=True)\n", "        self.dense_4_4 = DenseLayer(fmaps=512, name='4x4/Dense0')\n", "        self.dense_output = DenseLayer(fmaps=1, name='Output')\n", "    \n", "    def _call(self, y):\n", "        \"\"\"\n", "        Parameters\n", "        ----------\n", "        y : tensor of the image/s to evaluate. shape [batch, channel, height, width]\n", "        Returns\n", "        -------\n", "        output of the discriminator. \n", "        \"\"\"\n", "        y = tf.cast(y, 'float32')\n", "        x = None\n", "        \n", "        for res in range(self.resolution_log2, 2, -1):\n", "            if  res == self.resolution_log2:\n", "                x = self.from_rgb(x, y)\n", "            x = getattr(self, 'block_{}_{}'.format(2**res, 2**res))(x)\n\n", "        # minibatch std dev\n", "        x = self.mini_btch_std_layer(x)\n", "        \n", "        # last convolution layer\n", "        x = self.conv_4_4(x)\n", "        x += tf.reshape(self.conv_4_4_bias, [-1 if i == 1 else 1 for i in range(x.shape.rank)])\n", "        x = tf.math.multiply(tf.nn.leaky_relu(x, 0.2), tf.math.sqrt(2.))\n", "        \n", "        x = tf.reshape(x, [-1, np.prod([d for d in x.shape[1:]])])\n", "        # dense layer\n", "        x = self.dense_4_4(x)\n", "        x = tf.math.multiply(tf.nn.leaky_relu(x, 0.2), tf.math.sqrt(2.))\n", "        # output layer\n", "        x = self.dense_output(x)\n", "        \n", "        return tf.identity(x, name='scores_out')\n", "    \n", "    def call(self, inputs, training=False):\n", "        y, labels = inputs\n", "        y = tf.cast(y, 'float32')\n", "        x = None\n", "        \n", "        for res in range(self.resolution_log2, 2, -1):\n", "            if  res == self.resolution_log2:\n", "                x = self.from_rgb(x, y)\n", "            x = getattr(self, 'block_{}_{}'.format(2**res, 2**res))(x)\n\n", "        #minibatch std dev\n", "        x = self.mini_btch_std_layer(x)\n", "        \n", "        #last convolution layer\n", "        x = self.conv_4_4(x)\n", "        x += tf.reshape(self.conv_4_4_bias, [-1 if i == 1 else 1 for i in range(x.shape.rank)])\n", "        x = tf.math.multiply(tf.nn.leaky_relu(x, 0.2), tf.math.sqrt(2.))\n", "        \n", "        x = tf.reshape(x, [-1, np.prod([d for d in x.shape[1:]])])\n", "        # dense layer\n", "        x = self.dense_4_4(x)\n", "        x = tf.math.multiply(tf.nn.leaky_relu(x, 0.2), tf.math.sqrt(2.))\n", "        #output layer\n", "        x = self.dense_output(x)\n", "        \n", "        return tf.identity(x, name='scores_out')\n", "    \n", "    def __adjust_resolution(self, weights_name):\n", "        \"\"\"\n", "        Adjust resolution of the synthesis network output. \n", "        \n", "        Parameters\n", "        ----------\n", "        weights_name : name of the weights\n", "        \"\"\"\n", "        if  weights_name == 'ffhq': \n", "            self.resolution = 1024\n", "        elif weights_name == 'car': \n", "            self.resolution = 512\n", "        elif weights_name in ['cat', 'church', 'horse']: \n", "            self.resolution = 256\n", "    \n", "    def __load_weights(self, weights_name):\n", "        \"\"\"\n", "        Load pretrained weights, stored as a dict with numpy arrays.\n", "        Parameters\n", "        ----------\n", "        weights_name : name of the weights\n", "        \"\"\"\n", "        \n", "        if (weights_name in available_weights) and type(weights_name) == str:\n", "            data = np.load(weights_stylegan2_dir + weights_name + '.npy', allow_pickle=True)[()]\n", "            \n", "            weights_discriminator = [data.get(key) for key in discriminator_weights[weights_name]]\n", "            self.set_weights(weights_discriminator)\n", "            \n", "            print(\"Loaded {} discriminator weights!\".format(weights_name))\n", "        else:\n", "            print('Cannot load the specified weights')\n", "#\n", "#\n", "class MappingNetwork(tf.keras.layers.Layer):\n", "    \"\"\"\n", "    StyleGan2 generator mapping network, from z to dlatents for tensorflow 2.x\n", "    \"\"\"\n", "    def __init__(self, **kwargs):\n", "        \n", "        super(MappingNetwork, self).__init__(**kwargs)\n", "        \n", "        self.dlatent_size = 512\n", "        self.dlatent_vector = 18\n", "        self.mapping_layers = 8\n", "        self.lrmul = 0.01\n", "        \n", "    def build(self, input_shape):\n", "        self.weights_dict = {}\n", "        for i in range(self.mapping_layers):\n", "            setattr(self, 'Dense{}'.format(i), DenseLayer(fmaps=512, lrmul=self.lrmul, name='Dense{}'.format(i)))\n", "    \n", "        self.g_mapping_broadcast = tf.keras.layers.RepeatVector(self.dlatent_vector)\n", "            \n", "    def call(self, z):\n", "        \n", "        z = tf.cast(z, 'float32')\n", "        \n", "        # Normalize inputs\n", "        scale = tf.math.rsqrt(tf.reduce_mean(tf.square(z), axis=1, keepdims=True) + 1e-8)\n", "        x = tf.math.multiply(z, scale)\n", "        \n", "        # Mapping\n", "        for i in range(self.mapping_layers):\n", "        \n", "            x = getattr(self, 'Dense{}'.format(i))(x)\n", "            x = tf.math.multiply(tf.nn.leaky_relu(x, 0.2), tf.math.sqrt(2.))\n", "        \n", "        # Broadcasting\n", "        dlatents = self.g_mapping_broadcast(x)\n", "        \n", "        return dlatents\n", "#\n", "class SynthesisNetwork(tf.keras.layers.Layer):\n", "    \"\"\"\n", "    StyleGan2 generator synthesis network from dlatents to img tensor for tensorflow 2.x\n", "    \"\"\"\n", "    def __init__(self, resolution=1024, impl='cuda', gpu=True, **kwargs):\n", "        \"\"\"\n", "        Parameters\n", "        ----------\n", "        resolution : int, optional\n", "            Resolution output of the synthesis network, will be parsed to the floor integer power of 2. \n", "            The default is 1024.\n", "        impl : str, optional\n", "            Wether to run some convolutions in custom tensorflow operations or cuda operations. 'ref' and 'cuda' available.\n", "            The default is 'cuda'.\n", "        gpu : boolean, optional\n", "            Wether to use gpu. The default is True.\n", "        \"\"\"\n", "        super(SynthesisNetwork, self).__init__(**kwargs)\n", "        \n", "        self.impl = impl\n", "        self.gpu = gpu\n", "        self.resolution = resolution\n", "        \n", "        self.resolution_log2 = int(np.log2(self.resolution))\n", "        self.resample_kernel = [1, 3, 3, 1]\n", "    def build(self, input_shape):\n", "        \n", "        #constant layer\n", "        self.const_4_4 = self.add_weight(name='4x4/Const/const', shape=(1, 512, 4, 4), \n", "                                        initializer=tf.random_normal_initializer(0, 1), trainable=True)\n", "        #early layer 4x4\n", "        self.layer_4_4 = SynthesisMainLayer(fmaps=onrosa.nf(1), impl=self.impl, gpu=self.gpu, name='4x4')\n", "        self.torgb_4_4 = ToRgbLayer(impl=self.impl, gpu=self.gpu, name='4x4')\n", "        #main layers\n", "        for res in range(3, self.resolution_log2 + 1):\n", "            res_str = str(2**res)\n", "            setattr(self, 'layer_{}_{}_up'.format(res_str, res_str), \n", "                    SynthesisMainLayer(fmaps=onrosa.nf(res-1), impl=self.impl, gpu=self.gpu, up=True, name='{}x{}'.format(res_str, res_str)))\n", "            setattr(self, 'layer_{}_{}'.format(res_str, res_str), \n", "                    SynthesisMainLayer(fmaps=onrosa.nf(res-1), impl=self.impl, gpu=self.gpu, name='{}x{}'.format(res_str, res_str)))\n", "            setattr(self, 'torgb_{}_{}'.format(res_str, res_str), \n", "                    ToRgbLayer(impl=self.impl, gpu=self.gpu, name='{}x{}'.format(res_str, res_str)))\n", "        \n", "    def call(self, dlatents_in):\n", "        \n", "        dlatents_in = tf.cast(dlatents_in, 'float32')\n", "        y = None\n", "        \n", "        # Early layers\n", "        x = tf.tile(tf.cast(self.const_4_4, 'float32'), [tf.shape(dlatents_in)[0], 1, 1, 1])\n", "        x = self.layer_4_4(x, dlatents_in[:, 0])\n", "        y = self.torgb_4_4(x, dlatents_in[:, 1], y)\n", "                \n", "        # Main layers\n", "        for res in range(3, self.resolution_log2 + 1):\n", "            x = getattr(self, 'layer_{}_{}_up'.format(2**res, 2**res))(x, dlatents_in[:, res*2-5])\n", "            x = getattr(self, 'layer_{}_{}'.format(2**res, 2**res))(x, dlatents_in[:, res*2-4])\n", "            y = oncuda.upsample_2d(y, k=self.resample_kernel, impl=self.impl, gpu=self.gpu)\n", "            y = getattr(self, 'torgb_{}_{}'.format(2**res, 2**res))(x, dlatents_in[:, res*2-3], y)\n", "                    \n", "        images_out = y\n", "        return tf.identity(images_out, name='images_out')\n", "#\t\n", "#\n", "#\n", "#   stylegan2_generator.py\n", "#\n", "# from utils.weights_map import available_weights, synthesis_weights, mapping_weights, weights_stylegan2_dir\n", "class StyleGan2Generator(tf.keras.layers.Layer):\n", "    \"\"\"\n", "    StyleGan2 generator config f for tensorflow 2.x\n", "    \"\"\"\n", "    def __init__(self, resolution=1024, weights=None, impl='cuda', gpu=True, **kwargs):\n", "        \"\"\"\n", "        Parameters\n", "        ----------\n", "        resolution : int, optional\n", "            Resolution output of the synthesis network, will be parsed \n", "            to the floor integer power of 2. \n", "            The default is 1024.\n", "        weights : string, optional\n", "            weights name in weights dir to be loaded. The default is None.\n", "        impl : str, optional\n", "            Wether to run some convolutions in custom tensorflow operations \n", "            or cuda operations. 'ref' and 'cuda' available.\n", "            The default is 'cuda'.\n", "        gpu : boolean, optional\n", "            Wether to use gpu. The default is True.\n", "        \"\"\"\n", "        super(StyleGan2Generator, self).__init__(**kwargs)\n", "        \n", "        self.resolution = resolution\n", "        if weights is not None: self.__adjust_resolution(weights)\n", "        self.mapping_network = MappingNetwork(name='Mapping_network')\n", "        self.synthesis_network = SynthesisNetwork(resolution=self.resolution, impl=impl, \n", "                                                  gpu=gpu, name='Synthesis_network')\n", "        \n", "        # load weights\n", "        if weights is not None:\n", "            #we run the network to define it, not the most efficient thing to do...\n", "            _ = self([tf.zeros(shape=(1, 512)), None])\n", "            self.__load_weights(weights)\n", "        \n", "    def _call(self, z):\n", "        \"\"\"\n", "        Parameters\n", "        ----------\n", "        z : tensor, latent vector of shape [batch, 512]\n", "        Returns\n", "        -------\n", "        img : tensor, image generated by the generator of shape  [batch, channel, height, width]\n", "        \"\"\"\n", "        dlatents = self.mapping_network(z)\n", "        img = self.synthesis_network(dlatents)\n", "        return img\n", "    \n", "    # _e_\n", "    # add \n", "    def call(self, inputs, truncation_cutoff=None, truncation_psi=1.0, training=None, mask=None):\n\n", "        # weights_name = 'ffhq'\n", "        # w_average = np.load(f'weights/{weights_name}_dlatent_avg.npy')\n", "        # self.n_broadcast = len(self.resolutions) * 2        \n", "        # self.broadcast = tf.keras.layers.Lambda(lambda x: tf.tile(x[:, np.newaxis], [1, self.n_broadcast, 1]))\n", "        dlatents, labels = inputs\n", "        dlatents = self.mapping_network(dlatents) # z\n", "        img = self.synthesis_network(dlatents)\n\n", "        # if training:\n", "        #     self.update_moving_average_of_w(w_broadcasted)\n", "        #     w_broadcasted = self.style_mixing_regularization(dlatents, labels, w_broadcasted)\n\n", "        # if not training:\n", "        #     w_broadcasted = self.truncation_trick(w_broadcasted, truncation_cutoff, truncation_psi)\n\n", "        # # adjusting dlatents depending on truncation psi, if truncatio_psi = 1, no adjust\n", "        # dlatents = w_average + (dlatents - w_average) * truncation_psi \n", "        # # running synthesis network\n", "        # out = self.synthesis_network(dlatents)\n\n", "        # #converting image/s to uint8\n", "        # img = convert_images_to_uint8(out, nchw_to_nhwc=True, uint8_cast=True)\n\n", "        # # image_out = self.synthesis(w_broadcasted)\n", "        # # return image_out, w_broadcasted\n", "        return img   \n", "    def __adjust_resolution(self, weights_name):\n", "        \"\"\"\n", "        Adjust resolution of the synthesis network output. \n", "        \n", "        Parameters\n", "        ----------\n", "        weights_name : name of the weights\n", "        Returns\n", "        -------\n", "        None.\n", "        \"\"\"\n", "        if  weights_name == 'ffhq': \n", "            self.resolution = 1024\n", "        elif weights_name == 'car': \n", "            self.resolution = 512\n", "        elif weights_name in ['cat', 'church', 'horse']: \n", "            self.resolution = 256\n", "    \n", "    def __load_weights(self, weights_name):\n", "        \"\"\"\n", "        Load pretrained weights, stored as a dict with numpy arrays.\n", "        Parameters\n", "        ----------\n", "        weights_name : name of the weights\n", "        Returns\n", "        -------\n", "        None.\n", "        \"\"\"\n", "        \n", "        if (weights_name in available_weights) and type(weights_name) == str:\n", "            data = np.load(weights_stylegan2_dir + weights_name + '.npy', allow_pickle=True)[()]\n", "            \n", "            weights_mapping = [data.get(key) for key in mapping_weights]\n", "            weights_synthesis = [data.get(key) for key in synthesis_weights[weights_name]]\n", "            \n", "            self.mapping_network.set_weights(weights_mapping)\n", "            self.synthesis_network.set_weights(weights_synthesis)\n", "            \n", "            print(\"Loaded {} generator weights!\".format(weights_name))\n", "        else:\n", "            raise Exception('Cannot load {} weights'.format(weights_name))\n", "#\n", "#\n", "#\n", "#   stylegan2.py\n", "#\n", "class StyleGan2(tf.keras.Model):\n", "    \"\"\" \n", "    StyleGan2 config f for tensorflow 2.x \n", "    \"\"\"\n", "    def __init__(self, \n", "        resolution=1024, \n", "        weights=None, \n", "        impl='cuda', \n", "        gpu=True, \n", "  \n", "        # ---------\n", "        lr = 0.0001, \n", "        decay = 0.00001, \n", "        silent = True,\n", "        latent_size = 512,\n", "        im_size = 256,\n", "        batch_size = 4, # 16\n", "        mixed_prob = 0.9,\n", "    \n", "        steps = 1, \n", "        ncyc = None, \n", "        qsteps = 1000001,\n", "        name='sol',\n", "        results_dir = \"results\",\n", "        models_dir = \"models\",\n", "        logs_dir = \"logs\",\n", "        ckpt_dir = \"checkpoint\",\n", "        ckpt_prefix = 'ckpt',\n", "        dataorg_dir = \"images\",\n", "        data_dir = \"data\",\n", "        dataset_dir = \"dataset\",\n", "        tfrecord_dir = \"tfrecords\",\n", "        update = 0,\n", "        images = [],\n", "        segments = [],\n", "        verbose = True,   \n", "        training_parameters = {},\n", "        # ---------\n", "        **kwargs\n", "        ):\n", "        super(StyleGan2, self).__init__(**kwargs)\n\n", "        # --------------\n", "        self.results_dir = results_dir\n", "        self.models_dir = models_dir\n", "        self.logs_dir = logs_dir\n", "        self.data_dir = data_dir\n", "        self.dataset_dir = dataset_dir\n", "        self.tfrecord_dir = tfrecord_dir\n", "        self.latent_size = latent_size\n", "        self.im_size = im_size\n", "        self.batch_size = batch_size\n", "        self.update = update\n", "        self.images = images\n", "        self.segments = segments\n", "        self.verbose = verbose\n", "        self.mixed_prob = 0.9\n", "    \n", "        self.im_size = im_size\n", "        print(\"StyleGan:im_size: %d \" %self.im_size)    \n", "        self.n_layers = int(log2(im_size) - 1)\n", "        print(\"StyleGan:n_layers: %d \" %self.n_layers)\n", "        self.steps = steps\n", "        self.qsteps = qsteps                                # to train steps\n", "        print(\"StyleGan:qsteps: will train up to %d steps\" %self.qsteps)\n", "        t_params = training_parameters\n", "        self.model_base_dir = t_params['model_base_dir']\n", "        self.tfrecord_dir = t_params['tfrecord_dir']\n", "        self.shuffle_buffer_size = t_params['shuffle_buffer_size']\n", "        self.g_params = t_params['g_params']\n", "        self.d_params = t_params['d_params']\n", "        self.g_opt = t_params['g_opt']\n", "        self.d_opt = t_params['d_opt']\n", "        self.batch_size = t_params['batch_size']\n", "        self.n_total_image = t_params['n_total_image']\n", "        self.n_samples = min(t_params['batch_size'], t_params['n_samples'])\n", "        self.r1_gamma = 10.0\n", "        # self.r2_gamma = 0.0\n", "        self.max_steps = int(np.ceil(self.n_total_image / self.batch_size))\n", "        self.out_res = self.g_params['resolutions'][-1]\n", "        self.log_template = 'step {}: elapsed: {:.2f}s, d_loss: {:.3f}, g_loss: {:.3f}, r1_penalty: {:.3f}'\n", "        self.print_step = 10\n", "        self.save_step = 100\n", "        self.image_summary_step = 100\n", "        self.reached_max_steps = False        \n", "        # --------------\n", "        self.resolution = resolution\n", "        if weights is not None:\n", "            self.__adjust_resolution(weights)\n", "        print(f'resolution: {self.resolution}')            \n", "        print('Create models')            \n", "        self.G = StyleGan2Generator(resolution=self.resolution, weights=weights, \n", "                        impl=impl, gpu=gpu, name='Generator')\n", "        self.D = StyleGan2Discriminator(resolution=self.resolution, weights=weights, \n", "                        impl=impl, gpu=gpu, name='Discriminator')\n", "        \n", "        learning_rate = 0.01\n", "        beta1 = 0.99\n", "        beta2 = 0.99\n", "        epsilon = 1e-1\n", "        self.DMO = tf.keras.optimizers.Adam(learning_rate,\n", "                                        beta_1=beta1,\n", "                                        beta_2=beta2,\n", "                                        epsilon=epsilon)\n", "        self.GMO = tf.keras.optimizers.Adam(learning_rate,\n", "                                        beta_1=beta1,\n", "                                        beta_2=beta2,\n", "                                        epsilon=epsilon)\n", "        self.g_clone = StyleGan2Generator(resolution=self.resolution, \n", "                weights=weights, \n", "                impl=impl, gpu=gpu, name='Generator')\n", "        self.M = MappingNetwork(name='Mapping_network')\n", "        self.S = SynthesisNetwork(resolution=self.resolution, impl=impl, \n", "                                        gpu=gpu, name='Synthesis_network')\n", "        self.ckpt_dir = ckpt_dir\n", "        self.ckpt_prefix = ckpt_prefix\n", "        self.ckpt = tf.train.Checkpoint(\n", "            GMO=self.GMO,\n", "            DMO=self.DMO,\n", "            G=self.G,\n", "            D=self.D,\n", "             g_clone=self.g_clone)\n", "        self.manager = tf.train.CheckpointManager(self.ckpt, self.ckpt_dir, max_to_keep=2)\n", "        self.restore_checkpoint()\n", "        if self.manager.latest_checkpoint:\n", "            print('Restored from {}'.format(self.manager.latest_checkpoint))\n\n", "            # check if already trained in this resolution\n", "            restored_step = self.g_optimizer.iterations.numpy()\n", "            if restored_step >= self.max_steps:\n", "                print('Already reached max steps {}/{}'.format(restored_step, self.max_steps))\n", "                self.reached_max_steps = True\n", "                return\n", "        else:\n", "            print('Not restoring from saved checkpoint')\n", "        print(\"|... StyleGan2 inited\")\n", "    def call(self, latent_vector):\n", "        \"\"\"\n", "        Parameters\n", "        ----------\n", "        latent_vector : latent vector z of size [batch, 512].\n", "        Returns\n", "        -------\n", "        score : output of the discriminator. \n", "        \"\"\"\n", "        img = self.G([latent_vector, None]) # _e_\n", "        score = self.D([img, None])\n", "        return score    \n", "    def noise(self, n):\n", "        latent_size = self.latent_size\n", "        return np.random.normal(0.0, 1.0, size = [n, latent_size]).astype('float32')\n", "    def noiseList(self, n):\n", "        noise = self.noise\n", "        n_layers = self.n_layers\n", "        return [noise(n)] * (n_layers)\n", "    def mixedList(self, n):\n", "        noise = self.noise\n", "        n_layers = self.n_layers\n", "        tt = int(np.random.uniform(()) * n_layers)\n", "        p1 = [noise(n)] * tt\n", "        p2 = [noise(n)] * (n_layers - tt)\n", "        return p1 + [] + p2\n", "    def nImage(self, n):\n", "        im_size = self.im_size\n", "        return np.random.uniform(0.0, 1.0, size = [n, im_size, im_size, 1]).astype('float32')\n", "    def __adjust_resolution(self, weights_name):\n", "        \"\"\"\n", "        Adjust resolution of the synthesis network output. \n", "        \n", "        Parameters\n", "        ----------\n", "        weights_name : name of the weights\n", "        \"\"\"\n", "        if  weights_name == 'ffhq': \n", "            self.resolution = 1024\n", "        elif weights_name == 'car': \n", "            self.resolution = 512\n", "        elif weights_name in ['cat', 'church', 'horse']: \n", "            self.resolution = 256\n", "    @tf.function            \n", "    def train_step(self, real_images):\n", "        if 0:\n", "            print(f\"|===> train_step \\n \\\n", "                    real_images: {np.shape(real_images)} {type(real_images)} \\n \\\n", "            \")\n", "        with tf.GradientTape() as g_tape, tf.GradientTape() as d_tape:\n", "            z = tf.random.normal(shape=[tf.shape(real_images)[0], self.g_params['z_dim']], dtype=tf.dtypes.float32)\n", "            real_images = onmoono.preprocess_fit_train_image(real_images, self.out_res)\n", "            labels = tf.ones((tf.shape(real_images)[0], self.g_params['labels_dim']), dtype=tf.dtypes.float32)\n", "            fake_images = self.G([z, labels], training=True)\n", "            real_scores = self.D([real_images, labels], training=True)\n", "            fake_scores = self.D([fake_images, labels], training=True)\n", "            \n", "            divergence = tf.math.softplus(fake_scores)  # log ( 1 + exp( D(fakes) ) ) # alt tf.math.relu\n", "            divergence += tf.math.softplus(-real_scores) # log ( 1 - exp( D(reals) ) )  # alt tf.math.relu\n", "            divergence = tf.keras.backend.mean(divergence)\n", "            d_loss = tf.reduce_mean(divergence)\n", "            g_loss = tf.math.softplus(-fake_scores)\n", "            g_loss = tf.reduce_mean(g_loss)\n", "        g_gradients = g_tape.gradient(g_loss, self.G.trainable_variables)\n", "        self.GMO.apply_gradients(zip(g_gradients, self.G.trainable_variables))\n", "        d_gradients = d_tape.gradient(d_loss, self.D.trainable_variables)\n", "        self.DMO.apply_gradients(zip(d_gradients, self.D.trainable_variables))\n", "        return d_loss, g_loss\n", "    def fit(self):\n", "        print(f\"|===> fit \\n \\\n", "                self.steps: {self.steps} \\n \\\n", "                self.qsteps: {self.qsteps} \\n \\\n", "                self.tfrecord_dir: {self.tfrecord_dir} \\n \\\n", "                self.out_res: {self.out_res} \\n \\\n", "                self.shuffle_buffer_size: {self.shuffle_buffer_size} \\n \\\n", "                self.batch_size: {self.batch_size} \\n \\\n", "                self.g_params: {self.g_params} \\n \\\n", "            \\n \")\n", "        n_iterations = 100\n\n", "        # if self.reached_max_steps:\n", "        #     return\n\n", "        # tensorboards\n", "        summary_writer = tf.summary.create_file_writer(\n", "            os.path.join(self.logs_dir, \"fit\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")))\n\n", "        # loss metrics\n", "        metric_g_loss = tf.keras.metrics.Mean('g_loss', dtype=tf.float32)\n", "        metric_d_loss = tf.keras.metrics.Mean('d_loss', dtype=tf.float32)\n", "        metric_r1_reg = tf.keras.metrics.Mean('r1_reg', dtype=tf.float32)\n", "        metric_pl_reg = tf.keras.metrics.Mean('pl_reg', dtype=tf.float32)\n\n", "        # start training\n", "        # print('max_steps: {}'.format(self.max_steps))\n", "        losses = {'g_loss': 0.0, 'd_loss': 0.0, 'r1_reg': 0.0, 'pl_reg': 0.0}\n", "        t_start = time.time()\n", "        self.dataset = onrecord.get_dataset(\n", "            self.tfrecord_dir,\n", "            self.out_res,\n", "            self.shuffle_buffer_size,\n", "            self.batch_size,\n", "            epochs=None\n", "        )\n", "        for real_images in self.dataset: # (4, 3, 256, 256)\n", "            z = tf.random.normal(shape=[tf.shape(real_images)[0], self.g_params['z_dim']], dtype=tf.dtypes.float32)\n", "            real_images = onmoono.preprocess_fit_train_image(real_images, self.out_res)\n", "            labels = tf.ones((tf.shape(real_images)[0], self.g_params['labels_dim']), dtype=tf.dtypes.float32)\n\n", "            # get current step\n", "            step = self.GMO.iterations.numpy()\n", "            print('.', end='')\n", "            if (step+1) % 100 == 0: \n", "                print(f\"|---> fit \\n {step}: {np.shape(self.dataset)} {type(self.dataset)} \\n \")\n", "            self.train_step(real_images)\n\n", "            # \tsave checkpoint\n", "            \n", "            if (step + 1) % n_iterations == 0:\n", "                print(f'|... saving (checkpoint) the model every \\\n", "                    {n_iterations} steps to {self.ckpt_prefix}')\n", "                self.ckpt.save(file_prefix = self.ckpt_prefix)\n", "                #self.manager.save(checkpoint_number=step)\t\t\t\t\n", "                print ('Time taken for step {} is {} sec\\n'.format(step + 1, time.time()-t_start))\n", "        self.ckpt.save(file_prefix = self.ckpt_prefix)\n", "        # self.manager.save(checkpoint_number=step)\n", "    def restore_checkpoint(self, max_to_keep=5):\n", "        print(f'|===> model.restore_checkpoint \\n \\\n", "            self.ckpt: {self.ckpt} \\n \\\n", "            self.ckpt_dir: {self.ckpt_dir} \\n \\\n", "            max_to_keep: {max_to_keep} \\n \\\n", "        ')\n", "        self.ckpt_manager = ckpt_manager = tf.train.CheckpointManager(\n", "            self.ckpt, \n", "            self.ckpt_dir, \n", "            max_to_keep=max_to_keep\n", "        )\n", "        # if a checkpoint exists, restore the latest checkpoint.\n", "        if ckpt_manager.latest_checkpoint:\n", "            self.ckpt.restore(ckpt_manager.latest_checkpoint)\n", "            print(f'\\n |...> model.restore_checkpoint checkpoint restored !!! \\n')\n", "        else:\n", "            print(f'|...> model.restore_checkpoint checkpoint not found')\n", "#\n", "#\n", "#   CMDS\n", "#\n", "#\n", "#\n", "#\n", "#   nntrain\n", "#\n", "def nntrain(args, kwargs):\n", "    # ERROR TF COMPILE\n", "    \n", "    args = onutil.pargs(vars(args))\n", "    args.PROJECT = 'rosalberto'\n", "    args.DATASET = 'spaceone'\n", "    xp = getxp(vars(args))\n", "    args = onutil.pargs(xp)\n", "    onutil.ddict(vars(args), 'args')\n", "    print(f\"|===> nntrain:  \\n \\\n", "        cwd: {os.getcwd()} \\n \\\n", "        AUTHOR: {args.AUTHOR} \\n \\\n", "        PROJECT: {args.PROJECT} \\n \\\n", "        proj_dir: {args.proj_dir} \\n \\\n", "        verbose: {args.verbose} \\n \\\n", "    \")\n", "    if 1: # config\n", "        args.clip = (256, 256)\n", "        args.qslices = 10\n", "        args.eps = 0.9\n", "        args.impl = 'cuda' # 'ref' if cuda is not available in your machine\n", "        args.gpu = True # False if tensorflow cpu is used   \t\t\n", "        args.weights_name = 'ffhq' # face model trained by Nvidia\n", "        args.shuffle_buffer_size = 10 # 1000 # _e_\n", "        args.latent_size = 512\n", "        args.train_res = 256   # real images _e_\n", "        args.im_size = 256\n", "        args.batch_size = 4 # 12, # 16\n", "        args.mixed_prob = 0.9\n", "        args.qsteps = 1001 # 1000001,   #   up to step\n", "    print(f'|===> nndata config:  \\n \\\n", "        args.clip: {args.clip} \\n \\\n", "        args.qslices: {args.qslices} \\n \\\n", "        args.eps: {args.eps} \\n \\\n", "        args.impl: {args.impl} \\n \\\n", "        args.gpu: {args.gpu} \\n \\\n", "        args.weights_name: {args.weights_name} \\n \\\n", "        \\n \\\n", "        args.train_res: {args.train_res} \\n \\\n", "        args.shuffle_buffer_size: {args.shuffle_buffer_size} \\n \\\n", "        args.latent_size: {args.latent_size} \\n \\\n", "        args.im_size: {args.im_size}\\n \\\n", "        args.batch_size: {args.batch_size}\\n \\\n", "        args.mixed_prob: {args.mixed_prob}\\n \\\n", "        args.qsteps: {args.qsteps}\\n \\\n", "    ')\n", "    if 1: # tree\n", "        args.model_base_dir = args.models_dir\n", "        args.tfrecord_dir = args.records_dir\n", "        args.proj_dir = os.path.join(args.proj_dir, 'code')\n\n", "        # args.tfrecord_dir = os.path.join(args.gdata, 'ffhq')\n", "        # args.tfrecord_dir = args.dataset_dir\n", "        args.results_dir = os.path.join(args.proto_dir, 'results')\n", "        args.ckpt_dir = args.ckpt_dir\n", "        args.ckpt_prefix = os.path.join(args.ckpt_dir, \"ckpt\")\n", "        os.makedirs(args.data_dir, exist_ok=True)    \n", "        os.makedirs(args.proj_dir, exist_ok=True)    \n", "        os.makedirs(args.dataset_dir, exist_ok=True)    \n", "        os.makedirs(args.tfrecord_dir, exist_ok=True)     \n", "        os.makedirs(args.results_dir, exist_ok=True)     \n", "        os.makedirs(args.ckpt_dir, exist_ok=True)     \n", "        weights_dir = os.path.join(args.proj_dir, 'weights')\n", "        weights_path = os.path.join(weights_dir, args.weights_name + '.npy')\n", "        os.makedirs(weights_dir, exist_ok=True)\n", "    print(f'|===> nntrain tree:  \\n \\\n", "        cwd: {os.getcwd()} \\n \\\n", "        args.proj_dir: {args.proj_dir} \\n \\\n", "        args.model_base_dir: {args.model_base_dir} \\n \\\n", "        args.tfrecord_dir: {args.tfrecord_dir} \\n \\\n", "        args.ckpt_dir: {args.ckpt_dir} \\n \\\n", "        args.ckpt_prefix: {args.ckpt_prefix} \\n \\\n", "        args.models_dir: {args.models_dir} \\n \\\n", "        args.dataorg_dir: {args.dataorg_dir} \\n \\\n", "        args.data_dir: {args.data_dir} \\n \\\n", "        args.dataset_dir: {args.dataset_dir} \\n \\\n", "    ')\n", "    if 1: # git\n", "        onutil.get_git(args.AUTHOR, args.GITPOD, args.proj_dir)\n", "    if 1: # org => data (formdata)\n", "        print(f'|====> nndata formed images \\n \\\n", "            from {args.dataorg_dir} into {args.data_dir} \\n \\\n", "            args.clip: {args.clip} \\n \\\n", "            qslices: {args.qslices} \\n \\\n", "            eps: {args.eps} \\n \\\n", "        ')\n", "        qinfiles = onfile.qfiles(args.dataorg_dir, ['*.jpg', '*.png'])\n", "        qinslices = qinfiles * args.qslices\n", "        qoutfiles = onfile.qfiles(args.data_dir, ['*.jpg', '*.png'])\n", "        if qinslices > qoutfiles:\n", "            if onutil.isempty(args.data_dir):\n", "                print(f\"args.data_dir {args.data_dir} not empty !!!\")\n", "            imgs = ondata.folder_to_formed_pils(args.dataorg_dir, \n", "                clip = args.clip, qslices = args.qslices, eps = args.eps)\n", "            onfile.pils_to_folder(imgs, args.data_dir)\n", "        else:\n", "            print(f'|... no org to data files')\n", "        print(f\"|... nndata formed images \\n \\\n", "            {onfile.qfiles(args.data_dir)} files in {args.data_dir} \\n \\\n", "        \")\n", "    if 1: # data => tfrecords\n", "        print(f\"|===> nndata generate tfrecords \\n \\\n", "            from {args.data_dir} into {args.tfrecord_dir} \\n \\\n", "        \")\n", "        if onutil.isempty(args.tfrecord_dir):\n", "            print(f\"args.tfrecord_dir {args.tfrecord_dir} not empty !!!\")\n", "        onrecord.folder_to_tfrecords(args.data_dir, args.tfrecord_dir)\n", "        print(f\"|===> nndata tfrecords \\n \\\n", "            {onfile.qfiles(args.tfrecord_dir)} files in {args.tfrecord_dir} \\n \\\n", "        \")  \n", "    if 1: # net params\n", "        train_res = args.train_res\n", "        train_resolutions, train_featuremaps = onmoono.filter_resolutions_featuremaps(resolutions, featuremaps, train_res)\n", "        g_params = {\n", "            'z_dim': 512,\n", "            'w_dim': 512,\n", "            'labels_dim': 0,\n", "            'n_mapping': 8,\n", "            'resolutions': train_resolutions,\n", "            'featuremaps': train_featuremaps,\n", "            'w_ema_decay': 0.995,\n", "            'style_mixing_prob': 0.9,\n", "        }\n", "        d_params = {\n", "            'labels_dim': 0,\n", "            'resolutions': train_resolutions,\n", "            'featuremaps': train_featuremaps,\n", "        }\n", "        vs = vars(args)\n", "        training_parameters = {\n", "            # global params\n", "            **vs,\n\n", "            # network params\n", "            'g_params': g_params,\n", "            'd_params': d_params,\n\n", "            # training params\n", "            'g_opt': {'learning_rate': 0.002, 'beta1': 0.0, 'beta2': 0.99, 'epsilon': 1e-08},\n", "            'd_opt': {'learning_rate': 0.002, 'beta1': 0.0, 'beta2': 0.99, 'epsilon': 1e-08},\n", "            'batch_size': vs['batch_size'],\n", "            'n_total_image': 25000000,\n", "            'n_samples': 4,\n", "        }\n\n", "        # print(f\"training_parameters {training_parameters}\")\n", "        onutil.ddict(training_parameters, \"training_parameters\")\n", "    if 1: # model\n", "        model = StyleGan2(        \n", "            resolution=args.train_res, \n", "            weights=None, \n", "            impl=args.impl, \n", "            gpu=args.gpu, \n", "            latent_size = args.latent_size,\n", "            im_size = args.im_size,\n", "            batch_size = args.batch_size, # 12, # 16\n", "            mixed_prob = args.mixed_prob,\n", "            qsteps = args.qsteps, # 1000001,   #   up to step\n", "            name = args.MNAME,\n", "            results_dir = args.results_dir,\n", "            models_dir = args.models_dir,\n", "            ckpt_dir = args.ckpt_dir,\n", "            ckpt_prefix = args.ckpt_prefix,\n", "            dataorg_dir = args.dataorg_dir,\n", "            logs_dir = args.logs_dir,\n", "            data_dir = args.data_dir,\n", "            dataset_dir = args.dataset_dir,\n", "            tfrecord_dir = args.tfrecord_dir,\n", "            training_parameters = training_parameters,\n", "        )\n", "    if 0: # fit\n\n", "        # trainer = Trainer(training_parameters, name='stylegan2-ffhq')\n", "        # trainer.train()    \n", "        model.fit()\n", "    if 0: # weights\n", "        if (not os.path.exists(args.weights_path)):\n", "            print(f\"could not find weights file {args.weights_path}\")\n", "            weights_id = weights[args.weights_name]\n\n", "            # output = weight_dir + name[i]\n", "            output = args.weights_path\n", "            url = f\"https://drive.google.com/uc?id={weights_id}\"\n", "            print(f\"gdown {url} to {output}\")\n", "            gdown.download(url, output, quiet=False) \n", "        else:\n", "            print(f\"weights file {weights_path} found\")\n", "    if 1: # generator\n", "        print(\"instantiate generator network\")\n", "        #generator = StyleGan2Generator(weights=args.weights_name, \n", "        #\timpl=args.impl, gpu=args.gpu)\n", "        generator = model.G\n", "        print(\"load w average\")\n", "        wavg_path = os.path.join(args.proj_dir, \"weights\", \n", "            f\"{args.weights_name}_dlatent_avg.npy\")\n", "        w_average = np.load(wavg_path)\n", "        print(\"generate and plot images not using truncation\")\n", "        onplot.generate_and_plot_images(generator, seed=96, w_avg=w_average)\n", "        print(\"generate and plot images using truncation 0.5\")\n", "        onplot.generate_and_plot_images(generator, seed=96, w_avg=w_average, truncation_psi=0.5)\n", "    if 1: # generate images \t- creating random latent vector\n", "        import tqdm \n", "        seed = 96\n", "        rnd = np.random.RandomState(seed)\n", "        z = rnd.randn(4, 512).astype('float32')\n\n", "        # running network\n", "        out = generator([z, None]) # _e_\n\n", "        #converting image to uint8\n", "        out_image = onrosa.convert_images_to_uint8(out, nchw_to_nhwc=True, uint8_cast=True)\n", "        onfile.generate_and_save_images(out_image.numpy(), outdir = args.results_dir)\n", "        n_images = 500\n", "        for i in tqdm(range(n_images)):\n", "            onfile.generate_and_save_images(out_image.numpy(), i, plot_fig=False, outdir = args.results_dir)\n", "            \n", "            #moving randomly in the latent space z\n", "            seed = i\n", "            rnd = np.random.RandomState(seed)\n", "            \n", "            #mofying slightly latent vector and generating new images\n", "            z += rnd.randn(4, 512).astype('float32') / 40\n", "            out = generator([z, None]) # _e_\n", "            out_image = onrosa.convert_images_to_uint8(out, nchw_to_nhwc=True, uint8_cast=True)\n", "    if 0: # save gif\n", "        anim_file = os.path.join(args.results_dir, 'ffhq_latent.gif')\n", "        with imageio.get_writer(anim_file, mode='I') as writer:\n", "            filenames = glob.glob(os.path.join(args.results_dir, 'image_at_iter*.png'))\n", "            filenames = sorted(filenames)\n", "            for i,filename in enumerate(filenames):\n", "                if i % 8 != 0:\n", "                    continue\n", "                image = imageio.imread(filename)\n", "                writer.append_data(image)\n", "            image = imageio.imread(filename)\n", "            writer.append_data(image)\n", "    if 0: # project\n", "        args.dataorg_dir=os.path.join(args.dataorg_dir, \"\")\n", "        args.dataset_dir=os.path.join(args.proj_dir, \"dataset\")   \n", "        args.models_dir=os.path.join(args.proj_dir, \"Models\")   \n", "        args.results_dir=os.path.join(args.proj_dir, \"Results\")   \n", "        args.ani_dir=os.path.join(args.proj_dir, \"ani\")   \n", "        os.makedirs(args.data_dir, exist_ok=True) # deduped formed\n", "        os.makedirs(args.dataset_dir, exist_ok=True) # npy folder\n", "        os.makedirs(args.models_dir, exist_ok=True)\n", "        os.makedirs(args.results_dir, exist_ok=True)\n", "        os.makedirs(args.tmp_dir, exist_ok=True) # name raws\n", "        os.makedirs(args.ani_dir, exist_ok=True) # anis\n", "        numSteps = 1000\n", "        initialLearningRate = 0.1\n", "        initialNoiseFactor = 0.05\n", "        verbose = False\n", "        tfrecord_dir = args.dataset_dir\n", "        out_res =  256\n", "        shuffle_buffer_size = 10\n", "        batch_size = 4\n", "        \n", "        print(f\"|===> nnproj\\n \\\n", "            args.proj_dir: {args.proj_dir} \\n \\\n", "            args.data_dir: {args.data_dir} \\n \\\n", "            args.dataset_dir: {args.dataset_dir} \\n \\\n", "            tfrecord_dir: {tfrecord_dir} \\n \\\n", "        \")\n", "        dataset = onmoono.get_dataset(\n", "            tfrecord_dir,\n", "            out_res,\n", "            shuffle_buffer_size,\n", "            batch_size,\n", "            epochs=None\n", "        )\n", "#\n", "#\n", "#\n", "#   MAIN\n", "#\n", "#\n", "def main():\n", "    parser = argparse.ArgumentParser(description='Run \"python %(prog)s <subcommand> --help\" for subcommand help.')\n", "    onutil.dodrive()\n", "    ap = getap()\n", "    for p in ap:\n", "        cls = type(ap[p])\n", "        parser.add_argument('--'+p, type=cls, default=ap[p])\n", "    cmds = [key for key in globals() if key.startswith(\"nn\")]\n", "    primecmd = ap[\"primecmd\"]\n", "        \n", "    # ---------------------------------------------------------------\n", "    #   add subparsers\n", "    #\n", "    subparsers = parser.add_subparsers(help='subcommands', dest='command') # command - subparser\n", "    for cmd in cmds:\n", "        subparser = subparsers.add_parser(cmd, help='cmd')  # add subcommands\n", "    \n", "    subparsers_actions = [action for action in parser._actions\n", "        if isinstance(action, argparse._SubParsersAction)] # retrieve subparsers from parser\n", "  \n", "    for subparsers_action in subparsers_actions:  # add common       \n", "        for choice, subparser in subparsers_action.choices.items(): # get all subparsers and print help\n", "            for p in {}:  # subcommand args dict\n", "                cls = type(ap[p])\n", "                subparser.add_argument('--'+p, type=cls, default=ap[p])\n\n", "    # get args to pass to nn cmds\n", "    if onutil.incolab():\n", "        args = parser.parse_args('') #  defaults as args\n", "    else:\n", "        args = parser.parse_args() #  parse_arguments()\n", "    kwargs = vars(args)\n", "    subcmd = kwargs.pop('command')      \n", "    if subcmd is None:\n", "        print (f\"Missing subcommand. set to default {primecmd}\")\n", "        subcmd = primecmd\n", "    \n", "    for name in cmds:\n", "        if (subcmd == name):\n", "            print(f'|===> call {name}')\n", "            globals()[name](args, kwargs) # pass args to nn cmd\n", "#\n", "#\n", "#\n", "# python base/base.py nninfo\n", "if __name__ == \"__main__\":\n", "    print(\"|===>\", __name__)\n", "    main()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}