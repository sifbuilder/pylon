{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# -*- coding: utf-8 -*-\n", "# \n", "# # Copyright (c) 2019, NVIDIA Corporation. All rights reserved.\n", "#\n", "import os\n", "import io\n", "from io import StringIO\n", "import time\n", "import argparse\n", "import functools\n", "import errno\n", "import scipy\n", "import scipy.io\n", "import requests\n", "import zipfile\n", "import random\n", "import datetime\n", "#\n", "from functools import partial\n", "from importlib import import_module\n", "#\n", "import logging\n", "logging.getLogger('tensorflow').setLevel(logging.ERROR)\n", "#\n", "import numpy as np\n", "from numpy import *\n", "#\n", "import math\n", "from math import floor, log2\n", "from random import random\n", "from pylab import *\n", "from IPython.core.display import display\n", "import PIL\n", "from PIL import Image\n", "PIL.Image.MAX_IMAGE_PIXELS = 933120000\n", "#\n", "import scipy.ndimage as pyimg\n", "import cv2\n", "import imageio\n", "import glob\n", "import matplotlib as mpl\n", "import matplotlib.pyplot as plt \n", "import matplotlib.image as mgimg\n", "import matplotlib.animation as anim\n", "mpl.rcParams['figure.figsize'] = (12,12)\n", "mpl.rcParams['axes.grid'] = False\n", "#\n", "import shutil\n", "import gdown\n", "#\n", "import sys\n", "#\n", "import tensorflow as tf \n", "from tensorflow.keras import initializers, regularizers, constraints\n", "from tensorflow.keras import backend as K\n", "from tensorflow.keras import layers\n", "from tensorflow.keras.layers import Layer, InputSpec\n", "from tensorflow.keras.layers import BatchNormalization, Activation, ZeroPadding2D, UpSampling2D, Conv2D\n", "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout, LeakyReLU\n", "from tensorflow.keras.models import Sequential, Model\n", "from tensorflow.keras.optimizers import Adam\n", "from tensorflow.python.keras.utils import conv_utils\n", "#\n", "from tensorflow.keras.layers import Lambda\n", "from tensorflow.keras.layers import add\n", "from tensorflow.keras.layers import AveragePooling2D\n", "from tensorflow.keras.initializers import VarianceScaling\n", "from tensorflow.keras.models import clone_model\n", "from tensorflow.keras.models import model_from_json\n", "#\n", "from absl import app\n", "from absl import flags\n", "from absl import logging\n", "#\n", "tf.get_logger().setLevel('ERROR')\n", "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n", "#\n", "print(f'|===> {tf.__version__}')\n", "#\n", "if 1: # get base.py from github\n", "    cwd = os.getcwd()\n", "    base_path = os.path.join(cwd, 'base.py')\n", "    if not os.path.exists(base_path):\n", "        base_file = 'base.py'\n", "        urlfolder = 'https://raw.githubusercontent.com/sifbuilder/pylon/master/'\n", "        url = f'{urlfolder}{base_file}'\n", "        print(f\"|===> nnimg: get base file \\n \\\n", "            urlfolder: {urlfolder} \\n \\\n", "            url: {url} \\n \\\n", "            base_path: {base_path} \\n \\\n", "        \")\n", "        tofile = tf.keras.utils.get_file(f'{base_path}', origin=url, extract=True)\n", "    else:\n", "        print(f\"|===> base in cwd {cwd}\")\n", "#\n", "#\n", "#   IMPS\n", "#\n", "#\n", "# check if base.Onpyon is defined\n", "try:\n", "    var = Onpyon()\n", "except NameError:\n", "    sys.path.append('../')  # if called from eon, modules are in parallel folder\n", "    sys.path.append('./')  #  if called from dnns, modules are in folder\n", "    from base import *\n", "#\n", "onutil = Onutil()\n", "onplot = Onplot()\n", "onformat = Onformat()\n", "onfile = Onfile()\n", "onvid = Onvid()\n", "onimg = Onimg()\n", "ondata = Ondata()\n", "onset = Onset()\n", "onrecord = Onrecord()\n", "ontree = Ontree()\n", "#\n", "onvgg = Onvgg()\n", "onlllyas = Onlllyas()\n", "oncuda = Oncuda()\n", "onrosa = Onrosa()\n", "onmoono = Onmoono()\n", "#\n", "ontf = Ontf()\n", "#\n", "#\n", "#   CONTEXT\n", "#\n", "#\n", "#\n", "def getap():\n", "    # https://github.com/moono/stylegan2-tf-2.x/tree/master/stylegan2\n", "    cp = {\n", "        \"primecmd\": 'nntrain',    \n", "                \n", "        \"MNAME\": \"moono\",      \n", "        \"AUTHOR\": \"moono\",      \n", "        \"PROJECT\": \"stylegan2\",      \n", "        \"GITPOD\": \"stylegan2-tf-2.x\",      \n", "        \"DATASET\": \"ffhq\",        \n", "    \n", "        \"GDRIVE\": 1,            # mount gdrive: gdata, gwork    \n", "        \"TRAINDO\": 1,      \n", "        \"MAKEGIF\": 1,      \n", "        \"RUNGIF\": 0,      \n", "        \"CLEARTMP\": 0,      \n", "        \"REGET\": 0,             # get again data \n", "        \"ING\": 1,               # ckpt in gwork\n", "        \"MODITEM\": \"\",          # will look into module\n", "        \"RESETCODE\": False,\n", "        \"LOCALDATA\": False,\n", "        \"LOCALMODELS\": False,\n", "        \"LOCALLAB\": True,\n", "        \"grel_infix\": '../..',            # relative path to content \n", "        \"net_prefix\": '//enas/hdrive',     \n", "        \"gdrive_prefix\": '/content/drive/My Drive',     \n", "        \"gcloud_prefix\": '/content',     \n", "    }\n", "    local_prefix = os.path.abspath('')\n", "    try:\n", "        local_prefix = os.path.dirname(os.path.realpath(__file__)) # script dir\n", "    except:\n", "        pass\n", "    cp[\"local_prefix\"] = local_prefix\n", "    hp = {\n", "        \"verbose\": False,\n", "        \"visual\": True,\n", "    }\n", "    ap = {}\n", "    for key in cp.keys():\n", "        ap[key] = cp[key]\n", "    for key in hp.keys():\n", "        ap[key] = hp[key]\n", "    return ap\n", "#\n", "def getxp(cp):\n", "    yp={}\n", "    xp={}\n", "    for key in cp.keys():\n", "        xp[key] = cp[key]\n", "    tree = ontree.tree(cp)\n", "    for key in tree.keys():\n", "        xp[key] = tree[key]\n", "    for key in yp.keys():\n", "        xp[key] = yp[key]\n", "   \n", "    return xp\n", "#\n", "#\n", "#   NETS\n", "#\n", "#\n", "class Dense(tf.keras.layers.Layer):\n", "    def __init__(self, fmaps, gain, lrmul, **kwargs):\n", "        super(Dense, self).__init__(**kwargs)\n", "        self.fmaps = fmaps\n", "        self.gain = gain\n", "        self.lrmul = lrmul\n", "    def build(self, input_shape):\n", "        assert len(input_shape) == 2 or len(input_shape) == 4\n", "        fan_in = np.prod(input_shape[1:])\n", "        weight_shape = [fan_in, self.fmaps]\n", "        init_std, runtime_coef = onmoono.compute_runtime_coef(weight_shape, self.gain, self.lrmul)\n", "        self.runtime_coef = runtime_coef\n", "        w_init = tf.random.normal(shape=weight_shape, mean=0.0, stddev=init_std)\n", "        self.w = tf.Variable(w_init, name='w', trainable=True)\n", "    def call(self, inputs, training=None, mask=None):\n", "        weight = self.runtime_coef * self.w\n", "        x = tf.keras.layers.Flatten()(inputs)\n", "        x = tf.matmul(x, weight)\n", "        return x\n", "    def get_config(self):\n", "        config = super(Dense, self).get_config()\n", "        config.update({\n", "            'fmaps': self.fmaps,\n", "            'gain': self.gain,\n", "            'lrmul': self.lrmul,\n", "        })\n", "        return config\n", "#\n", "class Bias(tf.keras.layers.Layer):\n", "    def __init__(self, lrmul, **kwargs):\n", "        super(Bias, self).__init__(**kwargs)\n", "        self.lrmul = lrmul\n", "    def build(self, input_shape):\n", "        assert len(input_shape) == 2 or len(input_shape) == 4\n", "        self.len2 = True if len(input_shape) == 2 else False\n", "        b_init = tf.zeros(shape=(input_shape[1],), dtype=tf.dtypes.float32)\n", "        self.b = tf.Variable(b_init, name='b', trainable=True)\n", "    def call(self, inputs, training=None, mask=None):\n", "        b = self.lrmul * self.b\n", "        if self.len2:\n", "            x = inputs + b\n", "        else:\n", "            x = inputs + tf.reshape(b, [1, -1, 1, 1])\n", "        return x\n", "    def get_config(self):\n", "        config = super(Bias, self).get_config()\n", "        config.update({\n", "            'lrmul': self.lrmul,\n", "        })\n", "        return config\n", "#\n", "class LeakyReLU(tf.keras.layers.Layer):\n", "    def __init__(self, **kwargs):\n", "        super(LeakyReLU, self).__init__(**kwargs)\n", "        self.alpha = 0.2\n", "        self.gain = np.sqrt(2)\n", "        self.act = tf.keras.layers.LeakyReLU(alpha=self.alpha)\n", "    def call(self, inputs, training=None, mask=None):\n", "        x = self.act(inputs)\n", "        x *= self.gain\n", "        return x\n", "    def get_config(self):\n", "        config = super(LeakyReLU, self).get_config()\n", "        config.update({\n", "            'alpha': self.alpha,\n", "            'gain': self.gain,\n", "        })\n", "        return config\n", "#\n", "class LabelEmbedding(tf.keras.layers.Layer):\n", "    def __init__(self, embed_dim, **kwargs):\n", "        super(LabelEmbedding, self).__init__(**kwargs)\n", "        self.embed_dim = embed_dim\n", "    def build(self, input_shape):\n", "        weight_shape = [input_shape[1], self.embed_dim]\n", "        # tf 1.15 mean(0.0), std(1.0) default value of tf.initializers.random_normal()\n", "        w_init = tf.random.normal(shape=weight_shape, mean=0.0, stddev=1.0)\n", "        self.w = tf.Variable(w_init, name='w', trainable=True)\n", "    def call(self, inputs, training=None, mask=None):\n", "        x = tf.matmul(inputs, self.w)\n", "        return x\n", "    def get_config(self):\n", "        config = super(LabelEmbedding, self).get_config()\n", "        config.update({\n", "            'embed_dim': self.embed_dim,\n", "        })\n", "        return config\n", "#\n", "class Noise(tf.keras.layers.Layer):\n", "    def __init__(self, **kwargs):\n", "        super(Noise, self).__init__(**kwargs)\n", "    def build(self, input_shape):\n", "        self.noise_strength = tf.Variable(initial_value=0.0, dtype=tf.dtypes.float32, trainable=True, name='w')\n", "    def call(self, x, training=None, mask=None):\n", "        x_shape = tf.shape(x)\n", "        noise = tf.random.normal(shape=(x_shape[0], 1, x_shape[2], x_shape[3]), dtype=tf.dtypes.float32)\n", "        x += noise * self.noise_strength\n", "        return x\n", "#\n", "class MinibatchStd(tf.keras.layers.Layer):\n", "    def __init__(self, group_size, num_new_features, **kwargs):\n", "        super(MinibatchStd, self).__init__(**kwargs)\n", "        self.group_size = group_size\n", "        self.num_new_features = num_new_features\n", "    def call(self, x, training=None, mask=None):\n", "        group_size = tf.minimum(self.group_size, tf.shape(x)[0])\n", "        s = tf.shape(x)\n", "        y = tf.reshape(x, [group_size, -1, self.num_new_features, s[1] // self.num_new_features, s[2], s[3]])\n", "        y = tf.cast(y, tf.float32)\n", "        y -= tf.reduce_mean(y, axis=0, keepdims=True)\n", "        y = tf.reduce_mean(tf.square(y), axis=0)\n", "        y = tf.sqrt(y + 1e-8)\n", "        y = tf.reduce_mean(y, axis=[2, 3, 4], keepdims=True)\n", "        y = tf.reduce_mean(y, axis=[2])\n", "        y = tf.cast(y, x.dtype)\n", "        y = tf.tile(y, [group_size, 1, s[2], s[3]])\n", "        return tf.concat([x, y], axis=1)\n", "#\n", "class FusedModConv(tf.keras.layers.Layer):\n", "    def __init__(self, fmaps, kernel, gain, lrmul, style_fmaps, demodulate, up, down, resample_kernel, **kwargs):\n", "        super(FusedModConv, self).__init__(**kwargs)\n", "        assert not (up and down)\n", "        self.fmaps = fmaps\n", "        self.kernel = kernel\n", "        self.gain = gain\n", "        self.lrmul = lrmul\n", "        self.style_fmaps = style_fmaps\n", "        self.demodulate = demodulate\n", "        self.up = up\n", "        self.down = down\n", "        self.factor = 2\n", "        if resample_kernel is None:\n", "            resample_kernel = [1] * self.factor\n", "        self.k = onmoono.setup_resample_kernel(k=resample_kernel)\n", "        self.mod_dense = Dense(self.style_fmaps, gain=1.0, lrmul=1.0, name='mod_dense')\n", "        self.mod_bias = Bias(lrmul=1.0, name='mod_bias')\n", "    def build(self, input_shape):\n", "        x_shape, w_shape = input_shape[0], input_shape[1]\n", "        weight_shape = [self.kernel, self.kernel, x_shape[1], self.fmaps]\n", "        init_std, runtime_coef = onmoono.compute_runtime_coef(weight_shape, self.gain, self.lrmul)\n", "        self.runtime_coef = runtime_coef\n\n", "        # [kkIO]\n", "        w_init = tf.random.normal(shape=weight_shape, mean=0.0, stddev=init_std)\n", "        self.w = tf.Variable(w_init, name='w', trainable=True)\n", "    def scale_conv_weights(self, w):\n", "        # convolution kernel weights for fused conv\n", "        weight = self.runtime_coef * self.w     # [kkIO]\n", "        weight = weight[np.newaxis]             # [BkkIO]\n\n", "        # modulation\n", "        style = self.mod_dense(w)                                   # [BI]\n", "        style = self.mod_bias(style) + 1.0                          # [BI]\n", "        weight *= style[:, np.newaxis, np.newaxis, :, np.newaxis]   # [BkkIO]\n\n", "        # demodulation\n", "        if self.demodulate:\n", "            d = tf.math.rsqrt(tf.reduce_sum(tf.square(weight), axis=[1, 2, 3]) + 1e-8)  # [BO]\n", "            weight *= d[:, np.newaxis, np.newaxis, np.newaxis, :]                       # [BkkIO]\n\n", "        # weight: reshape, prepare for fused operation\n", "        new_weight_shape = [tf.shape(weight)[1], tf.shape(weight)[2], tf.shape(weight)[3], -1]      # [kkI(BO)]\n", "        weight = tf.transpose(weight, [1, 2, 3, 0, 4])                                              # [kkIBO]\n", "        weight = tf.reshape(weight, shape=new_weight_shape)                                         # [kkI(BO)]\n", "        return weight\n", "    def call(self, inputs, training=None, mask=None):\n", "        x, w = inputs\n", "        height, width = tf.shape(x)[2], tf.shape(x)[3]\n\n", "        # prepare convolution kernel weights\n", "        weight = self.scale_conv_weights(w)\n\n", "        # prepare inputs: reshape minibatch to convolution groups\n", "        x = tf.reshape(x, [1, -1, height, width])\n", "        if self.up:\n", "            x = onmoono.upsample_conv_2d(x, self.k, weight, self.factor, self.gain)\n", "        elif self.down:\n", "            x = onmoono.conv_downsample_2d(x, self.k, weight, self.factor, self.gain)\n", "        else:\n", "            x = tf.nn.conv2d(x, weight, data_format='NCHW', strides=[1, 1, 1, 1], padding='SAME')\n\n", "        # x: reshape back\n", "        x = tf.reshape(x, [-1, self.fmaps, tf.shape(x)[2], tf.shape(x)[3]])\n", "        return x\n", "    def get_config(self):\n", "        config = super(FusedModConv, self).get_config()\n", "        config.update({\n", "            'fmaps': self.fmaps,\n", "            'kernel': self.kernel,\n", "            'gain': self.gain,\n", "            'lrmul': self.lrmul,\n", "            'style_fmaps': self.style_fmaps,\n", "            'demodulate': self.demodulate,\n", "            'up': self.up,\n", "            'down': self.down,\n", "            'factor': self.factor,\n", "            'k': self.k,\n", "        })\n", "        return config\n", "#\n", "class ResizeConv2D(tf.keras.layers.Layer):\n", "    def __init__(self, fmaps, kernel, gain, lrmul, up, down, resample_kernel, **kwargs):\n", "        super(ResizeConv2D, self).__init__(**kwargs)\n", "        self.fmaps = fmaps\n", "        self.kernel = kernel\n", "        self.gain = gain\n", "        self.lrmul = lrmul\n", "        self.up = up\n", "        self.down = down\n", "        self.factor = 2\n", "        if resample_kernel is None:\n", "            resample_kernel = [1] * self.factor\n", "        self.k = onmoono.setup_resample_kernel(k=resample_kernel)\n", "    def build(self, input_shape):\n", "        assert len(input_shape) == 4\n", "        weight_shape = [self.kernel, self.kernel, input_shape[1], self.fmaps]\n", "        init_std, runtime_coef = onmoono.compute_runtime_coef(weight_shape, self.gain, self.lrmul)\n", "        self.runtime_coef = runtime_coef\n\n", "        # [kernel, kernel, fmaps_in, fmaps_out]\n", "        w_init = tf.random_normal_initializer(mean=0.0, stddev=init_std)\n", "        self.w = tf.Variable(initial_value=w_init(shape=weight_shape, dtype='float32'), trainable=True, name='w')\n", "    def call(self, inputs, training=None, mask=None):\n", "        x = inputs\n", "        weight = self.runtime_coef * self.w\n", "        if self.up:\n", "            x = onmoono.upsample_conv_2d(x, self.k, weight, self.factor, self.gain)\n", "        elif self.down:\n", "            x = onmoono.conv_downsample_2d(x, self.k, weight, self.factor, self.gain)\n", "        else:\n", "            x = tf.nn.conv2d(x, weight, data_format='NCHW', strides=[1, 1, 1, 1], padding='SAME')\n", "        return x\n", "    def get_config(self):\n", "        config = super(ResizeConv2D, self).get_config()\n", "        config.update({\n", "            'fmaps': self.fmaps,\n", "            'kernel': self.kernel,\n", "            'gain': self.gain,\n", "            'lrmul': self.lrmul,\n", "            'up': self.up,\n", "            'down': self.down,\n", "            'factor': self.factor,\n", "            'k': self.k,\n", "        })\n", "        return config\n", "#\n", "#\n", "#   losses.py\n", "#    -> https://github.com/moono/stylegan2-tf-2.x/blob/master/losses.py <-\n", "#\n", "#\n", "#\n", "def g_logistic_non_saturating(generator, discriminator, z, labels):\n", "    # forward pass\n", "    fake_images = generator([z, labels], training=True)\n", "    fake_scores = discriminator([fake_images, labels], training=True)\n\n", "    # gan loss\n", "    g_loss = tf.math.softplus(-fake_scores)\n", "    # g_loss = tf.reduce_mean(g_loss)\n", "    return g_loss\n", "#\n", "def pl_reg(fake_images, w_broadcasted, pl_mean, pl_decay=0.01):\n", "    print(f'|--->  _e_ pl_reg')\n", "    h, w = fake_images.shape[2], fake_images.shape[3]\n\n", "    # Compute |J*y|.\n", "    with tf.GradientTape() as pl_tape:\n", "        pl_tape.watch(w_broadcasted)\n", "        pl_noise = tf.random.normal(tf.shape(fake_images), mean=0.0, stddev=1.0, dtype=tf.float32) / np.sqrt(h * w)\n", "    pl_grads = pl_tape.gradient(tf.reduce_sum(fake_images * pl_noise), w_broadcasted)\n", "    print(f'|--->  _e_ pl_reg pl_grads   {pl_grads}')\n", "    print(f'|--->   pl_reg pl_mean   {pl_mean}')\n", "    pl_lengths = tf.math.sqrt(tf.reduce_mean(tf.reduce_sum(tf.math.square(pl_grads), axis=2), axis=1))\n\n", "    # Track exponential moving average of |J*y|.\n", "    pl_mean_val = pl_mean + pl_decay * (tf.reduce_mean(pl_lengths) - pl_mean)\n", "    pl_mean.assign(pl_mean_val)\n\n", "    # Calculate (|J*y|-a)^2.\n", "    pl_penalty = tf.square(pl_lengths - pl_mean)\n", "    return pl_penalty\n", "#\n", "def d_logistic(generator, discriminator, z, labels, real_images):\n", "    # forward pass\n", "    fake_images = generator([z, labels], training=True)\n", "    real_scores = discriminator([real_images, labels], training=True)\n", "    fake_scores = discriminator([fake_images, labels], training=True)\n\n", "    # gan loss\n", "    d_loss = tf.math.softplus(fake_scores)\n", "    d_loss += tf.math.softplus(-real_scores)\n", "    return d_loss\n", "#\n", "def r1_reg(discriminator, labels, real_images):\n", "    # simple GP\n", "    with tf.GradientTape() as r1_tape:\n", "        r1_tape.watch(real_images)\n", "        real_loss = tf.reduce_sum(discriminator([real_images, labels], training=True))\n", "    real_grads = r1_tape.gradient(real_loss, real_images)\n", "    r1_penalty = tf.reduce_sum(tf.math.square(real_grads), axis=[1, 2, 3])\n", "    r1_penalty = tf.expand_dims(r1_penalty, axis=1)\n", "    return r1_penalty\n", "#\n", "#\n", "#\n", "#   losses.py (strategy)\n", "#\n", "def d_logistic(real_images, generator, discriminator, z_dim, labels_dim):\n", "    print(f'|---> d_logistic')\n", "    batch_size = tf.shape(real_images)[0]\n", "    z = tf.random.normal(shape=[batch_size, z_dim], dtype=tf.float32)\n", "    labels = tf.random.normal(shape=[batch_size, labels_dim], dtype=tf.float32)\n\n", "    # forward pass\n", "    fake_images = generator([z, labels], training=True)\n", "    real_scores = discriminator([real_images, labels], training=True)\n", "    fake_scores = discriminator([fake_images, labels], training=True)\n\n", "    # gan loss\n", "    d_loss = tf.math.softplus(fake_scores)\n", "    d_loss += tf.math.softplus(-real_scores)\n", "    return d_loss\n", "#\n", "#\n", "def d_logistic_r1_reg(real_images, generator, discriminator, z_dim, labels_dim):\n", "    print(f'|---> d_logistic_r1_reg')\n", "    batch_size = tf.shape(real_images)[0]\n", "    z = tf.random.normal(shape=[batch_size, z_dim], dtype=tf.float32)\n", "    labels = tf.random.normal(shape=[batch_size, labels_dim], dtype=tf.float32)\n\n", "    # forward pass\n", "    fake_images = generator([z, labels], training=True)\n", "    real_scores = discriminator([real_images, labels], training=True)\n", "    fake_scores = discriminator([fake_images, labels], training=True)\n\n", "    # gan loss\n", "    d_loss = tf.math.softplus(fake_scores)\n", "    d_loss += tf.math.softplus(-real_scores)\n\n", "    # gradient penalty\n", "    with tf.GradientTape() as r1_tape:\n", "        r1_tape.watch([real_images, labels])\n", "        real_loss = tf.reduce_sum(discriminator([real_images, labels], training=True))\n", "    real_grads = r1_tape.gradient(real_loss, real_images)\n", "    r1_penalty = tf.reduce_sum(tf.math.square(real_grads), axis=[1, 2, 3])\n", "    r1_penalty = tf.expand_dims(r1_penalty, axis=1)\n", "    return d_loss, r1_penalty\n", "#\n", "#\n", "def g_logistic_non_saturating(real_images, generator, discriminator, z_dim, labels_dim):\n", "    print(f'|---> g_logistic_non_saturating')\n", "    batch_size = tf.shape(real_images)[0]\n", "    z = tf.random.normal(shape=[batch_size, z_dim], dtype=tf.float32)\n", "    labels = tf.random.normal(shape=[batch_size, labels_dim], dtype=tf.float32)\n\n", "    # forward pass\n", "    fake_images = generator([z, labels], training=True)\n", "    fake_scores = discriminator([fake_images, labels], training=True)\n\n", "    # gan loss\n", "    g_loss = tf.math.softplus(-fake_scores)\n", "    return g_loss\n", "#\n", "#\n", "def g_logistic_ns_pathreg(real_images, generator, discriminator, z_dim, labels_dim,\n", "                          pl_mean, pl_minibatch_shrink, pl_denorm, pl_decay):\n", "    print(f'|---> g_logistic_ns_pathreg')\n", "    batch_size = tf.shape(real_images)[0]\n", "    print(f'|---> g_logistic_ns_pathreg batch_size {batch_size}')\n", "    print(f'|---> g_logistic_ns_pathreg z_dim {z_dim}')\n", "    print(f'|---> g_logistic_ns_pathreg labels_dim {labels_dim}')\n", "    z = tf.random.normal(shape=[batch_size, z_dim], dtype=tf.float32)\n", "    labels = tf.random.normal(shape=[batch_size, labels_dim], dtype=tf.float32)\n", "    pl_minibatch = tf.maximum(1, tf.math.floordiv(batch_size, pl_minibatch_shrink))\n", "    pl_z = tf.random.normal(shape=[pl_minibatch, z_dim], dtype=tf.float32)\n", "    pl_labels = tf.random.normal(shape=[pl_minibatch, labels_dim], dtype=tf.float32)\n\n", "    # forward pass\n", "    fake_images, w_broadcasted = generator([z, labels], ret_w_broadcasted=True, training=True)\n", "    fake_scores = discriminator([fake_images, labels], training=True)\n", "    g_loss = tf.math.softplus(-fake_scores)\n\n", "    # Evaluate the regularization term using a smaller minibatch to conserve memory.\n", "    with tf.GradientTape() as pl_tape:\n", "        pl_tape.watch([pl_z, pl_labels])\n", "        pl_fake_images, pl_w_broadcasted = generator([pl_z, pl_labels], ret_w_broadcasted=True, training=True)\n", "        pl_noise = tf.random.normal(tf.shape(pl_fake_images)) * pl_denorm\n", "        pl_noise_applied = tf.reduce_sum(pl_fake_images * pl_noise)\n", "    pl_grads = pl_tape.gradient(pl_noise_applied, pl_w_broadcasted)\n", "    #pl_lengths = tf.math.sqrt(tf.reduce_mean(tf.reduce_sum(tf.math.square(pl_grads), axis=2), axis=1))\n\n", "    # ***************************************************************************\n", "    pl_lengths = 0.0                                # _e_ ***********************\n", "    if pl_grads:\n", "        pl_lengths = tf.math.sqrt(tf.reduce_mean(tf.reduce_sum(tf.math.square(pl_grads), axis=2), axis=1))\n", "    # ***************************************************************************\n", "    print(f\"|...>  pl_lengths: {pl_lengths}\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    # Track exponential moving average of |J*y|.\n", "    pl_mean_val = pl_mean + pl_decay * (tf.reduce_mean(pl_lengths) - pl_mean)\n", "    pl_mean.assign(pl_mean_val)\n\n", "    # Calculate (|J*y|-a)^2.\n", "    pl_penalty = tf.square(pl_lengths - pl_mean)\n", "    return g_loss, pl_penalty\n", "#\n", "#\n", "#\n", "#\n", "#    -> https://github.com/moono/stylegan2-tf-2.x/tree/master/stylegan2/generator.py <-\n", "#\n", "#\n", "class ToRGB(tf.keras.layers.Layer):\n", "    def __init__(self, in_ch, **kwargs):\n", "        super(ToRGB, self).__init__(**kwargs)\n", "        self.in_ch = in_ch\n", "        self.conv = FusedModConv(fmaps=3, kernel=1, gain=1.0, lrmul=1.0, style_fmaps=self.in_ch,\n", "                                 demodulate=False, up=False, down=False, resample_kernel=None, name='conv')\n", "        self.apply_bias = Bias(lrmul=1.0, name='bias')\n", "    def call(self, inputs, training=None, mask=None):\n", "        x, w = inputs\n", "        assert x.shape[1] == self.in_ch\n", "        x = self.conv([x, w])\n", "        x = self.apply_bias(x)\n", "        return x\n", "    def get_config(self):\n", "        config = super(ToRGB, self).get_config()\n", "        config.update({\n", "            'in_ch': self.in_ch,\n", "        })\n", "        return config\n", "#\n", "class Mapping(tf.keras.layers.Layer):\n", "    def __init__(self, w_dim, labels_dim, n_mapping, **kwargs):\n", "        super(Mapping, self).__init__(**kwargs)\n", "        self.w_dim = w_dim\n", "        self.labels_dim = labels_dim\n", "        self.n_mapping = n_mapping\n", "        self.gain = 1.0\n", "        self.lrmul = 0.01\n", "        if self.labels_dim > 0:\n", "            self.labels_embedding = LabelEmbedding(embed_dim=self.w_dim, name='labels_embedding')\n", "        self.normalize = tf.keras.layers.Lambda(lambda x: x * tf.math.rsqrt(tf.reduce_mean(tf.square(x), axis=1, keepdims=True) + 1e-8))\n", "        self.dense_layers = list()\n", "        self.bias_layers = list()\n", "        self.act_layers = list()\n", "        for ii in range(self.n_mapping):\n", "            self.dense_layers.append(Dense(w_dim, gain=self.gain, lrmul=self.lrmul, name='dense_{:d}'.format(ii)))\n", "            self.bias_layers.append(Bias(lrmul=self.lrmul, name='bias_{:d}'.format(ii)))\n", "            self.act_layers.append(LeakyReLU(name='lrelu_{:d}'.format(ii)))\n", "    def call(self, inputs, training=None, mask=None):\n", "        latents, labels = inputs\n", "        x = latents\n\n", "        # embed label if any\n", "        if self.labels_dim > 0:\n", "            y = self.labels_embedding(labels)\n", "            x = tf.concat([x, y], axis=1)\n\n", "        # normalize inputs\n", "        x = self.normalize(x)\n\n", "        # apply mapping blocks\n", "        for dense, apply_bias, leaky_relu in zip(self.dense_layers, self.bias_layers, self.act_layers):\n", "            x = dense(x)\n", "            x = apply_bias(x)\n", "            x = leaky_relu(x)\n", "        return x\n", "    def get_config(self):\n", "        config = super(Mapping, self).get_config()\n", "        config.update({\n", "            'w_dim': self.w_dim,\n", "            'labels_dim': self.labels_dim,\n", "            'n_mapping': self.n_mapping,\n", "            'gain': self.gain,\n", "            'lrmul': self.lrmul,\n", "        })\n", "        return config\n", "#\n", "class SynthesisConstBlock(tf.keras.layers.Layer):\n", "    def __init__(self, fmaps, res, **kwargs):\n", "        super(SynthesisConstBlock, self).__init__(**kwargs)\n", "        assert res == 4\n", "        self.res = res\n", "        self.fmaps = fmaps\n", "        self.gain = 1.0\n", "        self.lrmul = 1.0\n\n", "        # conv block\n", "        self.conv = FusedModConv(fmaps=self.fmaps, kernel=3, gain=self.gain, lrmul=self.lrmul, style_fmaps=self.fmaps,\n", "                                 demodulate=True, up=False, down=False, resample_kernel=[1, 3, 3, 1], name='conv')\n", "        self.apply_noise = Noise(name='noise')\n", "        self.apply_bias = Bias(lrmul=self.lrmul, name='bias')\n", "        self.leaky_relu = LeakyReLU(name='lrelu')\n", "    def build(self, input_shape):\n", "        # starting const variable\n", "        # tf 1.15 mean(0.0), std(1.0) default value of tf.initializers.random_normal()\n", "        const_init = tf.random.normal(shape=(1, self.fmaps, self.res, self.res), mean=0.0, stddev=1.0)\n", "        self.const = tf.Variable(const_init, name='const', trainable=True)\n", "    def call(self, inputs, training=None, mask=None):\n", "        w0 = inputs\n", "        batch_size = tf.shape(w0)[0]\n\n", "        # const block\n", "        x = tf.tile(self.const, [batch_size, 1, 1, 1])\n\n", "        # conv block\n", "        x = self.conv([x, w0])\n", "        x = self.apply_noise(x)\n", "        x = self.apply_bias(x)\n", "        x = self.leaky_relu(x)\n", "        return x\n", "    def get_config(self):\n", "        config = super(SynthesisConstBlock, self).get_config()\n", "        config.update({\n", "            'res': self.res,\n", "            'fmaps': self.fmaps,\n", "            'gain': self.gain,\n", "            'lrmul': self.lrmul,\n", "        })\n", "        return config\n", "#\n", "class SynthesisBlock(tf.keras.layers.Layer):\n", "    def __init__(self, in_ch, fmaps, res, **kwargs):\n", "        super(SynthesisBlock, self).__init__(**kwargs)\n", "        self.in_ch = in_ch\n", "        self.fmaps = fmaps\n", "        self.res = res\n", "        self.gain = 1.0\n", "        self.lrmul = 1.0\n\n", "        # conv0 up\n", "        self.conv_0 = FusedModConv(fmaps=self.fmaps, kernel=3, gain=self.gain, lrmul=self.lrmul, style_fmaps=self.in_ch,\n", "                                   demodulate=True, up=True, down=False, resample_kernel=[1, 3, 3, 1], name='conv_0')\n", "        self.apply_noise_0 = Noise(name='noise_0')\n", "        self.apply_bias_0 = Bias(lrmul=self.lrmul, name='bias_0')\n", "        self.leaky_relu_0 = LeakyReLU(name='lrelu_0')\n\n", "        # conv block\n", "        self.conv_1 = FusedModConv(fmaps=self.fmaps, kernel=3, gain=self.gain, lrmul=self.lrmul, style_fmaps=self.fmaps,\n", "                                   demodulate=True, up=False, down=False, resample_kernel=[1, 3, 3, 1], name='conv_1')\n", "        self.apply_noise_1 = Noise(name='noise_1')\n", "        self.apply_bias_1 = Bias(lrmul=self.lrmul, name='bias_1')\n", "        self.leaky_relu_1 = LeakyReLU(name='lrelu_1')\n", "    def call(self, inputs, training=None, mask=None):\n", "        x, w0, w1 = inputs\n\n", "        # conv0 up\n", "        x = self.conv_0([x, w0])\n", "        x = self.apply_noise_0(x)\n", "        x = self.apply_bias_0(x)\n", "        x = self.leaky_relu_0(x)\n\n", "        # conv block\n", "        x = self.conv_1([x, w1])\n", "        x = self.apply_noise_1(x)\n", "        x = self.apply_bias_1(x)\n", "        x = self.leaky_relu_1(x)\n", "        return x\n", "    def get_config(self):\n", "        config = super(SynthesisBlock, self).get_config()\n", "        config.update({\n", "            'in_ch': self.in_ch,\n", "            'res': self.res,\n", "            'fmaps': self.fmaps,\n", "            'gain': self.gain,\n", "            'lrmul': self.lrmul,\n", "        })\n", "        return config\n", "#\n", "class Synthesis(tf.keras.layers.Layer):\n", "    def __init__(self, resolutions, featuremaps, name, **kwargs):\n", "        super(Synthesis, self).__init__(name=name, **kwargs)\n", "        self.resolutions = resolutions\n", "        self.featuremaps = featuremaps\n", "        self.k = onmoono.setup_resample_kernel(k=[1, 3, 3, 1])\n\n", "        # initial layer\n", "        res, n_f = resolutions[0], featuremaps[0]\n", "        self.initial_block = SynthesisConstBlock(fmaps=n_f, res=res, name='{:d}x{:d}/const'.format(res, res))\n", "        self.initial_torgb = ToRGB(in_ch=n_f, name='{:d}x{:d}/ToRGB'.format(res, res))\n\n", "        # stack generator block with lerp block\n", "        prev_n_f = n_f\n", "        self.blocks = list()\n", "        self.torgbs = list()\n", "        for res, n_f in zip(self.resolutions[1:], self.featuremaps[1:]):\n", "            self.blocks.append(SynthesisBlock(in_ch=prev_n_f, fmaps=n_f, res=res,\n", "                                              name='{:d}x{:d}/block'.format(res, res)))\n", "            self.torgbs.append(ToRGB(in_ch=n_f, name='{:d}x{:d}/ToRGB'.format(res, res)))\n", "            prev_n_f = n_f\n", "    def call(self, inputs, training=None, mask=None):\n", "        w_broadcasted = inputs\n\n", "        # initial layer\n", "        w0, w1 = w_broadcasted[:, 0], w_broadcasted[:, 1]\n", "        x = self.initial_block(w0)\n", "        y = self.initial_torgb([x, w1])\n", "        layer_index = 1\n", "        for block, torgb in zip(self.blocks, self.torgbs):\n", "            w0 = w_broadcasted[:, layer_index]\n", "            w1 = w_broadcasted[:, layer_index + 1]\n", "            w2 = w_broadcasted[:, layer_index + 2]\n", "            x = block([x, w0, w1])\n", "            y = onmoono.upsample_2d(y, self.k, factor=2, gain=1.0)\n", "            y = y + torgb([x, w2])\n", "            layer_index += 2\n", "        images_out = y\n", "        return images_out\n", "    def get_config(self):\n", "        config = super(Synthesis, self).get_config()\n", "        config.update({\n", "            'resolutions': self.resolutions,\n", "            'featuremaps': self.featuremaps,\n", "            'k': self.k,\n", "        })\n", "        return config\n", "#\n", "class Generator(tf.keras.Model):\n", "    def __init__(self, g_params, **kwargs):\n", "        super(Generator, self).__init__(**kwargs)\n", "        self.z_dim = g_params['z_dim']\n", "        self.w_dim = g_params['w_dim']\n", "        self.labels_dim = g_params['labels_dim']\n", "        self.n_mapping = g_params['n_mapping']\n", "        self.resolutions = g_params['resolutions']\n", "        self.featuremaps = g_params['featuremaps']\n", "        self.w_ema_decay = g_params['w_ema_decay']\n", "        self.style_mixing_prob = g_params['style_mixing_prob']\n", "        self.n_broadcast = len(self.resolutions) * 2\n", "        self.mixing_layer_indices = np.arange(self.n_broadcast)[np.newaxis, :, np.newaxis]\n", "        self.g_mapping = Mapping(self.w_dim, self.labels_dim, self.n_mapping, name='g_mapping')\n", "        self.broadcast = tf.keras.layers.Lambda(lambda x: tf.tile(x[:, np.newaxis], [1, self.n_broadcast, 1]))\n", "        self.synthesis = Synthesis(self.resolutions, self.featuremaps, name='g_synthesis')\n", "    def build(self, input_shape):\n", "        # w_avg\n", "        self.w_avg = tf.Variable(tf.zeros(shape=[self.w_dim], dtype=tf.dtypes.float32), name='w_avg', trainable=False)\n", "    def set_as_moving_average_of(self, src_net, beta=0.99, beta_nontrainable=0.0):\n", "        def split_first_name(name):\n", "            splitted = name.split('/')\n", "            new_name = '/'.join(splitted[1:])\n", "            return new_name\n", "        for cw in self.trainable_weights:\n", "            cw_name = split_first_name(cw.name)\n", "            for sw in src_net.trainable_weights:\n", "                sw_name = split_first_name(sw.name)\n", "                if cw_name == sw_name:\n", "                    assert sw.shape == cw.shape\n", "                    cw.assign(onmoono.lerp(sw, cw, beta))\n", "                    break\n", "        for cw in self.non_trainable_weights:\n", "            cw_name = split_first_name(cw.name)\n", "            for sw in src_net.non_trainable_weights:\n", "                sw_name = split_first_name(sw.name)\n", "                if cw_name == sw_name:\n", "                    assert sw.shape == cw.shape\n", "                    cw.assign(onmoono.lerp(sw, cw, beta_nontrainable))\n", "                    break\n", "        return\n", "    def update_moving_average_of_w(self, w_broadcasted):\n", "        # compute average of current w\n", "        batch_avg = tf.reduce_mean(w_broadcasted[:, 0], axis=0)\n\n", "        # compute moving average of w and update(assign) w_avg\n", "        self.w_avg.assign(onmoono.lerp(batch_avg, self.w_avg, self.w_ema_decay))\n", "        return\n", "    def style_mixing_regularization(self, latents1, labels, w_broadcasted1):\n", "        # get another w and broadcast it\n", "        latents2 = tf.random.normal(shape=tf.shape(latents1), dtype=tf.dtypes.float32)\n", "        dlatents2 = self.g_mapping([latents2, labels])\n", "        w_broadcasted2 = self.broadcast(dlatents2)\n\n", "        # find mixing limit index\n", "        if tf.random.uniform([], 0.0, 1.0) < self.style_mixing_prob:\n", "            mixing_cutoff_index = tf.random.uniform([], 1, self.n_broadcast, dtype=tf.dtypes.int32)\n", "        else:\n", "            mixing_cutoff_index = tf.constant(self.n_broadcast, dtype=tf.dtypes.int32)\n\n", "        # mix it\n", "        mixed_w_broadcasted = tf.where(\n", "            condition=tf.broadcast_to(self.mixing_layer_indices < mixing_cutoff_index, tf.shape(w_broadcasted1)),\n", "            x=w_broadcasted1,\n", "            y=w_broadcasted2)\n", "        return mixed_w_broadcasted\n", "    def truncation_trick(self, w_broadcasted, truncation_cutoff, truncation_psi):\n", "        ones = np.ones_like(self.mixing_layer_indices, dtype=np.float32)\n", "        if truncation_cutoff is None:\n", "            truncation_coefs = ones * truncation_psi\n", "        else:\n", "            truncation_coefs = ones\n", "            for index in range(self.n_broadcast):\n", "                if index < truncation_cutoff:\n", "                    truncation_coefs[:, index, :] = truncation_psi\n", "        truncated_w_broadcasted = onmoono.lerp(self.w_avg, w_broadcasted, truncation_coefs)\n", "        return truncated_w_broadcasted\n", "    @tf.function\n", "    def call(self, inputs, truncation_cutoff=None, truncation_psi=1.0, \n", "        ret_w_broadcasted=True, \n", "        training=None, mask=None):\n", "        latents, labels = inputs\n", "        dlatents = self.g_mapping([latents, labels])\n", "        w_broadcasted = self.broadcast(dlatents)\n", "        if training:\n", "            self.update_moving_average_of_w(w_broadcasted)\n", "            w_broadcasted = self.style_mixing_regularization(latents, labels, w_broadcasted)\n", "        if not training:\n", "            w_broadcasted = self.truncation_trick(w_broadcasted, truncation_cutoff, truncation_psi)\n", "        image_out = self.synthesis(w_broadcasted)\n", "        return image_out, w_broadcasted\n", "    def compute_output_shape(self, input_shape):\n", "        assert isinstance(input_shape, list)\n\n", "        # shape_latents, shape_labels = input_shape\n", "        return input_shape[0][0], 3, self.resolutions[-1], self.resolutions[-1]\n", "    @tf.function\n", "    def serve(self, latents, labels, truncation_psi):\n", "        dlatents = self.g_mapping([latents, labels])\n", "        w_broadcasted = self.broadcast(dlatents)\n", "        w_broadcasted = self.truncation_trick(w_broadcasted, truncation_cutoff=None, truncation_psi=truncation_psi)\n", "        image_out = self.synthesis(w_broadcasted)\n", "        image_out.set_shape([None, 3, self.resolutions[-1], self.resolutions[-1]])\n", "        return image_out\n", "#\n", "#\n", "#    -> https://github.com/moono/stylegan2-tf-2.x/tree/master/stylegan2/discriminator.py <-\n", "#\n", "#\n", "class FromRGB(tf.keras.layers.Layer):\n", "    def __init__(self, fmaps, **kwargs):\n", "        super(FromRGB, self).__init__(**kwargs)\n", "        self.fmaps = fmaps\n", "        self.conv = ResizeConv2D(fmaps=self.fmaps, kernel=1, gain=1.0, lrmul=1.0,\n", "                                 up=False, down=False, resample_kernel=None, name='conv')\n", "        self.apply_bias = Bias(lrmul=1.0, name='bias')\n", "        self.leaky_relu = LeakyReLU(name='lrelu')\n", "    def call(self, inputs, training=None, mask=None):\n", "        y = self.conv(inputs)\n", "        y = self.apply_bias(y)\n", "        y = self.leaky_relu(y)\n", "        return y\n", "#\n", "class DiscriminatorBlock(tf.keras.layers.Layer):\n", "    def __init__(self, n_f0, n_f1, res, **kwargs):\n", "        super(DiscriminatorBlock, self).__init__(**kwargs)\n", "        self.gain = 1.0\n", "        self.lrmul = 1.0\n", "        self.n_f0 = n_f0\n", "        self.n_f1 = n_f1\n", "        self.res = res\n", "        self.resnet_scale = 1. / np.sqrt(2.)\n\n", "        # conv_0\n", "        self.conv_0 = ResizeConv2D(fmaps=self.n_f0, kernel=3, gain=self.gain, lrmul=self.lrmul,\n", "                                   up=False, down=False, resample_kernel=None, name='conv_0')\n", "        self.apply_bias_0 = Bias(self.lrmul, name='bias_0')\n", "        self.leaky_relu_0 = LeakyReLU(name='lrelu_0')\n\n", "        # conv_1 down\n", "        self.conv_1 = ResizeConv2D(fmaps=self.n_f1, kernel=3, gain=self.gain, lrmul=self.lrmul,\n", "                                   up=False, down=True, resample_kernel=[1, 3, 3, 1], name='conv_1')\n", "        self.apply_bias_1 = Bias(self.lrmul, name='bias_1')\n", "        self.leaky_relu_1 = LeakyReLU(name='lrelu_1')\n\n", "        # resnet skip\n", "        self.conv_skip = ResizeConv2D(fmaps=self.n_f1, kernel=1, gain=self.gain, lrmul=self.lrmul,\n", "                                      up=False, down=True, resample_kernel=[1, 3, 3, 1], name='skip')\n", "    def call(self, inputs, training=None, mask=None):\n", "        x = inputs\n", "        residual = x\n\n", "        # conv0\n", "        x = self.conv_0(x)\n", "        x = self.apply_bias_0(x)\n", "        x = self.leaky_relu_0(x)\n\n", "        # conv1 down\n", "        x = self.conv_1(x)\n", "        x = self.apply_bias_1(x)\n", "        x = self.leaky_relu_1(x)\n\n", "        # resnet skip\n", "        residual = self.conv_skip(residual)\n", "        x = (x + residual) * self.resnet_scale\n", "        return x\n", "#\n", "class DiscriminatorLastBlock(tf.keras.layers.Layer):\n", "    def __init__(self, n_f0, n_f1, res, **kwargs):\n", "        super(DiscriminatorLastBlock, self).__init__(**kwargs)\n", "        self.gain = 1.0\n", "        self.lrmul = 1.0\n", "        self.n_f0 = n_f0\n", "        self.n_f1 = n_f1\n", "        self.res = res\n", "        self.minibatch_std = MinibatchStd(group_size=4, num_new_features=1, name='minibatchstd')\n\n", "        # conv_0\n", "        self.conv_0 = ResizeConv2D(fmaps=self.n_f0, kernel=3, gain=self.gain, lrmul=self.lrmul,\n", "                                   up=False, down=False, resample_kernel=None, name='conv_0')\n", "        self.apply_bias_0 = Bias(self.lrmul, name='bias_0')\n", "        self.leaky_relu_0 = LeakyReLU(name='lrelu_0')\n\n", "        # dense_1\n", "        self.dense_1 = Dense(self.n_f1, gain=self.gain, lrmul=self.lrmul, name='dense_1')\n", "        self.apply_bias_1 = Bias(self.lrmul, name='bias_1')\n", "        self.leaky_relu_1 = LeakyReLU(name='lrelu_1')\n", "    def call(self, x, training=None, mask=None):\n", "        x = self.minibatch_std(x)\n\n", "        # conv_0\n", "        x = self.conv_0(x)\n", "        x = self.apply_bias_0(x)\n", "        x = self.leaky_relu_0(x)\n\n", "        # dense_1\n", "        x = self.dense_1(x)\n", "        x = self.apply_bias_1(x)\n", "        x = self.leaky_relu_1(x)\n", "        return x\n", "#\n", "class Discriminator(tf.keras.Model):\n", "    def __init__(self, d_params, **kwargs):\n", "        super(Discriminator, self).__init__(**kwargs)\n", "        # discriminator's (resolutions and featuremaps) are reversed against generator's\n", "        self.labels_dim = d_params['labels_dim']\n", "        self.r_resolutions = d_params['resolutions'][::-1]\n", "        self.r_featuremaps = d_params['featuremaps'][::-1]\n\n", "        # stack discriminator blocks\n", "        res0, n_f0 = self.r_resolutions[0], self.r_featuremaps[0]\n", "        self.initial_fromrgb = FromRGB(fmaps=n_f0, name='{:d}x{:d}/FromRGB'.format(res0, res0))\n", "        self.blocks = list()\n", "        for index, (res0, n_f0) in enumerate(zip(self.r_resolutions[:-1], self.r_featuremaps[:-1])):\n", "            n_f1 = self.r_featuremaps[index + 1]\n", "            self.blocks.append(DiscriminatorBlock(n_f0=n_f0, n_f1=n_f1, res=res0, name='{:d}x{:d}'.format(res0, res0)))\n\n", "        # set last discriminator block\n", "        res = self.r_resolutions[-1]\n", "        n_f0, n_f1 = self.r_featuremaps[-2], self.r_featuremaps[-1]\n", "        self.last_block = DiscriminatorLastBlock(n_f0, n_f1, res, name='{:d}x{:d}'.format(res, res))\n\n", "        # set last dense layer\n", "        self.last_dense = Dense(max(self.labels_dim, 1), gain=1.0, lrmul=1.0, name='last_dense')\n", "        self.last_bias = Bias(lrmul=1.0, name='last_bias')\n", "    def call(self, inputs, training=None, mask=None):\n", "        images, labels = inputs\n", "        x = self.initial_fromrgb(images)\n", "        for block in self.blocks:\n", "            x = block(x)\n", "        x = self.last_block(x)\n", "        x = self.last_dense(x)\n", "        x = self.last_bias(x)\n", "        if self.labels_dim > 0:\n", "            x = tf.reduce_sum(x * labels, axis=1, keepdims=True)\n", "        scores_out = x\n", "        return scores_out\n", "#\n", "#\n", "#    -> https://github.com/moono/stylegan2-tf-2.x/tree/master/stylegan2/train_advanced.py <-\n", "#\n", "#\n", "class StyleGAN2(object):\n", "    def __init__(self, t_params, name):\n", "        # _e_\n", "        self.cur_tf_ver = t_params['cur_tf_ver']\n", "        self.use_tf_function = t_params['use_tf_function']\n", "        self.use_custom_cuda = t_params['use_custom_cuda']\n", "        self.model_base_dir = t_params['model_base_dir']\n", "        self.tfrecord_dir = t_params['tfrecord_dir']\n", "        self.shuffle_buffer_size = t_params['shuffle_buffer_size']\n", "        self.g_params = t_params['g_params']\n", "        self.d_params = t_params['d_params']\n", "        self.g_opt = t_params['g_opt']\n", "        self.d_opt = t_params['d_opt']\n", "        self.batch_size = t_params['batch_size']\n", "        self.n_total_image = t_params['n_total_image']\n", "        self.n_samples = min(t_params['batch_size'], t_params['n_samples'])\n", "        self.lazy_regularization = t_params['lazy_regularization']\n", "        self.global_batch_size = t_params['batch_size']\n", "        self.global_batch_scaler = 1.0 / float(self.global_batch_size)\n", "        self.r1_gamma = 10.0\n", "        # self.r2_gamma = 0.0\n", "        self.max_steps = int(np.ceil(self.n_total_image / self.batch_size))\n", "        self.out_res = self.g_params['resolutions'][-1]\n", "        self.log_template = 'step {}: elapsed: {:.2f}s, d_loss: {:.3f}, g_loss: {:.3f}, r1_reg: {:.3f}, pl_reg: {:.3f}'\n", "        self.print_step = 10\n", "        self.save_step = 100\n", "        self.image_summary_step = 100\n", "        self.reached_max_steps = False\n\n", "        # setup optimizer params\n", "        self.g_opt = self.set_optimizer_params(self.g_opt)\n", "        self.d_opt = self.set_optimizer_params(self.d_opt)\n", "        self.pl_mean = tf.Variable(initial_value=0.0, name='pl_mean', trainable=False)\n", "        self.pl_decay = 0.01\n", "        self.pl_weight = 1.0\n", "        self.pl_denorm = 1.0 / np.sqrt(self.out_res * self.out_res)\n\n", "        # Trainer\n", "        self.pl_minibatch_shrink = 2\n", "        self.pl_weight = float(self.pl_minibatch_shrink)\n\n", "        ## grab dataset\n", "        #print('|...> StyleGAN2 Trainer setting datasets')\n", "        #self.dataset = folder_to_dataset(\n", "        #        self.tfrecord_dir, \n", "        #        self.out_res, \n", "        #        self.shuffle_buffer_size,\n", "        #        self.batch_size, \n", "        #        epochs=None)\n\n", "        # create models\n", "        print('|...> StyleGAN2 Trainer  Create models')\n", "        #self.generator = Generator(self.g_params)\n", "        #self.discriminator = Discriminator(self.d_params)\n", "        #self.g_clone = Generator(self.g_params)\n\n", "        # create model: model and optimizer must be created under `strategy.scope`\n", "        #self.discriminator, self.generator, self.g_clone = initiate_models(self.g_params,\n", "        #                                                                   self.d_params,\n", "        #                                                                   self.use_custom_cuda)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        self.discriminator = load_discriminator(self.d_params, ckpt_dir=None, custom_cuda=self.use_custom_cuda)\n", "        self.generator = load_generator(g_params=self.g_params, is_g_clone=False, ckpt_dir=None, custom_cuda=self.use_custom_cuda)\n", "        self.g_clone = load_generator(g_params=self.g_params, is_g_clone=True, ckpt_dir=None, custom_cuda=self.use_custom_cuda)\n\n", "        # set initial g_clone weights same as generator\n", "        self.g_clone.set_weights(self.generator.get_weights())"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        self.d_optimizer = tf.keras.optimizers.Adam(self.d_opt['learning_rate'],\n", "                                                    beta_1=self.d_opt['beta1'],\n", "                                                    beta_2=self.d_opt['beta2'],\n", "                                                    epsilon=self.d_opt['epsilon'])\n", "        self.g_optimizer = tf.keras.optimizers.Adam(self.g_opt['learning_rate'],\n", "                                                    beta_1=self.g_opt['beta1'],\n", "                                                    beta_2=self.g_opt['beta2'],\n", "                                                    epsilon=self.g_opt['epsilon'])\n\n", "        # finalize model (build)\n", "        test_latent = np.ones((1, self.g_params['z_dim']), dtype=np.float32)\n", "        test_labels = np.ones((1, self.g_params['labels_dim']), dtype=np.float32)\n", "        test_images = np.ones((1, 3, self.out_res, self.out_res), dtype=np.float32)\n", "        _, __ = self.generator([test_latent, test_labels], training=False)\n", "        _ = self.discriminator([test_images, test_labels], training=False)\n", "        _, __ = self.g_clone([test_latent, test_labels], training=False)\n", "        print(f'|...> StyleGAN2 Copying g_clone')\n", "        self.g_clone.set_weights(self.generator.get_weights())\n\n", "        # setup saving locations (object based savings)\n", "        self.ckpt_dir = os.path.join(self.model_base_dir, name)\n", "        self.ckpt = tf.train.Checkpoint(d_optimizer=self.d_optimizer,\n", "                                        g_optimizer=self.g_optimizer,\n", "                                        discriminator=self.discriminator,\n", "                                        generator=self.generator,\n", "                                        g_clone=self.g_clone)\n", "        self.manager = tf.train.CheckpointManager(self.ckpt, self.ckpt_dir, max_to_keep=2)\n\n", "        # try to restore\n", "        self.ckpt.restore(self.manager.latest_checkpoint)\n", "        if self.manager.latest_checkpoint:\n", "            print(f'|...> StyleGAN2 Restored from {self.manager.latest_checkpoint}')\n\n", "            # check if already trained in this resolution\n", "            restored_step = self.g_optimizer.iterations.numpy()\n", "            if restored_step >= self.max_steps:\n", "                print('Already reached max steps {}/{}'.format(restored_step, self.max_steps))\n", "                self.reached_max_steps = True\n", "                return\n", "        else:\n", "            print(f'|...> StyleGAN2 Not restoring checkpoint')\n", "    def set_optimizer_params(self, params):\n", "        if self.lazy_regularization:\n", "            mb_ratio = params['reg_interval'] / (params['reg_interval'] + 1)\n", "            params['learning_rate'] = params['learning_rate'] * mb_ratio\n", "            params['beta1'] = params['beta1'] ** mb_ratio\n", "            params['beta2'] = params['beta2'] ** mb_ratio\n", "        return params\n", "    @staticmethod\n", "    def update_optimizer_params(params):\n", "        params_copy = params.copy()\n", "        mb_ratio = params_copy['reg_interval'] / (params_copy['reg_interval'] + 1)\n", "        params_copy['learning_rate'] = params_copy['learning_rate'] * mb_ratio\n", "        params_copy['beta1'] = params_copy['beta1'] ** mb_ratio\n", "        params_copy['beta2'] = params_copy['beta2'] ** mb_ratio\n", "        return params_copy\n", "    @tf.function\n", "    def d_train_step(self, z, real_images, labels):\n", "        with tf.GradientTape() as d_tape:\n", "            # forward pass\n", "            fake_images, _ = self.generator([z, labels], training=True)\n", "            real_scores = self.discriminator([real_images, labels], training=True)\n", "            fake_scores = self.discriminator([fake_images, labels], training=True)\n\n", "            # gan loss\n", "            d_loss = tf.math.softplus(fake_scores)\n", "            d_loss += tf.math.softplus(-real_scores)\n", "            d_loss = tf.reduce_mean(d_loss)\n", "        d_gradients = d_tape.gradient(d_loss, self.discriminator.trainable_variables)\n", "        self.d_optimizer.apply_gradients(zip(d_gradients, self.discriminator.trainable_variables))\n", "        return d_loss\n", "    @tf.function\n", "    def d_reg_train_step(self, z, real_images, labels):\n", "        with tf.GradientTape() as d_tape:\n", "            # forward pass\n", "            fake_images, _ = self.generator([z, labels], training=True)\n", "            real_scores = self.discriminator([real_images, labels], training=True)\n", "            fake_scores = self.discriminator([fake_images, labels], training=True)\n\n", "            # gan loss\n", "            d_loss = tf.math.softplus(fake_scores)\n", "            d_loss += tf.math.softplus(-real_scores)\n\n", "            # simple GP\n", "            with tf.GradientTape() as p_tape:\n", "                p_tape.watch(real_images)\n", "                real_loss = tf.reduce_sum(self.discriminator([real_images, labels], training=True))\n", "            real_grads = p_tape.gradient(real_loss, real_images)\n", "            r1_penalty = tf.reduce_sum(tf.math.square(real_grads), axis=[1, 2, 3])\n", "            r1_penalty = tf.expand_dims(r1_penalty, axis=1)\n", "            r1_penalty = r1_penalty * self.d_opt['reg_interval']\n\n", "            # combine\n", "            d_loss += r1_penalty * (0.5 * self.r1_gamma)\n", "            d_loss = tf.reduce_mean(d_loss)\n", "        d_gradients = d_tape.gradient(d_loss, self.discriminator.trainable_variables)\n", "        self.d_optimizer.apply_gradients(zip(d_gradients, self.discriminator.trainable_variables))\n", "        return d_loss, tf.reduce_mean(r1_penalty)\n", "    @tf.function\n", "    def g_train_step(self, z, labels):\n", "        with tf.GradientTape() as g_tape:\n", "            # forward pass\n", "            fake_images, _ = self.generator([z, labels], training=True)\n", "            fake_scores = self.discriminator([fake_images, labels], training=True)\n\n", "            # gan loss\n", "            g_loss = tf.math.softplus(-fake_scores)\n", "            g_loss = tf.reduce_mean(g_loss)\n", "        g_gradients = g_tape.gradient(g_loss, self.generator.trainable_variables)\n", "        self.g_optimizer.apply_gradients(zip(g_gradients, self.generator.trainable_variables))\n", "        return g_loss\n", "    def g_reg_pl(self, z, labels):    # _e_\n\n", "        ## path length regularization\n", "        ## Compute |J*y|\n", "        with tf.GradientTape() as pl_tape:\n", "            pl_tape.watch([z, labels])\n", "            pl_fake_images, pl_w_broadcasted = self.generator([z, labels], training=True)\n", "            pl_noise = tf.random.normal(tf.shape(pl_fake_images), mean=0.0, stddev=1.0, dtype=tf.float32) * self.pl_denorm\n", "            pl_noise_added = tf.reduce_sum(pl_fake_images * pl_noise)\n\n", "            ##  pl_noise_added:  tf.Tensor(2.973158, shape=(), dtype=float32)\n", "            ##  pl_w_broadcasted:   tf.Tensor([[[-0.25851128  0.28737155  1.8203238  ... -0.5302262  -0.00633283\n", "        pl_grads = pl_tape.gradient(pl_noise_added, pl_w_broadcasted) # None\n", "        print(f\"\\n|****> g_reg_pl pl_grads: {pl_grads} \\n\")\n", "        return pl_grads\n\n", "    # _e_\n", "    def g_reg_train_step(self, dist_inputs):\n", "        real_images = dist_inputs\n", "        with tf.GradientTape() as g_tape:\n", "            # compute losses\n", "            g_gan_loss, pl_penalty = g_logistic_ns_pathreg(real_images, self.generator, self.discriminator,\n", "                                                           self.g_params['z_dim'], self.g_params['labels_dim'],\n", "                                                           self.pl_mean, self.pl_minibatch_shrink, self.pl_denorm,\n", "                                                           self.pl_decay)\n", "            pl_penalty = pl_penalty * self.pl_weight * self.g_opt['reg_interval']\n\n", "            # scale loss\n", "            pl_penalty = tf.reduce_sum(pl_penalty) * self.global_batch_scaler\n", "            g_gan_loss = tf.reduce_sum(g_gan_loss) * self.global_batch_scaler\n\n", "            # combine\n", "            g_loss = g_gan_loss + pl_penalty\n", "        g_gradients = g_tape.gradient(g_loss, self.generator.trainable_variables)\n", "        self.g_optimizer.apply_gradients(zip(g_gradients, self.generator.trainable_variables))\n", "        return g_loss, g_gan_loss, pl_penalty\n\n", "    # @tf.function\n", "    def __g_reg_train_step(self, z, labels):\n", "        print(f'|...>       g_reg_train_step z   {np.shape(z)}')\n", "        print(f'|...>       g_reg_train_step labels   {np.shape(labels)}')\n", "        print(f'|...>       g_reg_train_step self.pl_mean   {self.pl_mean}')\n", "        with tf.GradientTape() as g_tape:\n", "            # forward pass\n", "            fake_images, w_broadcasted = self.generator([z, labels], training=True)\n", "            fake_scores = self.discriminator([fake_images, labels], training=True)\n\n", "            # gan loss\n", "            g_loss = tf.math.softplus(-fake_scores)\n", "            pl_grads = self.g_reg_pl(z, labels)\n", "            print(f\"|...>  pl_grads: {pl_grads}\")\n\n", "            # ***************************************************************************\n", "            pl_lengths = 0.0                                # _e_ ***********************\n", "            if pl_grads:\n", "                pl_lengths = tf.math.sqrt(tf.reduce_mean(tf.reduce_sum(tf.math.square(pl_grads), axis=2), axis=1))\n", "            # ***************************************************************************\n", "            print(f\"|...>  pl_lengths: {pl_lengths}\")\n\n", "            # Track exponential moving average of |J*y|.\n", "            pl_mean_val = self.pl_mean + self.pl_decay * (tf.reduce_mean(pl_lengths) - self.pl_mean)\n", "            print(f\"|...>  pl_mean_val: {pl_mean_val}\")\n", "            self.pl_mean.assign(pl_mean_val)\n\n", "            # Calculate (|J*y|-a)^2.\n", "            pl_penalty = tf.square(pl_lengths - self.pl_mean)\n", "            print(f\"|...>  pl_penalty: {pl_penalty}\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["            # compute\n", "            _pl_reg = pl_penalty * self.pl_weight\n", "            print(f\"|...>  _pl_reg: {_pl_reg}\")\n\n", "            # combine\n", "            g_loss += _pl_reg\n", "            g_loss = tf.reduce_mean(g_loss)\n", "        g_gradients = g_tape.gradient(g_loss, self.generator.trainable_variables)\n", "        self.g_optimizer.apply_gradients(zip(g_gradients, self.generator.trainable_variables))\n", "        div = tf.reduce_mean(_pl_reg)\n", "        print(f\"|...>  g_loss: {g_loss}\")\n", "        print(f\"|...>  div: {div}\")\n", "        return g_loss, div\n", "    def train(self, dataset, strategy=None):\n", "        if self.reached_max_steps:\n", "            return\n\n", "        # start actual training\n", "        print(f'|---> train up to {self.max_steps} steps')\n\n", "        # setup tensorboards\n", "        train_summary_writer = tf.summary.create_file_writer(self.ckpt_dir)\n\n", "        # loss metrics\n", "        metric_g_loss = tf.keras.metrics.Mean('g_loss', dtype=tf.float32)\n", "        metric_d_loss = tf.keras.metrics.Mean('d_loss', dtype=tf.float32)\n", "        metric_r1_reg = tf.keras.metrics.Mean('r1_reg', dtype=tf.float32)\n", "        metric_pl_reg = tf.keras.metrics.Mean('pl_reg', dtype=tf.float32)\n\n", "        # start training\n", "        losses = {'g_loss': 0.0, 'd_loss': 0.0, 'r1_reg': 0.0, 'pl_reg': 0.0}\n", "        t_start = time.time()\n", "        for real_images in dataset:\n", "            # preprocess inputs\n", "            z = tf.random.normal(shape=[tf.shape(real_images)[0], self.g_params['z_dim']], dtype=tf.dtypes.float32)\n", "            real_images = onmoono.preprocess_fit_train_image(real_images, self.out_res)\n", "            labels = tf.ones((tf.shape(real_images)[0], self.g_params['labels_dim']), dtype=tf.dtypes.float32)\n\n", "            # get current step\n", "            step = self.g_optimizer.iterations.numpy()\n\n", "            # d train step\n", "            if step % self.d_opt['reg_interval'] == 0:\n", "                d_loss, r1_reg = self.d_reg_train_step(z, real_images, labels)\n", "                # update values for printing\n", "                losses['d_loss'] = d_loss.numpy()\n", "                losses['r1_reg'] = r1_reg.numpy()\n", "                # update metrics\n", "                metric_d_loss(d_loss)\n", "                metric_r1_reg(r1_reg)\n", "            else:\n", "                d_loss = self.d_train_step(z, real_images, labels)\n", "                # update values for printing\n", "                losses['d_loss'] = d_loss.numpy()\n", "                losses['r1_reg'] = 0.0\n", "                # update metrics\n", "                metric_d_loss(d_loss)\n\n", "            # update g_clone\n", "            self.g_clone.set_as_moving_average_of(self.generator)\n", "         \n", "            # g train step\n", "            if step % self.g_opt['reg_interval'] == 0:\n", "                # _e_\n", "                #g_loss, pl_reg = self.g_reg_train_step(z, labels)\n", "                # g_loss, g_gan_loss, pl_penalty\n", "                g_loss, pl_reg, pl_penalty = self.g_reg_train_step(real_images)\n", "                # update values for printing\n", "                losses['g_loss'] = g_loss.numpy()\n", "                losses['pl_reg'] = pl_reg.numpy()\n", "                # update metrics\n", "                metric_g_loss(g_loss)\n", "                metric_pl_reg(pl_reg)\n", "            else:\n", "                g_loss = self.g_train_step(z, labels)\n", "                # update values for printing\n", "                losses['g_loss'] = g_loss.numpy()\n", "                losses['pl_reg'] = 0.0\n", "                # update metrics\n", "                metric_g_loss(g_loss)\n\n", "            # save to tensorboard\n", "            with train_summary_writer.as_default():\n", "                tf.summary.scalar('g_loss', metric_g_loss.result(), step=step)\n", "                tf.summary.scalar('d_loss', metric_d_loss.result(), step=step)\n", "                tf.summary.scalar('r1_reg', metric_r1_reg.result(), step=step)\n", "                tf.summary.scalar('pl_reg', metric_pl_reg.result(), step=step)\n", "                tf.summary.histogram('w_avg', self.generator.w_avg, step=step)\n\n", "            # save every self.save_step\n", "            if step % self.save_step == 0:\n", "                self.manager.save(checkpoint_number=step)\n\n", "            # save every self.image_summary_step\n", "            if step % self.image_summary_step == 0:\n", "                # add summary image\n", "                summary_image = self.sample_images_tensorboard(real_images)\n", "                with train_summary_writer.as_default():\n", "                    tf.summary.image('images', summary_image, step=step)\n\n", "            # print every self.print_steps\n", "            if step % self.print_step == 0:\n", "                elapsed = time.time() - t_start\n", "                print(self.log_template.format(step, elapsed,\n", "                        losses['d_loss'], losses['g_loss'], losses['r1_reg'], losses['pl_reg']))\n", "                # reset timer\n", "                t_start = time.time()\n\n", "            # check exit status\n", "            if step >= self.max_steps:\n", "                break\n\n", "        # get current step\n", "        step = self.g_optimizer.iterations.numpy()\n", "        elapsed = time.time() - t_start\n", "        print(self.log_template.format(step, elapsed,\n", "                        losses['d_loss'], losses['g_loss'], losses['r1_reg'], losses['pl_reg']))\n\n", "        # save last checkpoint\n", "        self.manager.save(checkpoint_number=step)\n", "        return\n", "    def sample_images_tensorboard(self, real_images):\n", "        # prepare inputs\n", "        reals = real_images[:self.n_samples, :, :, :]\n", "        latents = tf.random.normal(shape=(self.n_samples, self.g_params['z_dim']), dtype=tf.dtypes.float32)\n", "        dummy_labels = tf.ones((self.n_samples, self.g_params['labels_dim']), dtype=tf.dtypes.float32)\n\n", "        # run networks\n", "        fake_images_00, _ = self.g_clone([latents, dummy_labels], truncation_psi=0.0, training=False)\n", "        fake_images_05, _ = self.g_clone([latents, dummy_labels], truncation_psi=0.5, training=False)\n", "        fake_images_07, _ = self.g_clone([latents, dummy_labels], truncation_psi=0.7, training=False)\n", "        fake_images_10, _ = self.g_clone([latents, dummy_labels], truncation_psi=1.0, training=False)\n\n", "        # merge on batch dimension: [5 * n_samples, 3, out_res, out_res]\n", "        out = tf.concat([reals, fake_images_00, fake_images_05, fake_images_07, fake_images_10], axis=0)\n\n", "        # prepare for image saving: [5 * n_samples, out_res, out_res, 3]\n", "        out = onmoono.postprocess_images(out)\n\n", "        # resize to save disk spaces: [5 * n_samples, size, size, 3]\n", "        size = min(self.out_res, 256)\n", "        out = tf.image.resize(out, size=[size, size])\n\n", "        # make single image and add batch dimension for tensorboard: [1, 5 * size, n_samples * size, 3]\n", "        out = onmoono.merge_batch_images(out, size, rows=5, cols=self.n_samples)\n", "        out = np.expand_dims(out, axis=0)\n", "        return out"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ef initiate_models(g_params, d_params, use_custom_cuda):<br>\n", "   discriminator = load_discriminator(d_params, ckpt_dir=None, custom_cuda=use_custom_cuda)<br>\n", "   generator = load_generator(g_params=g_params, is_g_clone=False, ckpt_dir=None, custom_cuda=use_custom_cuda)<br>\n", "   g_clone = load_generator(g_params=g_params, is_g_clone=True, ckpt_dir=None, custom_cuda=use_custom_cuda)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["   # set initial g_clone weights same as generator<br>\n", "   g_clone.set_weights(generator.get_weights())<br>\n", "   return discriminator, generator, g_clone"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class Trainer(object):\n", "    def __init__(self, t_params, name):\n", "        self.cur_tf_ver = t_params['cur_tf_ver']\n", "        self.use_tf_function = t_params['use_tf_function']\n", "        self.use_custom_cuda = t_params['use_custom_cuda']\n", "        self.model_base_dir = t_params['model_base_dir']\n", "        self.global_batch_size = t_params['batch_size']\n", "        self.n_total_image = t_params['n_total_image']\n", "        self.max_steps = int(np.ceil(self.n_total_image / self.global_batch_size))\n", "        self.n_samples = min(t_params['batch_size'], t_params['n_samples'])\n", "        self.train_res = t_params['train_res']\n", "        self.print_step = 10\n", "        self.save_step = 100\n", "        self.image_summary_step = 100\n", "        self.reached_max_steps = False\n", "        self.log_template = '{:s}, {:s}, {:s}'.format(\n", "            'step {}: elapsed: {:.2f}s, d_loss: {:.3f}, g_loss: {:.3f}',\n", "            'd_gan_loss: {:.3f}, g_gan_loss: {:.3f}',\n", "            'r1_penalty: {:.3f}, pl_penalty: {:.3f}')\n\n", "        # copy network params\n", "        self.g_params = t_params['g_params']\n", "        self.d_params = t_params['d_params']\n\n", "        # set optimizer params\n", "        self.global_batch_scaler = 1.0 / float(self.global_batch_size)\n", "        self.r1_gamma = 10.0\n", "        self.g_opt = self.update_optimizer_params(t_params['g_opt'])\n", "        self.d_opt = self.update_optimizer_params(t_params['d_opt'])\n", "        self.pl_minibatch_shrink = 2\n", "        self.pl_weight = float(self.pl_minibatch_shrink)\n", "        self.pl_denorm = tf.math.rsqrt(float(self.train_res) * float(self.train_res))\n", "        self.pl_decay = 0.01\n", "        self.pl_mean = tf.Variable(initial_value=0.0, name='pl_mean', trainable=False,\n", "                                   synchronization=tf.VariableSynchronization.ON_READ,\n", "                                   aggregation=tf.VariableAggregation.ONLY_FIRST_REPLICA)\n\n", "        # create model: model and optimizer must be created under `strategy.scope`\n", "        #self.discriminator, self.generator, self.g_clone = initiate_models(self.g_params,\n", "        #                                                                   self.d_params,\n", "        #                                                                   self.use_custom_cuda)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        self.discriminator = load_discriminator(self.d_params, ckpt_dir=None, custom_cuda=self.use_custom_cuda)\n", "        self.generator = load_generator(g_params=self.g_params, is_g_clone=False, ckpt_dir=None, custom_cuda=self.use_custom_cuda)\n", "        self.g_clone = load_generator(g_params=self.g_params, is_g_clone=True, ckpt_dir=None, custom_cuda=self.use_custom_cuda)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        # set optimizers\n", "        self.d_optimizer = tf.keras.optimizers.Adam(self.d_opt['learning_rate'],\n", "                                                    beta_1=self.d_opt['beta1'],\n", "                                                    beta_2=self.d_opt['beta2'],\n", "                                                    epsilon=self.d_opt['epsilon'])\n", "        self.g_optimizer = tf.keras.optimizers.Adam(self.g_opt['learning_rate'],\n", "                                                    beta_1=self.g_opt['beta1'],\n", "                                                    beta_2=self.g_opt['beta2'],\n", "                                                    epsilon=self.g_opt['epsilon'])\n\n", "        # setup saving locations (object based savings)\n", "        self.ckpt_dir = os.path.join(self.model_base_dir, name)\n", "        self.ckpt = tf.train.Checkpoint(d_optimizer=self.d_optimizer,\n", "                                        g_optimizer=self.g_optimizer,\n", "                                        discriminator=self.discriminator,\n", "                                        generator=self.generator,\n", "                                        g_clone=self.g_clone,\n", "                                        pl_mean=self.pl_mean)\n", "        self.manager = tf.train.CheckpointManager(self.ckpt, self.ckpt_dir, max_to_keep=2)\n\n", "        # try to restore\n", "        self.ckpt.restore(self.manager.latest_checkpoint)\n", "        if self.manager.latest_checkpoint:\n", "            print('Restored from {}'.format(self.manager.latest_checkpoint))\n\n", "            # check if already trained in this resolution\n", "            restored_step = self.g_optimizer.iterations.numpy()\n", "            if restored_step >= self.max_steps:\n", "                print('Already reached max steps {}/{}'.format(restored_step, self.max_steps))\n", "                self.reached_max_steps = True\n", "                return\n", "        else:\n", "            print('Not restoring from saved checkpoint')\n", "    @staticmethod\n", "    def update_optimizer_params(params):\n", "        params_copy = params.copy()\n", "        mb_ratio = params_copy['reg_interval'] / (params_copy['reg_interval'] + 1)\n", "        params_copy['learning_rate'] = params_copy['learning_rate'] * mb_ratio\n", "        params_copy['beta1'] = params_copy['beta1'] ** mb_ratio\n", "        params_copy['beta2'] = params_copy['beta2'] ** mb_ratio\n", "        return params_copy\n", "    def d_train_step(self, dist_inputs):\n", "        real_images = dist_inputs[0]\n", "        with tf.GradientTape() as d_tape:\n", "            # compute losses\n", "            d_loss = d_logistic(real_images, self.generator, self.discriminator,\n", "                                self.g_params['z_dim'], self.g_params['labels_dim'])\n\n", "            # scale loss\n", "            d_loss = tf.reduce_sum(d_loss) * self.global_batch_scaler\n", "        d_gradients = d_tape.gradient(d_loss, self.discriminator.trainable_variables)\n", "        self.d_optimizer.apply_gradients(zip(d_gradients, self.discriminator.trainable_variables))\n", "        return d_loss\n", "    def d_train_step_reg(self, dist_inputs):\n", "        real_images = dist_inputs[0]\n", "        with tf.GradientTape() as d_tape:\n", "            # compute losses\n", "            d_gan_loss, r1_penalty = d_logistic_r1_reg(real_images, self.generator, self.discriminator,\n", "                                                       self.g_params['z_dim'], self.d_params['labels_dim'])\n", "            r1_penalty = r1_penalty * (0.5 * self.r1_gamma) * self.d_opt['reg_interval']\n\n", "            # scale losses\n", "            r1_penalty = tf.reduce_sum(r1_penalty) * self.global_batch_scaler\n", "            d_gan_loss = tf.reduce_sum(d_gan_loss) * self.global_batch_scaler\n\n", "            # combine\n", "            d_loss = d_gan_loss + r1_penalty\n", "        d_gradients = d_tape.gradient(d_loss, self.discriminator.trainable_variables)\n", "        self.d_optimizer.apply_gradients(zip(d_gradients, self.discriminator.trainable_variables))\n", "        return d_loss, d_gan_loss, r1_penalty\n", "    def g_train_step(self, dist_inputs):\n", "        real_images = dist_inputs[0]\n", "        with tf.GradientTape() as g_tape:\n", "            # compute losses\n", "            g_loss = g_logistic_non_saturating(real_images, self.generator, self.discriminator,\n", "                                               self.g_params['z_dim'], self.g_params['labels_dim'])\n\n", "            # scale loss\n", "            g_loss = tf.reduce_sum(g_loss) * self.global_batch_scaler\n", "        g_gradients = g_tape.gradient(g_loss, self.generator.trainable_variables)\n", "        self.g_optimizer.apply_gradients(zip(g_gradients, self.generator.trainable_variables))\n", "        return g_loss\n", "    def g_train_step_reg(self, dist_inputs):\n", "        real_images = dist_inputs[0]\n", "        with tf.GradientTape() as g_tape:\n", "            # compute losses\n", "            g_gan_loss, pl_penalty = g_logistic_ns_pathreg(real_images, self.generator, self.discriminator,\n", "                                                           self.g_params['z_dim'], self.g_params['labels_dim'],\n", "                                                           self.pl_mean, self.pl_minibatch_shrink, self.pl_denorm,\n", "                                                           self.pl_decay)\n", "            pl_penalty = pl_penalty * self.pl_weight * self.g_opt['reg_interval']\n\n", "            # scale loss\n", "            pl_penalty = tf.reduce_sum(pl_penalty) * self.global_batch_scaler\n", "            g_gan_loss = tf.reduce_sum(g_gan_loss) * self.global_batch_scaler\n\n", "            # combine\n", "            g_loss = g_gan_loss + pl_penalty\n", "        g_gradients = g_tape.gradient(g_loss, self.generator.trainable_variables)\n", "        self.g_optimizer.apply_gradients(zip(g_gradients, self.generator.trainable_variables))\n", "        return g_loss, g_gan_loss, pl_penalty\n", "    def train(self, dist_datasets, strategy):\n", "        def dist_d_train_step(inputs):\n", "            if self.cur_tf_ver == '2.0.0':\n", "                per_replica_losses = strategy.experimental_run_v2(fn=self.d_train_step, args=(inputs,))\n", "            else:\n", "                per_replica_losses = strategy.run(fn=self.d_train_step, args=(inputs,))\n", "            mean_d_loss = strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses, axis=None)\n", "            return mean_d_loss\n", "        def dist_d_train_step_reg(inputs):\n", "            if self.cur_tf_ver == '2.0.0':\n", "                per_replica_losses = strategy.experimental_run_v2(fn=self.d_train_step_reg, args=(inputs,))\n", "            else:\n", "                per_replica_losses = strategy.run(fn=self.d_train_step_reg, args=(inputs,))\n", "            mean_d_loss = strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses[0], axis=None)\n", "            mean_d_gan_loss = strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses[1], axis=None)\n", "            mean_r1_penalty = strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses[2], axis=None)\n", "            return mean_d_loss, mean_d_gan_loss, mean_r1_penalty\n", "        def dist_g_train_step(inputs):\n", "            if self.cur_tf_ver == '2.0.0':\n", "                per_replica_losses = strategy.experimental_run_v2(fn=self.g_train_step, args=(inputs,))\n", "            else:\n", "                per_replica_losses = strategy.run(fn=self.g_train_step, args=(inputs,))\n", "            mean_g_loss = strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses, axis=None)\n", "            return mean_g_loss\n", "        def dist_g_train_step_reg(inputs):\n", "            if self.cur_tf_ver == '2.0.0':\n", "                per_replica_losses = strategy.experimental_run_v2(fn=self.g_train_step_reg, args=(inputs,))\n", "            else:\n", "                per_replica_losses = strategy.run(fn=self.g_train_step_reg, args=(inputs,))\n", "            mean_g_loss = strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses[0], axis=None)\n", "            mean_g_gan_loss = strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses[1], axis=None)\n", "            mean_pl_penalty = strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses[2], axis=None)\n", "            return mean_g_loss, mean_g_gan_loss, mean_pl_penalty\n", "        def dist_gen_samples(dist_inputs):\n", "            if self.cur_tf_ver == '2.0.0':\n", "                per_replica_samples = strategy.experimental_run_v2(self.gen_samples, args=(dist_inputs,))\n", "            else:\n", "                per_replica_samples = strategy.run(self.gen_samples, args=(dist_inputs,))\n", "            return per_replica_samples\n\n", "        # wrap with tf.function\n", "        if self.use_tf_function:\n", "            dist_d_train_step = tf.function(dist_d_train_step)\n", "            dist_g_train_step = tf.function(dist_g_train_step)\n", "            dist_d_train_step_reg = tf.function(dist_d_train_step_reg)\n", "            dist_g_train_step_reg = tf.function(dist_g_train_step_reg)\n", "            dist_gen_samples = tf.function(dist_gen_samples)\n", "        if self.reached_max_steps:\n", "            return\n\n", "        # start actual training\n", "        print(f'|===> Start Training')\n\n", "        # setup tensorboards\n", "        train_summary_writer = tf.summary.create_file_writer(self.ckpt_dir)\n\n", "        # loss metrics\n", "        metric_d_loss = tf.keras.metrics.Mean('d_loss', dtype=tf.float32)\n", "        metric_g_loss = tf.keras.metrics.Mean('g_loss', dtype=tf.float32)\n", "        metric_d_gan_loss = tf.keras.metrics.Mean('d_gan_loss', dtype=tf.float32)\n", "        metric_g_gan_loss = tf.keras.metrics.Mean('g_gan_loss', dtype=tf.float32)\n", "        metric_r1_penalty = tf.keras.metrics.Mean('r1_penalty', dtype=tf.float32)\n", "        metric_pl_penalty = tf.keras.metrics.Mean('pl_penalty', dtype=tf.float32)\n\n", "        # start training\n", "        zero = tf.constant(0.0, dtype=tf.float32)\n", "        print(f'|...> train max_steps: {self.max_steps}')\n", "        t_start = time.time()\n", "        for real_images in dist_datasets:\n", "            step = self.g_optimizer.iterations.numpy()\n", "            print(f'|...> train step: {step}')\n\n", "            # d train step\n", "            print(f'|...> d train step')\n", "            if (step + 1) % self.d_opt['reg_interval'] == 0:\n", "                d_loss, d_gan_loss, r1_penalty = dist_d_train_step_reg((real_images, ))\n", "            else:\n", "                d_loss = dist_d_train_step((real_images, ))\n", "                d_gan_loss = d_loss\n", "                r1_penalty = zero\n\n", "            # g train step\n", "            print(f'|...> g train step')\n", "            if (step + 1) % self.g_opt['reg_interval'] == 0:\n", "                g_loss, g_gan_loss, pl_penalty = dist_g_train_step_reg((real_images, ))\n", "            else:\n", "                g_loss = dist_g_train_step((real_images,))\n", "                g_gan_loss = g_loss\n", "                pl_penalty = zero\n\n", "            # update g_clone\n", "            self.g_clone.set_as_moving_average_of(self.generator)\n\n", "            # update metrics\n", "            metric_d_loss(d_loss)\n", "            metric_g_loss(g_loss)\n", "            metric_d_gan_loss(d_gan_loss)\n", "            metric_g_gan_loss(g_gan_loss)\n", "            metric_r1_penalty(r1_penalty)\n", "            metric_pl_penalty(pl_penalty)\n\n", "            # get current step\n", "            step = self.g_optimizer.iterations.numpy()\n\n", "            # save to tensorboard\n", "            with train_summary_writer.as_default():\n", "                tf.summary.scalar('d_loss', metric_d_loss.result(), step=step)\n", "                tf.summary.scalar('g_loss', metric_g_loss.result(), step=step)\n", "                tf.summary.scalar('d_gan_loss', metric_d_gan_loss.result(), step=step)\n", "                tf.summary.scalar('g_gan_loss', metric_g_gan_loss.result(), step=step)\n", "                tf.summary.scalar('r1_penalty', metric_r1_penalty.result(), step=step)\n", "                tf.summary.scalar('pl_penalty', metric_pl_penalty.result(), step=step)\n\n", "            # save every self.save_step\n", "            if step % self.save_step == 0:\n", "                self.manager.save(checkpoint_number=step)\n\n", "            # save every self.image_summary_step\n", "            if step % self.image_summary_step == 0:\n", "                # add summary image\n", "                test_z = tf.random.normal(shape=(self.n_samples, self.g_params['z_dim']), dtype=tf.dtypes.float32)\n", "                test_labels = tf.ones((self.n_samples, self.g_params['labels_dim']), dtype=tf.dtypes.float32)\n", "                summary_image = dist_gen_samples((test_z, test_labels))\n", "                # convert to tensor image\n", "                summary_image = self.convert_per_replica_image(summary_image, strategy)\n", "                with train_summary_writer.as_default():\n", "                    tf.summary.image('images', summary_image, step=step)\n\n", "            # print every self.print_steps\n", "            if step % self.print_step == 0:\n", "                elapsed = time.time() - t_start\n", "                print(self.log_template.format(step, elapsed, d_loss.numpy(), g_loss.numpy(),\n", "                                               d_gan_loss.numpy(), g_gan_loss.numpy(),\n", "                                               r1_penalty.numpy(), pl_penalty.numpy()))\n", "                # reset timer\n", "                t_start = time.time()\n\n", "            # check exit status\n", "            if step >= self.max_steps:\n", "                break\n\n", "        # save last checkpoint\n", "        step = self.g_optimizer.iterations.numpy()\n", "        self.manager.save(checkpoint_number=step)\n", "        return\n", "    def gen_samples(self, inputs):\n", "        test_z, test_labels = inputs\n\n", "        # run networks\n", "        fake_images_05 = self.g_clone([test_z, test_labels], truncation_psi=0.5, training=False)\n", "        fake_images_07 = self.g_clone([test_z, test_labels], truncation_psi=0.7, training=False)\n\n", "        # merge on batch dimension: [n_samples, 3, out_res, 2 * out_res]\n", "        final_image = tf.concat([fake_images_05, fake_images_07], axis=2)\n", "        return final_image\n", "    @staticmethod\n", "    def convert_per_replica_image(nchw_per_replica_images, strategy):\n", "        as_tensor = tf.concat(strategy.experimental_local_results(nchw_per_replica_images), axis=0)\n", "        as_tensor = tf.transpose(as_tensor, perm=[0, 2, 3, 1])\n", "        as_tensor = (tf.clip_by_value(as_tensor, -1.0, 1.0) + 1.0) * 127.5\n", "        as_tensor = tf.cast(as_tensor, tf.uint8)\n", "        return as_tensor        \n", "#\n", "#\n", "#   FUNS\n", "#\n", "#\n", "def filter_resolutions_featuremaps(resolutions, featuremaps, res):\n", "    index = resolutions.index(res)\n", "    filtered_resolutions = resolutions[:index + 1]\n", "    filtered_featuremaps = featuremaps[:index + 1]\n", "    return filtered_resolutions, filtered_featuremaps\n", "#\n", "#\n", "#    -> https://github.com/moono/stylegan2-tf-2.x/tree/master/stylegan2/dataset_ffhq.py <-\n", "#\n", "def parse_tfrecord_tf(record):\n", "    # n_samples = 70000\n", "    features = tf.io.parse_single_example(record, features={\n", "        'shape': tf.io.FixedLenFeature([3], tf.dtypes.int64),\n", "        'data': tf.io.FixedLenFeature([], tf.dtypes.string)\n", "    })\n\n", "    # [0 ~ 255] uint8\n", "    images = tf.io.decode_raw(features['data'], tf.dtypes.uint8)\n", "    images = tf.reshape(images, features['shape'])\n\n", "    # [0.0 ~ 255.0] float32\n", "    images = tf.cast(images, tf.dtypes.float32)\n", "    return images\n", "#\n", "def folder_to_dataset(tfrecord_base_dir, \n", "        res, buffer_size, batch_size, epochs=None, prefix='tfrecord'):\n", "    fn_index = int(np.log2(res))\n", "    recordidx = str(fn_index).zfill(2)\n", "    tfrecord_fn = os.path.join(tfrecord_base_dir, f'{prefix}-r{recordidx}.tfrecords')\n", "    with tf.device('/cpu:0'):\n", "        dataset = tf.data.TFRecordDataset(tfrecord_fn)\n", "        dataset = dataset.map(map_func=parse_tfrecord_tf, num_parallel_calls=8)\n", "        dataset = dataset.shuffle(buffer_size=buffer_size)\n", "        dataset = dataset.repeat(epochs)\n", "        dataset = dataset.batch(batch_size)\n", "        dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n", "    return dataset\n", "#\n", "#\n", "#   FUNS l4rz\n", "#\n", "#\n", "import multiprocessing\n", "#\n", "#\n", "def resize_and_convert(img, size, resample, quality=100):\n", "    img = trans_fn.resize(img, size, resample)\n", "    img = trans_fn.center_crop(img, size)\n", "    buffer = io.BytesIO()\n", "    img.save(buffer, format=\"jpeg\", quality=quality)\n", "    val = buffer.getvalue()\n", "    return val\n", "#\n", "#\n", "def resize_multiple(img, sizes=(128, 256, 512, 1024), resample=Image.LANCZOS, quality=100):\n", "    imgs = []\n", "    for size in sizes:\n", "        imgs.append(resize_and_convert(img, size, resample, quality))\n", "    return imgs\n", "#\n", "#\n", "def resize_worker(img_file, sizes, resample):\n", "    i, file = img_file\n", "    try:\n", "        img = Image.open(file)\n", "        img = img.convert(\"RGB\")\n", "    except:\n", "        print(file, \"truncated\")\n", "    out = resize_multiple(img, sizes=sizes, resample=resample)\n", "    return i, out\n", "#\n", "# \n", "def prepare(env, dataset, n_worker, sizes=(128, 256, 512, 1024), resample=Image.LANCZOS):\n", "    resize_fn = partial(resize_worker, sizes=sizes, resample=resample)\n", "    files = sorted(dataset.imgs, key=lambda x: x[0])\n", "    files = [(i, file) for i, (file, label) in enumerate(files)]\n", "    total = 0\n", "    with multiprocessing.Pool(n_worker) as pool:\n", "        for i, imgs in tqdm(pool.imap_unordered(resize_fn, files)):\n", "            for size, img in zip(sizes, imgs):\n", "                key = f\"{size}-{str(i).zfill(5)}\".encode(\"utf-8\")\n", "                with env.begin(write=True) as txn:\n", "                    txn.put(key, img)\n", "            total += 1\n", "        with env.begin(write=True) as txn:\n", "            txn.put(\"length\".encode(\"utf-8\"), str(total).encode(\"utf-8\"))\n", "#\n", "#\n", "#   https://github.com/NVlabs/stylegan2/blob/master/pretrained_networks.py\n", "#\n", "def show_gen():\n", "    print(f'|===> nngen: show generator model and layers \\n \\\n", "            cwd: {os.getcwd()} \\n \\\n", "    ')\n", "    batch_size = 4\n", "    g_params_with_label = {\n", "        'z_dim': 512,\n", "        'w_dim': 512,\n", "        'labels_dim': 0,\n", "        'n_mapping': 8,\n", "        'resolutions': [4, 8, 16, 32, 64, 128, 256, 512, 1024],\n", "        'featuremaps': [512, 512, 512, 512, 512, 256, 128, 64, 32],\n", "        'w_ema_decay': 0.995,\n", "        'style_mixing_prob': 0.9,\n", "        'truncation_psi': 0.5,\n", "        'truncation_cutoff': None,\n", "    }\n", "    test_z = np.ones((batch_size, g_params_with_label['z_dim']), dtype=np.float32)\n", "    test_y = np.ones((batch_size, g_params_with_label['labels_dim']), dtype=np.float32)\n", "    generator = Generator(g_params_with_label)\n", "    fake_images1, _ = generator([test_z, test_y], training=True)\n", "    fake_images2, _ = generator([test_z, test_y], training=False)\n", "    generator.summary()\n", "    print(f'|...> fake_images1.shape: {fake_images1.shape}')\n", "    for v in generator.variables:\n", "        print(f'|...> generator.variables: {v.name}: {v.shape}')\n", "#\n", "#\n", "def show_disc():\n", "    print(f'|===> nndisr: : show discriminator model and layers \\n \\\n", "            cwd: {os.getcwd()}  \\n \\\n", "    ')\n", "    batch_size = 4\n", "    d_params_with_label = {\n", "        'labels_dim': 0,\n", "        'resolutions': [4, 8, 16, 32, 64, 128, 256, 512, 1024],\n", "        'featuremaps': [512, 512, 512, 512, 512, 256, 128, 64, 32],\n", "    }\n", "    input_res = d_params_with_label['resolutions'][-1]\n", "    test_images = np.ones((batch_size, 3, input_res, input_res), dtype=np.float32)\n", "    test_labels = np.ones((batch_size, d_params_with_label['labels_dim']), dtype=np.float32)\n", "    discriminator = Discriminator(d_params_with_label)\n", "    scores1 = discriminator([test_images, test_labels], training=True)\n", "    scores2 = discriminator([test_images, test_labels], training=False)\n", "    discriminator.summary()\n", "    print(f'|...> scores1.shape: {scores1.shape}')\n", "    print(f'|...> scores2.shape: {scores2.shape}')\n", "    print()\n", "    for v in discriminator.variables:\n", "        print(f'|...> discriminator.variables: {v.name}: {v.shape}')\n", "#\n", "# https://github.com/moono/stylegan2-tf-2.x/dataset_ffhq.py\n", "# https://github.com/moono/stylegan2-tf-2.x/blob/master/dataset_ffhq.py\n", "# n_samples = 70000\n", "def parse_tfrecord_tf(record):\n", "    features = tf.io.parse_single_example(record, features={\n", "        'shape': tf.io.FixedLenFeature([3], tf.dtypes.int64),\n", "        'data': tf.io.FixedLenFeature([], tf.dtypes.string)\n", "    })\n\n", "    # [0 ~ 255] uint8 -> [-1.0 ~ 1.0] float32\n", "    image = tf.io.decode_raw(features['data'], tf.dtypes.uint8)\n", "    image = tf.reshape(image, features['shape'])\n", "    image = tf.transpose(image, perm=[1, 2, 0])\n", "    image = tf.image.random_flip_left_right(image)\n", "    image = tf.cast(image, tf.dtypes.float32)\n", "    image = image / 127.5 - 1.0\n", "    image = tf.transpose(image, perm=[2, 0, 1])\n", "    return image\n", "#\n", "#\n", "# https://github.com/moono/stylegan2-tf-2.x/blob/master/load_models.py\n", "def load_generator(g_params=None, is_g_clone=False, ckpt_dir=None, custom_cuda=True):\n", "    # _e_\n", "    #if custom_cuda:\n", "    #    from stylegan2.generator import Generator\n", "    #else:\n", "    #    from stylegan2_ref.generator import Generator\n", "    if g_params is None:\n", "        g_params = {\n", "            'z_dim': 512,\n", "            'w_dim': 512,\n", "            'labels_dim': 0,\n", "            'n_mapping': 8,\n", "            'resolutions': [4, 8, 16, 32, 64, 128, 256, 512, 1024],\n", "            'featuremaps': [512, 512, 512, 512, 512, 256, 128, 64, 32],\n", "        }\n", "    test_latent = tf.ones((1, g_params['z_dim']), dtype=tf.float32)\n", "    test_labels = tf.ones((1, g_params['labels_dim']), dtype=tf.float32)\n\n", "    # build generator model\n", "    generator = Generator(g_params)\n", "    _ = generator([test_latent, test_labels])\n", "    if ckpt_dir is not None:\n", "        if is_g_clone:\n", "            ckpt = tf.train.Checkpoint(g_clone=generator)\n", "        else:\n", "            ckpt = tf.train.Checkpoint(generator=generator)\n", "        manager = tf.train.CheckpointManager(ckpt, ckpt_dir, max_to_keep=1)\n", "        ckpt.restore(manager.latest_checkpoint).expect_partial()\n", "        if manager.latest_checkpoint:\n", "            print(f'Generator restored from {manager.latest_checkpoint}')\n", "    return generator\n", "#\n", "#\n", "def load_discriminator(d_params=None, ckpt_dir=None, custom_cuda=True):\n", "    # _e_\n", "    #if custom_cuda:\n", "    #    from stylegan2.discriminator import Discriminator\n", "    #else:\n", "    #    from stylegan2_ref.discriminator import Discriminator\n", "    if d_params is None:\n", "        d_params = {\n", "            'labels_dim': 0,\n", "            'resolutions': [4, 8, 16, 32, 64, 128, 256, 512, 1024],\n", "            'featuremaps': [512, 512, 512, 512, 512, 256, 128, 64, 32],\n", "        }\n", "    res = d_params['resolutions'][-1]\n", "    test_images = tf.ones((1, 3, res, res), dtype=tf.float32)\n", "    test_labels = tf.ones((1, d_params['labels_dim']), dtype=tf.float32)\n\n", "    # build discriminator model\n", "    discriminator = Discriminator(d_params)\n", "    _ = discriminator([test_images, test_labels])\n", "    if ckpt_dir is not None:\n", "        ckpt = tf.train.Checkpoint(discriminator=discriminator)\n", "        manager = tf.train.CheckpointManager(ckpt, ckpt_dir, max_to_keep=1)\n", "        ckpt.restore(manager.latest_checkpoint).expect_partial()\n", "        if manager.latest_checkpoint:\n", "            print('Discriminator restored from {}'.format(manager.latest_checkpoint))\n", "    return discriminator\n", "#\n", "#https://github.com/moono/stylegan2-tf-2.x/blob/master/inference_from_official_weights.py\n", "#\n", "#\n", "def handle_mapping(w_name):\n", "    def extract_info(name):\n", "        splitted = name.split('/')\n", "        index = splitted.index('g_mapping')\n", "        indicator = splitted[index + 1]\n", "        val = indicator.split('_')[-1]\n", "        return val\n", "    level = extract_info(w_name)\n", "    if 'w' in w_name:\n", "        official_var_name = 'G_mapping_1/Dense{}/weight'.format(level)\n", "    else:\n", "        official_var_name = 'G_mapping_1/Dense{}/bias'.format(level)\n", "    return official_var_name\n", "#\n", "#\n", "def handle_synthesis(w_name):\n", "    def extract_info(name):\n", "        splitted = name.split('/')\n", "        index = splitted.index('g_synthesis')\n", "        indicator1 = splitted[index + 1]\n", "        indicator2 = splitted[index + 2]\n", "        r = indicator1.split('x')[1]\n", "        d = indicator2\n", "        return r, d\n", "    def to_rgb_layer(name, r):\n", "        if 'conv/w:0' in name:\n", "            o_name = 'G_synthesis_1/{}x{}/ToRGB/weight'.format(r, r)\n", "        elif 'mod_dense/w:0' in name:\n", "            o_name = 'G_synthesis_1/{}x{}/ToRGB/mod_weight'.format(r, r)\n", "        elif 'mod_bias/b:0' in name:\n", "            o_name = 'G_synthesis_1/{}x{}/ToRGB/mod_bias'.format(r, r)\n", "        else:   # if 'bias/b:0' in name:\n", "            o_name = 'G_synthesis_1/{}x{}/ToRGB/bias'.format(r, r)\n", "        return o_name\n", "    def handle_block_layer(name, r):\n", "        if 'conv_0/w:0' in name:\n", "            o_name = 'G_synthesis_1/{}x{}/Conv0_up/weight'.format(r, r)\n", "        elif 'conv_0/mod_dense/w:0' in name:\n", "            o_name = 'G_synthesis_1/{}x{}/Conv0_up/mod_weight'.format(r, r)\n", "        elif 'conv_0/mod_bias/b:0' in name:\n", "            o_name = 'G_synthesis_1/{}x{}/Conv0_up/mod_bias'.format(r, r)\n", "        elif 'noise_0/w:0' in name:\n", "            o_name = 'G_synthesis_1/{}x{}/Conv0_up/noise_strength'.format(r, r)\n", "        elif 'bias_0/b:0' in name:\n", "            o_name = 'G_synthesis_1/{}x{}/Conv0_up/bias'.format(r, r)\n", "        elif 'conv_1/w:0' in name:\n", "            o_name = 'G_synthesis_1/{}x{}/Conv1/weight'.format(r, r)\n", "        elif 'conv_1/mod_dense/w:0' in name:\n", "            o_name = 'G_synthesis_1/{}x{}/Conv1/mod_weight'.format(r, r)\n", "        elif 'conv_1/mod_bias/b:0' in name:\n", "            o_name = 'G_synthesis_1/{}x{}/Conv1/mod_bias'.format(r, r)\n", "        elif 'noise_1/w:0' in name:\n", "            o_name = 'G_synthesis_1/{}x{}/Conv1/noise_strength'.format(r, r)\n", "        else:   # if 'bias_1/b:0' in name:\n", "            o_name = 'G_synthesis_1/{}x{}/Conv1/bias'.format(r, r)\n", "        return o_name\n", "    def handle_const_layer(name):\n", "        if 'const:0' in name:\n", "            o_name = 'G_synthesis_1/4x4/Const/const'\n", "        elif 'conv/w:0' in name:\n", "            o_name = 'G_synthesis_1/4x4/Conv/weight'\n", "        elif 'mod_dense/w:0' in name:\n", "            o_name = 'G_synthesis_1/4x4/Conv/mod_weight'\n", "        elif 'mod_bias/b:0' in name:\n", "            o_name = 'G_synthesis_1/4x4/Conv/mod_bias'\n", "        elif 'noise/w:0' in name:\n", "            o_name = 'G_synthesis_1/4x4/Conv/noise_strength'\n", "        else:\n", "            o_name = 'G_synthesis_1/4x4/Conv/bias'\n", "        return o_name\n", "    res, divider = extract_info(w_name)\n", "    if divider == 'ToRGB':\n", "        official_var_name = to_rgb_layer(w_name, res)\n", "    elif divider == 'block':\n", "        official_var_name = handle_block_layer(w_name, res)\n", "    else:   # const\n", "        official_var_name = handle_const_layer(w_name)\n", "    return official_var_name\n", "#\n", "#\n", "def variable_name_mapper(g):\n", "    name_mapper = dict()\n", "    for w in g.weights:\n", "        w_name, w_shape = w.name, w.shape\n\n", "        # mapping layer\n", "        if 'g_mapping' in w_name:\n", "            official_var_name = handle_mapping(w_name)\n", "        elif 'g_synthesis' in w_name:\n", "            official_var_name = handle_synthesis(w_name)\n", "        else:\n", "            official_var_name = 'Gs/dlatent_avg'\n", "            pass    # w_avg\n", "        name_mapper[official_var_name] = w\n", "    return name_mapper\n", "#\n", "#\n", "def check_shape(name_mapper, official_vars):\n", "    for official_name, v in name_mapper.items():\n", "        official_shape = [s for n, s in official_vars if n == official_name][0]\n", "        if official_shape == v.shape:\n", "            print('{}: shape matches'.format(official_name))\n", "        else:\n", "            # print(f'Official: {official_name} -> {official_shape}')\n", "            # print(f'Current: {v.name} -> {v.shape}')\n", "            raise ValueError('{}: wrong shape'.format(official_name))\n", "    return\n", "#\n", "#\n", "def test_generator(ckpt_dir, use_custom_cuda):\n", "    g_clone = load_generator(g_params=None, is_g_clone=True, ckpt_dir=ckpt_dir, custom_cuda=use_custom_cuda)\n\n", "    # test\n", "    seed = 6600\n", "    rnd = np.random.RandomState(seed)\n", "    latents = rnd.randn(1, g_clone.z_dim)\n", "    labels = rnd.randn(1, g_clone.labels_dim)\n", "    latents = latents.astype(np.float32)\n", "    labels = labels.astype(np.float32)\n", "    image_out = g_clone([latents, labels], training=False, truncation_psi=0.5)\n", "    image_out = onmoono.postprocess_images(image_out)\n", "    image_out = image_out.numpy()\n", "    out_fn = f'seed{seed}-restored-cuda.png' if use_custom_cuda else f'seed{seed}-restored-ref.png'\n", "    Image.fromarray(image_out[0], 'RGB').save(out_fn)\n", "    return\n", "#\n", "#\n", "def inference_from_each_other(ckpt_dir_base, ckpt_from='cuda', inference_from='ref'):\n", "    assert ckpt_from != inference_from\n\n", "    # set proper path and variables\n", "    use_custom_cuda = True if inference_from == 'cuda' else False\n", "    ckpt_dir = os.path.join(ckpt_dir_base, 'cuda') if ckpt_from == 'cuda' else os.path.join(ckpt_dir_base, 'ref')\n\n", "    # create generator\n", "    g_clone = load_generator(g_params=None, is_g_clone=True, ckpt_dir=ckpt_dir, custom_cuda=use_custom_cuda)\n\n", "    # test\n", "    seed = 6600\n", "    rnd = np.random.RandomState(seed)\n", "    latents = rnd.randn(1, g_clone.z_dim)\n", "    labels = rnd.randn(1, g_clone.labels_dim)\n", "    latents = latents.astype(np.float32)\n", "    labels = labels.astype(np.float32)\n", "    image_out = g_clone([latents, labels], training=False, truncation_psi=0.5)\n", "    image_out = onmoono.postprocess_images(image_out)\n", "    image_out = image_out.numpy()\n", "    out_fn = f'seed{seed}-restored-from-{ckpt_from}-to-{inference_from}.png'\n", "    Image.fromarray(image_out[0], 'RGB').save(out_fn)\n", "    return\n", "#\n", "#save_path = saver.save(tf.get_default_session(), \"./model.ckpt\")\n", "#\n", "#\n", "#\n", "#   CMDS\n", "#\n", "#\n", "#https://colab.research.google.com/drive/1s2XPNMwf6HDhrJ1FMwlW1jl-eQ2-_tlk?usp=sharing#scrollTo=7YFk46FLM9qo\n", "# Network blending in StyleGAN\n", "#https://colab.research.google.com/drive/1tputbmA9EaXs9HL9iO21g7xN7jz_Xrko?usp=sharing#scrollTo=2fCG-AZ69ttu\n", "#https://twitter.com/Buntworthy/status/1295445259971899393\n\n", "    #imgset = datasets.ImageFolder(args.data_dir)\n\n", "    #with lmdb.open(args.out, map_size=1024 ** 4, readahead=False) as env:\n", "    #    prepare(env, imgset, args.n_worker, sizes=sizes, resample=resample)\n\n", "    #!wget https://upload.wikimedia.org/wikipedia/commons/6/6d/Shinz%C5%8D_Abe_Official.jpg -O raw/example.jpg\n\n", "    # Convert weight from official checkpoints\n\n", "    ## use my copy of the blended model to save Doron's download bandwidth\n", "    ## get the original here https://mega.nz/folder/OtllzJwa#C947mCCdEfMCRTWnDcs4qw\n", "    #blended_url = \"https://drive.google.com/uc?id=1H73TfV5gQ9ot7slSed_l-lim9X7pMRiU\" \n", "    #ffhq_url = \"http://d36zk2xti64re0.cloudfront.net/stylegan2/networks/stylegan2-ffhq-config-f.pkl\"\n\n", "    #_, _, Gs_blended = pretrained_networks.load_networks(blended_url)\n", "    #_, _, Gs = pretrained_networks.load_networks(ffhq_url)\n", "    #!python align_images.py raw aligned\n", "    #!python project_images.py --num-steps 500 aligned generated\n", "    #import numpy as np\n", "    #from PIL import Image\n", "    #import dnnlib\n", "    #import dnnlib.tflib as tflib\n", "    #from pathlib import Path\n\n", "    #latent_dir = Path(\"generated\")\n", "    #latents = latent_dir.glob(\"*.npy\")\n", "    #for latent_file in latents:\n", "    #  latent = np.load(latent_file)\n", "    #  latent = np.expand_dims(latent,axis=0)\n", "    #  synthesis_kwargs = dict(output_transform=dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=False), minibatch_size=8)\n", "    #  images = Gs_blended.components.synthesis.run(latent, randomize_noise=False, **synthesis_kwargs)\n", "    #  Image.fromarray(images.transpose((0,2,3,1))[0], 'RGB').save(latent_file.parent / (f\"{latent_file.stem}-toon.jpg\"))\n\n", "    #from IPython.display import Image \n", "    #embedded = Image(filename=\"generated/example_01.png\", width=256)\n", "    #display(embedded)\n", "    #tooned = Image(filename=\"generated/example_01-toon.jpg\", width=256)\n", "    #display(tooned)  \n\n", "    # Generate samples\n", "    # python generate.py --sample N_FACES --pics N_PICS --ckpt PATH_CHECKPOINT\n", "    # Project images to latent spaces\n", "    # python projector.py --ckpt [CHECKPOINT] --size [GENERATOR_OUTPUT_SIZE] FILE1 FILE2 ...\n", "#  \n", "#\n", "#\n", "# https://github.com/moono/stylegan2-tf-2.x\n", "#   [1] weight modulation / demodulation\n", "#   [2] skip architecture\n", "#   [3] resnet architecture\n", "#   [4] path regularization\n", "#   [5] lazy regularization\n", "#   [6] single GPU training\n", "#   [7] inference from official Generator weights\n", "#\n", "#\n", "#\n", "#   nnrun\n", "#\n", "def nnrun(args, kwargs):\n", "    # https://github.com/moono/stylegan2-tf-2.x\n", "    # run git scrits\n", "    args = onutil.pargs(vars(args))\n", "    xp = getxp(vars(args))\n", "    args = onutil.pargs(xp)\n", "    onutil.ddict(vars(args), 'args')\n", "    print(f'|===> nnrun: {args.MNAME}:{args.PROJECT} \\n \\\n", "        data: {args.DATASET}) \\n \\\n", "        code: {args.GITPOD} \\n \\\n", "    ')#\n", "    if 1: # tree\n", "        print(f'|===> nnrun: tree \\n \\\n", "            cwd:  {os.getcwd()}, \\n \\\n", "            args.dataorg_dir: {args.dataorg_dir}, \\n \\\n", "        ')\n", "    if 1: # git\n", "        print(f'|===> nnrun: git ')\n", "        onutil.get_git(args.AUTHOR, args.GITPOD, args.proj_dir)\n", "    if 1: # config\n", "        print(f'|===> nnrun: config \\n \\\n", "        ')\n", "    if 1: # run py command\n", "        cmd = f\"python inference.py\"\n", "        print(\"cmd %s\" %cmd)\n", "        os.system(cmd)\n", "#\n", "#\n", "#   nntrain\n", "#\n", "def nntrain(args, kwargs):\n", "    # https://github.com/moono/stylegan2-tf-2.x/blob/master/dataset_ffhq.py\n", "    if 0:\n", "        args = onutil.pargs(vars(args))\n", "        args.PROJECT = 'ffhq'\n", "        args.DATASET = 'ffhq'\n", "        args.train_res = 256 # \n", "        xp = getxp(vars(args))\n", "        args = onutil.pargs(xp)\n", "        onutil.ddict(vars(args), 'args')\n", "    elif 1:\n", "        args = onutil.pargs(vars(args))\n", "        args.PROJECT = 'gsfc'\n", "        args.DATASET = 'gsfc'\n", "        args.train_res = 32 # fn_index = int(np.log2(res)) - res=32 => 5 # 256 #         \n", "        xp = getxp(vars(args))\n", "        args = onutil.pargs(xp)\n", "        onutil.ddict(vars(args), 'args')\n", "    print(f'|===> nnrun: {args.MNAME}:{args.PROJECT} \\n \\\n", "        data: {args.DATASET}) \\n \\\n", "        code: {args.GITPOD} \\n \\\n", "    ')\n", "    if 1: # tree\n", "        args.raw_dir = os.path.join(args.proj_dir, \"raw\")\n", "        args.aligned_dir = os.path.join(args.proj_dir, \"aligned\")\n", "        args.generated_dir = os.path.join(args.proj_dir, \"generated\")\n", "        args.tfrecord_dir = os.path.join(args.gdata, f'{args.DATASET}_records')\n", "        \n", "        args.ckpt_dir=os.path.join(args.proj_dir, 'ckpts_dir')\n", "        args.model_base_dir=os.path.join(args.proj_dir, 'models')\n", "        os.makedirs(args.raw_dir, exist_ok=True)\n", "        os.makedirs(args.aligned_dir, exist_ok=True)\n", "        os.makedirs(args.generated_dir, exist_ok=True)\n", "        os.makedirs(args.model_base_dir, exist_ok=True)\n", "        os.makedirs(args.tfrecord_dir, exist_ok=True)        \n", "        os.makedirs(args.data_dir, exist_ok=True)    \n", "    print(f'\\n |===> nntrain: tree \\n \\\n", "        cwd:  {os.getcwd()}, \\n \\\n", "        args.dataorg_dir: {args.dataorg_dir}, \\n \\\n", "        args.results_dir: {args.results_dir}, \\n \\\n", "        args.models_dir:  {args.models_dir}, \\n \\\n", "        args.ckpt_dir:  {args.ckpt_dir}, \\n \\\n", "        args.data_dir:    {args.data_dir}, \\n \\\n", "        args.tfrecord_dir:    {args.tfrecord_dir}, \\n \\\n", "        args.raw_dir:       {args.raw_dir}, \\n \\\n", "        args.aligned_dir:   {args.aligned_dir}, \\n \\\n", "        args.generated_dir: {args.generated_dir}, \\n \\\n", "    \\n ')\n", "    if 1: # git\n", "        print(f'|===> nnrun: git ')\n", "        onutil.get_git(args.AUTHOR, args.GITPOD, args.proj_dir)\n", "    if 1: # config\n", "        args.clip = (256, 256) # images will be clipped to clip (from bigger img)\n", "        args.ps = (256, 256) # imgs will be resized to ps\n", "        args.im_size = 256\n", "        args.qslices = 1 # 10 # number of slices per image\n", "        args.eps = 1.0 # 0.9 \n", "        args.size = \"128,256,512,1024\"\n", "        args.n_worker = 8\n", "        args.resample = \"bilinear\"\n", "        args.resample_map = {\"lanczos\": Image.LANCZOS, \"bilinear\": Image.BILINEAR}\n", "        args.resample = args.resample_map[args.resample]\n", "        args.n_samples = 70000\n", "        args.epochs = 1\n", "        args.allow_memory_growth = True\n", "        args.debug_split_gpu = False\n", "        args.use_tf_function = True\n", "        args.use_custom_cuda = True\n\n", "        # check tensorflow version\n", "        cur_tf_ver = ontf.check_tf_version()\n", "        if args.allow_memory_growth:\n", "            ontf.allow_memory_growth()\n", "        if args.debug_split_gpu:\n", "            ontf.split_gpu_for_testing(mem_in_gb=4.5)\n\n", "        # network params\n", "        args.shuffle_buffer_size = 1000\n", "        args.batch_size = 4\n", "        args.batch_size_per_replica = 4\n", "        print(f'|===> nntrain: config \\n \\\n", "                args.n_samples: {args.n_samples}, \\n \\\n", "                args.train_res: {args.train_res}, \\n \\\n", "                args.batch_size: {args.batch_size}, \\n \\\n", "                args.epochs: {args.epochs}, \\n \\\n", "        ')\n", "        train_res = args.train_res\n", "        resolutions = [  4,   8,  16,  32,  64, 128, 256, 512, 1024]\n", "        featuremaps = [512, 512, 512, 512, 512, 256, 128,  64,   32]\n", "        train_resolutions, train_featuremaps = filter_resolutions_featuremaps(resolutions, featuremaps, train_res)\n", "        g_params = {\n", "            'z_dim': 512,\n", "            'w_dim': 512,\n", "            'labels_dim': 0,\n", "            'n_mapping': 8,\n", "            'resolutions': train_resolutions,\n", "            'featuremaps': train_featuremaps,\n", "            # _e_            \n", "            'w_ema_decay': 0.995,\n", "            'style_mixing_prob': 0.9,\n", "            'truncation_psi': 0.5,\n", "            'truncation_cutoff': None,                    \n", "        }\n", "        d_params = {\n", "            'labels_dim': 0,\n", "            'resolutions': train_resolutions,\n", "            'featuremaps': train_featuremaps,\n", "        }\n\n", "        # training parameters\n", "        training_parameters = {\n", "            # global params\n", "            'cur_tf_ver': cur_tf_ver,\n", "            'use_tf_function': args.use_tf_function,\n", "            'use_custom_cuda': args.use_custom_cuda,\n\n", "            # **args,\n", "            'model_base_dir': args.model_base_dir,\n", "            'tfrecord_dir': args.tfrecord_dir,\n", "            'shuffle_buffer_size': args.shuffle_buffer_size,\n\n", "            # network params\n", "            'g_params': g_params,\n", "            'd_params': d_params,\n\n", "            # training params\n", "            'g_opt': {'learning_rate': 0.002, 'beta1': 0.0, 'beta2': 0.99, 'epsilon': 1e-08, 'reg_interval': 4},\n", "            'd_opt': {'learning_rate': 0.002, 'beta1': 0.0, 'beta2': 0.99, 'epsilon': 1e-08, 'reg_interval': 16},\n", "            'batch_size': args.batch_size,\n", "            'n_total_image': 25000000,\n", "            'n_samples': args.n_samples,\n", "            'lazy_regularization': True,\n\n", "            #\n", "            'train_res': args.train_res,\n", "        }\n", "        onutil.ddict(training_parameters, 'training_parameters')\n", "    if 1: # org => data (formdata)\n", "        print(f'|====> nndata formed images \\n \\\n", "            from {args.dataorg_dir} into {args.data_dir} \\n \\\n", "            args.clip: {args.clip} \\n \\\n", "            qslices: {args.qslices} \\n \\\n", "            ps: {args.ps} \\n \\\n", "            eps: {args.eps} \\n \\\n", "        ')\n", "        qinfiles = onfile.qfiles(args.dataorg_dir, ['*.jpg', '*.png'])\n", "        qinslices = qinfiles * args.qslices\n", "        qoutfiles = onfile.qfiles(args.data_dir, ['*.jpg', '*.png'])\n", "        if qinslices > qoutfiles:\n", "            if onutil.isempty(args.data_dir):\n", "                print(f\"args.data_dir {args.data_dir} not empty !!!\")\n", "            imgs = ondata.folder_to_formed_pils(\n", "                args.dataorg_dir, \n", "                ps = args.ps, \n", "                qslices = args.qslices, \n", "                eps = args.eps)\n", "            onfile.pils_to_folder(imgs, args.data_dir)\n", "        else:\n", "            print(f'|... no org to data files')\n", "        print(f\"|... nndata formed images \\n \\\n", "            {onfile.qfiles(args.data_dir)} files in {args.data_dir} \\n \\\n", "        \")\n", "    if 1: # data => tfrecords\n", "        print(f\"|===> nndata generate tfrecords \\n \\\n", "            from {args.data_dir} into {args.tfrecord_dir} \\n \\\n", "            {onfile.qfiles(args.tfrecord_dir)} files in {args.tfrecord_dir} \\n \\\n", "        \")\n", "        if onutil.isempty(args.tfrecord_dir):\n", "            print(f\"|...> args.tfrecord_dir {args.tfrecord_dir} not empty. SKIP\")\n", "        else:\n", "            onrecord.folder_to_tfrecords(args.data_dir, args.tfrecord_dir)\n", "    if 1: # get dataset from tfrecords\n", "        sizes = [int(s.strip()) for s in args.size.split(\",\")]\n", "        print(f'|===> probe dataset of image sizes: {\", \".join(str(s) for s in sizes)} \\n \\\n", "             convert images to jpeg and pre-resize it \\n \\\n", "             args.tfrecord_dir: {args.tfrecord_dir} \\n \\\n", "        ')\n", "         #dataset = get_ffhq_dataset(args.tfrecord_dir, \n", "         #  args.train_res, batch_size=global_batch_size, epochs=None)\n\n", "        #dataset = folder_to_dataset(args.tfrecord_dir, \n", "        #    args.train_res, args.batch_size, args.epochs)\n", "        args.out_res = g_params['resolutions'][-1]\n", "        dataset = folder_to_dataset(args.tfrecord_dir, \n", "            args.out_res, args.shuffle_buffer_size, args.batch_size, args.epochs)\n", "    if 0: # probe dataset from tfrecords\n", "        for real_images in dataset.take(args.batch_size):\n", "            print(real_images.shape)  # => (1, 3, 32, 32) ...\n", "        q_imgs_to_show = 4\n", "        print(f'|===> dataset probe with {q_imgs_to_show} imgs')\n", "        for real_images in dataset.take(q_imgs_to_show): # show imgs in tfrecord\n", "            # real_images: [batch_size, 3, res, res] (-1.0 ~ 1.0) float32\n", "            images = real_images.numpy()\n", "            images = np.transpose(images, axes=(0, 2, 3, 1))\n", "            images = (images + 1.0) * 127.5\n", "            images = images.astype(np.uint8)\n", "            image = Image.fromarray(images[0])\n", "            image.show()\n", "    if 0: # build generator model\n", "        print(f'|===> nnrun build generator model')\n", "        generator = Generator(g_params)\n", "        _ = generator([test_latent, test_labels])\n", "        if args.ckpt_dir is not None:\n", "            print(f'|...> Generator get checkpoint from {args.ckpt_dir}')\n", "            is_g_clone = 1\n", "            if is_g_clone:\n", "                ckpt = tf.train.Checkpoint(g_clone=generator)\n", "            else:\n", "                ckpt = tf.train.Checkpoint(generator=generator)\n", "            manager = tf.train.CheckpointManager(ckpt, args.ckpt_dir, max_to_keep=1)\n", "            ckpt.restore(manager.latest_checkpoint).expect_partial()\n", "            if manager.latest_checkpoint:\n", "                print(f'|...> Generator restored from {manager.latest_checkpoint}')\n", "    if 0: # trainer\n", "        pass\n", "    elif 1: # train strat\n", "        print(f'|===> trainer')\n\n", "        # prepare distribute strategy\n", "        strategy = tf.distribute.MirroredStrategy()\n", "        global_batch_size = args.batch_size_per_replica * strategy.num_replicas_in_sync\n", "        print(f'|...> global_batch_size {global_batch_size}')   # 4\n", "        with strategy.scope():\n", "            # distribute dataset\n", "            dist_dataset = strategy.experimental_distribute_dataset(dataset)\n", "            name=f'stylegan2-{args.PROJECT}-{args.train_res}x{args.train_res}'\n", "            trainer = Trainer(training_parameters, name=name)\n", "            trainer.train(dist_dataset, strategy)\n", "    \n", "    elif 0: # train prestat\n", "        print(f'|===> train')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        name=f'stylegan2-{args.PROJECT}-{args.train_res}x{args.train_res}'\n", "        trainer = StyleGAN2(training_parameters, name=name)\n", "        trainer.train(dataset)\n\n", "    #   https://github.com/eladrich/pixel2style2pixel\n", "    if 0: # inference - apply the trained model on a set of images\n", "        args.exp_dir=args.results_dir    # path to experiment\n", "        args.checkpoint_path=os.path.join(args.models_dir, 'thismodel.h5')\n", "        args.data_path=args.data_dir\n", "        args.test_batch_size=4\n", "        args.test_workers=4\n", "        args.couple_outputs=1\n", "    if 0: # style_mixing - segmentation-to-image experiment\n", "        args.exp_dir=args.results_dir    # path to experiment\n", "        args.checkpoint_path=os.path.join(args.models_dir, 'thismodel.h5')\n", "        args.data_path=args.data_dir\n", "        args.test_batch_size=4\n", "        args.test_workers=4\n", "        args.n_images=25\n", "        args.n_outputs_to_generate=5\n", "        args.latent_mask=8,9,10,11,12,13,14,15,16,17"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<br>\n", "<br>\n", "<br>\n", "  MAIN<br>\n", "<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def main():\n", "    parser = argparse.ArgumentParser(description='Run \"python %(prog)s <subcommand> --help\" for subcommand help.')\n", "    onutil.dodrive()\n", "    ap = getap()\n", "    for p in ap:\n", "        cls = type(ap[p])\n", "        parser.add_argument('--'+p, type=cls, default=ap[p])\n", "    cmds = [key for key in globals() if key.startswith(\"nn\")]\n", "    primecmd = ap[\"primecmd\"]\n", "        \n", "    # ---------------------------------------------------------------\n", "    #   add subparsers\n", "    #\n", "    subparsers = parser.add_subparsers(help='subcommands', dest='command') # command - subparser\n", "    for cmd in cmds:\n", "        subparser = subparsers.add_parser(cmd, help='cmd')  # add subcommands\n", "    \n", "    subparsers_actions = [action for action in parser._actions\n", "        if isinstance(action, argparse._SubParsersAction)] # retrieve subparsers from parser\n", "  \n", "    for subparsers_action in subparsers_actions:  # add common       \n", "        for choice, subparser in subparsers_action.choices.items(): # get all subparsers and print help\n", "            for p in {}:  # subcommand args dict\n", "                cls = type(ap[p])\n", "                subparser.add_argument('--'+p, type=cls, default=ap[p])\n\n", "    # get args to pass to nn cmds\n", "    if onutil.incolab():\n", "        args = parser.parse_args('') #  defaults as args\n", "    else:\n", "        args = parser.parse_args() #  parse_arguments()\n", "    kwargs = vars(args)\n", "    subcmd = kwargs.pop('command')      \n", "    if subcmd is None:\n", "        print (f\"Missing subcommand. set to default {primecmd}\")\n", "        subcmd = primecmd\n", "    \n", "    for name in cmds:\n", "        if (subcmd == name):\n", "            print(f'|===> call {name}')\n", "            globals()[name](args, kwargs) # pass args to nn cmd\n", "#\n", "#\n", "#\n", "# python base/base.py nninfo\n", "if __name__ == \"__main__\":\n", "    print(\"|===>\", __name__)\n", "    main()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}