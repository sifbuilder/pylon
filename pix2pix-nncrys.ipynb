{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# -*- coding: utf-8 -*-\n", "# \n", "# # Copyright (c) 2019, NVIDIA Corporation. All rights reserved.\n", "#\n", "import os\n", "import io\n", "from io import StringIO\n", "import time\n", "import argparse\n", "import functools\n", "import errno\n", "import scipy\n", "import scipy.io\n", "import requests\n", "import zipfile\n", "import random\n", "import datetime\n", "#\n", "from functools import partial\n", "from importlib import import_module\n", "#\n", "import logging\n", "logging.getLogger('tensorflow').setLevel(logging.ERROR)\n", "#\n", "import numpy as np\n", "from numpy import *\n", "#\n", "import math\n", "from math import floor, log2\n", "from random import random\n", "from pylab import *\n", "from IPython.core.display import display\n", "import PIL\n", "from PIL import Image\n", "PIL.Image.MAX_IMAGE_PIXELS = 933120000\n", "#\n", "import scipy.ndimage as pyimg\n", "import cv2\n", "import imageio\n", "import glob\n", "import matplotlib as mpl\n", "import matplotlib.pyplot as plt \n", "import matplotlib.image as mgimg\n", "import matplotlib.animation as anim\n", "mpl.rcParams['figure.figsize'] = (12,12)\n", "mpl.rcParams['axes.grid'] = False\n", "#\n", "import shutil\n", "import gdown\n", "#\n", "import sys\n", "#\n", "import tensorflow as tf \n", "from tensorflow.keras import initializers, regularizers, constraints\n", "from tensorflow.keras import backend as K\n", "from tensorflow.keras import layers\n", "from tensorflow.keras.layers import Layer, InputSpec\n", "from tensorflow.keras.layers import BatchNormalization, Activation, ZeroPadding2D, UpSampling2D, Conv2D\n", "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout, LeakyReLU\n", "from tensorflow.keras.models import Sequential, Model\n", "from tensorflow.keras.optimizers import Adam\n", "from tensorflow.python.keras.utils import conv_utils\n", "#\n", "from tensorflow.keras.layers import Lambda\n", "from tensorflow.keras.layers import add\n", "from tensorflow.keras.layers import AveragePooling2D\n", "from tensorflow.keras.initializers import VarianceScaling\n", "from tensorflow.keras.models import clone_model\n", "from tensorflow.keras.models import model_from_json\n", "#\n", "from absl import app\n", "from absl import flags\n", "from absl import logging\n", "#\n", "tf.get_logger().setLevel('ERROR')\n", "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n", "#\n", "print(f'|===> {tf.__version__}')\n", "#\n", "if 1: # get base.py from github\n", "    cwd = os.getcwd()\n", "    base_path = os.path.join(cwd, 'base.py')\n", "    if not os.path.exists(base_path):\n", "        base_file = 'base.py'\n", "        urlfolder = 'https://raw.githubusercontent.com/sifbuilder/pylon/master/'\n", "        url = f'{urlfolder}{base_file}'\n", "        print(f\"|===> nnimg: get base file \\n \\\n", "            urlfolder: {urlfolder} \\n \\\n", "            url: {url} \\n \\\n", "            base_path: {base_path} \\n \\\n", "        \")\n", "        tofile = tf.keras.utils.get_file(f'{base_path}', origin=url, extract=True)\n", "    else:\n", "        print(f\"|===> base in cwd {cwd}\")\n", "#\n", "#\n", "#   FUNS\n", "#\n", "#\n", "# check if base.Onpyon is defined\n", "try:\n", "    var = Onpyon()\n", "except NameError:\n", "    sys.path.append('../')  # if called from eon, modules are in parallel folder\n", "    sys.path.append('./')  #  if called from dnns, modules are in folder\n", "    from base import *\n", "#\n", "onutil = Onutil()\n", "onplot = Onplot()\n", "onformat = Onformat()\n", "onfile = Onfile()\n", "onvid = Onvid()\n", "onimg = Onimg()\n", "ondata = Ondata()\n", "onset = Onset()\n", "onrecord = Onrecord()\n", "ontree = Ontree()\n", "onvgg = Onvgg()\n", "onlllyas = Onlllyas()\n", "#\n", "#\n", "#   CONTEXT\n", "#\n", "#\n", "#   get primary params\n", "#   may have been superceeded in the command lne\n", "#\n", "def getap():\n", "    cp = {\n", "        \"primecmd\": 'nncrys', # 'nncrys', #  \n", "        \"MNAME\": \"pix2pix\",\n", "        \"AUTHOR\": \"tensorflow2\",\n", "        \"PROJECT\": \"facades\",   # python pix2pix/pix2pix.py --PROJECT=facades --DATASET=facades nnfacades\n", "        \"GITPOD\": \"facades\",\n", "        \"DATASET\": \"facades\",\n", "        \"RESETCODE\": 0,\n", "        \"LOCALDATA\": 0,\n", "        \"LOCALMODELS\": 0,\n", "        \"LOCALLAB\": 1,\n", "        \"grel_infix\": '../..',            # relative path to content \n", "        \"net_prefix\": '//enas/hdrive',     \n", "        \"gdrive_prefix\": '/content/drive/My Drive',     \n", "        \"gcloud_prefix\": '/content',     \n", "    }\n", "    local_prefix = os.path.abspath('')\n", "    try:\n", "        local_prefix = os.path.dirname(os.path.realpath(__file__)) # script dir\n", "    except:\n", "        pass\n", "    cp[\"local_prefix\"] = local_prefix\n", "    \n", "    hp = {\n", "        \"verbose\": 1, # [0,n]\n", "        \"visual\": 1, # [0,n]\n\n", "        # train\n", "        \"batch_size\": 1,\n", "        \"img_width\": 256,\n", "        \"img_height\": 256,\n", "        \"buffer_size\": 1000,\n", "        \"input_channels\": 3,\n", "        \"output_channels\": 3,\n", "        \"max_epochs\": 200,\n", "        \"n_iterations\": 10, # iters for snapshot\n\n", "        # dataset.py args\n", "        \"input_folder\": './input/',\n", "        \"output_folder\": './output/',\n", "        \"keep_folder\": 0,\n", "        \"process_type\": 'resize',\n", "        \"blur_type\": \"\", # [\"\",\"gaussian\",\"median\"]\n", "        \"blur_amount\": 1,\n", "        \"max_size\": 256,\n", "        \"height\": 256,\n", "        \"width\": 256,\n", "        \"shift_y\": 0,\n", "        \"v_align\": 'center',\n", "        \"h_align\": 'center',\n", "        \"shift_x\": 0,\n", "        \"scale\": 2.0,\n", "        \"direction\": 'AtoB',\n", "        \"border_type\": 'stretch',\n", "        \"border_color\": '255,255,255',\n", "        \"mirror\": 0,\n", "        \"rotate\": 0,\n", "        \"file_extension\": 'png',\n\n", "        # var\n", "        \"name\": 0, # use counter\n", "        \"keep_name\": 0, # _e_\n", "        \"numbered\": 1, # _e_\n", "        \"zfill\": 4, # zfill name counter\n", "    }\n", "    ap = {}\n", "    for key in cp.keys():\n", "        ap[key] = cp[key]\n", "    for key in hp.keys():\n", "        ap[key] = hp[key]\n", "    return ap\n", "#\n", "#   get args within nnfun\n", "#   cp params may have been superceeded in nnfun\n", "#\n", "def getxp(cp):\n", "    yp={\n", "    }\n", "    xp={\n", "    }\n", "    for key in cp.keys():\n", "        xp[key] = cp[key]\n", "    tree = ontree.tree(cp)\n", "    for key in tree.keys():\n", "        xp[key] = tree[key]\n", "    for key in yp.keys():\n", "        xp[key] = yp[key]\n", "   \n", "    return xp\n", "#\n", "#\n", "#   FUNS SEGMENT\n", "#\n", "#   https://github.com/lllyasviel/DanbooRegion/blob/master/code/segment.py\n", "#\n", "#\n", "def go_vector(x):\n", "    return x[None, :, :, :]\n", "#\n", "def go_flipped_vector(x):\n", "    a = go_vector(x)\n", "    b = np.fliplr(go_vector(np.fliplr(x))) # numpy.fliplr(m: marray_like) -> fndarray\n", "    c = np.flipud(go_vector(np.flipud(x)))\n", "    d = np.flipud(np.fliplr(go_vector(np.flipud(np.fliplr(x)))))\n", "    return (a + b + c + d) / 4.0\n", "#\n", "def go_transposed_vector(x):\n", "    a = go_flipped_vector(x)\n", "    b = np.transpose(go_flipped_vector(np.transpose(x, [1, 0, 2])), [1, 0, 2])\n", "    return (a + b) / 2.0\n", "#\n", "def get_fill(image):\n", "    labeled_array, num_features = label(image / 255)\n", "    filled_area = onlllyas.find_all(labeled_array)\n", "    return filled_area\n", "#\n", "def up_fill(fills, cur_fill_map):\n", "    new_fillmap = cur_fill_map.copy()\n", "    padded_fillmap = np.pad(cur_fill_map, [[1, 1], [1, 1]], 'constant', constant_values=0)\n", "    max_id = np.max(cur_fill_map)\n", "    for item in fills:\n", "        points0 = padded_fillmap[(item[0] + 1, item[1] + 0)]\n", "        points1 = padded_fillmap[(item[0] + 1, item[1] + 2)]\n", "        points2 = padded_fillmap[(item[0] + 0, item[1] + 1)]\n", "        points3 = padded_fillmap[(item[0] + 2, item[1] + 1)]\n", "        all_points = np.concatenate([points0, points1, points2, points3], axis=0)\n", "        pointsets, pointcounts = np.unique(all_points[all_points > 0], return_counts=True)\n", "        if len(pointsets) == 1 and item[0].shape[0] < 128:\n", "            new_fillmap[item] = pointsets[0]\n", "        else:\n", "            max_id += 1\n", "            new_fillmap[item] = max_id\n", "    return new_fillmap\n", "#\n", "#\n", "#   NETS\n", "#\n", "#\n", "class GAN(object):\n", "    def __init__(self, \n", "    \n", "            models_dir = './',\n", "            logs_dir = './',\n", "            ckptidx = None,\n", "            ckpt_dir = './',\n", "            ckpt_prefix = 'ckpt-',\n", "            results_dir = './results',\n", "            input_shape = [256,256,3],\n", "            output_shape = [256,256,3],\n", "            visual = 1,\n", "            verbose = 1,\n", "    ):\n", "        print(f'|---> sg2pix2pix.GAN')\n", "        self.input_shape = input_shape\n", "        self.output_shape = output_shape\n", "        self.models_dir = models_dir\n", "        self.logs_dir = logs_dir\n", "        self.results_dir = results_dir\n", "        self.ckptidx = ckptidx\n", "        self.ckpt_dir = ckpt_dir\n", "        self.ckpt_prefix = ckpt_prefix\n", "        self.visual = visual\n", "        self.verbose = verbose\n", "        self.generator = self.Generator(input_shape=input_shape)\n", "        self.discriminator = self.Discriminator(output_shape=output_shape)   \n", "        self.generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n", "        self.discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n", "        self.step = tf.Variable(0)\n", "        self.checkpoint = tf.train.Checkpoint(\n", "            generator_optimizer=self.generator_optimizer,\n", "            discriminator_optimizer=self.discriminator_optimizer,\n", "            generator=self.generator,\n", "            discriminator=self.discriminator,\n", "            step=self.step\n", "        )\n", "        self.restore_checkpoint()\n\n", "    # Build the Generator\n", "    #     The architecture of generator is a modified U-Net.\n", "    #     Each block in the encoder is (Conv -> Batchnorm -> Leaky ReLU)\n", "    #     Each block in the decoder is (Transposed Conv -> Batchnorm -> Dropout(applied to the first 3 blocks) -> ReLU)\n", "    #     There are skip connections between the encoder and decoder (as in U-Net)\n", "    def Generator(self, input_shape=[256,256,3]):\n", "        print(f'|---> Generator instance with input_shape: {input_shape}')\n", "        inputs = tf.keras.layers.Input(input_shape)\n", "        down_stack = [\n", "            ondata.downsample(64, 4, apply_batchnorm=False), # (bs, 128, 128, 64)\n", "            ondata.downsample(128, 4), # (bs, 64, 64, 128)\n", "            ondata.downsample(256, 4), # (bs, 32, 32, 256)\n", "            ondata.downsample(512, 4), # (bs, 16, 16, 512)\n", "            ondata.downsample(512, 4), # (bs, 8, 8, 512)\n", "            ondata.downsample(512, 4), # (bs, 4, 4, 512)\n", "            ondata.downsample(512, 4), # (bs, 2, 2, 512)\n", "            ondata.downsample(512, 4), # (bs, 1, 1, 512)\n", "        ]\n", "        up_stack = [\n", "            ondata.upsample(512, 4, apply_dropout=True), # (bs, 2, 2, 1024)\n", "            ondata.upsample(512, 4, apply_dropout=True), # (bs, 4, 4, 1024)\n", "            ondata.upsample(512, 4, apply_dropout=True), # (bs, 8, 8, 1024)\n", "            ondata.upsample(512, 4), # (bs, 16, 16, 1024)\n", "            ondata.upsample(256, 4), # (bs, 32, 32, 512)\n", "            ondata.upsample(128, 4), # (bs, 64, 64, 256)\n", "            ondata.upsample(64, 4), # (bs, 128, 128, 128)\n", "        ]\n", "        initializer = tf.random_normal_initializer(0., 0.02)\n", "        last = tf.keras.layers.Conv2DTranspose(\n", "            3, # output_channels, # filters\n", "            4,  # kernel_size\n", "            strides=2,\n", "            padding='same',\n", "            kernel_initializer=initializer,\n", "            activation='tanh') # (bs, 256, 256, 3)\n\n", "        # concat = tf.keras.layers.Concatenate()\n\n", "        # inputs = tf.keras.layers.Input(input_shape=[None, None, 3])\n", "        x = inputs\n\n", "        # Downsampling through the model\n", "        skips = []\n", "        for down in down_stack:\n", "                x = down(x)\n", "                skips.append(x)\n", "        skips = reversed(skips[:-1])\n\n", "        # Upsampling and establishing the skip connections\n", "        for up, skip in zip(up_stack, skips):\n", "                x = up(x)\n", "                x = tf.keras.layers.Concatenate()([x, skip])\n", "        x = last(x)\n", "        return tf.keras.Model(inputs=inputs, outputs=x)\n", "    #\n", "    # Discriminator\n", "    #     The Discriminator is a PatchGAN.\n", "    #     Each block in the discriminator is (Conv -> BatchNorm -> Leaky ReLU)\n", "    #     The shape of the output after the last layer is (batch_size, 30, 30, 1)\n", "    #     Each 30x30 patch of the output classifies a 70x70 portion of the input image (such an architecture is called a PatchGAN).\n", "    #     Discriminator receives 2 inputs.\n", "    #         Input image and the target image, which it should classify as real.\n", "    #         Input image and the generated image (output of generator), which it should classify as fake.\n", "    #         We concatenate these 2 inputs together in the code (tf.concat([inp, tar], axis=-1))\n", "    #\n", "    def Discriminator(self, output_shape):\n", "            initializer = tf.random_normal_initializer(0., 0.02)\n", "            inp = tf.keras.layers.Input(shape=output_shape, name='output_image')\n", "            tar = tf.keras.layers.Input(shape=output_shape, name='target_image')\n", "            x = tf.keras.layers.concatenate([inp, tar]) # (bs, 256, 256, input_channels*2)\n", "            down1 = ondata.downsample(64, 4, False)(x) # (bs, 128, 128, 64)\n", "            down2 = ondata.downsample(128, 4)(down1) # (bs, 64, 64, 128)\n", "            down3 = ondata.downsample(256, 4)(down2) # (bs, 32, 32, 256)\n", "            zero_pad1 = tf.keras.layers.ZeroPadding2D()(down3) # (bs, 34, 34, 256)\n", "            conv = tf.keras.layers.Conv2D(512, 4, strides=1,\n", "                            kernel_initializer=initializer,\n", "                            use_bias=False)(zero_pad1) # (bs, 31, 31, 512)\n", "            batchnorm1 = tf.keras.layers.BatchNormalization()(conv)\n", "            leaky_relu = tf.keras.layers.LeakyReLU()(batchnorm1)\n", "            zero_pad2 = tf.keras.layers.ZeroPadding2D()(leaky_relu) # (bs, 33, 33, 512)\n", "            last = tf.keras.layers.Conv2D(1, 4, strides=1,\n", "                            kernel_initializer=initializer)(zero_pad2) # (bs, 30, 30, 1)\n", "            return tf.keras.Model(inputs=[inp, tar], outputs=last)\n", "    #\n", "    # discriminator loss\n", "    #     The discriminator loss function takes 2 inputs; real images, generated images\n", "    #     real_loss is a sigmoid cross entropy loss of the real images and an array of ones(since these are the real images)\n", "    #     generated_loss is a sigmoid cross entropy loss of the generated images and an array of zeros(since these are the fake images)\n", "    #     Then the total_loss is the sum of real_loss and the generated_loss\n", "    #\n", "    def discriminator_loss(self, disc_real_output, disc_generated_output,\n", "            loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n", "    ):\n", "        real_loss = loss_object(tf.ones_like(disc_real_output), disc_real_output)\n", "        generated_loss = loss_object(tf.zeros_like(disc_generated_output), disc_generated_output)\n", "        total_disc_loss = real_loss + generated_loss\n", "        return total_disc_loss\n\n", "    # generator loss\n", "    #     It is a sigmoid cross entropy loss of the generated images and an array of ones.\n", "    #     The paper also includes L1 loss which is MAE (mean absolute error) between the generated image and the target image.\n", "    #     This allows the generated image to become structurally similar to the target image.\n", "    #     The formula to calculate the total generator loss = gan_loss + LAMBDA * l1_loss, where LAMBDA = 100. This value was decided by the authors of the paper.\n", "    def generator_loss(self, disc_generated_output, gen_output, target, lda = 100, \n", "            loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n", "    ):\n", "        LAMBDA = lda # LAMBDA = 100\n", "        gan_loss = loss_object(tf.ones_like(disc_generated_output), disc_generated_output)\n\n", "        # mean absolute error\n", "        l1_loss = tf.reduce_mean(tf.abs(target - gen_output))\n", "        total_gen_loss = gan_loss + (LAMBDA * l1_loss)\n", "        return total_gen_loss, gan_loss, l1_loss\n", "    #\n", "    #\n", "    #            \n", "    # @tf.function\n", "    def train_step(self, input_image, target, epoch, summary_writer, args=None):\n", "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n", "            gen_output = self.generator(input_image, training=True)\n", "            disc_real_output = self.discriminator([input_image, target], training=True)\n", "            disc_generated_output = self.discriminator([input_image, gen_output], training=True)\n", "            gen_total_loss, gen_gan_loss, gen_l1_loss = self.generator_loss(disc_generated_output, gen_output, target)\n", "            disc_loss = self.discriminator_loss(disc_real_output, disc_generated_output)\n", "        generator_gradients = gen_tape.gradient(gen_total_loss, self.generator.trainable_variables)\n", "        discriminator_gradients = disc_tape.gradient(disc_loss, self.discriminator.trainable_variables)\n", "        self.generator_optimizer.apply_gradients(zip(generator_gradients, self.generator.trainable_variables))\n", "        self.discriminator_optimizer.apply_gradients(zip(discriminator_gradients, self.discriminator.trainable_variables))\n", "        with summary_writer.as_default():\n", "            tf.summary.scalar('gen_total_loss', gen_total_loss, step=epoch)\n", "            tf.summary.scalar('gen_gan_loss', gen_gan_loss, step=epoch)\n", "            tf.summary.scalar('gen_l1_loss', gen_l1_loss, step=epoch)\n", "            tf.summary.scalar('disc_loss', disc_loss, step=epoch)    \n", "    #\n", "    #\n", "    #\n", "    def fit(self, train_ds, test_ds=None, args = None, ):\n", "        max_epochs = args.max_epochs\n", "        n_iterations  = args.n_iterations\n", "        print(f'|---> fit \\n \\\n", "            max_epochs: {max_epochs} \\n \\\n", "            n_iterations: {n_iterations} \\n \\\n", "            test_ds: {1 if test_ds else 0} \\n \\\n", "        ')\n\n", "        # tensorboard\n", "        summary_writer = tf.summary.create_file_writer(\n", "            os.path.join(self.logs_dir, \"fit\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")))\n", "        for epoch in range(max_epochs):\n", "            start = time.time()\n\n", "            # \tSTEP per batches in dataset\n", "            for n, (input_image, target) in train_ds.enumerate():\n", "                ''' {np.shape(input_image)}\" (1, 512, 512, 3) '''\n", "                print('.', end='')\n", "                if (n+1) % 100 == 0:\n", "                    print() # cr after 100 interations\n", "                self.train_step(input_image, target, epoch, summary_writer, args)\n", "            print()\n", "          \n", "            # \tsave step (epoch)\n", "            self.step.assign_add(1)\n\n", "            # \tsave checkpoint\n", "            if (epoch + 1) % n_iterations == 1:\n", "                print(f'|... saving (checkpoint) the model every {n_iterations} max_epochs to {self.ckpt_prefix}')\n", "                file_prefix = os.path.join(self.ckpt_dir, self.ckpt_prefix)\n", "                self.checkpoint.save(file_prefix = file_prefix)\n", " \n", "            #   save generated images           \n", "            if 0 and test_ds and (epoch + 1) % n_iterations == 1:\n", "                print(f'|... savings images every for epoch {epoch}')\n", "                self.generate_images(test_ds, epoch, args)\n", "            print ('Time taken for epoch {} is {} sec\\n'.format(epoch + 1, time.time()-start))\n", "        file_prefix = os.path.join(self.ckpt_dir, self.ckpt_prefix)\n", "        self.checkpoint.save(file_prefix = file_prefix)\n", "    #\n", "    #\n", "    #\n", "    def generate_images(self, test_dataset, epoch, args=None ):\n", "        generator = self.generator\n", "        results_dir = self.results_dir\n", "        zfill = args.zfill\n", "        print(f\"|===> generate_images \\n \\\n", "            results_dir: {results_dir} \\n \\\n", "            zfill: {zfill} \\n \\\n", "        \")\n", "        idx = 0\n", "        for n, (img_input, img_target) in test_dataset.enumerate():\n", "            img_prediction = generator(img_input, training=True) # _e_\n", "            display_list = [\n", "                onformat.nnba_to_rgb(img_input),\n", "                onformat.nnba_to_rgb(img_target), \n", "                onformat.nnba_to_rgb(img_prediction)\n", "            ]\n", "            titles = ['Input Image', 'Ground Truth', 'Predicted Image']\n", "            if args.visual > 1:\n", "                    print(f'generated image {idx} in epoch {epoch}')\n", "                    onplot.pil_show_rgbs(display_list, scale=1, rows=1)   \n", "    \n", "            filename = f'{str(idx).zfill(zfill)}_{str(epoch).zfill(zfill)}.png'\n", "            if args.verbose > 2:\n", "                print(f'|===> generate_images save \\n \\\n", "                    n: {n} \\n \\\n", "                    idx: {idx} \\n \\\n", "                    results_dir: {results_dir} \\n \\\n", "                    filename: {filename} \\n \\\n", "                ')            \n", "            save_image_path = os.path.join(results_dir, filename)\n", "            onfile.rgbs_to_file(display_list, scale=1, rows=1, save_path=save_image_path)\n", "            idx += 1\n", "    #\n", "    #\n", "    #        \n", "    def restore_checkpoint(self, ckptidx=None, max_to_keep=5):\n", "        print(f'|===> model.restore_checkpoint \\n \\\n", "            self.checkpoint: {self.checkpoint} \\n \\\n", "            self.ckptidx: {self.ckptidx} \\n \\\n", "            self.ckpt_dir: {self.ckpt_dir} \\n \\\n", "            self.ckpt_prefix = {self.ckpt_prefix} \\n \\\n", "            max_to_keep: {max_to_keep} \\n \\\n", "        ')\n", "        self.ckpt_manager = ckpt_manager = tf.train.CheckpointManager(\n", "            self.checkpoint, \n", "            self.ckpt_dir, \n", "            max_to_keep=max_to_keep\n", "        )\n", "        # if a checkpoint exists, restore the latest checkpoint.\n", "        \n\n", "        # self.ckptidx: {None => last, ckptidx-n => n, ckptidx--n => none}\n", "        if self.ckptidx == None:\n", "            fromcheckpoint = ckpt_manager.latest_checkpoint\n", "            self.ckptidx = fromcheckpoint.split('-')[-1]\n", "            if self.verbose > 0: print(f'|... get latest ckpt: {self.ckptidx}')\n", "        elif int(self.ckptidx) < 0:\n", "            if self.verbose > 0: print(f'|... (self.ckptidx < 0) get no ckpt')\n", "            fromcheckpoint = None\n", "            self.ckptidx = fromcheckpoint\n", "        elif int(self.ckptidx) >= 0:\n", "            if self.verbose > 0: print(f'|... get ckpt {self.ckptidx}')\n", "            fromcheckpoint = os.path.join(self.ckpt_dir, f'{self.ckpt_prefix}{self.ckptidx}')\n", "            self.ckptidx = self.ckptidx\n", "        if fromcheckpoint:\n", "            self.checkpoint.restore(fromcheckpoint)\n", "            return fromcheckpoint\n", "        else:\n", "            return None\n", "#\n", "#\n", "#   FUNS PRJ\n", "#\n", "#\n", "def path_to_pair(path, height=None, width=None, exotor=1.0):\n", "    print(f\"|---> path_to_pair 11: {path}\")\t\n", "    imgs = path_to_decoded(path)\n", "    imgs = imgs_process(imgs, height, width, exotor)\n", "    return imgs\n", "#\n", "def paths_to_pair(paths, height=None, width=None, exotor=1.0):\n", "    print(f'|---> paths_to_pair (22): {paths}')\n", "    imgs = paths_to_decoded(paths)\n", "    imgs = imgs_process(imgs, height, width, exotor)\n", "    return imgs\n", "#\n", "def path_to_decoded(path, rate=0.5):\n", "    print(f'|---> path_to_decoded: {path}')\n", "    imgs = []\n", "    img = tf.io.read_file(path) # => dtype=string\n", "    if 0: \n", "        print(f'|... img: {type(img)} {np.shape(img)}')    \n", "    img = tf.image.decode_jpeg(img) # => shape=(256, 512, 3), dtype=uint8)\n", "    img = tf.cast(img, tf.float32)\n", "    w = tf.shape(img)[1]\n", "    w = w // 2\n", "    img1 = img[:, :w, :] # real comes left \n", "    imgs.append(img1)\n", "    img2 = img[:, w:, :] \n", "    imgs.append(img2)\n", "    return imgs\n", "#\n", "def paths_to_decoded(paths, rate=2):\n", "    print(f'|---> paths_to_decoded: {paths}')\n", "    imgs = []\n", "    for path in paths:\n", "        img = tf.io.read_file(path) # => dtype=string\n", "        if 0: \n", "            print(f'|... img: {type(img)} {np.shape(img)}')\n", "        img = tf.image.decode_jpeg(img) # => shape=(256, 512, 3), dtype=uint8)\n", "        img = tf.cast(img, tf.float32)\n", "        imgs.append(img)\n", "    return imgs\n", "#\n", "# Random jittering:\n", "# Resize an image to bigger height and width\n", "# Randomly crop to the target size\n", "# Randomly flip the image horizontally\n", "# the image is resized to 286 x 286 and then randomly cropped to 256 x 256\n", "#\n", "def probe_dataset_11(dataset, dst_dir):\n", "    print(f'|---> probe_dataset_11')\t\t\t\n", "    i = 0\n", "    for sample_inp, sample_re in dataset.take(3):\n", "        inp, re = sample_inp, sample_re\n", "        plt.figure()\n", "        plt.imshow(inp[0] * 0.5 + 0.5)\n", "        print(f'|... save to {i}_example_input.png')\n", "        plt.savefig(os.path.join(dst_dir, f'{i}_example_input.png'))\n", "        plt.figure()\n", "        plt.imshow(re[0] * 0.5 + 0.5)\n", "        print(f'|... save to {i}_example_target.png')        \n", "        plt.savefig(os.path.join(dst_dir, f'{i}_example_target.png'))\n", "        i += 1\n", "#\n", "def path_to_dataset_from_src(path, patt, \n", "        batch_size=None, height=None, width=None, buffer_size=None):\n", "    print(f'|---> path_to_dataset_from_src ')\n", "    if type(patt) == str:\n", "        print('|...> get files from one source: input and real in one file')\n", "        #dataset = path_to_dataset_11(path, patt, \n", "        dataset = paths_to_dataset(path, patt, \n", "            height=height, width=width, buffer_size=buffer_size, batch_size=batch_size)\n", "    elif isinstance(patt, list): \n", "        print('|...> get files from two sources')\n", "        #dataset = paths_to_dataset_22(path, patt, \n", "        dataset = paths_to_dataset(path, patt, \n", "            height=height, width=width, buffer_size=buffer_size, batch_size=batch_size)\n", "    return dataset\n", "#\n", "def paths_to_dataset(pths, patts, \n", "        batch_size=None, height=None, width=None, buffer_size=None,\n", "        exotor=1.2):\n", "    pathsIsArr = isinstance(pths, list)\n", "    pattsIsArr = isinstance(patts, list)\n", "    print(f'|---> paths_to_dataset:   \\n \\\n", "        pths: {pths} \\n \\\n", "        patts: {patts} \\n \\\n", "        height: {height} \\n \\\n", "        width: {width} \\n \\\n", "        buffer_size: {buffer_size} \\n \\\n", "        batch_size: {batch_size} \\n \\\n", "        pathsIsArr: {pathsIsArr} \\n \\\n", "        pattsIsArr: {pattsIsArr} \\n \\\n", "    ')\n", "    if pathsIsArr and pattsIsArr: # arrays 22 \n", "        print(f'|---> paths_to_dataset 22')\n", "        lti_two = (lambda x: paths_to_pair(x, height, width, exotor))\n", "        a = tf.data.Dataset.list_files(os.path.join(pths[0], patts[0]), shuffle=False)\n", "        b = tf.data.Dataset.list_files(os.path.join(pths[1], patts[1]), shuffle=False)\n", "        c = tf.data.Dataset.zip((a, b))\n\n", "        # each element in the dataset is a list of two imgs\n", "        dataset = c.map(lambda x,y: lti_two([x,y]), num_parallel_calls=tf.data.experimental.AUTOTUNE)\n", "    elif not pathsIsArr and not pattsIsArr: # not arrays 11\n", "        print(f'|---> paths_to_dataset 11')\n", "        lti_one = (lambda x: path_to_pair(x, height, width))\n", "        c = tf.data.Dataset.list_files(os.path.join(pths, patts))\n\n", "        # each element in the dataset is a file with two imgs\n", "        dataset = c.map(lambda x: lti_one(x), num_parallel_calls=tf.data.experimental.AUTOTUNE)\n", "    dataset = dataset.batch(batch_size)\n", "    if 1: # list batches\n", "        for n, (inp, re) in dataset.enumerate():\n", "            ''' {np.shape(input_image)}\" (n, 512, 512, 3) '''\n", "            if n < 2:\n", "                print(f'|... path_to_dataset batch {n}: {np.shape(inp)} {np.shape(re)}')\n", "    return dataset\n", "#\n", "def path_process(path, height=256, width=256, exotor=1.0, flip=0):\n", "    print(f'|---> path_process')\n", "    img = tf.io.read_file(path)\n", "    img = tf.image.decode_jpeg(img)\n", "    img = tf.cast(img, tf.float32)\n", "    img = img_process(img, height, width, exotor, flip)\n", "    return img\n", "#\n", "def img_process(img, height=256, width=256, exotor=1.0, flip=0):\n", "    print(f'|---> img_process')\n", "    img = tnua_resize(img, int(exotor * height), int(exotor * width))\n", "    img = img_crop(img, height, width)\n", "    if flip > 0:\n", "        img = img_random_flip(img)\n", "    img = onformat.rgb_to_nba(img)  \n", "    return img\n", "#\n", "def imgs_process(imgs, height=256, width=256, exotor=1.0, flip=0):\n", "    print(f'|---> imgs_process')\n", "    imgs = imgs_resize_with_tf(imgs, int(exotor * height), int(exotor * width))\n", "    imgs = imgs_crop_random(imgs, height, width)\n", "    if flip > 0:\n", "        imgs = imgs_random_flip(imgs)\n", "    imgs = onformat.rgbs_to_nbas(imgs)\n", "    return imgs\n", "#\n", "def tnua_resize(img, height, width, method=tf.image.ResizeMethod.NEAREST_NEIGHBOR):\n", "    print(f'|---> tnua_resize {np.shape(img)} ')\t\t\t\n", "    img = tf.image.resize(img, [height, width],\n", "        method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n", "    return img\n", "#\n", "def imgs_resize_with_tf(imgs, height, width, method=tf.image.ResizeMethod.AREA):\n", "    print(f'|---> imgs_resize_with_tf: {np.shape(imgs)}')\t\n", "    res = []\n", "    for i,img in enumerate(imgs):\n", "        print(f'|... imgs_resize_with_tf {i} {np.shape(img)}')\n", "        img = tnua_resize(img, height, width, method)\n", "        res.append(img)\t\t\n", "    return res\n", "#\n", "def img_crop(img, height, width):\n", "    imgs = [img]\n", "    print(f'|---> img_crop: {np.shape(imgs)}')\t\n", "    stacked_image = tf.stack(imgs, axis=0)\n", "    b = len(imgs)\n", "    cropped_image = tf.image.random_crop(\n", "        stacked_image, size=[b, height, width, 3])\n", "    return cropped_image[0] # _e_\n", "#\n", "def img_crop_random(img, height, width):\n", "    shape = np.shape(img)\n", "    print(f'|---> img_crop_random {shape}, {height}, {width}')\n", "    \t\n", "    img = tf.image.random_crop(img, size=[height, width, 3])\n", "    print(f'|... img_crop_random {np.shape(img)}, {height}, {width}')\t\n", "    return img\n", "#\n", "def imgs_crop_random(imgs, height, width):\n", "    print(f'|---> imgs_crop_random: {np.shape(imgs)}')\t\n", "    stacked_images = tf.stack(imgs, axis=0)\n", "    b = len(imgs)\n", "    cropped_images = tf.image.random_crop( # Tensor\n", "        stacked_images, size=[b, height, width, 3])\n", "    res = cropped_images[0], cropped_images[1]  # _e_\n", "    return res\n", "#\n", "def img_random_flip(img):\n", "    imgs = [img]\n", "    imgs = imgs_random_flip(imgs)\n", "    return imgs[0]\n", "#\n", "def imgs_random_flip(imgs):\n", "    print(f'|---> imgs_random_flip')\t\n", "    _imgs = []\n", "    if tf.random.uniform(()) > 0.5: # random mirroring\n", "        for item in imgs:\n", "            item = tf.image.flip_left_right(item)\n", "            _imgs.append(item)\n", "    return imgs\n", "#\n", "def img_jitter_random(img, height, width):\n", "    print(f'|---> img_jitter_random {np.shape(img)}')\t\t\n", "    img = img_crop_random(img, height, width)\n", "    return img\n", "#\n", "# https://github.com/phillipi/pix2pix\n", "def load_predefined_image_data_by_task_name(task_name,\n", "                                            predefined_task_name_list=None,):\n", "    \"\"\"Data from https://people.eecs.berkeley.edu/~tinghuiz/projects/pix2pix/datasets/\n", "    View sample images here, https://github.com/yuanxiaosc/DeepNude-an-Image-to-Image-technology/tree/master/Pix2Pix\"\"\"\n", "    print(f\"|---> load_predefined_image_data_by_task_name: {task_name}\") \n", "    if task_name in predefined_task_name_list: # 'edges2shoes.tar.gz'\n", "        _URL = f'https://people.eecs.berkeley.edu/~tinghuiz/projects/pix2pix/datasets/{task_name}.tar.gz'\n", "        path_to_zip = tf.keras.utils.get_file(f'{task_name}.tar.gz', origin=_URL, extract=True)\n", "        PATH = os.path.join(os.path.dirname(path_to_zip), f'{task_name}/')\n", "        print(f\"Store {task_name} raw data to {PATH}\")\n", "    else:\n", "        raise ValueError(f\"Predefined tasks do not include this {task_name} task!\")\n", "    return PATH\n", "#\n", "def download_and_processing_pix2pix_dataset(data_dir_or_predefined_task_name=None,\n", "                                            predefined_task_name_list=None,\n", "                                            args=None):\n", "    print(f'|---> download_and_processing_pix2pix_dataset: {data_dir_or_predefined_task_name}')\n", "    if data_dir_or_predefined_task_name in predefined_task_name_list:\n", "        PATH = load_predefined_image_data_by_task_name(\n", "                data_dir_or_predefined_task_name,\n", "                predefined_task_name_list,\n", "                )\n", "        print(\"|... prepare data from task_name\")\n", "    elif os.path.exists(data_dir_or_predefined_task_name):\n", "        PATH = data_dir_or_predefined_task_name\n", "        print(\"|... prepare data from data_dir\")\n", "    else:\n", "        raise ValueError(\"Task_name error and data_dir does not exist!\")\n", "#\n", "#\n", "#   CMDS\n", "#\n", "#    ref: https://github.com/NVIDIA/pix2pixHD\n", "#    ref: https://www.tensorflow.org/tutorials/generative/pix2pix\n", "#\n", "#   nnzip\n", "#   \n", "def nnzip(args, kwargs):\n", "    args = onutil.pargs(vars(args))\n", "    args.PROJECT = 'enzip'\n", "    args.DATASET = 'facades'\n", "    xp = getxp(vars(args))\n", "    args = onutil.pargs(xp)\n", "    onutil.ddict(vars(args), 'args')\n", "    print(f\"|---> nnzip: {args.PROJECT}:   \\n \")\n", "    if 1: # tree\n", "        args.dataorg_train_dir = os.path.join(args.dataorg_dir, 'train')\n", "        args.dataorg_test_dir = os.path.join(args.dataorg_dir, 'test')\n", "        assert(os.path.exists(args.dataorg_dir))\n", "        assert(os.path.exists(args.dataorg_train_dir))\n", "        assert(os.path.exists(args.dataorg_test_dir))\n", "        args.ckpt_dir = args.models_dir\n", "        ''' train/test images in origin with pattern '''\n", "        args.data_train_B_dir = os.path.join(args.data_dir, 'train_B')\n", "        args.data_train_A_dir = os.path.join(args.data_dir, 'train_A')\n", "        args.data_test_B_dir = os.path.join(args.data_dir, 'test_B')\n", "        args.data_test_A_dir = os.path.join(args.data_dir, 'test_A')\n", "        args.dataset_train_B_dir = os.path.join(args.dataset_dir, 'train_B')\n", "        args.dataset_train_A_dir = os.path.join(args.dataset_dir, 'train_A')\n", "        args.dataset_test_B_dir = os.path.join(args.dataset_dir, 'test_B')\n", "        args.dataset_test_A_dir = os.path.join(args.dataset_dir, 'test_A')\n", "        args.zipfile = os.path.join(args.dataorg_dir, f'{args.DATASET}.zip')\n", "        os.makedirs(args.data_train_B_dir, exist_ok=True) \n", "        os.makedirs(args.data_train_A_dir, exist_ok=True) \n", "        os.makedirs(args.data_test_B_dir, exist_ok=True) \n", "        os.makedirs(args.data_test_A_dir, exist_ok=True) \n", "        os.makedirs(args.dataset_train_B_dir, exist_ok=True) \n", "        os.makedirs(args.dataset_train_A_dir, exist_ok=True) \n", "        os.makedirs(args.dataset_test_B_dir, exist_ok=True) \n", "        os.makedirs(args.dataset_test_A_dir, exist_ok=True) \n", "        os.makedirs(args.models_dir, exist_ok=True)\n", "        os.makedirs(args.logs_dir, exist_ok=True)\n", "        os.makedirs(args.tmp_dir, exist_ok=True)\n", "    if args.verbose: print(f\"|---> tree: {args.PROJECT}:   \\n \\\n", "        args.PROJECT:    \t  {args.PROJECT} \\n \\\n", "        args.DATASET:    \t  {args.DATASET} \\n \\\n", "        cwd:     \t\t\t\t{os.getcwd()} \\n \\\n", "        args.dataorg_dir:     {args.dataorg_dir} \\n \\\n", "        args.dataorg_train_dir: {args.dataorg_train_dir} \\n \\\n", "        args.dataorg_test_dir: {args.dataorg_test_dir} \\n \\\n", "        args.ckpt_dir:  {args.ckpt_dir} \\n \\\n", "        args.logs_dir:        {args.logs_dir} \\n \\\n", "        args.tmp_dir:        {args.tmp_dir} \\n \\\n", "        args.zipfile:         {args.zipfile} \\n \\\n", "        args.verbose:         {args.verbose}, \\n \\\n", "        args.visual:          {args.visual}, \\n \\\n", "    \")\n", "    if 1: # config\n", "        args.height = args.img_height\n", "        args.width = args.img_width\n", "        args.buffer_size = args.buffer_size\n", "        args.batch_size = args.batch_size\n", "        args.input_channels = args.input_channels\n", "        args.input_shape = [args.height, args.width, args.input_channels]\n", "        if 0:\n", "            ''' copy org to same data folder'''\n", "            args.patts = ['*in.png', '*re.png']\n", "        else:\n", "            ''' will separate images in data'''\n", "            args.patts = ['*.png', '*.png']\n", "    if args.verbose: print(f\"|---> nnleonardo config:   \\n \\\n", "        args.max_epochs:            {args.max_epochs}, \\n \\\n", "        args.output_channels:\t{args.output_channels} \\n \\\n", "        args.height: \t\t\t{args.height} \\n \\\n", "        args.width: \t\t\t{args.width} \\n \\\n", "        args.input_channels: \t{args.input_channels} \\n \\\n", "        args.buffer_size: \t\t{args.buffer_size} \\n \\\n", "        args.batch_size: \t\t{args.batch_size} \\n \\\n", "        args.input_shape: \t\t{args.input_shape} \\n \\\n", "        args.patts:     \t\t{args.patts}, \\n \\\n", "    \")\n", "    if 1: # remote data to local\n\n", "        #args.DATASET = 'facades'\n", "        dat = 'facades'\n", "        dats=['facades']\n", "        if 0: # create zip\n", "            tarfolder = os.path.join(args.data_dir, dat)\n", "            print(f'|===> create zip from {tarfolder} folder')\n", "            tarfile = os.path.join(args.data_dir, 'test.gz')\n", "            onutil.tenzip(tarfile, tarfolder)\n", "        print(f'|===> download google folder by id')\n", "        if 0: \n", "            URL='https://drive.google.com/drive/folders/'\n", "            gid = '1vTa_y5RYvzk6BPDXQ7HrXfhp8BgjzoKv'\n", "            onutil.gdownid(URL, gid, args.data_dir)\n", "        print(f'|===> download from a set of files on remote server')\n", "        print(f'|... chech that remote is url')\n", "        dats=['cityscapes', 'night2day', 'edges2handbags', 'edges2shoes', 'facades', 'maps']\n", "        url = 'http://efrosgans.eecs.berkeley.edu/pix2pix/datasets'\n", "        #url = args.dataorg_dir\n", "        zexts = ['.tar.gz', '.tar', '.tgz', '.zip']\n", "        print(f'|... chech that remote is path')\n", "        local_tar_path = None\n", "        if 1:\n", "            print(f'|... look for tar in local site {args.data_dir}')\t\t\n", "            print(len(dats), len(zexts))\n", "            it1 = ((i, j) for i in range(len(dats)) for j in range(len(zexts)))\n", "            for i, j in it1:\n", "                dat_path = os.path.join(args.data_dir, f'{dats[i]}{zexts[j]}')\n", "                print(f'|.... look for {dat_path}')\n", "                if os.path.exists(dat_path):\n", "                    local_tar_path = dat_path\n", "                    print(f'|.... local {dat_path} already EXISTS !!! ')\n", "                    break\n", "        remote_tar_path = None\n", "        if not local_tar_path:\n", "            print(f'|... look for tar in remote site {args.dataorg_dir}')\t\n", "            print(len(dats), len(zexts))\n", "            it2 = ((i, j) for i in range(len(dats)) for j in range(len(zexts)))\n", "            for i, j in it2:\n", "                dat_path = os.path.join(args.gdata, f'{dats[i]}{zexts[j]}')\n", "                if os.path.exists(dat_path):\n", "                    remote_tar_path = dat_path\n", "                    print(f'|... remote {dat_path} already EXISTS !!! ')\n", "                    break\n", "        print(f'|... local_tar_path EXISTS : {local_tar_path}')\n", "        print(f'|... remote_tar_path EXISTS : {remote_tar_path}')\n", "        if remote_tar_path and not local_tar_path:\n", "            print(f'|===> remote {remote_tar_path} to local {local_tar_path}')\n", "            tarname = os.path.basename(os.path.normpath(remote_tar_path))\n", "            print(tarname)\n", "            local_tar_path = os.path.join(args.data_dir, tarname)\n", "            print(f'|... copy {remote_tar_path} to {local_tar_path}')\n", "            from shutil import copyfile\n", "            copyfile(remote_tar_path, local_tar_path)\n", "        if local_tar_path:\n", "            print(\"|... unzip to data\")\n", "            tree_root = None\n", "            print(f'|... unzip to data local_tar_path {local_tar_path}')\n", "            # onutil.gunzip(file_basename, file_id, destination, results_dir)\n", "            onutil.tunzip(None, local_tar_path, args.data_dir, tree_root)\n", "    \n", "        # check data folder\n", "        untarfolder = os.path.join(args.data_dir, dat)\n", "        print(f'|... untar folder {untarfolder} exists\" {os.path.exists(untarfolder)}')\n", "#\n", "#\n", "#   nndanboo\n", "#\n", "#   https://github.com/lllyasviel/DanbooRegion\n", "#       InProceedings=DanbooRegion2020\n", "#       author=Lvmin Zhang, Yi JI, and Chunping Liu\n", "#       booktitle=European Conference on Computer Vision (ECCV)\n", "#       title=DanbooRegion: An Illustration Region Dataset\n", "#       year=2020\n", "#\n", "def nndanboo(args, kwargs):\n", "    \n", "    args = onutil.pargs(vars(args))\n", "    args.AUTHOR = 'lllyasviel'\n", "    args.GITPOD = 'DanbooRegion'\n", "    if onutil.incolab():\n", "        args.PROJECT = 'nndanboo'\n", "        args.DATASET = 'DanbooRegion2020'\n", "    else:\n", "        args.PROJECT = 'danregion'\n", "        args.DATASET = 'danregion' # 'DanbooRegion2020'\n", "    xp = getxp(vars(args))\n", "    args = onutil.pargs(xp)\n", "    onutil.ddict(vars(args), 'args')\n", "    if args.verbose > 0: print(f\"|===> nndanboo: {args.PROJECT}  \\n \")\n", "    if 1: # tree\n", "        # [1] https://github.com/lllyasviel/DanbooRegion\n", "        # [2] https://drive.google.com/drive/folders/1ihLt6P7UQRlaFtZUEclXkWC9grmEXEUK?usp=sharing\n", "        assert(os.path.exists(args.dataorg_dir))\n", "        args.dataorg_train_dir = os.path.join(args.dataorg_dir, 'train')\n", "        args.dataorg_test_dir = os.path.join(args.dataorg_dir, 'test')\n", "        args.download_dir = os.path.join(args.proj_dir, 'download')\n", "        args.results_dir = os.path.join(args.proj_dir, 'results') # in project dir\n", "        args.code_dir = os.path.join(args.proj_dir, 'code') # inside project dir\n", "        args.data_train_dir = os.path.join(args.data_dir, 'train')\n", "        args.data_test_dir = os.path.join(args.data_dir, 'test')\n", "        args.data_val_dir = os.path.join(args.data_dir, 'val')\n", "        if onutil.incolab():\n", "            args.ckpt_dir = args.models_dir\n", "        else:\n", "            _glab = os.path.join(args.gdata, '../glab/', args.MNAME, args.PROJECT)\n", "            args.ckpt_dir = os.path.normpath(os.path.join(_glab, 'Models'))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        args.data_dir = os.path.join(args.data_dir, '') # in project dir\n", "        args.data_train_pict_dir = os.path.join(args.data_train_dir, 'pict')\n", "        args.data_train_draw_dir = os.path.join(args.data_train_dir, 'draw')\n", "        args.data_test_pict_dir = os.path.join(args.data_test_dir, 'pict')\n", "        args.data_test_draw_dir = os.path.join(args.data_test_dir, 'draw')\n", "        args.data_test_predict_dir = os.path.join(args.data_test_dir, 'predict')\n", "        if args.verbose > 0: print(f\"|---> nndanboo tree:  \\n \\\n", "        cwd: {os.getcwd()} \\n \\\n", "        args.proto_dir: {args.proto_dir} \\n \\\n", "        args.code_dir: {args.code_dir} \\n \\\n", "        args.ckpt_dir: (ckpt-*) {args.ckpt_dir} \\n \\\n", "        \\n \\\n", "        args.dataorg_dir: {args.dataorg_dir}, {onfile.qfiles(args.dataorg_dir, '*.png')}\\n \\\n", "        args.dataorg_train_dir: {args.dataorg_train_dir}, {onfile.qfiles(args.dataorg_train_dir, '*.png')}\\n \\\n", "        args.dataorg_test_dir: {args.dataorg_test_dir}, {onfile.qfiles(args.dataorg_test_dir, '*.png')}\\n \\\n", "        \\n \\\n", "        args.data_dir: {args.data_dir}, \\n \\\n", "        args.data_train_dir: (png.s) {args.data_train_dir}, {onfile.qfiles(args.data_train_dir, '*.png')}\\n \\\n", "        args.data_train_dir (image.s): {args.data_train_dir}, {onfile.qfiles(args.data_train_dir, '*.image.png')} \\n \\\n", "        args.data_train_dir (region.s): {args.data_train_dir}, {onfile.qfiles(args.data_train_dir, '*.region.png')} \\n \\\n", "        args.data_train_dir (skel.s): {args.data_train_dir}, {onfile.qfiles(args.data_train_dir, '*.skeleton.png')} \\n \\\n", "        args.data_test_dir (png.s): {args.data_test_dir}, {onfile.qfiles(args.data_test_dir, '*.png')}\\n \\\n", "        args.data_val_dir (png.s): {args.data_val_dir}, {onfile.qfiles(args.data_val_dir, '*.png')}\\n \\\n", "        \")\n", "        args.dataorg_dir = os.path.join(args.dataorg_dir, '')\n", "        if not os.path.exists(args.dataorg_dir):\n", "            if args.verbose > 0: print(f'org data missing \\n \\\n", "                the org data folder: {args.dataorg_dir} was not found !!! \\n \\\n", "                set args.dataorg_dir if needed and \\n \\\n", "                download the dataset following instructions in \\n \\\n", "                    https://github.com/lllyasviel/DanbooRegion : \\n \\\n", "                Download the dataset from:\\n \\\n", "                    https://drive.google.com/drive/folders/1ihLt6P7UQRlaFtZUEclXkWC9grmEXEUK?usp=sharing\\n \\\n", "                For linux then run: (Windows does not need this step.)\\n \\\n", "                    cat DanbooRegion2020.zip.* > DanbooRegion2020.zip\\n \\\n", "                    zip -FF DanbooRegion2020.zip --out DanbooRegion2020_FF.zip\\n \\\n", "                    unzip DanbooRegion2020_FF.zip\\n \\\n", "            ')\n", "            exit()\n", "        os.makedirs(args.proj_dir, exist_ok=True) \n", "        os.makedirs(args.code_dir, exist_ok=True) \n", "        os.makedirs(args.results_dir, exist_ok=True) \n", "        os.makedirs(args.download_dir, exist_ok=True) \n", "        os.makedirs(args.data_train_dir, exist_ok=True) \n", "        os.makedirs(args.data_train_pict_dir, exist_ok=True) \n", "        os.makedirs(args.data_train_draw_dir, exist_ok=True) \n", "        os.makedirs(args.data_test_dir, exist_ok=True) \n", "        os.makedirs(args.data_test_pict_dir, exist_ok=True) \n", "        os.makedirs(args.data_test_draw_dir, exist_ok=True) \n", "        os.makedirs(args.data_test_predict_dir, exist_ok=True) \n", "    if 1: # config\n", "        args.ckpt_prefix = 'ckpt-'\n", "        args.dim = 512\n", "        args.show_size = 512\n", "        args.height = 512\n", "        args.width = 512\n", "        args.max_size = None # control set resize\n", "        args.buffer_size = 10000\n", "        args.batch_size = 1\n", "        args.max_epochs = 601\n", "        args.gpu = 1 # _e_\n", "        args.input_shape = [args.height, args.width, args.input_channels]\t\t\n", "    if args.verbose > 0: print(f\"|---> nndanboo config:  \\n \\\n", "        args.show_size: {args.show_size}, \\n \\\n", "        args.batch_size: {args.batch_size}, \\n \\\n", "        args.gpu: {args.gpu}, \\n \\\n", "        args.height: {args.height}, \\n \\\n", "        args.width: {args.width}, \\n \\\n", "        args.buffer_size: {args.buffer_size}, \\n \\\n", "        args.batch_size: {args.batch_size}, \\n \\\n", "        args.input_shape: {args.input_shape}, \\n \\\n", "    \")\n", "    #\n", "    #\n", "    if 1: # git\n", "        onutil.get_git(args.AUTHOR, args.GITPOD, args.code_dir)\n", "    #\n", "    #\n", "    assert os.path.exists(args.code_dir), \"code_dir not found\"        \n", "    os.chdir(args.code_dir) # _e_ not std\n", "    #\n", "    #\n", "    # visualize region image with image color map\n", "    #\n", "    if args.visual > 1: \n", "        if 0: # py command\n", "            cmd = f\"python visualize.py ./X.image.png ./X.region.png\"\n", "            print(\"cmd %s\" %cmd)\n", "            os.system(cmd)\n", "        else: # cv2\n", "            color_map = cv2.imread('./X.image.png') # _e_\n", "            region_map = cv2.imread('./X.region.png')\n", "            cv2.imshow('vis', onlllyas.vis(region_map, color_map))\n", "            cv2.waitKey(0)\n", "    #\n", "    #\n", "    #\n", "    if 1: # org to _train_ data \n", "        if args.verbose > 0: print(f'|---> nndanregion: org => data train \\n \\\n", "            \\n \\\n", "            org image: {onfile.qfiles(args.dataorg_train_dir, \"*.png\")} \\n \\\n", "            train: {onfile.qfiles(args.data_train_pict_dir, \"*.png\")} \\n \\\n", "        ')\n", "        args.keep_folder=True    \n", "        args.process_type='resize'\n", "        args.file_extension= 'png'\n", "        args.name=1 # if 0: calculate name on index\n", "        args.input_folder = args.dataorg_train_dir\n", "        args.filepatt = f'.*{args.file_extension}'\n", "        args.output_folder = args.data_train_pict_dir\n", "        qinfiles = onfile.qfiles(args.input_folder, f'*{args.file_extension}')\n", "        qoutfiles = onfile.qfiles(args.output_folder)\n", "        if args.verbose > 0: print(f\"|---> nndanregion train copy: {args.process_type} \\n \\\n", "            {args.input_folder} (q: {qinfiles})  \\n \\\n", "            \\t ==> {args.output_folder} (q: {qoutfiles}) \\n \\\n", "        \")\n\n", "        # count max and exclude list _e_\n", "        if  qinfiles > qoutfiles:\n", "            print(f'|... processFolder from ({qinfiles}) onto ({qoutfiles}) files ')\n", "            args.exclude = [os.path.basename(item) for item in onfile.path_to_paths(args.output_folder)]\n", "            if args.verbose > 2: \n", "                print(args.exclude)\n", "            onset.processFolder(args) # copy inputs to train\n", "        else:\n", "            print(f'|... train no processFolder !!!!. files already there ')\n", "    #\n", "    #\n", "    #\n", "    if 1: # org to _test_ data \n", "        if args.verbose > 0: print(f'|---> nndanregion org test to data q: \\n \\\n", "            org image: {onfile.qfiles(args.dataorg_test_dir, \"*.png\")} \\n \\\n", "            test re: {onfile.qfiles(args.data_test_pict_dir, \"*.png\")} \\n \\\n", "        ')\n", "        args.keep_folder=True    \n", "        args.process_type='resize' # just copy\n", "        args.file_extension= 'png'\n", "        args.name=1\n", "        args.zfill=4\n", "        args.input_folder = args.dataorg_test_dir\n", "        args.filepatt = f'.*{args.file_extension}'\n", "        args.output_folder = args.data_test_pict_dir\n", "        qinfiles = onfile.qfiles(args.input_folder, f'*{args.file_extension}')\n", "        qoutfiles = onfile.qfiles(args.output_folder)\n", "        print(f\"|---> test copy: {args.process_type} \\n \\\n", "            {args.input_folder} (q: {qinfiles})  \\n \\\n", "            \\t ==> {args.output_folder} (q: {qoutfiles}) \\n \\\n", "        \")\n", "        if  qinfiles > qoutfiles:\n", "            args.exclude = [os.path.basename(item) for item in onfile.path_to_paths(args.output_folder)]\n", "            onset.processFolder(args) # copy inputs to test\n", "        else:\n", "            print(f'|... test no processFolder !!!!. files already there ')\n", "    #\n", "    #\n", "    #\n", "    if 0: # probe images to skeletons\n", "        basename = 'region_test.png'\n", "        imgpath = os.path.join(args.code_dir, basename)\n", "        \n", "        print(f'|---> skeletonize test png \\n \\\n", "            cwd: {os.getcwd()} \\n \\\n", "            args.proto_dir: {args.proto_dir} \\n \\\n", "            args.code_dir: {args.code_dir} \\n \\\n", "            basename: {basename} \\n \\\n", "            imgpath: {imgpath} \\n \\\n", "        ')\n", "        from skimage.morphology import thin as skeletonize\n", "        if 0:\n", "            cmd = f\"python skeletonize.py {imgpath}\"\n", "            print(\"cmd %s\" %cmd)\n", "            os.system(cmd)\n", "        else:\n", "            region_map = cv2.imread(imgpath)\n", "            cv2.imshow(basename, onlllyas.get_skeleton(region_map, filterstrength=1.0))\n", "            cv2.waitKey(0)\n", "    #\n", "    #\n", "    #\n", "    if 1: # (train) data to skeletons\n", "        if args.verbose > 0: print(f'|===> skeletonize_all')\n", "        linpatts = ['*.region.png']\n", "        fromdir = args.data_train_pict_dir\n", "        input_region_train_paths = onfile.path_to_paths(fromdir, linpatts)\n", "        train_paths = input_region_train_paths[0:len(input_region_train_paths)]\n", "        qinfiles = len(train_paths)\n", "        todir = args.data_train_draw_dir\n", "        qoutfiles = onfile.qfiles(todir)\n", "        \n", "        filterstrengths = [5.0] # {1.0,5.0}\n", "        if args.verbose > 0: print(f'|...>  skeletonize_all \\n \\\n", "            from {fromdir} ({qinfiles}) \\n \\\n", "            to {todir} ({qoutfiles}) \\n \\\n", "            to filterstrengths: {filterstrengths} \\n \\\n", "        ')\n", "        for filterstrength in filterstrengths:\n", "            _todir = f'{todir}' # {int(filterstrength)}\n", "            os.makedirs(_todir, exist_ok=True)\n", "            loutpatt = f'.skeleton'\n", "            patt = f'*{loutpatt}*' # look for skels with strength\n", "            qoutfiles = onfile.qfiles(_todir, patt)\n", "            outprefixes = [os.path.basename(item).split('.')[0] for item in onfile.path_to_paths(_todir)]\n", "            if qinfiles > qoutfiles: # files in outdir with loutpatt\n", "                print(f'|...>  raw to data ({qinfiles}) to ({qoutfiles})')\n", "                for i,path in enumerate(train_paths):\n", "                    filename = os.path.basename(path)\n", "                    ext = filename.split('.')[-1]\t# maintain ext\n", "                    prefix = filename.split('.')[0] # get left to dot\n", "                    if prefix not in outprefixes: # exclude\n", "                        out_path = os.path.join(_todir,f'{prefix}{loutpatt}.{ext}',)\n", "                        region = cv2.imread(path)\n", "                        if 0: print(f'|...> skeleton  region  {np.shape(region)} to {_todir}')\n", "                        skeleton = onlllyas.get_skeleton(region, \n", "                            filterstrength=filterstrength\n", "                        )\n", "                        if 0: print(f'|...> skeleton  shape  {np.shape(skeleton)}')\n", "                        print(f'|...> write   {out_path}   {str(i + 1)} /{qinfiles}')\n", "                        skeleton = cv2.cvtColor(skeleton,cv2.COLOR_GRAY2RGB)\t\t\t\t\t\n", "                        cv2.imwrite(out_path, skeleton)\n", "                    else:\n", "                        print(f'prefix: {prefix} already in target')\n", "            else:\n", "                print(f'|... no process. out files {qoutfiles} in')\n", "    #\n", "    #\n", "    #\n", "    if 0: # skeletom to regions show\n", "        basename = 'danskel.jpg'\n", "        skeleton_path = os.path.join(args.code_dir, basename)\n", "        assert os.path.exists(skeleton_path), f\"skeleton_path {skeleton_path} does not exist\"\n", "        if args.verbose > 0: print(f'|---> skeletom to regions \\n \\\n", "            skeleton_path: {skeleton_path} \\n \\\n", "        ')\n\n", "        #skeleton_path = os.path.join(args.code_dir, 'skeleton_test.png')\n", "        skeleton_map = cv2.imread(skeleton_path)\n", "        img = onlllyas.skeleton_to_regions(skeleton_map)\n", "        if onutil.incolab():\n", "            from google.colab.patches import cv2_imshow\n", "            cv2_imshow(img)\n", "            cv2.waitKey(0)            \n", "        else:\n", "            cv2.imshow(basename, img)\n", "            cv2.waitKey(0)\n", "    #\n", "    #\n", "    #\n", "    if 1: # model\n", "        if args.verbose > 0: print(f'|===> model:   \\n \\\n", "            models_dir = {args.models_dir},\\n \\\n", "            logs_dir = {args.logs_dir},\\n \\\n", "            results_dir = {args.results_dir},\\n \\\n", "            ckpt_dir = {args.ckpt_dir},\\n \\\n", "            ckpt_prefix = {args.ckpt_prefix},\\n \\\n", "            input_shape = {args.input_shape},\\n \\\n", "            output_shape = {args.input_shape},\\n \\\n", "        ')\n", "        model = GAN(\n", "            models_dir = args.models_dir,\n", "            logs_dir = args.logs_dir,\n", "            results_dir = args.results_dir,\n", "            ckpt_dir = args.ckpt_dir,\n", "            ckpt_prefix = args.ckpt_prefix,\n", "            ckptidx = None  , # -1 : get no ckpt, None for latest\n", "            input_shape = args.input_shape,\n", "            output_shape = args.input_shape,\n", "        )\n", "    #\n", "    # 3. segment\n", "    #\n", "    if 1:\t# python segment.py ./emilia.jpg\n", "        path = os.path.join(args.code_dir, 'emilia.jpg')\n", "        path = os.path.join(args.code_dir, 'danimage.jpg')\n", "        path = os.path.join(args.code_dir, 'danskel.jpg')\n", "        assert os.path.exists(path), f'{path} could not be found'\n", "        basename = os.path.basename(path)\n", "        assert os.path.exists(path), f\"path {path} does not exist\"\n", "        if args.verbose: print(f'|---> segment \\n \\\n", "            basename: {basename} \\n \\\n", "            skeleton_path: {path} \\n \\\n", "        ')\n\n", "        # config\n", "        #\n", "        img1_max_size = 512\n", "        img2_max_size = 512\n", "        img1 = cv2.imread(path)\n", "        img1 = onlllyas.skeleton_to_regions(img1)\n", "        img1 = onlllyas.min_resize(img1, img1_max_size)\n", "        if 0: onplot.cv_img(img1, title=f'regions {basename}')\n\n", "        #raw_img = cv2.imread(path, cv2.IMREAD_GRAYSCALE) # go_srcnn\n", "        raw_img = cv2.imread(path) # go_srcnn\n", "        raw_img = onlllyas.min_resize(raw_img, img1_max_size)\n", "        if 0: onplot.cv_img(raw_img, title=f'raw_img {basename} ')\n\n", "        #raw_img = raw_img.clip(0, 255)\n", "        #raw_img = raw_img.astype(np.uint8) # (img1_max_size, img1_max_size, 3)\n", "        #if 0: onplot.pil_show_rgb(raw_img)\n\n", "        #pads = 7\n", "        #raw_img = raw_img[np.newaxis,:,:,:]\n", "        #raw_img = tf.pad(raw_img / 255.0, [[0, 0], [pads, pads], [pads, pads], [0, 0]], 'REFLECT')\n", "        #if 1: onplot.pil_show_nba(raw_img)\n", "        \n", "        #img1 = model.generator(raw_img, training=True)       \n", "        #img1 = img1[:, pads * 2:-pads * 2, pads * 2:-pads * 2, :][:, 1:-1, 1:-1, :] * 255.0\n", "        img1 = img1[np.newaxis,:,:,:]\n", "        img1 = model.generator(img1, training=True)\n", "        img_rgb = onformat.nnba_to_rgb(img1)\n", "        if 1: onplot.cv_img(img_rgb, title=f'gen rgb img1')            \n", "        img2 = onlllyas.min_resize(raw_img, img2_max_size)        \n", "        if 0: onplot.cv_img(img2, title=f'img2')\n", "        \n", "        transposed = onlllyas.go_transposed_vector(onlllyas.mk_resize(raw_img, 64))\n", "        height = onlllyas.d_resize(transposed, img2.shape) * 255.0\n", "        final_height = height.copy()\n", "        height += (height - cv2.GaussianBlur(height, (0, 0), 3.0)) * 10.0\n", "        height = height.clip(0, 255).astype(np.uint8)\n", "        if 1: onplot.cv_img(height, title=f'height')\n", "        marker = height.copy() # (img2_max_size, img2_max_size, 3)\n", "        marker[marker > 135] = 255\n", "        marker[marker < 255] = 0\n", "        marker = cv2.cvtColor(marker, cv2.COLOR_BGR2GRAY) # marker gray\n", "        fills = onlllyas.get_fill(marker / 255)\n", "        if 0:\n", "            print(f'segment fills: {fills}')\n\n", "        ## *********************************************\n", "        for fill in fills:\n", "            if fill[0].shape[0] < 64:\n", "                marker[fill] = 0\n", "        filter = np.array([\n", "            [0, 1, 0],\n", "            [1, 1, 1],\n", "            [0, 1, 0]],\n", "            dtype=np.uint8)\n", "        big_marker = cv2.erode(marker, filter, iterations=5)\n", "        fills = onlllyas.get_fill(big_marker / 255)\n", "        for fill in fills:\n", "            if fill[0].shape[0] < 64:\n", "                big_marker[fill] = 0\n", "        big_marker = cv2.dilate(big_marker, filter, iterations=5)\n", "        small_marker = marker.copy()\n", "        small_marker[big_marker > 127] = 0\n", "        fin_labels, nil = label(big_marker / 255)\n", "        fin_labels = up_fill(onlllyas.get_fill(small_marker), fin_labels)\n", "        water = cv2.watershed(img2.clip(0, 255).astype(np.uint8), fin_labels.astype(np.int32)) + 1\n", "        water = onlllyas.thinning(water)\n", "        all_region_indices = onlllyas.find_all(water)\n", "        regions = np.zeros_like(img2, dtype=np.uint8)\n", "        for region_indices in all_region_indices:\n", "            regions[region_indices] = np.random.randint(low=0, high=255, size=(3,)).clip(0, 255).astype(np.uint8)\n", "        result = np.zeros_like(img2, dtype=np.uint8)\n", "        for region_indices in all_region_indices:\n", "            result[region_indices] = np.median(img2[region_indices], axis=0)\n", "        \n", "        skeleton = final_height.clip(0, 255).astype(np.uint8)\n", "        region = regions.clip(0, 255).astype(np.uint8)\n", "        flatten = result.clip(0, 255).astype(np.uint8)\n", "        skeleton_path = os.path.join(args.results_dir, 'current_skeleton.png')\n", "        region_path = os.path.join(args.results_dir, 'current_region.png')\n", "        flatten_path = os.path.join(args.results_dir, 'current_flatten.png')\n", "        if 1: onplot.cv_img(skeleton, title=f'skeleton')\n", "        if 1: onplot.cv_img(region, title=f'region')\n", "        if 1: onplot.cv_img(flatten, title=f'flatten')\n", "        print(f'save {skeleton_path}')\n", "        print(f'save {region_path}')\n", "        print(f'save {flatten_path}')\n", "        cv2.imwrite(skeleton_path, skeleton)\n", "        cv2.imwrite(region_path, region)\n", "        cv2.imwrite(flatten_path, flatten)\n\n", "    # 3b. predict test images\n", "    \n", "    if 0:\t# \n", "        \n", "        paths = Onfile.folder_to_paths(args.data_test_pict_dir)\n", "        idx = 0\n", "        for n, path in enumerate(paths):\n", "            basename = os.path.basename(os.path.normpath(path))\n", "            print(f'|===> predict test images path {path}')\n\n", "            #img = tf.io.read_file(path)\n", "            #img = tf.image.decode_jpeg(img)\n", "            #img = tf.cast(img, tf.float32)\n", "            #img = tf.image.resize(img, [512, 512])\n", "            #img = onformat.rgb_to_nba(img)\n", "            #img = img[np.newaxis,:,:,:]\n", "            img = path_process(path, height=512, width=512)\n", "            img = img[np.newaxis,:,:,:]\n", "            img = model.generator(img, training=True) # _e_\n", "            img = onformat.nnba_to_rgb(img)\n", "            try:\n", "                from google.colab.patches import cv2_imshow\n", "                cv2_imshow(img)\n", "                cv2.waitKey(0)            \n", "            except:\n", "                cv2.imshow(basename, img)\n", "                cv2.waitKey(0)\n", "            save_image_path = os.path.join(args.data_test_predict_dir, basename)\n", "            print(f'|... save {save_image_path}')            \n", "            onfile.rgbs_to_file([img], scale=1, rows=1, save_path=save_image_path)\n", "    if 0: # train\n", "        if 1: #  data => dataset (train) # paths_to_dataset_22\n\n", "            #pths_train = [args.data_train_draw_dir, args.data_train_pict_dir]\n", "            #patts = ['*.skeleton.png', '*.region.png']\n", "            pths_train = [args.data_train_pict_dir, args.data_train_draw_dir]\n", "            patts = ['*.region.png', '*.skeleton.png']\n", "            print(f'|===> nndanregion train dataset:  \\n \\\n", "                pths_train {pths_train} \\n \\\n", "                train_draw ({onfile.qfiles(args.data_train_draw_dir, \"*.png\")}) \\n \\\n", "                train_pict ({onfile.qfiles(args.data_train_pict_dir, \"*.png\")}) \\n \\\n", "            ')\n\n", "            #train_dataset = paths_to_dataset_22(pths_train, patts, # BatchDataset\n", "            train_dataset = paths_to_dataset(pths_train, patts, # BatchDataset\n", "                height=args.height, width=args.width, \n", "                buffer_size=args.buffer_size, batch_size=args.batch_size)\n", "        if 1: #  data => dataset (test) --- # paths_to_dataset_22\n", "            print(f'|---> nndanregion datasets:  \\n \\\n", "                test_draw ({onfile.qfiles(args.data_test_draw_dir, \"*.png\")}) \\n \\\n", "                test_pict ({onfile.qfiles(args.data_test_pict_dir, \"*.png\")}) \\n \\\n", "            ')\n", "            if 0:\n", "                pths_test = [args.data_train_draw_dir, args.data_train_pict_dir]\n", "                patts = ['*.skeleton.png', '*.region.png']\n", "            else:\n", "                pths_test = [args.data_train_pict_dir, args.data_train_draw_dir]\n", "                patts = ['*.region.png', '*.skeleton.png']\n\n", "            #test_dataset = paths_to_dataset_22(pths_test, patts,\n", "            test_dataset = paths_to_dataset(pths_test, patts,\n", "                height=args.height, width=args.width, \n", "                buffer_size=args.buffer_size, batch_size=1) # 1 per batch in test dataset _e_\n", "        if 0: # probe train dataset\n", "            print(f'|===> probe nndanregion train dataset')\n", "            for im,re in train_dataset.take(1):\n", "                print(f'|... item shape in dataset: {np.shape(im)} {np.shape(re)}')\n", "                img1 = onformat.nnba_to_rgb(im)\n", "                img2 = onformat.nnba_to_rgb(re)\n", "                display_list = [img1, img2]\n", "                onplot.pil_show_rgbs(display_list, scale=1, rows=1) \n", "        print(f'|===> training loop:')\n", "        model.fit(train_dataset, test_dataset, args)     # , summary_writer\n", "    print('|===> end danboo')\n", "#\n", "#\n", "#   nnart\n", "#\n", "def nnart(args, kwargs):\n", "# https://github.com/memo/webcam-pix2pix-tensorflow\n", "    args = onutil.pargs(vars(args))\n", "    args.PROJECT = 'art'\n", "    args.DATASET = 'danregion'\n", "    xp = getxp(vars(args))\n", "    args = onutil.pargs(xp)\n", "    onutil.ddict(vars(args), 'args')\n", "    print(f\"|---> nnart: {args.PROJECT}:  \\n \")\n", "    if 1: # tree\n", "        # ckpt_dir\n", "        ckpt_dir = args.models_dir\n", "        ckpt_prefix = 'ckpt-'\n\n", "        # data\n", "        args.data_train_dir = os.path.join(args.data_dir, 'train')\n", "        args.data_test_dir = os.path.join(args.data_dir, 'test')\n\n", "        # dataset\n", "        args.dataset_train_B_dir = os.path.join(args.dataset_dir, 'train_B_dir')\n", "        args.dataset_train_A_dir = os.path.join(args.dataset_dir, 'train_A_dir')\n", "        args.dataset_test_B_dir = os.path.join(args.dataset_dir, 'test_B_dir')\n", "        args.dataset_test_A_dir = os.path.join(args.dataset_dir, 'test_A_dir')\n", "        os.makedirs(args.models_dir, exist_ok=True)\n", "        os.makedirs(args.logs_dir, exist_ok=True)\n\n", "        # raw data src\n", "        os.makedirs(args.dataorg_dir, exist_ok=True)\n", "        os.makedirs(args.data_dir, exist_ok=True)\n", "        os.makedirs(args.data_train_dir, exist_ok=True) \n", "        os.makedirs(args.data_test_dir, exist_ok=True)\t\n", "        os.makedirs(args.dataset_dir, exist_ok=True)\n", "        os.makedirs(args.dataset_train_B_dir, exist_ok=True) \n", "        os.makedirs(args.dataset_train_A_dir, exist_ok=True) \n", "        os.makedirs(args.dataset_test_B_dir, exist_ok=True) \n", "        os.makedirs(args.dataset_test_A_dir, exist_ok=True) \n", "        os.makedirs(args.records_dir, exist_ok=True)\n", "    if args.verbose: print(f\"|---> nnart tree: {args.PROJECT}:  \\n \\\n", "    cwd: {os.getcwd()} \\n \\\n", "    args.PROJECT:        {args.PROJECT} \\n \\\n", "    args.DATASET:        {args.DATASET} \\n \\\n", "    args.proj_dir:       {args.proj_dir}, data and code will be in args.proj_dir\\n \\\n", "    args.logs_dir:       {args.logs_dir} {onfile.qfiles(args.models_dir, '*')} logs \\n \\\n", "    args.records_dir:    {args.records_dir} :-: {onfile.qfiles(args.records_dir, '*')} files \\n \\\n", "    args.models_dir (ckpts): {args.models_dir} :-: {onfile.qfiles(args.models_dir, '*.index')} \\n \\\n", "    args.dataorg_dir:    {args.dataorg_dir} :-: {onfile.qfiles(args.dataorg_dir, '*.jpg')}  jpgs \\n \\\n", "    \\n \\\n", "    args.data_dir:       {args.data_dir}: {onfile.qfiles(args.data_dir, '*')} files \\n \\\n", "    args.data_train_dir: {args.data_train_dir} :-: {onfile.qfiles(args.data_train_dir, '*.jpg')} \\n \\\n", "    args.data_test_dir:  {args.data_test_dir} :-: {onfile.qfiles(args.data_test_dir, '*.jpg')} \\n \\\n", "    \\n \\\n", "    args.dataset_dir:    {args.dataset_dir} :-: {onfile.qfolders(args.dataset_dir)} folders\\n \\\n", "    args.dataset_train_B_dir (re): {args.dataset_train_B_dir} :-: {onfile.qfiles(args.dataset_train_B_dir, '*.jpg')}  \\n \\\n", "    args.dataset_train_A_dir (in): {args.dataset_train_A_dir} :-: {onfile.qfiles(args.dataset_train_A_dir, '*.jpg')}  \\n \\\n", "    args.dataset_test_B_dir (re): {args.dataset_test_B_dir} :-: {onfile.qfiles(args.dataset_test_B_dir, '*.jpg')}  \\n \\\n", "    args.dataset_test_A_dir (in): {args.dataset_test_A_dir} :-: {onfile.qfiles(args.dataset_test_A_dir, '*.jpg')}  \\n \\\n", "    \")\n", "    if 0: # clear tree\n", "        print(f'|---> clear tree at {args.proj_dir}')\n", "        onfile.clearfolder(args.proj_dir, inkey=args.PROJECT)\n", "    if 1: # data params\n", "        args.img_height = 512\n", "        args.img_width = 512\n", "        args.max_size=512\n", "        args.height=args.img_height\n", "        args.width=args.img_height\n", "        args.input_shape = [args.height, args.width, args.input_channels]\n", "    if args.verbose: print(f\"|---> config  \\n \\\n", "        args.height:         {args.height} \\n \\\n", "        args.width:          {args.width} \\n \\\n", "        args.input_channels: {args.input_channels} \\n \\\n", "        args.buffer_size:    {args.buffer_size} \\n \\\n", "        args.batch_size:     {args.batch_size} \\n \\\n", "        args.input_shape:    {args.input_shape} \\n \\\n", "    \")\n", "    if 1: # raw to paths\n", "        trainpc = 0.9\n", "        testpc = 0.1\n", "        forcecopy = 0\n", "        input_paths = onfile.path_to_paths(args.dataorg_dir, patts=['*.jpg', '*.jpeg', '*.png'])\n", "        qimgs = len(input_paths)\n", "        q_train_imgs = int(qimgs * trainpc )\n", "        q_test_imgs = int(qimgs * testpc )\t\t\n", "        train_paths = input_paths[0:q_train_imgs]\n", "        test_paths = input_paths[q_train_imgs:qimgs]\t\t\n", "        print(f'|--->  raw to data - keep img file names \\n \\\n", "        from {args.dataorg_dir}, {qimgs} images \\n \\\n", "            to data_train_dir: {args.data_train_dir} {q_train_imgs} ({trainpc} %) \\n \\\n", "            to data_test_dir:  {args.data_test_dir}  {q_test_imgs} ({testpc} %)\\n \\\n", "        ')\n", "        \n", "        train_roots = [onutil.get_rootid(path) for path in train_paths]\n", "        if all(root.isdigit() for root in train_roots):\n", "            print(f'|---> sort numeric')\n", "            train_paths = sorted(train_paths, key=lambda path: int(onutil.get_rootid(path)))\n", "        else:\n", "            print(f'|---> sort alphabetic')\n", "            train_paths = sorted(train_paths)\n", "        assert len(train_paths) > 0, f'train files missing'\n", "        test_roots = [onutil.get_rootid(path) for path in test_paths]\n", "        if all(root.isdigit() for root in test_roots):\n", "            test_paths = sorted(test_paths, key=lambda path: int(onutil.get_rootid(path)))\n", "        else:\n", "            test_paths = sorted(test_paths)\n", "        assert len(test_paths) >= 0, f'test files may be missing'\n", "    if 0: # raw to formed data (dataorg_dir => data_train_dir, data_test_dir)\n", "        for i,path in enumerate(train_paths):\n", "            rootid = int(onutil.get_rootid(path))\n", "            rootfilled = onutil.nameint(rootid)\n", "            ext = os.path.splitext(path)[-1]\n", "            out_path = os.path.join(args.data_train_dir, f'img{rootfilled}{ext}')\n", "            print(f\"|---> {i} {rootfilled} {path} {out_path}\")\n", "            img = ondata.path_to_formed_pair(path)\n", "            img.save(os.path.join(out_path))\n", "        for i,path in enumerate(test_paths):\n", "            rootid = int(onutil.get_rootid(path))\n", "            rootfilled = onutil.nameint(rootid)\n", "            ext = os.path.splitext(path)[-1]\n", "            out_path = os.path.join(args.data_test_dir, f'img{rootfilled}{ext}')\n", "            print(f\"{i} {rootfilled} {path} {out_path}\")\n", "            img = ondata.path_to_formed_pair(path)\n", "            img.save(os.path.join(out_path))\n", "        assert len(onfile.qfiles(args.data_train_dir)) > 0, f'train data files missing'\n", "        assert len(onfile.qfiles(args.data_test_dir)) > 0, f'test data files missing'\n", "    if 1: # model\n", "        print('|---> gan model')\n", "        gan = GAN(\n", "            models_dir = args.models_dir,\n", "            logs_dir = args.logs_dir,\n", "            ckpt_dir = ckpt_dir,\n", "            #ckpt_prefix = ckpt_prefix,\n", "            input_shape = args.input_shape,\n", "            output_shape = args.input_shape,\n", "        )\n", "    if 1: #  formed => datasets 11\n", "        print(f'|===> to datasets 11')\n", "        #train_dataset = path_to_dataset_11(\n", "        train_dataset = paths_to_dataset(\n", "            args.data_train_dir, \n", "            '*.png', \n", "            batch_size=4)\n", "        #test_dataset = path_to_dataset_11(\n", "        test_dataset = paths_to_dataset(\n", "            args.data_test_dir, \n", "            '*.png', \n", "            batch_size=4)\n", "        print(f'|---> train_dataset {type(train_dataset)}')\n", "        print(f'|---> test_dataset {type(test_dataset)}')\n", "    \n", "    if 1: # train\n", "        print('|===> run the training loop')\n", "        gan.fit(train_dataset, test_dataset, args)     # , summary_writer\n", "    print(f'|===> end nnart')\n", "#\n", "#\n", "#   nncrys - 22\n", "#   \n", "def nncrys(args, kwargs):\n", "    args = onutil.pargs(vars(args))\n", "    args.PROJECT = 'crystals'\n", "    args.DATASET = 'quimica_tech'\n", "    args.LOCALLAB = 0\n", "    xp = getxp(vars(args))\n", "    args = onutil.pargs(xp)\n", "    onutil.ddict(vars(args), 'args')\n", "    print(f\"|---> nncrys: {args.PROJECT}:  \\n \")\n", "    if 1: # tree\n", "        assert(os.path.exists(args.dataorg_dir))\n", "        args.ckpt_dir = args.models_dir\n", "        args.data_train_dir = os.path.join(args.data_dir, 'train_dir')\n", "        args.data_test_dir = os.path.join(args.data_dir, 'test_dir')\n", "        args.results_dir = os.path.join(args.proj_dir, 'results') # in project dir\n", "        args.dataset_train_B_dir = os.path.join(args.dataset_dir, 'train_B')\n", "        args.dataset_train_A_dir = os.path.join(args.dataset_dir, 'train_A')\n", "        args.dataset_test_B_dir = os.path.join(args.dataset_dir, 'test_B')\n", "        args.dataset_test_A_dir = os.path.join(args.dataset_dir, 'test_A')\n", "        os.makedirs(args.models_dir, exist_ok=True)\n", "        os.makedirs(args.logs_dir, exist_ok=True)\n", "        os.makedirs(args.data_train_dir, exist_ok=True) \n", "        os.makedirs(args.data_test_dir, exist_ok=True) \n", "        os.makedirs(args.dataset_train_B_dir, exist_ok=True) \n", "        os.makedirs(args.dataset_train_A_dir, exist_ok=True) \n", "        os.makedirs(args.dataset_test_B_dir, exist_ok=True) \n", "        os.makedirs(args.dataset_test_A_dir, exist_ok=True) \n", "        os.makedirs(args.models_dir, exist_ok=True)\n", "        os.makedirs(args.logs_dir, exist_ok=True)\n", "        os.makedirs(args.tmp_dir, exist_ok=True)\n", "        os.makedirs(args.records_dir, exist_ok=True)\n", "        os.makedirs(args.results_dir, exist_ok=True)\n", "    if args.verbose: print(f\"|---> nncrys tree: {args.PROJECT}:  \\n \\\n", "    cwd: {os.getcwd()} \\n \\\n", "    args.PROJECT:        {args.PROJECT} \\n \\\n", "    args.DATASET:        {args.DATASET} \\n \\\n", "    args.proj_dir:       {args.proj_dir} \\n \\\n", "    args.dataorg_dir:    {args.dataorg_dir} :-: {onfile.qfiles(args.dataorg_dir, '*.jpg')}  jpgs \\n \\\n", "    args.data_dir:       {args.data_dir} :-: {onfile.qfiles(args.data_dir, '*')} items \\n \\\n", "    args.data_train_dir: {args.data_train_dir} :-: {onfile.qfiles(args.data_train_dir, '*.jpg')} jpgs \\n \\\n", "    args.data_test_dir:  {args.data_test_dir} :-: {onfile.qfiles(args.data_test_dir, '*.jpg')} jpgs \\n \\\n", "    args.dataset_dir:    {args.dataset_dir} :-: {onfile.qfolders(args.dataset_dir)} folders\\n \\\n", "    args.logs_dir:       {args.logs_dir} {onfile.qfiles(args.models_dir, '*')} logs \\n \\\n", "    args.results_dir:       {args.results_dir} {onfile.qfiles(args.results_dir, '*')} results \\n \\\n", "    args.dataset_train_B_dir: {args.dataset_train_B_dir} :-: {onfile.qfiles(args.dataset_train_B_dir, '*.jpg')}  jpgs \\n \\\n", "    args.dataset_train_A_dir: {args.dataset_train_A_dir} :-: {onfile.qfiles(args.dataset_train_A_dir, '*.jpg')}  jpgs \\n \\\n", "    args.dataset_test_B_dir:  {args.dataset_test_B_dir} :-: {onfile.qfiles(args.dataset_test_B_dir, '*.jpg')}  jpgs \\n \\\n", "    args.dataset_test_A_dir:  {args.dataset_test_A_dir} :-: {onfile.qfiles(args.dataset_test_A_dir, '*.jpg')}  jpgs \\n \\\n", "    args.records_dir:    {args.records_dir} :-: {onfile.qfiles(args.records_dir, '*')} files \\n \\\n", "    args.models_dir:     {args.models_dir} :-: {onfile.qfiles(args.models_dir, '*.index')} snaps \\n \\\n", "    \")\n", "    if 1: # config\n", "        args.ckpt_prefix = 'ckpt-'\n", "        args.img_height = 512\n", "        args.img_width = 512\n", "        args.max_size=512\n", "        args.height=args.img_height\n", "        args.width=args.img_height\n", "        args.batch_size=1\n", "        args.input_shape = [args.height, args.width, args.input_channels]\n", "    if args.verbose: print(f'|--->  {args.PROJECT}: config  \\n \\\n", "        args.height:         {args.height} \\n \\\n", "        args.width:          {args.width} \\n \\\n", "        args.max_size:       {args.max_size} \\n \\\n", "        args.input_channels: {args.input_channels} \\n \\\n", "        args.buffer_size:    {args.buffer_size} \\n \\\n", "        args.batch_size:     {args.batch_size} \\n \\\n", "        args.input_shape:    {args.input_shape} \\n \\\n", "    ')\n", "    if 0: # clear tree\n", "        print(f\"clear tree at {args.proj_dir}\")\n", "        onfile.clearfolder(args.proj_dir, inkey=args.PROJECT)\n", "    if 0: # make gif out of results: all generatd imgs with patterns\n", "        imgpatts = ['0012*.png']\n", "        dstpath = os.path.join(args.results_dir, 'out.gif')\n", "        nresults = args.results_dir\n", "        srcdir = nresults # args.results_dir\n", "        print(f\"|===> tovid \\n \\\n", "            args.results_dir: {args.results_dir} \\n \\\n", "            nresults: {nresults} \\n \\\n", "            srcdir: {srcdir} \\n \\\n", "        \")\n", "        onvid.folder_to_gif(srcdir, dstpath, patts=imgpatts)\n", "    if 1: # \tmodel\n", "        print(f\"|===> get model from {args.models_dir} \\n \")\t\t\n", "        model = GAN( \n", "            models_dir = args.models_dir,\n", "            logs_dir = args.logs_dir,\n", "            results_dir = args.results_dir,\n", "            ckptidx = -1,\n", "            ckpt_dir = args.ckpt_dir,\n", "            ckpt_prefix = args.ckpt_prefix,\n", "            input_shape = args.input_shape,\n", "            output_shape = args.input_shape,\n", "        )\n", "    if 1: # raw images to data (dataorg_dir => data_train_dir, data_test_dir)\n", "        trainpc = 0.9\n", "        testpc = 0.1\n", "    \n", "        input_paths = onfile.folder_to_paths(args.dataorg_dir)\n", "        q_from_imgs = len(input_paths)\n", "        q_train_imgs = int(q_from_imgs * trainpc)\n", "        q_test_imgs = int(q_from_imgs * testpc)\n", "        train_paths = input_paths[0:q_train_imgs]\n", "        test_paths = input_paths[0:q_test_imgs]\n", "        q_from_train_imgs = len(train_paths)\n", "        q_from_test_imgs = len(test_paths)\n", "        q_to_train_imgs = onfile.qfiles(args.data_train_dir)\n", "        q_to_test_imgs = onfile.qfiles(args.data_test_dir)\n", "        print(f\"|===>  org raw to data \\n \\\n", "            {len(train_paths)} to {args.data_train_dir} with {q_to_train_imgs} \\n \\\n", "            {len(test_paths)} to {args.data_test_dir} with {q_to_test_imgs} \\n \\\n", "        \")\n\n", "        # raw images to train data (args.dataorg_dir => args.data_train_dir)\n", "        if not q_from_train_imgs == q_to_train_imgs:\t\t\n", "            onfile.paths_to_folder_with_cv(train_paths, args.data_train_dir)\n", "        else:\n", "            print(f\"|... !!! train not copied. {args.data_train_dir} got them\")\n\n", "        # raw images to test data (args.dataorg_dir => args.data_test_dir)\n", "        if not q_from_test_imgs == q_to_test_imgs:\t\t\t\n", "            onfile.paths_to_folder_with_cv(test_paths, args.data_test_dir)\n", "        else:\n", "            print(f\"|... !!! test not  copied. {args.data_test_dir} got them\")\n", "        \n", "        if 1:  # show raw images shapes\n", "            nuas = onfile.folder_to_nuas(args.data_train_dir)\n", "            n = np.random.randint(0, len(nuas))\n", "            print(f\"|... data train image {n} shape: {np.shape(nuas[n])}\")\n", "    if 1: # data to dataset B (data_dir => (train, test))\n", "        args.keep_folder=True    \n", "        args.process_type='crop_to_square'\n", "        args.file_extension= 'jpg'\n", "        args.name=1 # alpha name\n", "        print(f\"|===> data to dataset B (real) \\n \\\n", "            {args.data_train_dir} to {args.dataset_train_B_dir}   \\n \\\n", "            {args.data_test_dir}  to {args.dataset_test_B_dir} \\n \\\n", "            args.process_type:  {args.process_type} \\n \\\n", "            args.file_extension:{args.file_extension} \\n \\\n", "            args.max_size:{args.max_size} \\n \\\n", "        \")\n\n", "        # dataset to train data\n", "        args.input_folder = args.data_train_dir\n", "        args.output_folder = args.dataset_train_B_dir\n", "        q_from_train_imgs = onfile.qfiles(args.input_folder)\n", "        q_to_train_imgs = onfile.qfiles(args.output_folder)\n", "        print(f'|==> data to dataset train: {args.process_type} \\n \\\n", "            {args.input_folder} ==> {args.output_folder} \\n \\\n", "            q_from_train_imgs: {onfile.qfiles(args.input_folder)} \\n \\\n", "            q_to_train_imgs: {onfile.qfiles(args.output_folder)} \\n \\\n", "        ')\n", "        if not q_from_train_imgs == q_to_train_imgs: # dir empty\t\t\t\t\n", "            onset.processFolder(args) # copy reals to train\n", "        else:\n", "            print(f\"|... nothing copied. {args.output_folder} not empty\")\n", "        assert onfile.qfiles(args.output_folder) > 0, f're train files not found {args.output_folder}'\n\n", "        # show train images shapes\n", "        if 1:\n", "            nuas = onfile.folder_to_nuas(args.dataset_train_B_dir)\n", "            n = np.random.randint(0, len(nuas))\n", "            print(f\"|---> train image {n} shape: {np.shape(nuas[n])}\")\t\t\n\n", "        # dataset to test data\n", "        args.input_folder = args.data_test_dir\n", "        args.output_folder = args.dataset_test_B_dir\n", "        q_from_test_imgs = onfile.qfiles(args.input_folder)\n", "        q_to_test_imgs = onfile.qfiles(args.output_folder)\n", "        print(f'|==> data to dataset test: {args.process_type} \\n \\\n", "            {args.input_folder} ==> {args.output_folder} \\n \\\n", "            q_from_test_imgs: {onfile.qfiles(args.input_folder)} \\n \\\n", "            q_to_test_imgs: {onfile.qfiles(args.output_folder)} \\n \\\n", "        ')\n", "        if not q_from_test_imgs == q_to_test_imgs: # dir empty\t\t\t\t\n", "            onset.processFolder(args) # copy reals to test\n", "        else:\n", "            print(f\"|... nothing copied. {args.output_folder} not empty\")\n", "    if 1: # canny to dataset A ((train, test)B => (train, test)A)\n", "        args.keep_folder=True    \n", "        args.process_type='canny' # 'square' # 'canny-pix2pix'\n", "        args.direction='B2A'\n", "        args.file_extension='jpg'\n", "        args.blur_type='gaussian'\n", "        args.blur_amount=3\n", "        args.name=1\n", "        args.mirror=None\n", "        args.rotate=None\n", "        if args.verbose: print(f\"|===>  canny B ==> dataset A (sketch):   \\n \\\n", "            args.process_type:   {args.process_type} \\n \\\n", "            args.direction:   \t {args.direction} \\n \\\n", "            args.blur_type:   \t {args.blur_type} \\n \\\n", "            args.blur_amount:    {args.blur_amount} \\n \\\n", "            args.file_extension: {args.file_extension} \\n \\\n", "            from {args.dataset_train_B_dir}  \\n \\\n", "                to {args.dataset_train_A_dir} \\n \\\n", "            from {args.dataset_test_B_dir}  \\n \\\n", "                to {args.dataset_test_A_dir} \\n \\\n", "        \")\n\n", "        # data to dataset train B\n", "        args.input_folder = args.dataset_train_B_dir\n", "        args.output_folder = args.dataset_train_A_dir\n", "        if not os.listdir(args.output_folder): # dir empty\n", "            print(f\"|---> train canny {args.process_type}: {args.input_folder}   \\n \\\n", "                to {args.output_folder},  \\n \\\n", "                from imgs q: {onfile.qfiles(args.input_folder)}\t\\n \\\n", "                to imgs q: {onfile.qfiles(args.output_folder)}\t\\n \\\n", "            \")\n", "            onset.processFolder(args) # canny's to train\n\n", "            #convert grey to rgb\n", "            for filename in os.listdir(args.output_folder):\n", "                file_path = os.path.join(args.output_folder, filename)\n", "                img = cv2.imread(file_path)    \n", "                canny = cv2.cvtColor(Onset.processCanny(img,args),cv2.COLOR_GRAY2RGB)\n", "                if(args.file_extension == \"png\"):\n", "                    new_file = os.path.splitext(filename)[0] + \".png\"\n", "                    cv2.imwrite(os.path.join(args.output_folder, new_file), canny, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n", "                elif(args.file_extension == \"jpg\"):\n", "                    new_file = os.path.splitext(filename)[0] + \".jpg\"\n", "                    cv2.imwrite(os.path.join(args.output_folder, new_file), canny, [cv2.IMWRITE_JPEG_QUALITY, 90])\n", "        else:\n", "            print(f\"|---> nothing copied. {args.output_folder} not empty\")\n\n", "        # data to dataset test B\n", "        args.input_folder = args.dataset_test_B_dir\n", "        args.output_folder = args.dataset_test_A_dir\n", "        if not os.listdir(args.output_folder): # dir  empty\t\t\t\n", "            print(f\"|---> test canny {args.process_type}: {args.input_folder}   \\n \\\n", "                to {args.output_folder},  \\n \\\n", "                from imgs q: {onfile.qfiles(args.input_folder)}\t\\n \\\n", "                to imgs q: {onfile.qfiles(args.output_folder)}\t\\n \\\n", "            \")\n", "            onset.processFolder(args) # canny's to test\n\n", "            #convert grey to rgb\n", "            for filename in os.listdir(args.output_folder):\n", "                file_path = os.path.join(args.output_folder, filename)\n", "                img = cv2.imread(file_path)    \n", "                canny = cv2.cvtColor(Onset.processCanny(img,args),cv2.COLOR_GRAY2RGB)\n", "                if(args.file_extension == \"png\"):\n", "                    new_file = os.path.splitext(filename)[0] + \".png\"\n", "                    cv2.imwrite(os.path.join(args.output_folder, new_file), canny, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n", "                elif(args.file_extension == \"jpg\"):\n", "                    new_file = os.path.splitext(filename)[0] + \".jpg\"\n", "                    cv2.imwrite(os.path.join(args.output_folder, new_file), canny, [cv2.IMWRITE_JPEG_QUALITY, 90])\n", "            \n", "        else:\n", "            print(f\"|---> nothing copied. {args.output_folder} not empty\")\n", "    if 1: #  data_train_dir => tf datasets 22\n", "        print(f\"|===> data to datasets 22\")\n", "        pths_train = [args.dataset_train_A_dir, args.dataset_train_B_dir, ]\n", "        pths_test = [args.dataset_test_A_dir,args.dataset_test_B_dir, ]\n", "        args.patts = ['*.jpg', '*.jpg']\n", "        print(f\"|--->  data to dataset A:   \\n \\\n", "            train_dataset from {pths_train} with args.patts {args.patts} \\n \\\n", "            test_dataset from {pths_test} with args.patts {args.patts} \\n \\\n", "            height {args.height} \\n \\\n", "            width {args.width} \\n \\\n", "            buffer_size {args.buffer_size} \\n \\\n", "            batch_size {args.height} \\n \\\n", "        \")\n\n", "        #train_dataset = paths_to_dataset_22(\n", "        train_dataset = paths_to_dataset(\n", "            pths_train, \n", "            args.patts, \n", "            height=args.height, width=args.width, buffer_size=args.buffer_size, batch_size=args.batch_size)\n", "        \n", "        #test_dataset = paths_to_dataset_22(\n", "        test_dataset = paths_to_dataset(\n", "            pths_test, \n", "            args.patts, \n", "            height=args.height, width=args.width, buffer_size=args.buffer_size, batch_size=args.batch_size)\n", "    if 0: # probe train dataset\n", "        print(f\"|===> probe train dataset\")\n", "        iterator = train_dataset.take(1) # <class 'tensorflow.python.data.ops.dataset_ops.TakeDataset'>\n", "        for elem in iterator:\n", "            #itemlist = list(elem)\n", "            example_input, example_target = elem\n", "            if args.verbose:\n", "                print(f'|---> probe train dataset {type(example_input)} {type(example_target)} ')\n", "            img1 = onformat.nnba_to_rgb(example_input)\n", "            img2 = onformat.nnba_to_rgb(example_target)\n", "                      \n", "            display_list = [img1, img2]\n", "            onplot.pil_show_rgbs(display_list, scale=1, rows=1) \n", "    if 0: #   \tdata => tfrecords\n", "        print(f\"|===> data to tfrecords   \\n \\\n", "        from: {args.dataset_train_A_dir} \\n \\\n", "            to args.records_dir: {args.records_dir} \\n \\\n", "        \")\t\t\n", "        # <class 'numpy.ndarray'> (512, 1024, 3)\n", "        onrecord.folder_to_tfrecords(\n", "            args.dataset_train_A_dir, \n", "            args.records_dir)\n", "    if 1: # walk ckpt models\n", "        maxitems = 40\n", "        patts = ['*.index']\n", "        paths = onfile.path_to_paths(model.ckpt_manager.directory, patts)\n", "        print(f'|===> walk ckpt models \\n \\\n", "            ckpt_manager: {model.ckpt_manager.directory} \\n \\\n", "            ckpt_manager.latest_checkpoint: {model.ckpt_manager.latest_checkpoint} \\n \\\n", "            ckpt_manager.checkpoints: {model.ckpt_manager.checkpoints} \\n \\\n", "            ckpt_manager.directory: {model.ckpt_manager.directory} \\n \\\n", "            patts: {patts} \\n \\\n", "            paths: {len(paths)} \\n \\\n", "        ')\n", "        for path in paths:\n", "            filename = os.path.basename(path)\n", "            ckpt = filename.split('.')[0] # {prefix}-{ckptidx}.index => {prefix}-{ckptidx}\n", "            ckptidx = oncheck.getckptidx(ckpt)\n", "        ckptidxs = []\n", "        for path in paths:\n", "            filename = os.path.basename(path)\n", "            infix = filename.split('.')[0]\n", "            ckptidx = oncheck.getckptidx(infix)\n", "            ckptidxs.append(int(ckptidx)) # if None\n", "        ckptidxs = sorted(ckptidxs)\n", "        qckptidxs = len(ckptidxs)\n", "        mod = int(qckptidxs/maxitems)\n", "        print(f'|===> walk ckpt models with mod {mod}')\n", "        ckptidxs=[]\n", "        for i,idx in enumerate(range(qckptidxs-1)):\n", "            if i % mod == 1:\n", "                ckptidxs.append(idx)\n", "        ckptidxs.append(len(ckptidxs))\n", "        \n", "        for ckptidx in ckptidxs:\n", "            print(f\"|===> walk ckptidxs with ckpt: {ckpt}\")\n", "            model = GAN( \n", "                models_dir = args.models_dir,\n", "                logs_dir = args.logs_dir,\n", "                results_dir = args.results_dir,\n", "                ckptidx = ckptidx,  # 1, None, -1\n", "                ckpt_dir = args.ckpt_dir,\n", "                ckpt_prefix = args.ckpt_prefix, # 'ckpt-'\n", "                input_shape = args.input_shape,\n", "                output_shape = args.input_shape,\n", "            )\n", "            if 0: # img waits\n", "                onplot.plot_iter_grid(model, test_dataset, 1, 3, figsize = (6.4, 6.3), do=['save']) # do=['plot', 'save']\n", "    if 1: # ckpt models to gif\n", "        fromfolder = args.results_dir\n", "        dstpath = os.path.join(args.results_dir, 'out.gif')\n", "        patts= ['frame*']   \n", "        print(f'|===>  gif of ckpt models \\n \\\n", "            fromfolder: {fromfolder} \\n \\\n", "            dstpath: {dstpath} \\n \\\n", "            patts: {patts}  \\n \\\n", "        ')\n", "        onvid.folder_to_gif(fromfolder, dstpath, patts)\n", "        #_folder_to_gif(fromfolder, dstpath, patts)\n", "    if 0: #  \tcolab\n", "        if onutil.incolab():\n", "            print(\"|---> load tensorboard to monitor logs with colab\")\n", "            os.system(f\"load_ext tensorboard\")\n", "            os.system(f\"tensorboard --logdir {args.logs_dir}\")\n", "        else:\n", "            print(f\"|---> launch a separate tensorboard process to monitor logs with colab\")\n", "    if 0: # walk test_dataset\n", "        print(f\"|===> walk the test_dataset\")\n", "        onplot.plot_iter_grid(model, test_dataset, 3, 3, figsize = (6.4, 6.3), do=['plot', 'save'])\n", "    if 0: # show train first\n", "        print(f\"|===> show first in train dataset\")\n", "        for train_input, train_target in train_dataset.take(1):\n", "            prediction = model.generator(train_input, training=True) # _e_\n", "            display_list = [\n", "                onformat.nnba_to_rgb(train_input),\n", "                onformat.nnba_to_rgb(train_target),\n", "                onformat.nnba_to_rgb(prediction)\n", "            ]\n", "            onplot.pil_show_rgbs(display_list, scale=1, rows=1)   \n", "    if 0: # show test first\n", "        print(f\"|===> show first in test dataset\")\n", "        for test_input, test_target in test_dataset.take(1):\n", "            prediction = model.generator(test_input, training=True) # _e_\n", "            display_list = [\n", "                onformat.nnba_to_rgb(test_input),\n", "                onformat.nnba_to_rgb(test_target),\n", "                onformat.nnba_to_rgb(prediction)\n", "            ]\n", "            onplot.pil_show_rgbs(display_list, scale=1, rows=1)        \n", "    if 0: # show all in dataset\n", "        print(f\"|===> show all in test dataset\")\n", "        for inp,tar in test_dataset.as_numpy_iterator():\n", "            prediction = model.generator(inp, training=True) # _e_\n", "            display_list = [\n", "                onformat.nnba_to_rgb(inp),\n", "                onformat.nnba_to_rgb(tar),\n", "                onformat.nnba_to_rgb(prediction)\n", "            ]\n", "            onplot.pil_show_rgbs(display_list, scale=1, rows=1)   \n", "    if 0: # train\n", "        print(f\"|===> train loop\")\n", "        model.fit(train_dataset, test_dataset, args)\n", "    print(f'|===> end nncrys')\n", "#\n", "#\n", "#   nnleonardo - 22\n", "#   \n", "def nnleonardo(args, kwargs):\n", "    args = onutil.pargs(vars(args))\n", "    args.PROJECT = 'leonardo'\n", "    args.DATASET = 'leonardo'\n", "    xp = getxp(vars(args))\n", "    args = onutil.pargs(xp)\n", "    onutil.ddict(vars(args), 'args')\n", "    print(f\"|---> nnleonardo: {args.PROJECT}:   \\n \")\n", "    if 1: # tree\n", "        args.dataorg_train_dir = os.path.join(args.dataorg_dir, 'train')\n", "        args.dataorg_test_dir = os.path.join(args.dataorg_dir, 'test')\n", "        assert(os.path.exists(args.dataorg_dir))\n", "        assert(os.path.exists(args.dataorg_train_dir))\n", "        assert(os.path.exists(args.dataorg_test_dir))\n", "        args.ckpt_dir = args.models_dir\n", "        ''' train/test images in origin with pattern '''\n", "        args.data_train_B_dir = os.path.join(args.data_dir, 'train_B')\n", "        args.data_train_A_dir = os.path.join(args.data_dir, 'train_A')\n", "        args.data_test_B_dir = os.path.join(args.data_dir, 'test_B')\n", "        args.data_test_A_dir = os.path.join(args.data_dir, 'test_A')\n", "        args.dataset_train_B_dir = os.path.join(args.dataset_dir, 'train_B')\n", "        args.dataset_train_A_dir = os.path.join(args.dataset_dir, 'train_A')\n", "        args.dataset_test_B_dir = os.path.join(args.dataset_dir, 'test_B')\n", "        args.dataset_test_A_dir = os.path.join(args.dataset_dir, 'test_A')\n", "        args.zipfile = os.path.join(args.dataorg_dir, f'{args.DATASET}.zip')\n", "        os.makedirs(args.data_train_B_dir, exist_ok=True) \n", "        os.makedirs(args.data_train_A_dir, exist_ok=True) \n", "        os.makedirs(args.data_test_B_dir, exist_ok=True) \n", "        os.makedirs(args.data_test_A_dir, exist_ok=True) \n", "        os.makedirs(args.dataset_train_B_dir, exist_ok=True) \n", "        os.makedirs(args.dataset_train_A_dir, exist_ok=True) \n", "        os.makedirs(args.dataset_test_B_dir, exist_ok=True) \n", "        os.makedirs(args.dataset_test_A_dir, exist_ok=True) \n", "        os.makedirs(args.models_dir, exist_ok=True)\n", "        os.makedirs(args.logs_dir, exist_ok=True)\n", "        os.makedirs(args.tmp_dir, exist_ok=True)\n", "    if args.verbose: print(f\"|---> tree: {args.PROJECT}:   \\n \\\n", "        args.PROJECT:    \t  {args.PROJECT} \\n \\\n", "        args.DATASET:    \t  {args.DATASET} \\n \\\n", "        args.dataorg_dir:     {args.dataorg_dir} \\n \\\n", "        args.dataorg_train_dir: {args.dataorg_train_dir} \\n \\\n", "        args.dataorg_test_dir: {args.dataorg_test_dir} \\n \\\n", "        args.ckpt_dir:  {args.ckpt_dir} \\n \\\n", "        args.logs_dir:        {args.logs_dir} \\n \\\n", "        args.tmp_dir:        {args.tmp_dir} \\n \\\n", "        args.zipfile:         {args.zipfile} \\n \\\n", "        args.verbose:         {args.verbose}, \\n \\\n", "        args.visual:          {args.visual}, \\n \\\n", "    \")\n", "    if 1: # config\n", "        args.height = args.img_height\n", "        args.width = args.img_width\n", "        args.buffer_size = args.buffer_size\n", "        args.batch_size = args.batch_size\n", "        args.input_channels = args.input_channels\n", "        args.input_shape = [args.height, args.width, args.input_channels]\n", "        if 0:\n", "            ''' copy org to same data folder'''\n", "            args.patts = ['*in.png', '*re.png']\n", "        else:\n", "            ''' will separate images in data'''\n", "            args.patts = ['*.png', '*.png']\n", "    if args.verbose: print(f\"|---> nnleonardo config:   \\n \\\n", "        args.max_epochs:            {args.max_epochs}, \\n \\\n", "        args.output_channels:\t{args.output_channels} \\n \\\n", "        args.height: \t\t\t{args.height} \\n \\\n", "        args.width: \t\t\t{args.width} \\n \\\n", "        args.input_channels: \t{args.input_channels} \\n \\\n", "        args.buffer_size: \t\t{args.buffer_size} \\n \\\n", "        args.batch_size: \t\t{args.batch_size} \\n \\\n", "        args.input_shape: \t\t{args.input_shape} \\n \\\n", "        args.patts:     \t\t{args.patts}, \\n \\\n", "    \")\n", "    if args.visual > 1: # show ref images\n", "        ref_pict_path = os.path.join(args.dataorg_train_dir, 'da02_re.png')\n", "        ref_draw_path = os.path.join(args.dataorg_train_dir, 'da02_in.png')\n", "        re = onfile.path_to_rgb(ref_pict_path)\n", "        inp = onfile.path_to_rgb(ref_draw_path)\n", "        down_model = ondata.downsample(3, 4)\n", "        down_result = down_model(tf.expand_dims(tf.cast(inp, tf.float32), 0)) # _e_\n", "        up_model = ondata.upsample(3, 4)\n", "        up_result = up_model(down_result)\n", "        print(f\"|---> show ref images:   \\n \\\n", "            ref_pict_path: {ref_pict_path} \\n \\\n", "            ref_draw_path: {ref_draw_path} \\n \\\n", "            down_result.shape: {down_result.shape} \\n \\\n", "            up_result.shape: {up_result.shape} \\n \\\n", "            args.input_shape: {args.input_shape} \\n \\\n", "            re shape: {np.shape(re)} \\n \\\n", "            inp shape: {np.shape(inp)} \\n \\\n", "        \")\n", "        print(f\"|---> plot re, inp ...\")\n", "        onplot.pil_show_rgbs([re, inp])\n", "    if 1: #  dataorg raw => data train \n", "        print(f\"|---> raw to data\")\n", "        args.keep_folder=True    \n", "        args.process_type='crop_to_square'\n", "        args.file_extension= 'png'\n", "        args.name=1\n", "        args.zfill=0\n", "        args.input_folder = args.dataorg_train_dir\n", "        args.filepatt = f'.*in.{args.file_extension}'\n", "        #args.filepatt = f'*' => re.error: nothing to repeat at position 0\n", "        args.output_folder = args.data_train_A_dir\n", "        qinfiles = onfile.qfiles(args.input_folder, f'*in.{args.file_extension}')\n", "        qoutfiles = onfile.qfiles(args.output_folder)\n", "        print(f\"|---> nnleonardo train copy: {args.process_type}: \\n \\\n", "            {args.input_folder} ==> {args.output_folder}, \\n \\\n", "            qinfiles : {qinfiles}, \\n \\\n", "            qoutfiles : {qoutfiles}, \\n \\\n", "        \")\n", "        if  qinfiles > qoutfiles:\n", "            onset.processFolder(args) # copy inputs to train\n", "        else:\n", "            print(f'|... no processFolder !!!!. files already there ')\n", "        args.filepatt = f'.*re.{args.file_extension}'\n", "        args.output_folder = args.data_train_B_dir\n", "        qinfiles = onfile.qfiles(args.input_folder, f'*in.{args.file_extension}')\n", "        qoutfiles = onfile.qfiles(args.output_folder)\n", "        print(f\"|---> train copy: {args.process_type}: \\n \\\n", "            {args.input_folder} ==> {args.output_folder}, \\n \\\n", "            qinfiles : {qinfiles}, \\n \\\n", "            qoutfiles : {qoutfiles}, \\n \\\n", "        \")\n", "        if  qinfiles > qoutfiles:\n", "            onset.processFolder(args) # copy reals to train\n", "        else:\n", "            print(f'|... no processFolder !!!!. files already there ')\n", "    if 1: #  dataorg_test_dir raw => data_test_dir (A/B) data\n", "        args.keep_folder=True    \n", "        args.process_type='crop_to_square'\n", "        args.file_extension= 'png'\n", "        args.name=1\n", "        args.zfill=0\n", "        args.input_folder = args.dataorg_test_dir\n", "        args.filepatt = f'.*in.{args.file_extension}'\n", "        args.output_folder = args.data_test_A_dir\n", "        args.filepatt = f'.*re.{args.file_extension}'\n", "        args.output_folder = args.data_train_B_dir\n", "        print(f\"|---> test copy: {args.process_type}: \\n \\\n", "            {args.input_folder} ==> {args.output_folder}, \\n \\\n", "            qinfiles : {qinfiles}, \\n \\\n", "            qoutfiles : {qoutfiles}, \\n \\\n", "        \")\n", "        if not qinfiles == qoutfiles:\n", "            onset.processFolder(args) # copy inputs to test\n", "        else:\n", "            print(f'|... no processFolder !!!!. files there ')\n", "        args.filepatt = f'.*re.{args.file_extension}'\n", "        args.output_folder = args.data_test_B_dir\n", "        args.filepatt = f'.*re.{args.file_extension}'\n", "        args.output_folder = args.data_train_B_dir\n", "        print(f\"|---> test copy: {args.process_type}:  \\n \\\n", "            {args.input_folder} ==> {args.output_folder},\\n \\\n", "            qinfiles : {qinfiles}, \\n \\\n", "            qoutfiles : {qoutfiles}, \\n \\\n", "        \")\n", "        if not qinfiles == qoutfiles:\n", "            onset.processFolder(args) # copy reals to test\n", "        else:\n", "            print(f'|... no processFolder !!!!. files there ')\n", "    if 1: #  data to dataset (A/B) data\n", "        print(f\"|---> data to dataset\")\n", "        args.keep_folder=True    \n", "        args.process_type='crop_to_square'\n", "        args.file_extension= 'png'\n", "        args.name=1\n", "        args.zfill=0\n\n", "        # data_train_dir raw => dataset_train_dir (A/B) data\n", "        args.input_folder = args.data_train_A_dir\n", "        args.filepatt = f'.*.{args.file_extension}'\n", "        args.output_folder = args.dataset_train_A_dir\n", "        qinfiles = onfile.qfiles(args.input_folder, f'*.{args.file_extension}')\n", "        qoutfiles = onfile.qfiles(args.output_folder)\n", "        print(f\"|---> train copy: {args.process_type}:   \\n \\\n", "            {args.input_folder} ==> {args.output_folder}, \\n \\\n", "            qinfiles : {qinfiles}, \\n \\\n", "            qoutfiles : {qoutfiles}, \\n \\\n", "        \")\n", "        if not qinfiles == qoutfiles:\n", "            onset.processFolder(args) # copy inputs to train\n", "        else:\n", "            print(f'|... no processFolder !!!!. files there ')\n", "        args.input_folder = args.data_train_B_dir\n", "        args.filepatt = f'.*.{args.file_extension}'\n", "        args.output_folder = args.dataset_train_B_dir\n", "        qinfiles = onfile.qfiles(args.input_folder, f'*.{args.file_extension}')\n", "        qoutfiles = onfile.qfiles(args.output_folder)\n", "        print(f\"|---> train copy: {args.process_type}:   \\n \\\n", "            {args.input_folder} ==> {args.output_folder}, \\n \\\n", "            qinfiles : {qinfiles}, \\n \\\n", "            qoutfiles : {qoutfiles}, \\n \\\n", "        \")\n", "        if not qinfiles == qoutfiles:\n", "            onset.processFolder(args) # copy reals to train\n", "        else:\n", "            print(f'|... no processFolder !!!!. files there ')\n\n", "        # data_test_dir raw => dataset\n", "        args.input_folder = args.data_test_A_dir\n", "        args.filepatt = f'.*in.{args.file_extension}'\n", "        args.output_folder = args.dataset_test_A_dir\n", "        qinfiles = onfile.qfiles(args.input_folder, f'*in.{args.file_extension}')\n", "        qoutfiles = onfile.qfiles(args.output_folder)\n", "        print(f\"|---> test copy: {args.process_type}:   \\n \\\n", "            {args.input_folder} ==> {args.output_folder}, \\n \\\n", "            qinfiles : {qinfiles}, \\n \\\n", "            qoutfiles : {qoutfiles}, \\n \\\n", "        \")\n", "        if not qinfiles == qoutfiles:\n", "            onset.processFolder(args) # copy inputs to test\n", "        else:\n", "            print(f'|... no processFolder !!!!. files there ')\n", "        args.input_folder = args.data_test_B_dir\n", "        args.filepatt = f'.*re.{args.file_extension}'\n", "        args.output_folder = args.dataset_test_B_dir\n", "        qinfiles = onfile.qfiles(args.input_folder, f'*re.{args.file_extension}')\n", "        qoutfiles = onfile.qfiles(args.output_folder)\n", "        print(f\"|---> test copy: {args.process_type}:   \\n \\\n", "            {args.input_folder} ==> {args.output_folder}, \\n \\\n", "            qinfiles : {qinfiles}, \\n \\\n", "            qoutfiles : {qoutfiles}, \\n \\\n", "        \")\n", "        if not qinfiles == qoutfiles:\n", "            onset.processFolder(args) # copy reals to test\n", "        else:\n", "            print(f'|... no processFolder !!!!. files there ')\n", "    if 1: #  data_train_dir => tf datasets\n", "        print(f\"|---> raw to datasets\")\n", "        pths_train = [args.data_train_A_dir, args.data_train_B_dir]\n", "        #train_dataset = paths_to_dataset_22(\n", "        train_dataset = paths_to_dataset(\n", "            pths_train, \n", "            args.patts, \n", "            height=args.height, width=args.width, buffer_size=args.buffer_size, batch_size=args.batch_size)\n", "        pths_test = [args.data_test_A_dir, args.data_test_B_dir]\n", "        #test_dataset = paths_to_dataset_22(\n", "        test_dataset = paths_to_dataset(\n", "            pths_test, \n", "            args.patts, \n", "            height=args.height, width=args.width, buffer_size=args.buffer_size, batch_size=args.batch_size)\n", "        \n", "    if args.visual > 1: # probe train dataset\n", "        print(f\"|---> probe dataset\")\n", "        iter = train_dataset.take(1) # <class 'tensorflow.python.data.ops.dataset_ops.TakeDataset'>\n", "        for i,elem in enumerate(iter):\n", "            example_input, example_target = elem\n", "            img1 = onformat.nba_to_rgb(example_input)\n", "            img2 = onformat.nba_to_rgb(example_target)\n", "            print(f'probe train dataset: {i} \\n \\\n", "                input:{type(example_input)} \\n \\\n", "                target: {type(example_target)}')\n", "            display_list = [\n", "                img1,\n", "                img2,\n", "            ]\n", "            onplot.pil_show_rgbs(display_list, scale=1, rows=1) \n", "    if 1: # model\n", "        print(\"|===> model\")\n", "        gan = GAN(\n", "            models_dir = args.models_dir,\n", "            logs_dir = args.logs_dir,\n", "            ckpt_dir = args.ckpt_dir,\n", "            ckpt_prefix = args.ckpt_prefix,\n", "            input_shape = args.input_shape,\n", "            output_shape = args.input_shape,\n", "        )\n", "    if 1: # colab\n", "        if onutil.incolab():\n", "            print(\"|---> load tensorboard to monitor logs with colab\")\n", "            os.system(f\"load_ext tensorboard\")\n", "            os.system(f\"tensorboard --logdir {args.logs_dir}\")\n", "        else:\n", "            print(\"|---> launch a separate tensorboard process to monitor logs with colab\")\n", "    if args.visual: # try generator\n", "        print(\"|===> probe generator with train image pair\")\n", "        path1 = os.path.join(args.data_dir, 'train_A/da09_in.png')\n", "        path2 = os.path.join(args.data_dir, 'train_B/da09_re.png')\n", "        imgs = paths_to_pair([path1, path2], args.img_height, args.img_width)\n", "        print(\"|... path1\", type(path1), np.shape(path1))\n", "        print(\"|... path2\", type(path2), np.shape(path2))\n", "        img1 = tf.cast(imgs[0], tf.float32)[tf.newaxis,...]\n", "        img2 = tf.cast(imgs[1], tf.float32)[tf.newaxis,...]\n", "        prediction = gan.generator(img1, training=True) # _e_\n", "        print(\"|... prediction\", type(prediction), np.shape(prediction))\n", "        img1 = onformat.nnba_to_rgb(img1)\n", "        img2 = onformat.nnba_to_rgb(img2)\n", "        img3 = onformat.nnba_to_rgb(prediction)\n", "        display_list = [ img1, img2, img3 ]\n", "        print(\"|... pil show rgbs\")\n", "        onplot.pil_show_rgbs(display_list, scale=1, rows=1)     \n", "    if args.visual:  # demo dataset\n", "        print(\"|===> probe train dataset prediction\")\n", "        for train_input, train_target in train_dataset.take(1):\n", "                \n", "            print(\"|--->.. train_input\", type(train_input), np.shape(train_input))\n", "            prediction = gan.generator(train_input, training=True) # _e_\n", "            print(\"|--->.. prediction\", type(prediction), np.shape(prediction))\n", "            img1 = onformat.nnba_to_rgb(train_input)\n", "            img2 = onformat.nnba_to_rgb(train_target) \n", "            img3 = onformat.nnba_to_rgb(prediction)\n", "            display_list = [ img1, img2,  img3 ]\n", "            onplot.pil_show_rgbs(display_list, scale=1, rows=1) \n", "                    \n", "        if test_dataset:\n", "            print(\"|---> probe test dataset prediction\")\n", "            for test_input, test_target in test_dataset.take(1):\n", "                prediction = gan.generator(test_input, training=True) # _e_\n", "                img1 = onformat.nnba_to_rgb(test_input)\n", "                img2 = onformat.nnba_to_rgb(test_target) \n", "                img3 = onformat.nnba_to_rgb(prediction)\n", "            display_list = [ img1, img2,  img3 ]\n", "            onplot.pil_show_rgbs(display_list, scale=1, rows=1)        \n", "    \n", "    if 1: # train\n", "        print(\"|===> training loop\")\n", "        gan.fit(train_dataset, test_dataset, args)     # , summary_writer\n", "    print(f'|===> end nnleonardo')\n", "#\n", "#\n", "#   nnfacades - 11\n", "#   \n", "def nnfacades(args, kwargs):\n", "    args = onutil.pargs(vars(args))\n", "    args.PROJECT = 'facades'\n", "    args.DATASET = 'facades'\n", "    xp = getxp(vars(args))\n", "    args = onutil.pargs(xp)\n", "    onutil.ddict(vars(args), 'args')\n", "    print(f\"|---> nnfacades: {args.PROJECT}:  \\n \")\n", "    if 1: # tree\n", "        args.ckpt_dir = args.models_dir\n", "        os.makedirs(args.models_dir, exist_ok=True)\n", "        os.makedirs(args.logs_dir, exist_ok=True)\n", "        assert(os.path.exists(args.dataorg_dir))\n", "    if args.verbose: print(f\"|---> {args.PROJECT} tree:   \\n \\\n", "        args.ckpt_dir: {args.ckpt_dir} \\n \\\n", "        args.logs_dir: {args.logs_dir} \\n \\\n", "        args.output_channels: {args.output_channels} \\n \\\n", "        args.batch_size: {args.batch_size}, \\n \\\n", "        args.img_width: {args.img_width} \\n \\\n", "        args.img_height: {args.img_height} \\n \\\n", "        args.input_channels: {args.input_channels} \\n \\\n", "        args.max_epochs: {args.max_epochs} \\n \\\n", "    \")\n", "    if 1: # config\n", "        args.height = args.img_height\n", "        args.width = args.img_width\n", "        args.buffer_size = args.buffer_size\n", "        args.batch_size = 1 # args.batch_size\n", "        args.input_channels = args.input_channels\n", "        args.input_shape = [args.height, args.width, args.input_channels]\n", "        args.src_pattern = '*.jpg'  # superseed pat\n", "    if args.verbose: print(f\"|---> {args.PROJECT} config:   \\n \\\n", "        cwd: {os.getcwd()} \\n \\\n", "        args.PROJECT: {args.PROJECT} \\n \\\n", "        args.height: {args.height} \\n \\\n", "        args.width: {args.width} \\n \\\n", "        args.input_channels: {args.input_channels} \\n \\\n", "        args.buffer_size: {args.buffer_size} \\n \\\n", "        args.batch_size: {args.batch_size} \\n \\\n", "        args.input_shape: {args.input_shape}, \\n \\\n", "        args.src_pattern: {args.src_pattern}, \\n \\\n", "        args.verbose: {args.verbose}, \\n \\\n", "        args.visual: {args.visual}, \\n \\\n", "    \")\n", "    if 1: # git\n", "        onutil.get_git(args.AUTHOR, args.GITPOD, args.proj_dir)\n", "    if args.visual: # ref images\n", "        ref_img_path = os.path.join(args.dataorg_dir, 'train/100.jpg')        \n", "        inp, re = path_to_decoded(ref_img_path)\n", "        if args.visual : \n", "            onplot.pil_show_rgbs([re, inp])\n", "        down_model = ondata.downsample(3, 4)\n", "        down_result = down_model(tf.expand_dims(tf.cast(inp, tf.float32), 0)) # _e_\n", "        up_model = ondata.upsample(3, 4)\n", "        up_result = up_model(down_result)\n", "        if args.verbose: print(f\"|---> {args.PROJECT}: ref images:  \\n \\\n", "            args.input_shape: {args.input_shape} \\n \\\n", "            ref_img_path: {ref_img_path} \\n \\\n", "            down_result.shape: {down_result.shape} \\n \\\n", "            up_result.shape: {up_result.shape} \\n \\\n", "        \")\n", "    if 1: # get DATASETS from src\n", "        path_train = os.path.join(args.dataorg_dir, 'train')\n", "        path_test = os.path.join(args.dataorg_dir, 'val')\n\n", "        #train_dataset = path_to_dataset_11(path_train, '*.jpg',\n", "        train_dataset = paths_to_dataset(path_train, '*.jpg',\n", "            height=args.height,width=args.width,buffer_size=args.buffer_size,batch_size=args.batch_size)\n\n", "        #test_dataset = path_to_dataset_11(path_test, '*.jpg',\n", "        test_dataset = paths_to_dataset(path_test, '*.jpg',\n", "            height=args.height,width=args.width,buffer_size=args.buffer_size,batch_size=args.batch_size)\n", "    if 1: # model\n", "        print(f\"|===> model\")\n", "        gan = GAN(\n", "            models_dir = args.models_dir,\n", "            logs_dir = args.logs_dir,\n", "            ckpt_dir = args.ckpt_dir,\n", "            ckpt_prefix = args.ckpt_prefix,\n", "            input_shape = args.input_shape,\n", "            output_shape = args.input_shape,\n", "        )\n", "    if 0: # # tensorboard\n", "        if onutil.incolab():\n", "            print(\"|---> load tensorboard to monitor logs with colab\")\n", "            os.system(f\"load_ext tensorboard\")\n", "            os.system(f\"tensorboard -- logdir {args.logs_dir}\")\n", "        else:\n", "            print(\"launch a separate tensorboard process to monitor logs with colab\")\n", "    if args.visual: # \n", "        print(f\"|---> show dataset train\")\n", "        for train_input, train_target in train_dataset.take(1):\n", "            prediction = gan.generator(train_input, training=True) # _e_\n", "            print(\"|... train_input\", type(train_input), np.shape(train_input))\n", "            print(\"|... train_target\", type(train_target), np.shape(train_target))\n", "            print(\"|... prediction\", type(prediction), np.shape(prediction))\n", "            \n", "            img1 = onformat.nnba_to_rgb(train_input)\n", "            img2 = onformat.nnba_to_rgb(train_target) \n", "            img3 = onformat.nnba_to_rgb(prediction)\n", "            display_list = [img1, img2, img3]\n", "            onplot.pil_show_rgbs(display_list, scale=1, rows=1)        \n", "    if args.visual: \n", "        print(f\"|---> show dataset test\")\n", "        for test_input, test_target in test_dataset.take(1):\n", "            prediction = gan.generator(test_input, training=True) # _e_\n", "            \n", "            img1 = onformat.nnba_to_rgb(test_input)\n", "            img2 = onformat.nnba_to_rgb(test_target) \n", "            img3 = onformat.nnba_to_rgb(prediction)\n", "            display_list = [img1, img2, img3]\n", "            onplot.pil_show_rgbs(display_list, scale=1, rows=1)        \n", "    if 1: # train\n", "        print(f\"|===> training loop\")\n", "        gan.fit(train_dataset, test_dataset, args)     # , summary_writer\n", "    print(f'|===> end nnfacades')\n", "#\n", "#\n", "#   nngoya\n", "#   \n", "def nngoya(args, kwargs):\n", "    args = onutil.pargs(vars(args))\n", "    args.PROJECT = 'goya'\n", "    args.DATASET = 'goya'\n", "    xp = getxp(vars(args))\n", "    args = onutil.pargs(xp)\n", "    onutil.ddict(vars(args), 'args')\n", "    print(f\"|---> nngoya: {args.PROJECT}:  \\n \")\n", "    if 1: # data params\n", "        args.src_pattern = '*.jpg'  # superseed pat\n", "        height = args.img_height\n", "        width = args.img_width\n", "        buffer_size = args.buffer_size\n", "        batch_size = args.batch_size\n", "        input_channels = args.input_channels\n", "        input_shape = [height, width, input_channels]\n", "    if 1: # tree\n", "        ckpt_dir = os.path.join(args.proto_dir, 'leonardo', 'Models')\n", "        os.makedirs(args.data_dir, exist_ok=True)\n", "        os.makedirs(args.models_dir, exist_ok=True)\n", "        os.makedirs(args.logs_dir, exist_ok=True)\n", "    if args.verbose: print(f\"|---> nngoya tree:   \\n \\\n", "        args.data_dir: {args.data_dir} \\n \\\n", "        ckpt_dir: {ckpt_dir} \\n \\\n", "        ckpt_prefix: {ckpt_prefix} \\n \\\n", "        logs_dir: {args.logs_dir} \\n \\\n", "    \")\n", "    if args.verbose: print(f\"|---> nngoya config:   \\n \\\n", "        cwd: {os.getcwd()} \\n \\\n", "        PROJECT: {args.PROJECT} \\n \\\n", "        height: {height} \\n \\\n", "        width: {width} \\n \\\n", "        input_channels: {input_channels} \\n \\\n", "        buffer_size: {buffer_size} \\n \\\n", "        batch_size: {batch_size} \\n \\\n", "        input_shape: {input_shape} \\n \\\n", "    \")\n", "    if 1: # model\n", "        gan = GAN(\n", "            models_dir = args.models_dir,\n", "            logs_dir = args.logs_dir,\n", "            ckpt_dir = ckpt_dir,\n", "            ckpt_prefix = ckpt_prefix,\n", "            input_shape = input_shape,\n", "            output_shape = input_shape,\n", "        )\n", "    if 1: # try generator\n", "        img1 = os.path.join(args.gdata, 'leonardo', 'train', 'da02_in.png')\n", "        img1 = os.path.join(args.gdata, 'leonardo', 'test', 'da13_in.png')\t\t\t\n", "        img1 = os.path.join(args.gdata, 'Goya__Guerra', 'img0006.jpg')\n", "        img1 = onfile.path_to_rgb(img1)\n", "        img1 = img_jitter_random(img1, height, width)        \n", "        img1 = onformat.rgb_to_nba(img1)\n", "        img1 = tf.cast(img1, tf.float32)[tf.newaxis,...]\n", "        prediction = gan.generator(img1, training=True) # _e_\n", "        print(f\"|---> prediction\", type(prediction), np.shape(prediction))\n", "        display_list = [\n", "            onformat.nnba_to_rgb(img1),\n", "            onformat.nnba_to_rgb(prediction)\n", "        ]\n", "        onplot.pil_show_rgbs(display_list, scale=1, rows=1)  \n", "    print(f'|---> end nngoya')\n", "#\n", "#\n", "#\n", "#   MAIN\n", "#\n", "#\n", "def main():\n", "    parser = argparse.ArgumentParser(description='Run \"python %(prog)s <subcommand> --help\" for subcommand help.')\n", "    onutil.dodrive()\n", "    ap = getap()\n", "    for p in ap:\n", "        cls = type(ap[p])\n", "        parser.add_argument('--'+p, type=cls, default=ap[p])\n", "    cmds = [key for key in globals() if key.startswith(\"nn\")]\n", "    primecmd = ap[\"primecmd\"]\n", "        \n", "    # ---------------------------------------------------------------\n", "    #   add subparsers\n", "    #\n", "    subparsers = parser.add_subparsers(help='subcommands', dest='command') # command - subparser\n", "    for cmd in cmds:\n", "        subparser = subparsers.add_parser(cmd, help='cmd')  # add subcommands\n", "    \n", "    subparsers_actions = [action for action in parser._actions\n", "        if isinstance(action, argparse._SubParsersAction)] # retrieve subparsers from parser\n", "  \n", "    for subparsers_action in subparsers_actions:  # add common       \n", "        for choice, subparser in subparsers_action.choices.items(): # get all subparsers and print help\n", "            for p in {}:  # subcommand args dict\n", "                cls = type(ap[p])\n", "                subparser.add_argument('--'+p, type=cls, default=ap[p])\n\n", "    # get args to pass to nn cmds\n", "    if onutil.incolab():\n", "        args = parser.parse_args('') #  defaults as args\n", "    else:\n", "        args = parser.parse_args() #  parse_arguments()\n", "    kwargs = vars(args)\n", "    subcmd = kwargs.pop('command')      \n", "    if subcmd is None:\n", "        print (f\"Missing subcommand. set to default {primecmd}\")\n", "        subcmd = primecmd\n", "    \n", "    for name in cmds:\n", "        if (subcmd == name):\n", "            print(f'|===> call {name}')\n", "            globals()[name](args, kwargs) # pass args to nn cmd\n", "#\n", "#\n", "#\n", "# python base/base.py nninfo\n", "if __name__ == \"__main__\":\n", "    print(\"|===>\", __name__)\n", "    main()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}