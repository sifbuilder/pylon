{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# -*- coding: utf-8 -*-\n", "# \n", "# # Copyright (c) 2019, NVIDIA Corporation. All rights reserved.\n", "#\n", "import os\n", "import io\n", "from io import StringIO\n", "import time\n", "import argparse\n", "import functools\n", "import errno\n", "import scipy\n", "import scipy.io\n", "import requests\n", "import zipfile\n", "import random\n", "import datetime\n", "#\n", "from functools import partial\n", "from importlib import import_module\n", "#\n", "import logging\n", "logging.getLogger('tensorflow').setLevel(logging.ERROR)\n", "#\n", "import numpy as np\n", "from numpy import *\n", "#\n", "import math\n", "from math import floor, log2\n", "from random import random\n", "from pylab import *\n", "from IPython.core.display import display\n", "import PIL\n", "from PIL import Image\n", "PIL.Image.MAX_IMAGE_PIXELS = 933120000\n", "#\n", "import scipy.ndimage as pyimg\n", "import cv2\n", "import imageio\n", "import glob\n", "import matplotlib as mpl\n", "import matplotlib.pyplot as plt \n", "import matplotlib.image as mgimg\n", "import matplotlib.animation as anim\n", "mpl.rcParams['figure.figsize'] = (12,12)\n", "mpl.rcParams['axes.grid'] = False\n", "#\n", "import shutil\n", "import gdown\n", "#\n", "import sys\n", "#\n", "import tensorflow as tf \n", "from tensorflow.keras import initializers, regularizers, constraints\n", "from tensorflow.keras import backend as K\n", "from tensorflow.keras import layers\n", "from tensorflow.keras.layers import Layer, InputSpec\n", "from tensorflow.keras.layers import BatchNormalization, Activation, ZeroPadding2D, UpSampling2D, Conv2D\n", "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout, LeakyReLU\n", "from tensorflow.keras.models import Sequential, Model\n", "from tensorflow.keras.optimizers import Adam\n", "from tensorflow.python.keras.utils import conv_utils\n", "#\n", "from tensorflow.keras.layers import Lambda\n", "from tensorflow.keras.layers import add\n", "from tensorflow.keras.layers import AveragePooling2D\n", "from tensorflow.keras.initializers import VarianceScaling\n", "from tensorflow.keras.models import clone_model\n", "from tensorflow.keras.models import model_from_json\n", "#\n", "from absl import app\n", "from absl import flags\n", "from absl import logging\n", "#\n", "tf.get_logger().setLevel('ERROR')\n", "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n", "#\n", "print(f'|===> {tf.__version__}')\n", "#\n", "if 1: # get base.py from github\n", "    cwd = os.getcwd()\n", "    base_path = os.path.join(cwd, 'base.py')\n", "    if not os.path.exists(base_path):\n", "        base_file = 'base.py'\n", "        urlfolder = 'https://raw.githubusercontent.com/sifbuilder/pylon/master/'\n", "        url = f'{urlfolder}{base_file}'\n", "        print(f\"|===> nnimg: get base file \\n \\\n", "            urlfolder: {urlfolder} \\n \\\n", "            url: {url} \\n \\\n", "            base_path: {base_path} \\n \\\n", "        \")\n", "        tofile = tf.keras.utils.get_file(f'{base_path}', origin=url, extract=True)\n", "    else:\n", "        print(f\"|===> base in cwd {cwd}\")\n", "#\n", "#\n", "#   FUNS\n", "#\n", "#\n", "# check if base.Onpyon is defined\n", "try:\n", "    var = Onpyon()\n", "except NameError:\n", "    sys.path.append('../')  # if called from eon, modules are in parallel folder\n", "    sys.path.append('./')  #  if called from dnns, modules are in folder\n", "    from base import *\n", "#\n", "onutil = Onutil()\n", "onplot = Onplot()\n", "onformat = Onformat()\n", "onfile = Onfile()\n", "onvid = Onvid()\n", "ondata = Ondata()\n", "onset = Onset()\n", "ontree = Ontree()\n", "onrecord = Onrecord()\n", "onrolux = Onrolux()\n", "onvgg = Onvgg()\n", "onlllyas = Onlllyas()\n", "oncuda = Oncuda()\n", "onrosa = Onrosa()\n", "onmoono = Onmoono()\n", "#\n", "#\n", "#   CONTEXT\n", "#\n", "#\n", "#\n", "def getap():\n", "    cp = {\n", "        \"primecmd\": 'nntrain',\n", "        \"MNAME\": \"matchue\",\n", "        \"AUTHOR\": \"manicman1999\",\n", "        \"GITPOD\": \"StyleGan2-Tensorflow-2.0\",\n", "        \"PROJECT\": \"space\",\n", "        \"DATASET\": \"space\",\n", "    \n", "        \"RESETCODE\": False,\n", "        \"LOCALDATA\": False,\n", "        \"LOCALMODELS\": False,\n", "        \"LOCALLAB\": True,\n", "        \"grel_infix\": '../..',            # relative path to content \n", "        \"net_prefix\": '//enas/hdrive',     \n", "        \"gdrive_prefix\": '/content/drive/My Drive',     \n", "        \"gcloud_prefix\": '/content',     \n", "    }\n", "    local_prefix = os.path.abspath('')\n", "    try:\n", "        local_prefix = os.path.dirname(os.path.realpath(__file__)) # script dir\n", "    except:\n", "        pass\n", "    cp[\"local_prefix\"] = local_prefix\n", "    \n", "    hp = {\n", "        \"batch_size\": 1,\n", "        \"img_width\": 256,\n", "        \"img_height\": 256,\n", "        \"buffer_size\": 1000,\n", "        \"input_channels\": 3,\n", "        \"output_channels\": 3,\n", "        \"epochs\": 100,\n", "        \"n_iterations\": 10, # iters for snapshot\n", "        \"verbose\": False,\n", "        \"visual\": True,\n", "    }\n", "    ap = {}\n", "    for key in cp.keys():\n", "        ap[key] = cp[key]\n", "    for key in hp.keys():\n", "        ap[key] = hp[key]\n", "    return ap\n", "#\n", "def getxp(cp):\n", "    yp={}\n", "    xp={}\n", "    for key in cp.keys():\n", "        xp[key] = cp[key]\n", "    tree = ontree.tree(cp)\n", "    for key in tree.keys():\n", "        xp[key] = tree[key]\n", "    for key in yp.keys():\n", "        xp[key] = yp[key]\n", "   \n", "    return xp\n", "#\n", "#\n", "#   NETS\n", "#\n", "#\n", "# Convolutional layers.\n", "#\n", "class Conv2DMod(tf.keras.layers.Layer):\n", "    def __init__(self,\n", "                 filters,\n", "                 kernel_size,\n", "                 strides=1,\n", "                 padding='valid',\n", "                 dilation_rate=1,\n", "                 kernel_initializer='glorot_uniform',\n", "                 kernel_regularizer=None,\n", "                 activity_regularizer=None,\n", "                 kernel_constraint=None,\n", "                 demod=True,\n", "                 **kwargs):\n", "         \n", "        super(Conv2DMod, self).__init__(**kwargs) # super(Conv2DMod, self).__init__() # \n", "      \n", "        self.filters = filters\n", "        self.rank = 2\n", "        self.kernel_size = conv_utils.normalize_tuple(kernel_size, 2, 'kernel_size')\n", "        self.strides = conv_utils.normalize_tuple(strides, 2, 'strides')\n", "        self.padding = conv_utils.normalize_padding(padding)\n", "        self.dilation_rate = conv_utils.normalize_tuple(dilation_rate, 2, 'dilation_rate')\n", "        self.kernel_initializer = initializers.get(kernel_initializer)\n", "        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n", "        self.activity_regularizer = regularizers.get(activity_regularizer)\n", "        self.kernel_constraint = constraints.get(kernel_constraint)\n", "        self.demod = demod\n", "        self.input_spec = [InputSpec(ndim = 4),\n", "                            InputSpec(ndim = 2)]\n", "    def build(self, input_shape):\n", "        channel_axis = -1\n", "        if input_shape[0][channel_axis] is None:\n", "            raise ValueError('The channel dimension of the inputs '\n", "                             'should be defined. Found `None`.')\n", "        input_dim = input_shape[0][channel_axis]\n", "        kernel_shape = self.kernel_size + (input_dim, self.filters)\n", "        if input_shape[1][-1] != input_dim:\n", "            raise ValueError('The last dimension of modulation input should be equal to input dimension.')\n", "        self.kernel = self.add_weight(shape=kernel_shape,\n", "                                      initializer=self.kernel_initializer,\n", "                                      name='kernel',\n", "                                      regularizer=self.kernel_regularizer,\n", "                                      constraint=self.kernel_constraint)\n\n", "        # Set input spec.\n", "        self.input_spec = [InputSpec(ndim=4, axes={channel_axis: input_dim}),\n", "                            InputSpec(ndim=2)]\n", "        self.built = True\n", "    def call(self, inputs):\n", "        #To channels last\n", "        x = tf.transpose(inputs[0], [0, 3, 1, 2])\n\n", "        #Get weight and bias modulations\n", "        #Make sure w's shape is compatible with self.kernel\n", "        w = K.expand_dims(K.expand_dims(K.expand_dims(inputs[1], axis = 1), axis = 1), axis = -1)\n\n", "        #Add minibatch layer to weights\n", "        wo = K.expand_dims(self.kernel, axis = 0)\n\n", "        #Modulate\n", "        weights = wo * (w+1)\n\n", "        #Demodulate\n", "        if self.demod:\n", "            d = K.sqrt(K.sum(K.square(weights), axis=[1,2,3], keepdims = True) + 1e-8)\n", "            weights = weights / d\n\n", "        #Reshape/scale input\n", "        x = tf.reshape(x, [1, -1, x.shape[2], x.shape[3]]) # Fused => reshape minibatch to convolution groups.\n", "        w = tf.reshape(tf.transpose(weights, [1, 2, 3, 0, 4]), [weights.shape[1], weights.shape[2], weights.shape[3], -1])\n", "        x = tf.nn.conv2d(x, w,\n", "                strides=self.strides,\n", "                padding=\"SAME\",\n", "                data_format=\"NCHW\")\n\n", "        # Reshape/scale output.\n", "        x = tf.reshape(x, [-1, self.filters, x.shape[2], x.shape[3]]) # Fused => reshape convolution groups back to minibatch.\n", "        x = tf.transpose(x, [0, 2, 3, 1])\n", "        return x\n", "    def compute_output_shape(self, input_shape):\n", "        item = input_shape[0][1:-1]\n", "        new_item = []\n", "        for i in range(len(item)):\n", "            new_dim = conv_utils.conv_output_length(\n", "                item[i],\n", "                self.kernel_size[i],\n", "                padding=self.padding,\n", "                stride=self.strides[i],\n", "                dilation=self.dilation_rate[i])\n", "            new_item.append(new_dim)\n", "        return (input_shape[0],) + tuple(new_space) + (self.filters,)\n", "    def get_config(self):\n", "        config = {\n", "            'filters': self.filters,\n", "            'kernel_size': self.kernel_size,\n", "            'strides': self.strides,\n", "            'padding': self.padding,\n", "            'dilation_rate': self.dilation_rate,\n", "            'kernel_initializer': initializers.serialize(self.kernel_initializer),\n", "            'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),\n", "            'activity_regularizer':\n", "                regularizers.serialize(self.activity_regularizer),\n", "            'kernel_constraint': constraints.serialize(self.kernel_constraint),\n", "            'demod': self.demod\n", "        }\n", "        base_config = super(Conv2DMod, self).get_config()\n", "        return dict(list(base_config.items()) + list(config.items()))\n", "#\n", "#\n", "class StyleGan2(object):\n", "    def __init__(self, \n", "        lr = 0.0001, \n", "        decay = 0.00001,\n", "        im_size = 256,\n", "        latent_size = 512,\n", "        BATCH_SIZE = 4, # 16\n", "        cha = 24,\n", "        mixed_prob = 0.9,\n", "   \n", "        steps = 1, \n", "        ncyc = None, \n", "        qsteps = 1000001,\n", "        n_cycle = 1000,\n", "        n_save = 500,\n", "        n_ref = 10000,\n", "        name='sol',\n", "        results_dir = \"results\",\n", "        models_dir = \"models\",\n", "        dataorg_dir = \"images\",\n", "        data_dir = \"data\",\n", "        dataset_dir = \"dataset\",\n", "        ani_dir = \"ani\",\n", "        update = 0,\n", "        images = [],\n", "        segments = [],\n", "        verbose = True,    \n", "        silent = True,\n", "    ):\n", "        print(\" ------------- matchue ------------- \")\n", "        self.name = name\n", "        self.results_dir = results_dir\n", "        self.models_dir = models_dir\n", "        self.data_dir = data_dir\n", "        self.dataset_dir = dataset_dir\n", "        self.ani_dir = ani_dir\n", "        self.latent_size = latent_size\n", "        self.im_size = im_size\n", "        self.BATCH_SIZE = BATCH_SIZE\n", "        self.update = update\n", "        self.images = images\n", "        self.segments = segments\n", "        self.verbose = verbose\n", "        self.mixed_prob = 0.9        \n", "        self.steps = steps\n", "        self.qsteps = qsteps       \n", "        if 0:                         # to train steps\n", "            print(\"StyleGan:qsteps: will train up to %d steps\" %self.qsteps)\n", "        self.n_cycle = n_cycle  # will evaluate model each\n", "        self.n_save = n_save    # will save model each\n", "        self.n_ref = n_ref   # will identify model each\n", "        self.im_size = im_size\n", "        self.latent_size = latent_size\n", "        self.BATCH_SIZE = BATCH_SIZE\n", "        self.cha = cha\n", " \n", "        self.mixed_prob = 0.9\n", "    \n", "        self.n_layers = int(log2(im_size) - 1)\n", "        if 0:\n", "            print(\"matchue.Gan.n_layers %d\" %self.n_layers)\n\n", "        #Models\n", "        self.D = None\n", "        self.S = None\n", "        self.G = None\n", "        self.GE = None\n", "        self.SE = None\n", "        self.DM = None\n", "        self.AM = None\n\n", "        #Config\n", "        self.LR = lr\n", "        self.beta = 0.999\n\n", "        #Init Models\n", "        self.discriminator()\n", "        self.stylemapper()\n", "        self.generator()\n", "        self.GMO = Adam(lr = self.LR, beta_1 = 0, beta_2 = 0.999)\n", "        self.DMO = Adam(lr = self.LR, beta_1 = 0, beta_2 = 0.999)\n", "        self.GE = clone_model(self.G)\n", "        self.GE.set_weights(self.G.get_weights())\n", "        self.SE = clone_model(self.S)\n", "        self.SE.set_weights(self.S.get_weights())\n", "        self.GenModel()\n", "        self.GenModelA()\n\n", "        # --------------\n", "        self.ncyc = ncyc\n", "        if self.ncyc is not None:\n", "            print(f\"ncyc {self.ncyc} specified as arg\")\n", "        else:\n", "            lastSavedCyc = self.getRecordNumber()\n", "            if lastSavedCyc is not None:\n", "                print()\n", "                print(\"StyleGan2:lastSavedCyc: %d\" %lastSavedCyc)\n", "                print()\n", "            self.ncyc = lastSavedCyc\n", "        if self.ncyc is not None:\n", "            nstep = (self.ncyc + 1) * self.n_cycle + 1 # cyc 0 save will jump to n_cycle steps\n", "            self.steps = nstep\n", "            print(f\"StyleGan2:load MODEL {self.ncyc} for steps: {nstep}\")\n", "            self.load(self.ncyc)\n", "        else:\n", "            print(\"StyleGan2:ncyc is None, will not load model\")\n", "        if 0:\n", "            print(\"StyleGan2:steps %d\" %self.steps)\n\n", "        #Set up variables\n", "        self.lastblip = time.process_time()\n", "        self.silent = silent\n", "        self.ones = np.ones((BATCH_SIZE, 1), dtype=np.float32)\n", "        self.zeros = np.zeros((BATCH_SIZE, 1), dtype=np.float32)\n", "        self.nones = -self.ones\n", "        self.pl_mean = 0\n", "        self.av = np.zeros([44]) # _e_\n", "    def noise(self, n):\n", "        latent_size = self.latent_size\n", "        return np.random.normal(0.0, 1.0, size = [n, latent_size]).astype('float32')\n", "    def noiseList(self, n):\n", "        noise = self.noise\n", "        n_layers = self.n_layers\n", "        return [noise(n)] * (n_layers)\n", "    def mixedList(self, n):\n", "        noise = self.noise\n", "        n_layers = self.n_layers\n", "        tt = int(np.random.uniform(()) * n_layers)\n", "        p1 = [noise(n)] * tt\n", "        p2 = [noise(n)] * (n_layers - tt)\n", "        return p1 + [] + p2\n", "    def nImage(self, n):\n", "        im_size = self.im_size\n", "        return np.random.uniform(0.0, 1.0, size = [n, im_size, im_size, 1]).astype('float32')\n", "    @staticmethod\n", "    def hinge_d(y_true, y_pred):\n", "        return K.mean(K.relu(1.0 + (y_true * y_pred)))\n", "    @staticmethod\n", "    def w_loss(y_true, y_pred):\n", "        return K.mean(y_true * y_pred)\n\n", "    #Lambdas\n", "    # https://www.tensorflow.org/api_docs/python/tf/keras/layers/Lambda?version=stable\n", "    @staticmethod\n", "    def crop_to_fit(x):\n", "        height = x[1].shape[1]\n", "        width = x[1].shape[2]\n", "        return x[0][:, :height, :width, :]\n", "    @staticmethod\n", "    def upsample(x):\n", "        return K.resize_images(x,2,2,\"channels_last\",interpolation='bilinear')\n", "    @staticmethod\n", "    def upsample_to_size(x, im_size=1024):\n", "        y = int(im_size / x.shape[2]) # _e_\n", "        x = K.resize_images(x, y, y, \"channels_last\",interpolation='bilinear')\n", "        return x\n\n", "    #Blocks\n", "    def g_block(self, inp, istyle, inoise, fil, u = True):\n", "        crop_to_fit = self.crop_to_fit\n", "        to_rgb = self.to_rgb\n", "        upsample = self.upsample\n", "        if u:\n", "            #Custom upsampling because of clone_model issue\n", "            out = Lambda(upsample, output_shape=[None, inp.shape[2] * 2, inp.shape[2] * 2, None])(inp)\n", "        else:\n", "            out = Activation('linear')(inp)\n", "        rgb_style = Dense(fil, kernel_initializer = VarianceScaling(200/out.shape[2]))(istyle)\n", "        style = Dense(inp.shape[-1], kernel_initializer = 'he_uniform')(istyle)\n", "        delta = Lambda(crop_to_fit)([inoise, out])\n", "        d = Dense(fil, kernel_initializer = 'zeros')(delta)\n", "        out = Conv2DMod(filters = fil, kernel_size = 3, padding = 'same', kernel_initializer = 'he_uniform')([out, style])\n", "        out = add([out, d])\n", "        out = LeakyReLU(0.2)(out)\n", "        style = Dense(fil, kernel_initializer = 'he_uniform')(istyle)\n", "        d = Dense(fil, kernel_initializer = 'zeros')(delta)\n", "        out = Conv2DMod(filters = fil, kernel_size = 3, padding = 'same', kernel_initializer = 'he_uniform')([out, style])\n", "        out = add([out, d])\n", "        out = LeakyReLU(0.2)(out)\n", "        return out, to_rgb(out, rgb_style)\n", "    def d_block(self, inp, fil, p = True):\n", "        res = Conv2D(fil, 1, kernel_initializer = 'he_uniform')(inp)\n", "        out = Conv2D(filters = fil, kernel_size = 3, padding = 'same', kernel_initializer = 'he_uniform')(inp)\n", "        out = LeakyReLU(0.2)(out)\n", "        out = Conv2D(filters = fil, kernel_size = 3, padding = 'same', kernel_initializer = 'he_uniform')(out)\n", "        out = LeakyReLU(0.2)(out)\n", "        out = add([res, out])\n", "        if p:\n", "            out = AveragePooling2D()(out)\n", "        return out\n", "    def to_rgb(self, inp, style):\n", "        im_size = self.im_size\n", "        upsample_to_size = self.upsample_to_size\n", "        size = inp.shape[2]\n", "        x = Conv2DMod(3, 1, kernel_initializer = VarianceScaling(200/size), demod = False)([inp, style])\n", "        return Lambda(upsample_to_size, output_shape=[None, im_size, im_size, None], arguments= {'im_size': im_size})(x)\n", "    def from_rgb(self, inp, conc = None):\n", "        \n", "        im_size = self.im_size\n", "        fil = int(im_size * 4 / inp.shape[2])\n", "        z = AveragePooling2D()(inp)\n", "        x = Conv2D(fil, 1, kernel_initializer = 'he_uniform')(z)\n", "        if conc is not None:\n", "            x = concatenate([x, conc])\n", "        return x, z\n", "    def discriminator(self):\n", "        im_size = self.im_size\n", "        cha = self.cha\n", "        if self.D:\n", "            return self.D\n", "        inp = Input(shape = [im_size, im_size, 3])\n", "        x = self.d_block(inp, 1 * cha)   #128\n", "        x = self.d_block(x, 2 * cha)   #64\n", "        x = self.d_block(x, 4 * cha)   #32\n", "        x = self.d_block(x, 6 * cha)  #16\n", "        x = self.d_block(x, 8 * cha)  #8\n", "        x = self.d_block(x, 16 * cha)  #4\n", "        x = self.d_block(x, 32 * cha, p = False)  #4\n", "        x = Flatten()(x)\n", "        x = Dense(1, kernel_initializer = 'he_uniform')(x)\n", "        self.D = Model(inputs = inp, outputs = x)\n", "        return self.D\n", "    def stylemapper(self):\n", "        print(\" ------------- matchue stylemapper start ------------- \")\n", "        if self.S:\n", "            return self.S\n", "        latent_size = self.latent_size\n", "        self.S = Sequential()\n", "        self.S.add(Dense(512, input_shape = [latent_size]))\n", "        self.S.add(LeakyReLU(0.2))\n", "        self.S.add(Dense(512))\n", "        self.S.add(LeakyReLU(0.2))\n", "        self.S.add(Dense(512))\n", "        self.S.add(LeakyReLU(0.2))\n", "        self.S.add(Dense(512))\n", "        self.S.add(LeakyReLU(0.2))\n", "        return self.S\n", "    def generator(self):\n", "        print(\" ------------- matchue generator start ------------- \")\n", "        latent_size = self.latent_size\n", "        cha = self.cha\n", "        n_layers = self.n_layers\n", "        im_size = self.im_size\n", "        if self.G:\n", "            return self.G\n\n", "        # # === Style Mapping ===\n\n", "        # self.S = Sequential()\n\n", "        # self.S.add(Dense(512, input_shape = [latent_size]))\n", "        # self.S.add(LeakyReLU(0.2))\n", "        # self.S.add(Dense(512))\n", "        # self.S.add(LeakyReLU(0.2))\n", "        # self.S.add(Dense(512))\n", "        # self.S.add(LeakyReLU(0.2))\n", "        # self.S.add(Dense(512))\n", "        # self.S.add(LeakyReLU(0.2))\n\n", "        # === Generator ===\n\n", "        #Inputs\n", "        inp_style = []\n", "        for i in range(n_layers):\n", "            inp_style.append(Input([512]))\n", "        inp_noise = Input([im_size, im_size, 1])\n\n", "        #Latent\n", "        x = Lambda(lambda x: x[:, :1] * 0 + 1)(inp_style[0])\n", "        outs = []\n\n", "        #Actual Model\n", "        x = Dense(4*4*4*cha, activation = 'relu', kernel_initializer = 'random_normal')(x)\n", "        x = Reshape([4, 4, 4*cha])(x)\n", "        x, r = self.g_block(x, inp_style[0], inp_noise, 32 * cha, u = False)  #4\n", "        outs.append(r)\n", "        x, r = self.g_block(x, inp_style[1], inp_noise, 16 * cha)  #8\n", "        outs.append(r)\n", "        x, r = self.g_block(x, inp_style[2], inp_noise, 8 * cha)  #16\n", "        outs.append(r)\n", "        x, r = self.g_block(x, inp_style[3], inp_noise, 6 * cha)  #32\n", "        outs.append(r)\n", "        x, r = self.g_block(x, inp_style[4], inp_noise, 4 * cha)   #64\n", "        outs.append(r)\n", "        x, r = self.g_block(x, inp_style[5], inp_noise, 2 * cha)   #128\n", "        outs.append(r)\n", "        x, r = self.g_block(x, inp_style[6], inp_noise, 1 * cha)   #256\n", "        outs.append(r)\n", "        x = add(outs)\n", "        x = Lambda(lambda y: y/2 + 0.5)(x) #Use values centered around 0, but normalize to [0, 1], providing better initialization\n", "        self.G = Model(inputs = inp_style + [inp_noise], outputs = x)\n", "        return self.G\n", "    def GenModel(self):\n", "        n_layers = self.n_layers\n", "        im_size = self.im_size\n", "        latent_size = self.latent_size\n\n", "        # Generator Model for Evaluation\n", "        if 0:\n", "            print(\"GM\")\n", "            print(\"GM:n_layers\", n_layers)\n", "            print(\"GM:im_size\", im_size)\n", "            print(\"GM:latent_size\", latent_size)\n", "        inp_style = []\n", "        style = []\n", "        for i in range(n_layers):\n", "            inp_style.append(Input([latent_size]))\n", "            style.append(self.S(inp_style[-1])) # add S layers\n", "        inp_noise = Input([im_size, im_size, 1])\n", "        if 0:\n", "            print(\"GM:shape style (added S layers)\", np.shape(style)) # (7,)\n", "            print(\"GM:shape style plus noise\", np.shape(style + [inp_noise])) # (8,)\n", "        if 0:\n", "            self.G.summary()\n", "        gf = self.G(style + [inp_noise])\n", "        if 0:\n", "            print(\"GM:shape style + noise\", np.shape(inp_style + [inp_noise])) # style + noise (8,)\n", "            # A None dimension in a shape tuple means that the network will be able to accept inputs of any dimension\n", "            print(\"GM:shape generated style + noise\", np.shape(gf)) # (None, 256, 256, 3)\n", "        self.GM = Model(inputs = inp_style + [inp_noise], outputs = gf)\n", "        return self.GM\n", "    def GenModelA(self):\n", "        n_layers = self.n_layers\n", "        im_size = self.im_size\n", "        latent_size = self.latent_size\n\n", "        #Parameter Averaged Generator Model\n", "        inp_style = []\n", "        style = []\n", "        for i in range(n_layers):\n", "            inp_style.append(Input([latent_size]))\n", "            style.append(self.SE(inp_style[-1]))\n", "        inp_noise = Input([im_size, im_size, 1])\n", "        gf = self.GE(style + [inp_noise])\n", "        self.GMA = Model(inputs = inp_style + [inp_noise], outputs = gf)\n", "        return self.GMA\n", "    def EMA(self):\n", "        #Parameter Averaging\n", "        for i in range(len(self.G.layers)):\n", "            up_weight = self.G.layers[i].get_weights()\n", "            old_weight = self.GE.layers[i].get_weights()\n", "            new_weight = []\n", "            for j in range(len(up_weight)):\n", "                new_weight.append(old_weight[j] * self.beta + (1-self.beta) * up_weight[j])\n", "            self.GE.layers[i].set_weights(new_weight)\n", "        for i in range(len(self.S.layers)):\n", "            up_weight = self.S.layers[i].get_weights()\n", "            old_weight = self.SE.layers[i].get_weights()\n", "            new_weight = []\n", "            for j in range(len(up_weight)):\n", "                new_weight.append(old_weight[j] * self.beta + (1-self.beta) * up_weight[j])\n", "            self.SE.layers[i].set_weights(new_weight)\n", "    def MAinit(self):\n", "        #Reset Parameter Averaging\n", "        self.GE.set_weights(self.G.get_weights())\n", "        self.SE.set_weights(self.S.get_weights())\n", "    def get_batch(self, num, flip = True, verbose=False):\n", "        npyfolder = self.dataset_dir\n\n", "        # load self.images from npy if beyond limit\n", "        if self.update > self.images.shape[0]:\n", "            self.load_from_npy(npyfolder)\n", "            # self.update = 0\n", "        self.update = self.update + num\n", "        idx = np.random.randint(0, self.images.shape[0] - 1, num)\n", "        out = []\n", "        for i in idx:\n", "            out.append(self.images[i])\n", "            if flip and np.random.uniform(0.0, 1.0) < 0.5:  # flip as arg\n", "                out[-1] = np.flip(out[-1], 1)\n", "        return np.array(out).astype('float32') / 255.0\n", "    def fit(self):\n", "        im_size = self.im_size\n", "        latent_size = self.latent_size\n", "        mixed_prob = self.mixed_prob\n", "        noiseList = self.noiseList\n", "        mixedList = self.mixedList\n", "        nImage = self.nImage\n", "        BATCH_SIZE = self.BATCH_SIZE\n", "        reststeps = self.qsteps - self.steps\n", "        self.load_from_npy(self.dataset_dir)\n", "        n_cycle = self.n_cycle\n", "        n_save = self.n_save\n", "        n_ref = self.n_ref\n", "        firststep = self.steps\n", "        print(f\"|===> fit:  \\n \\\n", "            steps: {self.steps} \\n \\\n", "            qsteps: {self.qsteps} \\n \\\n", "            reststeps: {reststeps} \\n \\\n", "            BATCH_SIZE: {BATCH_SIZE} \\n \\\n", "            n_layers: {self.n_layers} \\n \\\n", "            latent_size: {self.latent_size} \\n \\\n", "            im_size: {self.im_size} \\n \\\n", "            self.data_dir: {self.data_dir} \\n \\\n", "            n_cycle: {n_cycle} \\n \\\n", "            n_save: {n_save} \\n \\\n", "            n_ref: {n_ref} \\n \\\n", "            verbose: {self.verbose} \\n \\\n", "        \")\n", "        while self.steps < self.qsteps:\n\n", "            #   train alternating - per layer\n", "            styletype = ''\n", "            if np.random.uniform(()) < mixed_prob:\n", "                styletype = 'mixedList'\n", "                style = mixedList(BATCH_SIZE)\n", "            else:\n", "                # style = np.random.normal(0.0, 1.0, size = [BATCH_SIZE, latent_size]).astype('float32')\n", "                styletype = 'noiseList'\n", "                style = noiseList(BATCH_SIZE)\n\n", "            #   batch of real images\n", "            images = self.get_batch(BATCH_SIZE, flip = True, verbose=True)\n\n", "            #   \n", "            noises = np.random.uniform(0.0, 1.0, size = [BATCH_SIZE, im_size, im_size, 1]).astype('float32')\n", "            if self.steps - firststep < 6: # doc first steps\n", "                print(f\"|===> step: {self.steps - firststep}:  \\n \\\n", "                    styletype: {styletype} \\n \\\n", "                    style: {np.shape(style)} {type(style)} \\n \\\n", "                    images: {np.shape(images)} {type(images)} \\n \\\n", "                    noises: {np.shape(noises)} {type(noises)} \\n \\\n", "                \")\n", "            apply_gradient_penalty = self.steps % 2 == 0 or self.steps < 10000\n", "            apply_path_penalty = self.steps % 16 == 0 # penalties every 16 steps\n\n", "            # ===========\n", "            # train step\n", "            # d_loss, g_loss, divergence, pl_lengths\n", "            a, b, c, d = self.train_step(images, style, noises, \n", "                        apply_gradient_penalty, \n", "                        apply_path_penalty)\n\n", "            # ===========\n\n", "            #Adjust path length penalty mean\n", "            #d = pl_mean when no penalty is applied\n", "            if self.pl_mean == 0:\n", "                self.pl_mean = np.mean(d)\n", "            self.pl_mean = 0.99*self.pl_mean + 0.01*np.mean(d)\n\n", "            # GAN EMA if steps > 20000 mod 10\n", "            if self.steps % 10 == 0 and self.steps > 20000:\n", "                self.EMA() # Parameter Averaging\n\n", "            # GAN MAinit if \n", "            if self.steps <= 25000 and self.steps % 1000 == 2:\n", "                self.MAinit() # Reset Parameter Averaging\n", "            if np.isnan(a):\n", "                print(\"NaN Value Error.\")\n", "                exit()\n", "            if self.steps % 100 == 0:\n", "                if self.verbose:\n", "                    print(f'|===> fit:  \\n \\\n", "                        steps:  {str(self.steps)}\\n \\\n", "                        steps to save model:  {n_save - (self.steps % n_save)}\\n \\\n", "                        steps to increase cycle:  {n_cycle - (self.steps % n_cycle)}\\n \\\n", "                        steps to evaluate:  {n_cycle - (self.steps % n_cycle)}\\n \\\n", "                    ')     \n", "            if self.steps % 100 == 0:\n", "                if self.verbose:\n", "                    print(f\"|===> fit:  \\n \\\n", "                        D loss:     {np.array(a)}\\n \\\n", "                        G loss:     {np.array(b)}\\n \\\n", "                        path length:{self.pl_mean}\\n \\\n", "                    \")                       \n", "                s = round((time.process_time() - self.lastblip), 4)\n", "                self.lastblip = time.process_time()\n", "                steps_per_second = 100 / s\n", "                steps_per_minute = steps_per_second * 60\n", "                steps_per_hour = steps_per_minute * 60\n", "                min1k = floor(1000/steps_per_minute)\n", "                sec1k = floor(1000/steps_per_second) % 60\n", "                steps_left = self.qsteps - self.steps + 1e-7\n", "                hours_left = steps_left // steps_per_hour\n", "                minutes_left = (steps_left // steps_per_minute) % 60\n", "                if self.verbose:\n", "                    print(f'|===> fit:  \\n \\\n", "                        StyleGan2 Steps/Second:  {str(round(steps_per_second, 2))}\\n \\\n", "                        StyleGan2 1k Steps:  {str(min1k) + \":\" + str(sec1k)} \\n \\\n", "                        StyleGan2 Till Completion: {str(int(hours_left)) + \"h\" + str(int(minutes_left)) + \"m\"} \\n \\\n", "                    ')       \n", "                # save model\n", "                if self.steps % n_save == 0:\n", "                    _num = int(floor(self.steps / n_ref))\n", "                    print(f\"|===> fit:  \\n \\\n", "                        step :  {self.steps}\\n \\\n", "                        save model :  {_num}\\n \\\n", "                    \")                          \n", "                    self.save(_num)\n", "                # increase cycle\n", "                if self.steps % n_cycle == 0:\n", "                    self.ncyc = floor(self.steps / n_cycle)\n", "                    print(f\"|===> fit:  \\n \\\n", "                        self.steps:  {self.steps}\\n \\\n", "                        n_cycle:  {n_cycle}\\n \\\n", "                        StyleGan2.train cycle:  {self.ncyc}\\n \\\n", "                    \")                     \n", "                # Model Evaluate\n", "                if self.steps % n_cycle == 0:\n", "                    print(f\"|===> fit:  \\n \\\n", "                        evaluate step:  {self.steps}\\n \\\n", "                    \")                        \n", "                    self.evaluate(self.steps)\n", "            onutil.printProgressBar(self.steps % 100, 99, decimals = 0, fill=\">\")\n", "            self.steps = self.steps + 1\n", "    @tf.function\n", "    def train_step(self, real_images, style, noise, perform_gp = True, perform_pl = False):\n", "        with tf.GradientTape() as g_tape, tf.GradientTape() as d_tape:\n", "            w_space = []\n", "            pl_lengths = self.pl_mean   # _e_\n", "            for i in range(len(style)):\n", "                w_space.append(self.S(style[i]))\n", "            fake_images = self.G(w_space + [noise])\n", "            real_scores = self.D(real_images, training=True)\n", "            fake_scores = self.D(fake_images, training=True)\n", "            divergence = tf.math.softplus(fake_scores)  # log ( 1 + exp( D(fakes) ) ) # alt tf.math.relu\n", "            divergence += tf.math.softplus(-real_scores) # log ( 1 - exp( D(reals) ) )  # alt tf.math.relu\n", "            divergence = tf.keras.backend.mean(divergence)\n", "            d_loss = divergence\n", "            with tf.GradientTape() as p_tape:\n", "                p_tape.watch(real_images)\n", "                real_loss = tf.reduce_sum(self.D(real_images, training=True))\n", "            if perform_gp: # gradient penalty - Penalize the gradient norm  \n", "                real_grads = p_tape.gradient(real_loss, real_images)\n", "                r1_penalty = tf.reduce_sum(tf.math.square(real_grads), # ||grad||^2\n", "                    axis=np.arange(0, len(np.shape(real_grads)))) # [0, 1, 2, 3]\n", "                self.r1_gamma = 10.0 # weight\n", "                r1_penalty = r1_penalty * (0.5 * self.r1_gamma) # (weight / 2) * ||grad||^2\n", "                d_loss += r1_penalty\n", "            d_loss = tf.reduce_mean(d_loss)\n", "            g_loss = tf.math.softplus(-fake_scores)\n", "            if perform_pl: # path length penalty - slightly adjust W space\n", "                w_space_2 = []\n", "                for i in range(len(style)):\n", "                    std = 0.1 / (tf.keras.backend.std(w_space[i], axis = 0, keepdims = True) + 1e-8)\n", "                    w_space_2.append(w_space[i] + tf.keras.backend.random_normal(tf.shape(w_space[i])) / (std + 1e-8))\n", "                # Generate from slightly adjusted W space\n", "                pl_images = self.G(w_space_2 + [noise])\n", "                # Get distance after adjustment (path length)\n", "                delta_g = tf.keras.backend.mean(tf.keras.backend.square(pl_images - fake_images), axis = [1, 2, 3])\n", "                pl_lengths = delta_g\n", "                if self.pl_mean > 0:\n", "                    g_loss += tf.keras.backend.mean(tf.keras.backend.square(pl_lengths - self.pl_mean))\n", "            g_loss = tf.reduce_mean(g_loss)\n", "        g_gradients = g_tape.gradient(g_loss, self.GM.trainable_variables)\n", "        self.GMO.apply_gradients(zip(g_gradients, self.GM.trainable_variables))\n", "        d_gradients = d_tape.gradient(d_loss, self.D.trainable_variables)\n", "        self.DMO.apply_gradients(zip(d_gradients, self.D.trainable_variables))\n", "        return d_loss, g_loss, divergence, pl_lengths\n", "    def load_from_npy(self, folder):\n", "        # for dirpath, dirnames, filenames in os.walk(\"data/\" + folder + \"-npy-\" + str(self.im_size)):\n", "        for dirpath, dirnames, filenames in os.walk(folder):\n", "            for filename in [f for f in filenames if f.endswith(\".npy\")]:\n", "                self.segments.append(os.path.join(dirpath, filename))\n", "        self.load_segment()\n", "    def load_segment(self):\n", "        segment_num =np.random.randint(0, len(self.segments))\n", "        self.images = np.load(self.segments[segment_num])\n", "        self.update = 0\n\n", "    #\n", "    def evaluate(self, trunc = 1.0, outImage = True, num = None, qsegs = 1, frames=1, verbose=False):\n", "        results_dir = self.results_dir\n", "        latent_size = self.latent_size\n", "        noise = self.noise      # np.random.normal(0.0, 1.0, size = [n, self.latent_size]).astype('float32')\n", "        nImage = self.nImage    # np.random.uniform(0.0, 1.0, size = [n, self.im_size, self.im_size, 1]).astype('float32')\n", "        BATCH_SIZE = self.BATCH_SIZE\n", "        n_layers = self.n_layers\n", "        noise = self.noise\n", "        noiseList = self.noiseList\n", "        im_size = self.im_size\n", "        GM = self.GM\n", "        GMA = self.GMA\n", "        if (not num == None):\n", "            ncyc = num\n", "        elif (not self.ncyc == None):\n", "            ncyc = self.ncyc\n", "        else:\n", "            ncyc =0\n", "        qcells = qsegs * qsegs\n", "        nnoisedata = [np.random.random(size = [qcells, latent_size]).astype('float32')] * (n_layers)\n", "        nimagedata = np.random.uniform(low = 0, high = 1, size = [qcells, im_size, im_size, 1]).astype('float32')\n", "        trunc = np.ones([qcells, 1]) * trunc\n\n", "        # will save\n", "        img_path = os.path.join(results_dir, \"i{:04d}\".format(int(ncyc)) + \".png\")\n", "        ema_path = os.path.join(results_dir, \"i{:04d}\".format(int(ncyc)) + \"-ema.png\")\n", "        mr_path = os.path.join(results_dir,  \"i{:04d}\".format(int(ncyc)) + \"-mr.png\")\n\n", "        # GM  predict\n", "        seed = nnoisedata + [nimagedata] #\n", "        if self.verbose:\n", "            print(f\"|===> evaluate:  \\n \\\n", "                get samples: {qcells} * {latent_size} normal distribution, style map, average \\n \\\n", "                nnoisedata:  {np.shape(nnoisedata)} {type(nnoisedata)}\\n \\\n", "                [nimagedata]:  {np.shape([nimagedata])} {type([nimagedata])}\\n \\\n", "                trunc:  {np.shape(trunc)} {type(trunc)}\\n \\\n", "                save predict:  {img_path} \\n \\\n", "                save ema:  {ema_path} \\n \\\n", "                save mixed:  {mr_path} \\n \\\n", "            \")                           \n", "        generated_images = GM.predict(seed, batch_size = BATCH_SIZE)\n", "        r = []\n", "        for i in range(0, qcells, qsegs):\n", "            r.append(np.concatenate(generated_images[i:i+qsegs], axis = 1))\n", "        c1 = np.concatenate(r, axis = 0)\n", "        c1 = np.clip(c1, 0.0, 1.0)\n", "        x = Image.fromarray(np.uint8(c1*255))\n", "        x.save(img_path)\n\n", "        # GMA predict     \n", "        generated_images = GMA.predict(nnoisedata + [nimagedata, trunc], batch_size = BATCH_SIZE)\n", "        r = []\n", "        for i in range(0, qcells, qsegs):\n", "            r.append(np.concatenate(generated_images[i:i+qsegs], axis = 1))\n", "        c1 = np.concatenate(r, axis = 0)\n", "        c1 = np.clip(c1, 0.0, 1.0)\n", "        x = Image.fromarray(np.uint8(c1*255))\n", "        x.save(ema_path)\n\n", "        #Mixing Regularities\n", "        nn = noise(qsegs)\n", "        nnoisedata = np.tile(nn, (qsegs, 1))\n", "        nimagedata = np.repeat(nn, qsegs, axis = 0)\n", "        tt = int(n_layers / 2)\n", "        p1 = [nnoisedata] * tt\n", "        p2 = [nimagedata] * (n_layers - tt)\n", "        latent = p1 + [] + p2\n\n", "        # GMA predict\n", "        generated_images = GMA.predict(latent + [nImage(qcells), trunc], batch_size = BATCH_SIZE)\n", "        r = []\n", "        for i in range(0, qcells, qsegs):\n", "            r.append(np.concatenate(generated_images[i:i+qsegs], axis = 0))\n", "        c1 = np.concatenate(r, axis = 1)\n", "        c1 = np.clip(c1, 0.0, 1.0)\n", "        x = Image.fromarray(np.uint8(c1*255))\n", "        x.save(mr_path)\n", "        return x\n", "    \n", "    #\n", "    def generateTruncated(self, trunc = 0.7, outImage = False, num = 0, qsegs=1):\n\n", "        # n1 = model.noiseList(64)\n", "        # n2 = model.nImage(64)\n", "        # n1, noi = n2\n", "        results_dir = self.results_dir\n", "        BATCH_SIZE = self.BATCH_SIZE\n", "        noise = self.noise\n", "        noiseList = self.noiseList\n", "        nImage = self.nImage\n", "        GE = self.GE\n", "        S = self.S # Style Mapping\n", "        pl_mean = self.pl_mean # 0\n", "        # av = self.av # np.zeros([44])\n", "        ncyc = self.ncyc\n", "        latent_size = self.latent_size\n", "        n_layers = self.n_layers\n", "        im_size = self.im_size\n", "        qcells = qsegs * qsegs  # will predict images\n", "            \n", "        # Get W's (latents') center of mass\n", "        dlatent_avg_start = np.random.normal(0.0, 1.0, size = [qcells, latent_size]).astype('float32')\n", "        dlatent_avg_predict = S.predict(dlatent_avg_start, batch_size = BATCH_SIZE)\n", "        dlatent_avg_mean = np.mean(dlatent_avg_predict, axis = 0)\n", "        dlatent_avg = np.expand_dims(dlatent_avg_mean, axis = 0)\n", "        vary = np.random.normal(0.0, 1.0, size = [qcells, latent_size]).astype('float32')\n", "        dlatent_imgs = []\n", "        styles = [vary] * (n_layers)\n", "        for i in range(len(styles)):\n", "            dlatent = S.predict(styles[i])\n", "            dl = trunc * (dlatent - dlatent_avg) + dlatent_avg # trunc * dlatent\n", "            dlatent_imgs.append(dl)\n", "        noises = np.random.uniform(0.0, 1.0, size = [qcells, im_size, im_size, 1]).astype('float32')\n", "        seeds = dlatent_imgs + [noises]\n", "        z_images = GE.predict(seeds, batch_size = BATCH_SIZE)\n", "        if self.verbose:\n", "            print(f\"|===> generateTruncated:  \\n \\\n", "                [noises]: {np.shape([noises])} {type([noises])} \\n \\\n", "                dlatent_imgs: {np.shape(dlatent_imgs)} {type(dlatent_imgs)} \\n \\\n", "                trunc get {qcells} * {latent_size} normal distribution samples, style map, average\\n \\\n", "            \")    \n", "        if outImage:\n", "            imgpath = os.path.join(results_dir, f\"t{str(num)}.png\")\n", "            if self.verbose:\n", "                print(f\"|===> generateTruncated:  \\n \\\n", "                    save:  {imgpath}\\n \\\n", "                \")                   \n", "            onformat.imgs_to_tiling(z_images, imgpath, qsegs)\n", "        return z_images\n", "    def generateWalk(self, trunc = 0.7, outImage = True, num = 0, qsegs=1, fps = 2, maxTime = 3, ):\n", "        results_dir = self.results_dir\n", "        ani_dir = self.ani_dir\n", "        BATCH_SIZE = self.BATCH_SIZE\n", "        noise = self.noise\n", "        noiseList = self.noiseList\n", "        nImage = self.nImage\n", "        GE = self.GE\n", "        S = self.S # Style Mapping\n", "        pl_mean = self.pl_mean # 0\n", "        # av = self.av # np.zeros([44])\n", "        ncyc = self.ncyc\n", "        latent_size = self.latent_size\n", "        n_layers = self.n_layers\n", "        im_size = self.im_size\n", "        qcells = qsegs * qsegs  # will predict images\n\n", "        # video settings\n", "        frameCount = 0\n", "        time = 0\n", "        nframes = int( maxTime*fps )\n", "        print(f\"walk get {qcells} * {latent_size} normal distribution samples, style map, average\")\n\n", "        # Get W's (latents') center of mass\n", "        dlatent_avg_start = np.random.normal(0.0, 1.0, size = [qcells, latent_size]).astype('float32')\n", "        dlatent_avg_predict = S.predict(dlatent_avg_start, batch_size = BATCH_SIZE)\n", "        dlatent_avg_mean = np.mean(dlatent_avg_predict, axis = 0)\n", "        dlatent_avg = np.expand_dims(dlatent_avg_mean, axis = 0)\n", "        seed_start = np.random.normal(1, 1, (qcells, latent_size))\n", "        latentSpeed = np.random.normal(2, 1, (nframes, latent_size))\n", "        varys = np.random.normal(1, 1, (nframes, qcells, latent_size))        \n", "        noises = np.random.uniform(0.0, 1.0, size = [qcells, im_size, im_size, 1]).astype('float32')  # (1, 9, 512, 512, 1)\n", "        print(f\"|===> generateWalk:  \\n \\\n", "            nframes: {nframes} \\n \\\n", "            qcells: {qcells} \\n \\\n", "            latent_size: {latent_size} \\n \\\n", "            noises: {type([noises])}{np.shape([noises])} \\n \\\n", "        \")    \n", "        imgs = []\n", "        for i in range(nframes): \n", "            time = i/nframes\n", "            if 0:\n", "                print(f\"{i} -------------------------{time} {maxTime} {time/maxTime}\")\n", "            for k in range(qcells):\n", "                \n", "                for j in range(latent_size): # _e_\n", "                    idelta = np.sin( 2*np.pi*(time/maxTime) * latentSpeed[i][j] ) \n", "                    if 0:\n", "                        print(f\"{i}:{j}:{k}: {seed_start[k][j]} - {time/maxTime} - {latentSpeed[i][j]} - {idelta}\")\n", "                    varys[i][k][j] = seed_start[k][j] + idelta\n", "                    \n", "            vary = varys[i] # <class 'numpy.ndarray'> (9, 512) (segs, ldims)\n", "            dlatent_imgs = []  # (8, 9, 512)\n", "            styles = [vary] * (n_layers)\n", "            for n in range(len(styles)):\n", "                dlatent = S.predict(styles[n])\n", "                dl = trunc * (dlatent - dlatent_avg) + dlatent_avg # trunc * dlatent\n", "                dlatent_imgs.append(dl)\n", "            seeds = dlatent_imgs + [noises]\n", "            z_images = GE.predict(seeds, batch_size = BATCH_SIZE) # (1, 512, 512, 3)\n", "            if outImage:\n", "                imgpath = os.path.join(ani_dir, f\"frame{str(i)}.png\")\n", "                onformat.imgs_to_tiling(z_images, imgpath, qsegs)\n", "            imgs.append(z_images)\n", "        return imgs\n", "    def getRecordNumber(self):\n", "        import re\n", "        models_dir = self.models_dir\n", "        num = None\n", "        nums = []\n", "        num_re = re.compile(r'^gen_(\\d+).h5$')\n", "        if self.verbose:\n", "            print(\"getRecordNumber in models_dir\", models_dir)\n", "        \n", "        for file in os.listdir(models_dir):\n", "            m = num_re.search(file)\n", "            if 0:\n", "                print(\"getRecordNumber\", file, m)            \n", "            if m:\n", "                num = int(m.group(1))\n", "                nums.append(num)     \n", "        if nums:\n", "            num = max(nums)\n", "        return num  # None or int\n", "    def saveModel(self, model, name, num):\n", "        \n", "        models_dir = self.models_dir\n", "        json = model.to_json()\n", "        with open(models_dir + \"/\"+name+\".json\", \"w\") as json_file:\n", "            json_file.write(json)\n", "        model.save_weights(models_dir + \"/\"+name+\"_\"+str(int(num))+\".h5\")\n", "    def loadModel(self, name, num):\n", "        \n", "        models_dir = self.models_dir\n", "        file_path = models_dir + \"/\"+name+\".json\"\n", "        file = open(file_path, 'r')\n", "        json = file.read()\n", "        file.close()\n", "        mod = model_from_json(json, custom_objects = {'Conv2DMod': Conv2DMod})\n", "        weights_path = models_dir + \"/\"+name+\"_\"+str(num)+\".h5\"\n", "        if 0:\n", "            print(f\"loadModel weights_path: {weights_path}\")\n", "        mod.load_weights(weights_path)\n", "        return mod\n", "    def save(self, num): #Save JSON and Weights into /Models/\n", "        if self.verbose:\n", "            print(f\"StyleGan.save num {num}\")\n", "        self.saveModel(self.S, \"sty\", num)\n", "        self.saveModel(self.G, \"gen\", num)\n", "        self.saveModel(self.D, \"dis\", num)\n", "        self.saveModel(self.GE, \"genMA\", num)\n", "        self.saveModel(self.SE, \"styMA\", num)\n", "    def load(self, num): #Load JSON and Weights from /Models/\n", "        if self.verbose:\n", "            print(\"StyleGan.load num %d\" %num)\n\n", "        #Load Models\n", "        self.D = self.loadModel(\"dis\", num)\n", "        self.S = self.loadModel(\"sty\", num)\n", "        self.G = self.loadModel(\"gen\", num)\n", "        self.GE = self.loadModel(\"genMA\", num)\n", "        self.SE = self.loadModel(\"styMA\", num)\n", "        self.GenModel()\n", "        self.GenModelA()\n", "#\n", "#\n", "#   CMDS\n", "#\n", "#\n", "#\n", "#   nnviv\n", "#\n", "def nnviv(args, kwargs):\n", "    args = onutil.pargs(vars(args))\n", "    args.PROJECT = 'StyleGan2-Tensorflow-2.0'\n", "    args.DATASET = 'space'\n", "    xp = getxp(vars(args))\n", "    args = onutil.pargs(xp)\n", "    onutil.ddict(vars(args), 'args')\n", "    if 1: # git\n", "        onutil.get_git(args.AUTHOR, args.GITPOD, args.proj_dir)\n", "    if 1: # tree\n", "        args.data_dir = os.path.join(args.proj_dir, \"data\")\n", "        args.models_dir = os.path.join(args.proj_dir, \"Models\")\n", "        args.results_dir = os.path.join(args.proj_dir, \"Results\")\n", "        os.makedirs(args.data_dir, exist_ok=True)\n", "        os.makedirs(args.models_dir, exist_ok=True)\n", "        os.makedirs(args.results_dir, exist_ok=True)\n", "        args.dataorg_dir=os.path.join(args.gdata, \"spaceone\")\n", "        args.data_dir = os.path.join(args.data_dir, 'Earth')\n", "        os.makedirs(args.data_dir, exist_ok=True)    \n", "    print(f\"|===> nnviv:  \\n \\\n", "        cwd:  {os.getcwd()}, \\n \\\n", "        args.dataorg_dir: {args.dataorg_dir}, \\n \\\n", "        args.results_dir: {args.results_dir}, \\n \\\n", "        args.models_dir:  {args.models_dir}, \\n \\\n", "        args.data_dir:    {args.data_dir}, \\n \\\n", "        \")\n", "    if 1: # copy models\n", "        earth_model_src_dir = os.path.join(args.gdata, \"LandscapesBig\")\n", "        onfile.copyfolder(earth_model_src_dir, args.models_dir)\n", "    if 0: # copy images\n", "        clip = (256, 256)\n", "        imgs = ondata.folder_to_formed_pils(args.dataorg_dir, clip = clip, qslices = 10, eps = 0.5)\n", "        onfile.pils_to_folder(imgs, args.data_dir)\n", "    if 1: # run script\n", "        cmd = f'python stylegan_two.py'\n", "        print(f'cmd: {cmd}')\n", "        os.system(cmd)\n", "#\n", "#\n", "#   nnearth\n", "#\n", "def nnearth(args, kwargs):\n", "    args = onutil.pargs(vars(args))\n", "    onutil.ddict(vars(args), 'args')\n", "    args.models_dir = os.path.join(args.gmodel, 'LandscapesBig')\n", "    clip = (256, 256)\n", "    latent_size = 512\n", "    im_size = 256\n", "    BATCH_SIZE = 8\n", "    mixed_prob = 0.9\n", "    qsteps = 20001\n", "    n_cycle = 500  # will evaluate model each\n", "    n_save = int(n_cycle / 1)    # will save model each\n", "    n_ref = n_cycle   # will identify model each\n", "    print(f\"|===> nnearth:  \\n \\\n", "                cwd: {os.getcwd()}, \\n \\\n", "                results_dir: {args.results_dir}, \\n \\\n", "                models_dir:  {args.models_dir}, \\n \\\n", "                dataorg_dir: {args.dataorg_dir}, \\n \\\n", "                data_dir:    {args.data_dir}, \\n \\\n", "                dataset_dir: {args.dataset_dir}, \\n \\\n", "                latent_size: {latent_size}, \\n \\\n", "                im_size: {im_size}, \\n \\\n", "                BATCH_SIZE: {BATCH_SIZE}, \\n \\\n", "                mixed_prob: {mixed_prob}, \\n \\\n", "                qsteps: {qsteps}, \\n \\\n", "            \\n \")\n", "    model = StyleGan2(lr = 0.0001, silent = False,\n", "        latent_size = latent_size,\n", "        im_size = im_size,\n", "        BATCH_SIZE = BATCH_SIZE, # 16\n", "        mixed_prob = mixed_prob,\n", "        qsteps = qsteps,   #   up to step\n", "        n_cycle = n_cycle,\n", "        n_save = n_save,\n", "        n_ref = n_ref,\n", "        results_dir = args.results_dir,\n", "        models_dir = args.models_dir,\n", "        dataorg_dir = args.dataorg_dir,\n", "        data_dir = args.data_dir,\n", "        dataset_dir = args.dataset_dir,\n", "    )\n", "    if 1:\n", "        model.evaluate(trunc = 0.7, qsegs = 1)\n", "#\n", "#   nndata\n", "#\n", "def nndata(args, kwargs):\n", "    args = onutil.pargs(vars(args))\n", "    args.PROJECT = 'space'\n", "    args.DATASET = 'space'\n", "    xp = getxp(vars(args))\n", "    args = onutil.pargs(xp)\n", "    onutil.ddict(vars(args), 'args')\n", "    print(f\"|===> nndata \\n \\\n", "                cwd: {os.getcwd()} \\n \\\n", "        \\n \")\n", "    zfill = 4\n", "    tile = (int(512*2), int(512*2))\n", "    clip = (512, 512)\n", "    im_size = 512\n", "    latent_size = 512\n", "    BATCH_SIZE = 8\n", "    mixed_prob = 0.9\n", "    qsteps = 200001\n", "    if 1: # clear code folder\n", "        onfile.clearfolder(args.proj_dir, inkey=args.PROJECT)\n", "    if 0: # clear domain folder\n", "        onfile.clearfolder(args.proto_dir, inkey=args.MNAME)\n", "    if 1: # tree\n", "        args.dataorg_dir=os.path.join(args.dataorg_dir, \"\")\n\n", "        # args.data_dir=os.path.join(args.gdata, args.DATASET + '_' + str(clip[0]) + '_' + str(clip[1]))   \n", "        args.dataset_dir=os.path.join(args.proj_dir, \"dataset\")   \n", "        args.models_dir=os.path.join(args.proj_dir, \"Models\")   \n", "        args.results_dir=os.path.join(args.proj_dir, \"Results\")  \n", "        tmp1_dir =  os.path.join(args.proto_dir, \"tmp1\")  # named\n", "        tmp2_dir =  os.path.join(args.proto_dir, \"tmp2\")  # formed\n", "        tmp3_dir =  os.path.join(args.proto_dir, \"tmp3\")  # dedup\n", "        os.makedirs(args.data_dir, exist_ok=True) # deduped formed\n", "        os.makedirs(args.dataset_dir, exist_ok=True) # npy folder\n", "        os.makedirs(args.models_dir, exist_ok=True)\n", "        os.makedirs(args.results_dir, exist_ok=True)\n", "        os.makedirs(args.tmp_dir, exist_ok=True)\n", "        os.makedirs(tmp1_dir, exist_ok=True)\n", "        os.makedirs(tmp2_dir, exist_ok=True)\n", "        os.makedirs(tmp3_dir, exist_ok=True)\n", "    print(f\"|===> nndata \\n \\\n", "                dataorg (raw) => tmp (raw) => data (formed) => dataset (npy) \\n \\\n", "                cwd:  {os.getcwd()}, \\n \\\n", "                args.dataorg_dir: {args.dataorg_dir} \\n \\\n", "                args.data_dir: {args.data_dir} \\n \\\n", "                args.dataset_dir: {args.dataset_dir} \\n \\\n", "                args.models_dir: {args.models_dir} \\n \\\n", "                args.results_dir: {args.results_dir} \\n \\\n", "        \\n \")\n", "    print(f\"|===> nndata:  \\n \\\n", "                clip: {clip} \\n \\\n", "                latent_size: {latent_size} \\n \\\n", "                im_size: {im_size} \\n \\\n", "                BATCH_SIZE: {BATCH_SIZE} \\n \\\n", "                mixed_prob: {mixed_prob} \\n \\\n", "                qsteps: {qsteps} \\n \\\n", "        \\n \")\n", "    if 0: #     copy models tp models_dir\n", "        print(f\"copy models from {earth_model_src_dir} to {args.models_dir}\")\n", "        earth_model_src_dir = os.path.join(args.gdata, \"LandscapesBig\")\n", "        onfile.copyfolder(earth_model_src_dir, args.models_dir)\n", "    if 0: #     plot dataorg sample\n", "        imgs = onfile.folder_to_pils(args.dataorg_dir, n=1)\n", "        img = imgs[0]\n", "        print(f\"img {type(img)} {np.shape(img)}\")\n", "        onplot.pil_show_pil(img)\n", "    if 0: #     dataorg to tmp1_dir (raws to named)\n", "        print(f\"nndata {onfile.qfiles(args.dataorg_dir)} raws in {args.dataorg_dir}\")\n", "        onfile.folder_to_named_files(args.dataorg_dir, tmp1_dir, n=-1) # _e_\n", "        # onfile.folder_to_named_files(args.dataorg_dir, tmp1_dir, n=18) # _e_\n", "    if 1: #     tmp1_dir to tmp2_dir (raws  to  formed)\n", "        \n", "        paths = onfile.folder_to_paths(tmp1_dir)\n", "        print(f\"{len(paths)} raws in {tmp1_dir} to {tmp2_dir}\")\n", "        if 1:  # get form imgs\n", "            for ipath,imgpath in enumerate(paths):\n", "                basename = os.path.basename(imgpath)\n", "                name = os.path.splitext(basename)[0]\n", "                ext = os.path.splitext(basename)[1]\n", "                namecode = name[len(\"img\"):]\n", "                if 0:\n", "                    print(f\"nndata imgpath: {imgpath}  {basename} {name} {ext} {namecode}\")\n", "                newidx=0\n", "                with Image.open(imgpath) as img:\n", "                    if 1: # scale\n", "                        img = ondata.pil_scale(img, 1)\n", "                    if 1: # tile\n", "                        _newimgs = ondata.img_to_tiled_pils(img, tile = tile)\n", "                        maxtiles = 9\n", "                        if len(_newimgs) > maxtiles:\n", "                            ids = np.random.choice(len(_newimgs), maxtiles)\n", "                            selectimgs = []\n", "                            for i in ids:\n", "                                selectimgs.append(_newimgs[i])\n", "        \n", "                            print(f\"{ipath}/{len(paths)}: tiles found {len(selectimgs)} in {np.shape(img)} {imgpath}. add {len(selectimgs[1:])}\")\n", "                            for _img in selectimgs:\n", "                                _newimg = ondata.pil_resize(_img, ps = clip)\n", "                                newpath = os.path.join( tmp2_dir, name + str(newidx).zfill(zfill) + \".jpg\")\n", "                                _newimg.save(newpath, 'JPEG', quality=90)                                 \n", "                                newidx += 1\n", "                        else:\n", "        \n", "                            if (len(_newimgs)) > 0:\n", "                                print(f\"{ipath}/{len(paths)}: tiles found {len(_newimgs)} in {np.shape(img)} {imgpath}. add {len(_newimgs[1:])}\")\n", "                                for _img in _newimgs:\n", "                                    _newimg = ondata.pil_resize(_img, ps = clip)\n", "                                    newpath = os.path.join( tmp2_dir, name + str(newidx).zfill(zfill) + \".jpg\")\n", "                                    _newimg.save(newpath, 'JPEG', quality=90)                                 \n", "                                    newidx += 1              \n", "                            \n", "                    if 1: # resize\n", "                        _newimg = ondata.pil_resize(img, ps = clip)\n", "                        newpath = os.path.join( tmp2_dir, name + str(newidx).zfill(zfill) + \".jpg\")\n", "                        _newimg.save(newpath, 'JPEG', quality=90)                                 \n", "                        newidx += 1    \n", "                    if 1: # purge file from data_dir until empty\n", "                        os.remove(imgpath)\n", "    if 1: #     tmp2_dir => dedup => tmp3_dir / excluded\n", "            #   tmp2_dir =>       => data_dir\n", "        pairs = []            \n", "        args.process_type = 'exclude'\n", "        args.file_extension = 'jpg'\n", "        args.avg_match = 1.0\n", "        args.absolute = False\n", "        args.output_folder = tmp2_dir # will save dups to args.output_folder/excluded\n", "        pairs = onfile.folder_to_cv_name_pairs(tmp2_dir, args) # get from \n", "        deduppairs = onset.exclude(pairs, args) \n", "        print(f\"nndata: got {len(deduppairs)} dedups\")\n", "        if not len(deduppairs) == onfile.qfiles(args.data_dir):\n", "            args.output_folder = args.data_dir  # imgs => output_folder (data_dir)\n", "            print(f\"nndata: will save undups to {args.output_folder}\")\n", "            onfile.cv_name_pairs_to_folder(deduppairs, args)\n", "    if 1: #     data folder  ==>  dataset npy\n", "        onrecord.folder_to_npy(args.data_dir, args.dataset_dir, im_size = clip[0], mss = (1024 ** 3))\n", "        imgs = onrecord.npys_folder_to_rgbs(args.dataset_dir)\n", "        print(f\"nndata: got imgs: {np.shape(imgs)}\")\n", "#\n", "#   nntrain\n", "#\n", "def nntrain(args, kwargs):\n", "    args = onutil.pargs(vars(args))\n", "    args.PROJECT = 'space'\n", "    args.DATASET = 'space'\n", "    \n", "    xp = getxp(vars(args))\n", "    args = onutil.pargs(xp)\n", "    onutil.ddict(vars(args), 'args')\n", "    print(f\"|===> nntrain \\n \\\n", "                cwd: {os.getcwd()} \\n \\\n", "        \\n \")\n", "    zfill = 4\n", "    tile = (int(512*2), int(512*2))\n", "    clip = (512, 512)\n", "    qslices = 4\n", "    eps = 0.9\n", "    latent_size = 512\n", "    im_size = 512\n", "    BATCH_SIZE = 4\n", "    mixed_prob = 0.9\n", "    qsteps = 200001\n", "    n_cycle = 500               # will evaluate model each\n", "    n_save = int(n_cycle / 1)   # will save model each\n", "    n_ref = n_cycle             # will identify model each\n", "    if 1: # tree\n", "        args.dataorg_dir=os.path.join(args.dataorg_dir, \"\")\n\n", "        # args.data_dir=os.path.join(args.gdata, args.DATASET + '_' + str(clip[0]) + '_' + str(clip[1]))   \n", "        args.dataset_dir=os.path.join(args.proj_dir, \"dataset\")   \n", "        args.models_dir=os.path.join(args.proj_dir, \"Models\")   \n", "        args.results_dir=os.path.join(args.proj_dir, \"Results\")   \n", "        os.makedirs(args.data_dir, exist_ok=True) # deduped formed\n", "        os.makedirs(args.dataset_dir, exist_ok=True) # npy folder\n", "        os.makedirs(args.models_dir, exist_ok=True)\n", "        os.makedirs(args.results_dir, exist_ok=True)\n", "        os.makedirs(args.tmp_dir, exist_ok=True) # name raws\n", "    print(f\"|===> nntrain \\n \\\n", "                dataorg (raw) => tmp (raw) => data (formed) => dataset (npy) \\n \\\n", "                cwd:  {os.getcwd()}, \\n \\\n", "                args.dataorg_dir: {args.dataorg_dir} \\n \\\n", "                args.data_dir: {args.data_dir} \\n \\\n", "                args.dataset_dir: {args.dataset_dir} \\n \\\n", "                args.models_dir: {args.models_dir} \\n \\\n", "                args.results_dir: {args.results_dir} \\n \\\n", "        \\n \")\n", "    print(f\"|===> nntrain:  \\n \\\n", "                clip: {clip} \\n \\\n", "                latent_size: {latent_size} \\n \\\n", "                im_size: {im_size} \\n \\\n", "                BATCH_SIZE: {BATCH_SIZE} \\n \\\n", "                mixed_prob: {mixed_prob} \\n \\\n", "                qsteps: {qsteps} \\n \\\n", "                n_cycle: {n_cycle} \\n \\\n", "                n_save: {n_save} \\n \\\n", "                n_ref: {n_ref} \\n \\\n", "        \\n \")\n", "    if 1: #     get model\n", "        model = StyleGan2(lr = 0.0001, silent = False,\n", "            latent_size = latent_size,\n", "            im_size = im_size,\n", "            BATCH_SIZE = BATCH_SIZE,\n", "            mixed_prob = mixed_prob,\n", "            qsteps = qsteps,\n", "            n_cycle = n_cycle,\n", "            n_save = n_save,\n", "            n_ref = n_ref,\n", "            name = args.MNAME,\n", "            results_dir = args.results_dir,\n", "            models_dir = args.models_dir,\n", "            dataorg_dir = args.dataorg_dir,\n", "            data_dir = args.data_dir,\n", "            dataset_dir = args.dataset_dir,\n", "        )\n", "    if 1: # train\n", "        model.fit()\n", "    if 1: # evaluate\n", "        img = model.evaluate()\n", "        onplot.pil_show_pil(img)\n", "#\n", "#   nntrunc\n", "#\n", "def nntrunc(args, kwargs):\n", "    args = onutil.pargs(vars(args))\n", "    onutil.ddict(vars(args), 'args')\n", "    print(f\"|===> nntrunc:  \\n \\\n", "    \")\n", "    latent_size = 512\n", "    im_size = 512\n", "    BATCH_SIZE = 4\n", "    mixed_prob = 0.9\n", "    qsteps = 200001\n", "    n_cycle = 500               # will evaluate model each\n", "    n_save = int(n_cycle / 1)   # will save model each\n", "    n_ref = n_cycle             # will identify model each\n", "    if 1: # tree\n", "        args.dataorg_dir=os.path.join(args.dataorg_dir, \"\")\n\n", "        # args.data_dir=os.path.join(args.gdata, args.DATASET + '_' + str(clip[0]) + '_' + str(clip[1]))   \n", "        args.dataset_dir=os.path.join(args.proj_dir, \"dataset\")   \n", "        args.models_dir=os.path.join(args.proj_dir, \"Models\")   \n", "        args.results_dir=os.path.join(args.proj_dir, \"Results\")   \n", "        args.ani_dir=os.path.join(args.proj_dir, \"ani\")   \n", "        os.makedirs(args.data_dir, exist_ok=True) # deduped formed\n", "        os.makedirs(args.dataset_dir, exist_ok=True) # npy folder\n", "        os.makedirs(args.models_dir, exist_ok=True)\n", "        os.makedirs(args.results_dir, exist_ok=True)\n", "        os.makedirs(args.tmp_dir, exist_ok=True) # name raws\n", "        os.makedirs(args.ani_dir, exist_ok=True) # anis\n", "    if 1: #     get model\n", "        model = StyleGan2(lr = 0.0001, silent = False,\n", "            latent_size = latent_size,\n", "            im_size = im_size,\n", "            BATCH_SIZE = BATCH_SIZE,\n", "            mixed_prob = mixed_prob,\n", "            qsteps = qsteps,\n", "            n_cycle = n_cycle,\n", "            n_save = n_save,\n", "            n_ref = n_ref,\n", "            name = args.MNAME,\n", "            results_dir = args.results_dir,\n", "            models_dir = args.models_dir,\n", "            dataorg_dir = args.dataorg_dir,\n", "            data_dir = args.data_dir,\n", "            dataset_dir = args.dataset_dir,\n", "            ani_dir = args.ani_dir,\n", "            verbose = True,\n", "        )\n", "    if 1:  # truncate\n", "        model.generateTruncated(trunc = 0.5, outImage = True, num = 0, qsegs=1)\n", "    if 1:  # frames truncate\n", "        fps = 6 # 30\n", "        maxTime = 5 # 30 # seconds\n", "        nframes = int( maxTime*fps )               \n", "        for i in range(nframes):\n", "            imgs = model.generateTruncated(trunc = i / 50, outImage = True, num = i, qsegs=2)\n", "    if 1:  # ani create\n", "        onvid.folder_to_vid(args.results_dir, os.path.join(args.results_dir, \"ani.gif\"))\n", "    if 1:  # ani show\n", "        onvid.vid_show(os.path.join(args.results_dir, \"ani.gif\"))\n", "#\n", "#   nnwalk\n", "#\n", "def nnwalk(args, kwargs):\n", "    args = onutil.pargs(vars(args))\n", "    onutil.ddict(vars(args), 'args')\n", "    print(f\"|===> nnwalk:  \\n \\\n", "    \")\n", "    latent_size = 512\n", "    im_size = 512\n", "    BATCH_SIZE = 4\n", "    mixed_prob = 0.9\n", "    qsteps = 200001\n", "    n_cycle = 500               # will evaluate model each\n", "    n_save = int(n_cycle / 1)   # will save model each\n", "    n_ref = n_cycle             # will identify model each\n", "    if 1: # tree\n", "        args.dataorg_dir=os.path.join(args.dataorg_dir, \"\")\n\n", "        # args.data_dir=os.path.join(args.gdata, args.DATASET + '_' + str(clip[0]) + '_' + str(clip[1]))   \n", "        args.dataset_dir=os.path.join(args.proj_dir, \"dataset\")   \n", "        args.models_dir=os.path.join(args.proj_dir, \"Models\")   \n", "        args.results_dir=os.path.join(args.proj_dir, \"Results\")   \n", "        args.ani_dir=os.path.join(args.proj_dir, \"ani\")   \n", "        os.makedirs(args.data_dir, exist_ok=True) # deduped formed\n", "        os.makedirs(args.dataset_dir, exist_ok=True) # npy folder\n", "        os.makedirs(args.models_dir, exist_ok=True)\n", "        os.makedirs(args.results_dir, exist_ok=True)\n", "        os.makedirs(args.tmp_dir, exist_ok=True) # name raws\n", "        os.makedirs(args.ani_dir, exist_ok=True) # anis\n", "    if 1: #     get model\n", "        model = StyleGan2(lr = 0.0001, silent = False,\n", "            latent_size = latent_size,\n", "            im_size = im_size,\n", "            BATCH_SIZE = BATCH_SIZE,\n", "            mixed_prob = mixed_prob,\n", "            qsteps = qsteps,\n", "            n_cycle = n_cycle,\n", "            n_save = n_save,\n", "            n_ref = n_ref,\n", "            name = args.MNAME,\n", "            results_dir = args.results_dir,\n", "            models_dir = args.models_dir,\n", "            dataorg_dir = args.dataorg_dir,\n", "            data_dir = args.data_dir,\n", "            dataset_dir = args.dataset_dir,\n", "            ani_dir = args.ani_dir,\n", "            verbose = True,\n", "        )\n", "        \n", "    if 1: # create imgs\n", "        print(f\"nnwalk create imgs in {args.ani_dir}\")\n", "        imgs = model.generateWalk(qsegs=1, fps=20,maxTime=6,)\n", "        print(f\"nnwalk got {len(imgs)} imgs\")\n", "    if 1: # create gif\n", "        dstpath = os.path.join(args.ani_dir, 'latent.gif')\n", "        ext='png'\n", "        onvid.folder_to_gif(args.ani_dir, dstpath, ext)\n", "        onvid.vid_show(dstpath)\n\n", "    # # creating random latent vector\n", "    # seed = 96\n", "    # rnd = np.random.RandomState(seed)\n", "    # z = rnd.randn(4, 512).astype('float32')\n", "    # print(f\"z: {np.shape(z)}\")\n\n", "    # # # running network\n", "    # # # out = generator([z, None]) # _e_\n", "    # # out = model.G(z) # _e_\n", "    # # print(f\"out: {np.shape(out)}\")\n\n", "    # #converting image to uint8\n", "    # out_image = onrosa.convert_images_to_uint8(out, nchw_to_nhwc=True, uint8_cast=True)\n\n", "    # onfile.generate_and_save_images(out_image.numpy(), 0)\n\n", "    # n_images = 500\n\n", "    # for i in tqdm(range(n_images)):\n", "    #     onfile.generate_and_save_images(out_image.numpy(), i, plot_fig=False)\n", "        \n", "    #     #moving randomly in the latent space z\n", "    #     seed = i\n", "    #     rnd = np.random.RandomState(seed)\n", "        \n", "    #     #mofying slightly latent vector and generating new images\n", "    #     z += rnd.randn(4, 512).astype('float32') / 40\n", "    #     out = generator([z, None]) # _e_\n", "    #     out_image = onrosa.convert_images_to_uint8(out, nchw_to_nhwc=True, uint8_cast=True)\n", "#\n", "#   nninfo\n", "#\n", "def nninfo(args, kwargs):\n", "    args = onutil.pargs(vars(args))\n", "    onutil.ddict(vars(args), 'args')\n", "    print(f\"|===> nninfo:  \\n \\\n", "        nnviv: run git stylegan_two.py cmd \\n \\\n", "        nnearth: earth model \\n \\\n", "        nntrain: fit model with args \\n \\\n", "        nnwalk: generate images with model on seeds \\n \\\n", "        nneval: evaluate model on LandscapesBig \\n \\\n", "        nntrunc: model generate truncated images \\n \\\n", "    \\n \")\n", "#\n", "#   nnproj\n", "#\n", "def nnproj(args, kwargs):\n", "    args = onutil.pargs(vars(args))\n", "    args.PROJECT = 'ffhq'\n", "    args.DATASET = 'ffhq'\n", "    \n", "    xp = getxp(vars(args))\n", "    args = onutil.pargs(xp)\n", "    onutil.ddict(vars(args), 'args')\n", "    print(f\"|===> nnproj\\n \\\n", "                cwd: {os.getcwd()} \\n \\\n", "        \\n \")\n", "    if 1: # tree\n", "        args.dataorg_dir=os.path.join(args.dataorg_dir, \"\")\n", "        args.dataset_dir=os.path.join(args.proj_dir, \"dataset\")   \n", "        args.models_dir=os.path.join(args.proj_dir, \"Models\")   \n", "        args.results_dir=os.path.join(args.proj_dir, \"Results\")   \n", "        args.ani_dir=os.path.join(args.proj_dir, \"ani\")   \n", "        os.makedirs(args.data_dir, exist_ok=True) # deduped formed\n", "        os.makedirs(args.dataset_dir, exist_ok=True) # npy folder\n", "        os.makedirs(args.models_dir, exist_ok=True)\n", "        os.makedirs(args.results_dir, exist_ok=True)\n", "        os.makedirs(args.tmp_dir, exist_ok=True) # name raws\n", "        os.makedirs(args.ani_dir, exist_ok=True) # anis\n", "    if 1: #     get model\n", "        latent_size = 512\n", "        im_size = 512\n", "        BATCH_SIZE = 4\n", "        mixed_prob = 0.9\n", "        qsteps = 200001\n", "        n_cycle = 500               # will evaluate model each\n", "        n_save = int(n_cycle / 1)   # will save model each\n", "        n_ref = n_cycle             # will identify model each\n", "        model = StyleGan2(lr = 0.0001, silent = False,\n", "            latent_size = latent_size,\n", "            im_size = im_size,\n", "            BATCH_SIZE = BATCH_SIZE,\n", "            mixed_prob = mixed_prob,\n", "            qsteps = qsteps,\n", "            n_cycle = n_cycle,\n", "            n_save = n_save,\n", "            n_ref = n_ref,\n", "            name = args.MNAME,\n", "            results_dir = args.results_dir,\n", "            models_dir = args.models_dir,\n", "            dataorg_dir = args.dataorg_dir,\n", "            data_dir = args.data_dir,\n", "            dataset_dir = args.dataset_dir,\n", "        )\n", "    if 1:\n", "        dataset = DatasetLoader(\n", "            path_dir = args.data_dir, \n", "            resolution = 1024, \n", "            batch_size = args.batch_size, \n", "            cache_file=True\n", "        )\n", "        for i in range(2):\n", "            print(i)\n", "            imgs = dataset.get_batch() # (4, 3, 256, 256)\n", "            print(f\"{i} {np.shape(imgs)}\")\n\n", "    #   stylegan2-ffhq-config-f.pkl\tStyleGAN2 for FFHQ dataset at 1024\u00c3\u20141024\n", "    #   vgg16_zhang_perceptual.pkl\tStandard LPIPS metric to estimate perceptual similarity.\n\n", "    # print('Projecting image \"%s\"...' % os.path.basename(src_file))\n", "    # images, _labels = dataset_obj.get_minibatch_np(1)\n", "    prj = Projector(\n", "        verbose=True,\n", "        im_size=512,\n", "    )\n", "    prj._info()\n", "    prj.set_network(model.G)\n", "#\n", "#\n", "#\n", "#   MAIN\n", "#\n", "#\n", "def main():\n", "    parser = argparse.ArgumentParser(description='Run \"python %(prog)s <subcommand> --help\" for subcommand help.')\n", "    onutil.dodrive()\n", "    ap = getap()\n", "    for p in ap:\n", "        cls = type(ap[p])\n", "        parser.add_argument('--'+p, type=cls, default=ap[p])\n", "    cmds = [key for key in globals() if key.startswith(\"nn\")]\n", "    primecmd = ap[\"primecmd\"]\n", "        \n", "    # ---------------------------------------------------------------\n", "    #   add subparsers\n", "    #\n", "    subparsers = parser.add_subparsers(help='subcommands', dest='command') # command - subparser\n", "    for cmd in cmds:\n", "        subparser = subparsers.add_parser(cmd, help='cmd')  # add subcommands\n", "    \n", "    subparsers_actions = [action for action in parser._actions\n", "        if isinstance(action, argparse._SubParsersAction)] # retrieve subparsers from parser\n", "  \n", "    for subparsers_action in subparsers_actions:  # add common       \n", "        for choice, subparser in subparsers_action.choices.items(): # get all subparsers and print help\n", "            for p in {}:  # subcommand args dict\n", "                cls = type(ap[p])\n", "                subparser.add_argument('--'+p, type=cls, default=ap[p])\n\n", "    # get args to pass to nn cmds\n", "    if onutil.incolab():\n", "        args = parser.parse_args('') #  defaults as args\n", "    else:\n", "        args = parser.parse_args() #  parse_arguments()\n", "    kwargs = vars(args)\n", "    subcmd = kwargs.pop('command')      \n", "    if subcmd is None:\n", "        print (f\"Missing subcommand. set to default {primecmd}\")\n", "        subcmd = primecmd\n", "    \n", "    for name in cmds:\n", "        if (subcmd == name):\n", "            print(f'|===> call {name}')\n", "            globals()[name](args, kwargs) # pass args to nn cmd\n", "#\n", "#\n", "#\n", "# python base/base.py nninfo\n", "if __name__ == \"__main__\":\n", "    print(\"|===>\", __name__)\n", "    main()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}