{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# -*- coding: utf-8 -*-\n", "# \n", "# # Copyright (c) 2019, NVIDIA Corporation. All rights reserved.\n", "#\n", "import os\n", "import io\n", "from io import StringIO\n", "import time\n", "import argparse\n", "import functools\n", "import errno\n", "import scipy\n", "import scipy.io\n", "import requests\n", "import zipfile\n", "import random\n", "import datetime\n", "import re\n", "import uuid\n", "import hashlib\n", "import tempfile\n", "from typing import Any, List, Tuple, Union\n", "import types"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from functools import partial\n", "import importlib\n", "from importlib import import_module"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import logging\n", "logging.getLogger('tensorflow').setLevel(logging.ERROR)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import math\n", "from math import floor, log2\n", "from random import random"]}, {"cell_type": "markdown", "metadata": {}, "source": ["import IPython.display as display"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from IPython.core.display import display"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import PIL\n", "from PIL import Image\n", "PIL.Image.MAX_IMAGE_PIXELS = 933120000"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from mpl_toolkits.axes_grid1 import ImageGrid"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import shutil"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import scipy.ndimage as pyimg"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import cv2\n", "import imageio\n", "import glob"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import matplotlib as mpl\n", "import matplotlib.pyplot as plt \n", "import matplotlib.image as mgimg\n", "import matplotlib.animation as anim\n", "mpl.rcParams['figure.figsize'] = (12,12)\n", "mpl.rcParams['axes.grid'] = False"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import gdown"]}, {"cell_type": "markdown", "metadata": {}, "source": [" https://github.com/lllyasviel/DanbooRegion"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from numba import njit\n", "from scipy.ndimage import label"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import sys\n", "sys.path.append('../')  # if called from eon, modules are in parallel folder\n", "sys.path.append('./')  #  if called from dnns, modules are in folder"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["try:\n", "    TF1\n", "    print(\"set tf 1.x env\")\n", "    # %tensorflow_version 1.x\n", "except:\n", "    pass"]}, {"cell_type": "markdown", "metadata": {}, "source": ["pip install -q -U tensorboard"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import tensorflow as tf \n", "from tensorflow.keras import initializers, regularizers, constraints\n", "from tensorflow.keras import backend as K\n", "from tensorflow.keras import layers\n", "from tensorflow.keras.layers import Layer, InputSpec\n", "from tensorflow.keras.layers import BatchNormalization, Activation, ZeroPadding2D, UpSampling2D, Conv2D\n", "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout, LeakyReLU\n", "from tensorflow.keras.models import Sequential, Model\n", "from tensorflow.keras.optimizers import Adam\n", "from tensorflow.python.keras.utils import conv_utils"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from tensorflow.keras.layers import Lambda\n", "from tensorflow.keras.layers import add\n", "from tensorflow.keras.layers import AveragePooling2D\n", "from tensorflow.keras.initializers import VarianceScaling\n", "from tensorflow.keras.models import clone_model\n", "from tensorflow.keras.models import model_from_json\n", "from tensorflow.python.client import device_lib # pylint: disable=no-name-in-module"]}, {"cell_type": "markdown", "metadata": {}, "source": ["python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\""]}, {"cell_type": "markdown", "metadata": {}, "source": ["GLOBALS "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["local_prefix = os.path.abspath('')\n", "try:\n", "    local_prefix = os.path.dirname(os.path.realpath(__file__)) # script dir\n", "except:\n", "    pass"]}, {"cell_type": "markdown", "metadata": {}, "source": ["cuda_cache_path = os.path.join(os.path.dirname(__file__), '_cudacache')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["cuda_cache_path = os.path.join(os.path.dirname(local_prefix), '_cudacache')\n", "cuda_cache_version_tag = 'v1' # _e_\n", "do_not_hash_included_headers = True # _e_ # Speed up compilation by assuming that headers included by the CUDA code never change. Unsafe!"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["compiler_bindir_search_path = [\n", "    'C:/Program Files (x86)/Microsoft Visual Studio/2017/Community/VC/Tools/MSVC/14.14.26428/bin/Hostx64/x64',\n", "    'C:/Program Files (x86)/Microsoft Visual Studio/2019/Community/VC/Tools/MSVC/14.25.28610/bin/Hostx64/x64',\n", "    'C:/Program Files (x86)/Microsoft Visual Studio 14.0/vc/bin',\n", "    'C:/Program Files (x86)/Microsoft Visual Studio/2019/Community/VC/Tools/MSVC/14.26.28801/bin/Hostx64/x64'\n", "]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["_plugin_cache = dict()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class Onpyon:\n", "    @staticmethod\n", "    def ver():\n", "        return '0.0.0'"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class Ontree:\n", "    @staticmethod\n", "    def tree(cp):\n\n", "        # dataprefix\n", "        if os.path.exists('/content/drive/My Drive'):  # collab with drive\n", "            dataprefix = '/content/drive/My Drive'\n", "        elif os.path.exists('/content'): # if /content exists, is collab\n", "            dataprefix = '/content' \n", "        elif not cp[\"LOCALDATA\"] and os.path.exists(cp['net_prefix']): # network\n", "            dataprefix = cp['net_prefix'] \n", "        else:                               # local\n", "            dataprefix = os.path.join(cp[\"local_prefix\"], cp[\"grel_infix\"], 'content') # dnns/../content/gdata/\n\n", "        # modelsprefix\n", "        if os.path.exists('/content/drive/My Drive'):  # collab with drive\n", "            modelsprefix = '/content/drive/My Drive'\n", "        elif os.path.exists('/content'): # if /content exists, is collab\n", "            modelsprefix = '/content' \n", "        elif cp[\"LOCALMODELS\"]:                               # local\n", "            modelsprefix = os.path.join(cp[\"local_prefix\"], cp[\"grel_infix\"], 'content') # dnns/../content/gmodel/\n", "        elif os.path.exists(cp['net_prefix']): # try net drive\n", "                modelsprefix = cp['net_prefix'] \n", "        else:                               # local\n", "            print(f'drive could not be found !!!!!!!!!!!!!! ')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        # labprefix\n", "        if os.path.exists('/content/drive/My Drive'):  # collab with drive\n", "            labprefix = '/content/drive/My Drive'\n", "        elif os.path.exists('/content'): # if /content exists, is collab\n", "            labprefix = '/content' \n", "        elif cp[\"LOCALLAB\"]:                               # local\n", "            labprefix = os.path.join(cp[\"local_prefix\"], cp[\"grel_infix\"], 'content') # dnns/../content/glab/\n", "        elif os.path.exists(cp['net_prefix']): # try net drive\n", "                labprefix = cp['net_prefix'] \n", "        else:                               # local\n", "            print(f'drive could not be found !!!!!!!!!!!!!! ')\n", "        gdata = dataprefix + '/gdata/'\n", "        gmodel = modelsprefix + '/gmodel/'\n", "        glab = labprefix + '/glab/'\n", "        gadir = os.getcwd()\n", "        gedir = os.path.join(cp[\"local_prefix\"])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        Onutil.ddict(cp, 'cp')\n", "        print(labprefix, glab)\n", "        assert os.path.exists(gdata), f\"gdata {gdata} does not exist\"\n", "        assert os.path.exists(gmodel), f\"gmodel {gmodel} does not exist\"\n", "        assert os.path.exists(glab), f\"glab {glab} does not exist\"\n", "        assert os.path.exists(gadir), f\"gadir {gadir} does not exist\"\n", "        assert os.path.exists(gedir), f\"gedir {gedir} does not exist\"\n", "        lab=os.path.normpath(os.path.join(glab, cp[\"MNAME\"]))\n", "        os.makedirs(lab, exist_ok=True)\n", "        proto_dir=os.path.normpath(os.path.join(glab,cp[\"MNAME\"]))\n", "        os.makedirs(proto_dir, exist_ok=True)\n", "        proj_dir = os.path.join(proto_dir, cp[\"PROJECT\"])\n", "        if cp[\"RESETCODE\"] and os.path.exists(proj_dir):\n", "            print(\"will remove tree %s\" %proj_dir)\n", "            try:\n", "                shutil.rmtree(proj_dir)\n", "            except:\n", "                print(\"could not remove git tree\")\n", "                pass\n", "        os.makedirs(proj_dir, exist_ok=True)\n", "        os.chdir(proj_dir) # %cd $proj_dir\n", "        cwd = os.getcwd()\n", "        proj_dir = cwd"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        tp = {\n", "            \"LOCAL\": cp[\"local_prefix\"], # ''\n", "            \"FROMPATH\": cp[\"local_prefix\"],\n", "                    \n", "            \"gdata\": gdata,\n", "            \"gmodel\": gmodel,\n", "            \"glab\": glab,\n", "            \"gadir\": gadir,\n", "            \"gedir\": gedir,\n", "            \"lab\": lab,\n", "            \"proto_dir\": proto_dir,\n", "            \"proj_dir\": proj_dir,\n", "            \"cwd\": cwd,\n", "            \"ani_dir\": os.path.join(proj_dir, 'ani'),           # ani results gifs dir (.gif, .mp4) \n", "            \"results_dir\": os.path.join(proj_dir, \"Results\"),   # Results\n", "            \"tmp_dir\": os.path.join(proj_dir, \"tmp\"),           # tmp\n", "            \"logs_dir\": os.path.join(proj_dir, 'logs'),         # logs\n", "            \"trace_dir\": os.path.join(proj_dir, 'trace'),       # trace\n", "            \"data_dir\": os.path.join(proj_dir, \"data\"),         # data\n", "            \"train_dir\": os.path.join(proj_dir, \"data\", \"train\"),  # train\n", "            \"test_dir\": os.path.join(proj_dir, \"data\", \"test\"), # test\n", "            \n", "            \"dataset_dir\": os.path.join(proj_dir, \"dataset\"),   # dataset\n", "            \"records_dir\": os.path.join(proj_dir, \"records\"),   # records\n", "            \"ckpt_dir\": os.path.join(proj_dir, 'ckpt'),  # ckpt checkpoints place\n", "            \"weights_dir\": os.path.join(proj_dir, 'weights'),   # weights dir (h5) \n", "            \"models_dir\": os.path.join(proj_dir, \"Models\"),     # Models\n", "            \"dataorg_dir\": gdata + '/' + cp[\"DATASET\"],   # dataorg\n", "        }\n", "        return tp"]}, {"cell_type": "markdown", "metadata": {}, "source": ["  ******************<br>\n", "  FUNS UTILS<br>\n", "<br>\n", "  ******************"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class Onutil:\n", "    @staticmethod\n", "    def info():\n", "        print(\"Onutil\")\n", "    @staticmethod\n", "    def error(msg):\n", "        print('Error: ' + msg)\n", "        exit(1)\n", "    @staticmethod\n", "    def incolab():\n", "        res = False\n", "        if os.path.exists('/content'):\n", "            res = True\n", "        return res\n", "    @staticmethod\n", "    def conda():\n\n", "        ## StyleGAN:\n", "        cmd = f'pip install pillow numpy moviepy scipy opencv-python lmdb matplotlib'\n", "        os.system(cmd)\n", "        cmd = f'pip install cmake'\n", "        os.system(cmd)\n", "        cmd = f'pip install dlib'\n", "        os.system(cmd)\n", "        cmd = f'pip install ipython gdown'\n", "        os.system(cmd)\n\n", "        # ## lllyasviel\n", "        cmd = f'pip install numba scikit-image scikit-learn'\n", "        os.system(cmd)\n\n", "        # ## \n", "        cmd = f'pip install cython h5py Pillow'\n", "        os.system(cmd)\n", "        cmd = f'pip install -U gradient'\n", "        os.system(cmd)\n", "        cmd = f'pip install windows-curses'\n", "        os.system(cmd)\n\n", "        # ## confignet https://github.com/microsoft/ConfigNet/blob/main/setup/requirements.txt\n", "        #scipy==1.4.1\n", "        #scikit-learn==0.20.0\n", "        #tensorflow-gpu==2.1.0\n", "        cmd = f'pip install azureml-sdk matplotlib numpy opencv-python pytest transformations'\n", "        os.system(cmd)\n", "    @staticmethod\n", "    def pargs(cp):\n", "        xp={}        \n", "        for key in cp.keys():\n", "            xp[key] = cp[key]\n\n", "        ## ------------ _e_tbc ref stransfer.py\n", "        tree = Ontree.tree(cp)\n", "        for key in tree.keys():\n", "            xp[key] = tree[key]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["        parser = argparse.ArgumentParser(description=\nRun 'python %(prog)s <subcommand> --help' for subcommand help.\n)<br>\n", "        for p in xp:<br>\n", "            cls = type(xp[p])<br>\n", "            parser.add_argument('--'+p, type=cls, default=xp[p])<br>\n", "        args = parser.parse_args('')<br>\n", "        return args<br>\n", "    @staticmethod<br>\n", "    def dodrive(domount=True):<br>\n", "        if domount:<br>\n", "            if os.path.exists('/content/'):<br>\n", "                if not os.path.exists('/content/drive'):<br>\n", "                    try:<br>\n", "                        from google.colab import drive # drive from colab<br>\n", "                        drive.mount('/content/drive', force_remount=True)<br>\n", "                    except:<br>\n", "                        print(\"|===> unable to mount drive\")<br>\n", "    @staticmethod<br>\n", "    def check_file(file, path):<br>\n", "        if file is None:<br>\n", "            raise OSError(errno.ENOENT, \"No such file\", path)<br>\n", "    @staticmethod<br>\n", "    def get_git(AUTHOR, PROJECT, proj_dir='./'):<br>\n", "        try:<br>\n", "            # os.system(\"git clone https://github.com/rolux/stylegan2encoder %s\" %proj_dir)<br>\n", "            cmd = f'git clone https://github.com/{AUTHOR}/{PROJECT}.git \"{proj_dir}\"'<br>\n", "            print(\"|... cmd %s\" %cmd)<br>\n", "            os.system(cmd)<br>\n", "        except:<br>\n", "            cmd = f'git pull https://github.com/{AUTHOR}/{PROJECT}.git \"{proj_dir}\"'<br>\n", "            print(\"|... cmd %s\" %cmd)<br>\n", "            os.system(cmd)<br>\n", "    @staticmethod<br>\n", "    def ddict(item, txt=\":\"):<br>\n", "        print(f\"|===> {txt}\")<br>\n", "        for i in item:<br>\n", "            print (f\"  {i} => {item[i]}\")<br>\n", "    @staticmethod<br>\n", "    def ditem(item, txt=\":\", val=True):<br>\n", "        print(txt)<br>\n", "        print(type(item))<br>\n", "        # print(np.shape(item))<br>\n", "        if val:<br>\n", "            print(item)<br>\n", "    @staticmethod<br>\n", "    def isempty(folder):<br>\n", "        empty = True<br>\n", "        if [f for f in os.listdir(folder) if not f.startswith('.')] == []:<br>\n", "            empty = False<br>\n", "        return empty<br>\n", "    @staticmethod<br>\n", "    def walkfolder(folder):<br>\n", "        if os.path.exists(folder):        <br>\n", "            for root, dirs, files in os.walk(folder, topdown=False):<br>\n", "                for name in files:<br>\n", "                    print(os.path.join(root, name))<br>\n", "                for name in dirs:<br>\n", "                    print(os.path.join(root, name))<br>\n", "    @staticmethod<br>\n", "    def nameint(i,zfill=4):<br>\n", "        return str(i).zfill(4)<br>\n", "    @staticmethod<br>\n", "    def pathsort(paths):<br>\n", "        roots = [Onutil.get_rootid(path) for path in paths]<br>\n", "        if all(root.isdigit() for root in roots):<br>\n", "            paths = sorted(paths, key=lambda path: int(Onutil.get_rootid(path)))<br>\n", "            print(f'|---> pathsort numeric q: {len(paths)}')<br>\n", "        else:<br>\n", "            paths = sorted(paths)<br>\n", "            print(f'|---> pathsort alphabetic q: {len(paths)}')<br>\n", "        return paths<br>\n", "    @staticmethod<br>\n", "    def printProgressBar (iteration, total, prefix = '', suffix = '', decimals = 1, length = 50, fill = '\u00e2\u2013\u02c6'):<br>\n", "      \n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        Call in a loop to create terminal progress bar\n", "        @params:\n", "            iteration   - Required  : current iteration (Int)\n", "            total       - Required  : total iterations (Int)\n", "            prefix      - Optional  : prefix string (Str)\n", "            suffix      - Optional  : suffix string (Str)\n", "            decimals    - Optional  : positive number of decimals in percent complete (Int)\n", "            length      - Optional  : character length of bar (Int)\n", "            fill        - Optional  : bar fill character (Str)\n", "        \"\"\"\n", "        percent = (\"{0:.\" + str(decimals) + \"f}\").format(100 * (iteration / float(total)))\n", "        filledLength = int(length * iteration // total)\n", "        bar = fill * filledLength + '.' * (length - filledLength)\n", "        print('\\r %s |%s| %s%% %s' % (prefix, bar, percent, suffix), end = '\\r')\n", "        # Print New Line on Complete\n", "        if iteration == total:\n", "            print()\n", "            print()\n", "    @staticmethod\n", "    def gunzip(file_basename, file_id, dst, results_dir):\n", "        if not os.path.exists(dst):\n", "            print(f'|... download {file_basename} from google drive to {dst}')\n", "            gdown.download(file_id, dst)\n", "        else:\n", "            print(f'|... {file_basename} already in content {dst}')\n", "        path_to_zip_file = dst\n", "        directory_to_extract_to = results_dir\n", "        print(\"will unzip %s to %s\" %(path_to_zip_file, directory_to_extract_to))\n", "        with zipfile.ZipFile(path_to_zip_file, 'r') as zip_ref:\n", "            zip_ref.extractall(directory_to_extract_to)\n", "    @staticmethod\n", "    def gdownid(urlfolder, gfolderid, dst):\n", "        import gdown\n", "        print(f'|... gdownid {urlfolder} / {gfolderid} to {dst}')\n", "        #urlfolder = 'https://drive.google.com/drive/folders/'\n", "        #gfolderid = '1ihLt6P7UQRlaFtZUEclXkWC9grmEXEUK'\n", "        #dst = 'DanbooRegion2020.zip.xxx' # 001 - 077\n", "        url = f'{urlfolder}{gfolderid}'\n", "        gdown.download(url, dst)\t\t\n", "    @staticmethod\n", "    def gdownfile(link_name, dest):\n", "        from google_drive_downloader import GoogleDriveDownloader as gdd\n", "        print(f'|... gdownfile {link_name} to {dest}')\t\t\n", "        gdd.download_file_from_google_drive(file_id=link_name,dest_path=dest,unzip=True)\n", "    @staticmethod\n", "    def tenzip(output_filename, source_dir, arcname=None):\n", "        import tarfile\n", "        with tarfile.open(output_filename, \"w:gz\") as tar:\n", "            tar.add(source_dir, arcname=arcname)\n", "    @staticmethod\n", "    def tunzip(url, tarpath, results_dir, tree_root=None):\n", "        # tar xvzf car_devkit.tgz\n", "        import tarfile\n", "        #print(f'|---> tunzip {tarpath} to {results_dir}')\n", "        #if not os.path.exists(tarpath): \n", "        #\tcmd = f'wget -O \"{tarpath}\" \"{url}\"'\n", "        #\tprint(f\"cmd: {cmd}\")\n", "        #\tos.system(cmd)\n", "        #else:\n", "        #\tprint(f\"{tarpath} already exists\")\n", "        target_dir = None\n", "        if tree_root:\n", "            target_dir = os.path.join(results_dir, tree_root)\n", "        if target_dir and os.path.exists(target_dir): \n", "            print(f'do nothing. target dir {target_dir} already exists')\n", "        else:\n", "            if tarpath.endswith(\"tar.gz\"):\n", "                print(f'|... tar.gz {tarpath} is tarfile {tarfile.is_tarfile(tarpath)}')\n", "                tar = tarfile.open(tarpath, \"r:\")\n", "                tar.extractall(results_dir)\n", "                tar.close()\n", "            elif tarpath.endswith(\"tar\"):\n", "                print(f'|... tar {tarpath} is tarfile {tarfile.is_tarfile(tarpath)}')\n", "                tar = tarfile.open(tarpath, \"r:\")\n", "                tar.extractall()\n", "                tar.close()\n", "            elif tarpath.endswith(\"tgz\"):\n", "                print(f'|... tgz {tarpath} is tarfile {tarfile.is_tarfile(tarpath)}')                \n", "                tar = tarfile.open(tarpath, \"r:gz\")\n", "                tar.extractall()\n", "                tar.close()\n", "            elif tarpath.endswith(\"zip\"):\n", "                print(f'|... tar {tarpath} is zip {tarfile.is_tarfile(tarpath)}')\n", "                tar = tarfile.open(tarpath, \"r:\")\n", "                tar.extractall()\n", "                tar.close()                \n", "            else:\n", "                print(f'|... unsupported tarfile {tarpath}')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    @staticmethod\n", "    def zipdir(folder, dstzip='Python.zip'):\n", "        import zipfile\n", "        zipf = zipfile.ZipFile(dstzip, 'w', zipfile.ZIP_DEFLATED)\t\t\n", "        # zipf is zipfile handle\n", "        for root, dirs, files in os.walk(folder):\n", "            for file in files:\n", "                zipf.write(os.path.join(root, file))\n", "        zipf.close()\n", "    def mnormal(mu=0.0, sigma=1.0, size=None):\n", "        return np.random.normal(loc = mu, scale = sigma, size = size).astype('float32')\n", "    @staticmethod\n", "    def muniform(low=0.0, high=1.0, size=None):\n", "        return np.random.uniform(low = low, high = high, size = size).astype('float32')\n", "    @staticmethod\n", "    def mrandom(size=None):\n", "        return np.random.random(size = size).astype('float32')\n", "    @staticmethod\n", "    def get_filename(path):\n", "        name, _ = os.path.splitext(os.path.basename(path))\n", "        return name\n", "    @staticmethod\n", "    def get_rootname(name):\n", "        root, _ = os.path.splitext(name)\n", "        return root\n", "    @staticmethod\n", "    def get_rootid(path):\n", "        return Onutil.get_rootname(Onutil.get_filename(path))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["https://github.com/rolux/stylegan2encoder/dnnlib/util.py"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class EasyDict(dict):\n", "    \"\"\"Convenience class that behaves like a dict but allows access with the attribute syntax.\"\"\"\n", "    def __getattr__(self, name: str) -> Any:\n", "        try:\n", "            return self[name]\n", "        except KeyError:\n", "            raise AttributeError(name)\n", "    def __setattr__(self, name: str, value: Any) -> None:\n", "        self[name] = value\n", "    def __delattr__(self, name: str) -> None:\n", "        del self[name]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["https://github.com/rolux/stylegan2encoder/dnnlib/util.py"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class Logger(object):\n", "    \"\"\"Redirect stderr to stdout, optionally print stdout to a file, and optionally force flushing on both stdout and the file.\"\"\"\n", "    def __init__(self, file_name: str = None, file_mode: str = \"w\", should_flush: bool = True):\n", "        self.file = None\n", "        if file_name is not None:\n", "            self.file = open(file_name, file_mode)\n", "        self.should_flush = should_flush\n", "        self.stdout = sys.stdout\n", "        self.stderr = sys.stderr\n", "        sys.stdout = self\n", "        sys.stderr = self\n", "    def __enter__(self) -> \"Logger\":\n", "        return self\n", "    def __exit__(self, exc_type: Any, exc_value: Any, traceback: Any) -> None:\n", "        self.close()\n", "    def write(self, text: str) -> None:\n", "        \"\"\"Write text to stdout (and a file) and optionally flush.\"\"\"\n", "        if len(text) == 0: # workaround for a bug in VSCode debugger: sys.stdout.write(''); sys.stdout.flush() => crash\n", "            return\n", "        if self.file is not None:\n", "            self.file.write(text)\n", "        self.stdout.write(text)\n", "        if self.should_flush:\n", "            self.flush()\n", "    def flush(self) -> None:\n", "        \"\"\"Flush written text to both stdout and a file, if open.\"\"\"\n", "        if self.file is not None:\n", "            self.file.flush()\n", "        self.stdout.flush()\n", "    def close(self) -> None:\n", "        \"\"\"Flush, close possible files, and remove stdout/stderr mirroring.\"\"\"\n", "        self.flush()\n\n", "        # if using multiple loggers, prevent closing in wrong order\n", "        if sys.stdout is self:\n", "            sys.stdout = self.stdout\n", "        if sys.stderr is self:\n", "            sys.stderr = self.stderr\n", "        if self.file is not None:\n", "            self.file.close()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["  ******************<br>\n", "  FUNS PLOT<br>\n", "<br>\n", "  ******************"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class Onplot:\n", "    @staticmethod\n", "    def info():\n", "        print(\"Plot\")\n", "    @staticmethod   \n", "    def display_pil(img):\n", "        display.display(PIL.Image.fromarray(np.array(img)))\n", "    @staticmethod\n", "    def pil_show_pil(img, title=\"\"):\n", "        display(img) if Onutil.incolab() else img.show(title=title)\n", "        return img\n", "    \n", "    @staticmethod    \n", "    def pil_show_nua(img, title=\"\"):\n", "        img = np.asarray(img)\n", "        if np.ndim(img)>3:\n", "            assert img.shape[0] == 1\n", "            rgb = img[0]        \n", "        #img = np.clip(img, 0, 1).astype('float32')        \n", "        img = Onformat.nua_to_pil(img)\n", "        Onplot.pil_show_pil(img, title)\n", "    @staticmethod\n", "    def pil_show_nuas(nuas, scale=1, rows=1):\n", "        rgbs=Onformat.nuas_to_rgbs(nuas)\n", "        Onplot.pil_show_rgbs(rgbs, scale=1, rows=1)\n", "    @staticmethod   \n", "    def pil_show_nba(img, title=\"\"):\n", "        img = np.asarray(img)        \n", "        img = Onformat.nba_to_nua(img)\n", "        img = Onformat.nua_to_rgb(img)\n", "        img = PIL.Image.fromarray(img)\n", "        Onplot.pil_show_pil(img, title)\n", "     \n", "    @staticmethod   \n", "    def pil_show_nbas(nbas, title=[]):\n", "        for nba in nbas:\n", "            Onplot.pil_show_nba(nba)\n", "    @staticmethod    \n", "    def pil_show_rgb(img, title=\"\"):\n", "        img = np.asarray(img)  \n", "        if len(img.shape) > 3: img = tf.squeeze(img, axis=0)  # img = img[0,...]            \n", "        img = Onformat.rgb_to_pil(img)\n", "        Onplot.pil_show_pil(img, title)\n", "    @staticmethod\n", "    def pil_show_rgbs(rgbs, scale=1, rows=1):\n", "        pils = []\n", "        for img in rgbs:\n", "            if len(img.shape) > 3: img = tf.squeeze(img, axis=0)  # img = img[0,...]\n", "            pils.append(PIL.Image.fromarray(np.array(img, dtype=np.uint8)))\n", "        w,h = pils[0].size\n", "        w = int(w*scale)\n", "        h = int(h*scale)\n", "        height = rows*h\n", "        cols = int(math.ceil(len(pils) / rows))\n", "        width = cols*w\n", "        pil = PIL.Image.new('RGBA', (width,height), 'white')\n", "        for i,img in enumerate(pils):\n", "            img = img.resize((w,h), PIL.Image.ANTIALIAS)\n", "            pil.paste(img, (w*(i % cols), h*(i // cols))) \n", "        Onplot.pil_show_pil(pil)\n", "    @staticmethod\n", "    def pil_show_nba(img, title=\"img\"):\n", "        if len(img.shape) > 3:\n", "            assert img.shape[0] == 1\n", "            img = tf.squeeze(img, axis=0)  # img = img[0,...] # bnbt => nba    \n", "        img = (img + 1.0)/2.0\n", "        img = np.array(255 * img, dtype=np.uint8)\n", "        img = PIL.Image.fromarray(img)\n", "        img if Onutil.incolab() else img.show(title=title)\n", "        return img\n", "    @staticmethod\n", "    def plot_pils_grid(imgs, rows=2, cols=2, figsize=(4, 4)):\n", "        qtiles = cols * rows\n", "        plt.figure(figsize=figsize)\n", "        for i in range(qtiles):\n", "            plt.subplot(rows, cols, i+1)\n", "            plt.imshow(np.array(imgs[i])/255.0)\n", "            plt.axis('off')\n", "        plt.show()\n", " \n\n", "    #https://stackoverflow.com/questions/53255432/saving-a-grid-of-heterogenous-images-in-python\n", "    @staticmethod\n", "    def plot_save_grid(ims, path=None, rows=None, cols=None, \n", "            figsize = (6,5.9),\n", "            fill=1, showax=0,\n", "            do =  ['plot']):\n", "        if rows is None != cols is None:\n", "            raise ValueError(\"Set either both rows and cols or neither.\")\n", "        print(f'|---> plot_save_grid {len(ims)} to {path}')\n", "        plt.close() \n", "        if rows is None:\n", "            rows = len(ims)\n", "            cols = 1\n", "        gridspec_kw = {'wspace': 0, 'hspace': 0} if fill else {}\n", "        fig,axarr = plt.subplots(rows, cols, gridspec_kw=gridspec_kw, figsize=figsize)\n", "        if fill:\n", "            bleed = 0\n", "            fig.subplots_adjust(left=bleed, bottom=bleed, right=(1 - bleed), top=(1 - bleed))\n", "        for ax,im in zip(axarr.ravel(), ims):\n", "            ax.imshow(im)\n", "            if not showax:\n", "                ax.set_axis_off()\n", "        kwargs = {'pad_inches': .01} if fill else {}\n", "        if 'save' in do:\n", "            if path:\n", "                fig.savefig(path, **kwargs)\n", "            else:\n", "                print(f'path must be defined')\n", "        if 'plot' in do:\n", "            plt.show()\n", "    @staticmethod\n", "    def plot_iter_grid(model, dataset, rows, cols, figsize = (10,9), do=['plot'], ext='jpg', prefix = 'frame'):\n", "        rndvects = {}\n", "        print(f'|--->  plot_iter_grid {do}')\n", "        size = (model.input_shape[0], model.input_shape[1], model.input_shape[2])\n", "        vary = np.random.normal(0.0, 1.0, size=size).astype('float32') # vary shape: (512, 512, 3)\n", "        iterator = iter(dataset)\n", "        \n", "        ppi = 80\n", "        ppt = 3 * ppi\n", "        fy = int(cols * ppt / ppi)\n", "        fx = int(rows * ppt / ppi)\n\n", "        #fig = plt.figure(figsize=figsize)\n", "        fig = plt.figure(figsize=(fy, fx))\n", "        #plt.tight_layout(pad=0.2, w_pad=0.2, h_pad=1.0)\n", "        if 1: # fill:\n", "            bleed = 0\n", "            fig.subplots_adjust(left=bleed, bottom=bleed, right=(1 - bleed), top=(1 - bleed))\n", "        qtiles = cols * rows\n", "        \n", "        ckptidx = model.ckptidx\n", "        ckptidx = Onutil.nameint(ckptidx)\n", "        frame = f'{prefix}{ckptidx}.{ext}'\n", "        path = os.path.join(model.results_dir, frame)\n", "        images = []\n", "        for i in range(rows):\n", "            for j in range(cols):\n", "                inp, rea = iterator.get_next()\n", "                img = model.generator(inp, training=True)\n", "                img = Onformat.nnba_to_rgb(img)\n", "                images.append(img)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        Onplot.plot_save_grid(images, path, rows, cols,do=['plot', 'save'])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    @staticmethod   \n", "    def plot_nuas(imgs=[], r=1, c=1, titles=[]):\n", "        assert(not c == 0)\n", "        qtiles = r * c\n", "        qimgs = len(imgs)\n", "        for i,img in enumerate(imgs):\n", "            col = 1 + (i % c)   # subplot rows: 1 ..\n", "            row = 1 + int(i/c)  # subplot cols: 1 ..\n", "            print(\"plot_nuas x\", i, r, c)\n", "            plt.subplot(r, c, i + 1)\n", "            idx =  i if i < qimgs else qimgs -1\n", "            plt.imshow(imgs[idx]) \n", "            if (len(titles) > i):\n", "                plt.title(titles[i])\n", "            plt.axis('off')\n", "        plt.show()\n", "        plt.close()\n", "    @staticmethod\n", "    def plot_paths(img_paths=[], rows=1, cols=1):\n", "        qtiles = rows * cols\n", "        qimgs = len(img_paths)\n", "        imgs = []\n", "        for i in range(qtiles):\n", "            idx =  i if i < qimgs else qimgs -1\n", "            imgs.append(Image.open(img_paths[idx]))\n", "        Onplot.plot_pils_grid(imgs, rows, cols)\n", "    @staticmethod\n", "    def plot_names(names=[], dir=\"./\", rows=1, cols=1):\n", "        imgpaths = []\n", "        for name in names:\n", "            imgpaths.append(os.path.join(dir, name))\n", "        Onplot.plot_paths(imgpaths, rows, cols)     \n", "    @staticmethod    \n", "    def plot_pil(img, title=None):\n", "        plt.imshow(img)\n", "        if title:\n", "            plt.title(title)\n", "        plt.show()\n", "    @staticmethod   \n", "    def plot_nua(nua, title=None):\n", "        plt.imshow(nua)\n", "        if title:\n", "            plt.title(title)\n", "        plt.show()\n", "    @staticmethod   \n", "    def plot_dnua(tnua, title=None):\n", "        nua = Onformat.dnua_to_nua(tnua)\n", "        Onplot.plot_nua(nua, title)\n", "    @staticmethod   \n", "    def plot_rgb(img, title=None):\n", "        rgb = np.array(img, dtype=np.uint8)\n", "        plt.imshow(rgb)\n", "        if title:\n", "            plt.title(title)\n", "        plt.show() \n", "    @staticmethod        \n", "    def plot_grid_pils(imgs, rows=2, cols=2, figsize=(4, 4)):\n", "        from mpl_toolkits.axes_grid1 import ImageGrid\n", "        fig = plt.figure(figsize=figsize) # width, height in inches\n", "        grid = ImageGrid(fig, 111,\n", "                        nrows_ncols=(rows, cols),  # creates 2x2 grid of axes\n", "                        axes_pad=0.1,  # pad between axes in inch.\n", "                        )\n", "        for ax, im in zip(grid, imgs): # Iterating over the grid returns the Axes.\n", "            ax.imshow(im)\n", "        plt.show()\n", "    @staticmethod\n", "    def plot_grid(im_list, grid_shape, scale=0.1, axes_pad=0.07):\n", "    # https://gist.github.com/lebedov/7018889ba47668c64bcf96aee82caec0\n", "        \"\"\"\n", "        Display the specified PIL images in a grid.\n", "        Parameters\n", "        ----------\n", "        im_list : list of numpy.ndarray instances\n", "            Bitmaps to display.\n", "        grid_shape : tuple\n", "            Grid shape.\n", "        scale : float\n", "            Scaling factor; 1 is 100%.\n", "        axes_pad : float or (float, float)\n", "            Padding between axes, in inches.\n", "        \"\"\"\n\n", "        # Grid must be 2D:\n", "        assert len(grid_shape) == 2\n\n", "        # Make sure all images can fit in grid:\n", "        assert np.prod(grid_shape) >= len(im_list)\n", "        grid = ImageGrid(plt.gcf(), 111, grid_shape, axes_pad=axes_pad)\n", "        for i, data in enumerate(im_list):\n\n", "            # Scale image:\n", "            im = PIL.Image.fromarray(data)\n", "            thumb_shape = [int(scale*j) for j in im.size]\n", "            im.thumbnail(thumb_shape, PIL.Image.ANTIALIAS)\n", "            data_thumb = np.array(im)\n", "            grid[i].plot_dnua(data_thumb)\n\n", "            # Turn off axes:\n", "            grid[i].axes.get_xaxis().set_visible(False)\n", "            grid[i].axes.get_yaxis().set_visible(False)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    @staticmethod   \n", "    def generate_and_plot_images(gen, seed, w_avg, truncation_psi=1):\n", "        # https://github.com/rosasalberto/StyleGAN2-TensorFlow-2.x\n", "        \"\"\" plot images from generator output \"\"\"\n", "        \n", "        fig, ax = plt.subplots(1,3,figsize=(15,15))\n", "        for i in range(3):\n", "            \n", "            # creating random latent vector\n", "            rnd = np.random.RandomState(seed)\n", "            z = rnd.randn(1, 512).astype('float32')\n\n", "            # running mapping network\n", "            dlatents = gen.mapping_network(z)\n", "            # adjusting dlatents depending on truncation psi, if truncatio_psi = 1, no adjust\n", "            dlatents = w_avg + (dlatents - w_avg) * truncation_psi \n", "            # running synthesis network\n", "            out = gen.synthesis_network(dlatents)\n\n", "            #converting image/s to uint8\n", "            img = Onrosa.convert_images_to_uint8(out, nchw_to_nhwc=True, uint8_cast=True)\n\n", "            #plotting images\n", "            # ax[i].axis('off')\n", "            # img_plot = ax[i].imshow(img.numpy()[0])\n", "            print(f\"plot img {i}: {type(img)} : {np.shape(img)}\")\n", "            Onplot.pil_show_rgb(img)\n", "            seed += 1\n", "    @staticmethod   \n", "    def cv_tfr(src_dir,tfr_file):\n", "        images = []\n", "        tfr_files = sorted(glob.glob(os.path.join(src_dir, '*.tfrecords')))\n", "        dataset = tf.data.TFRecordDataset(src_dir, compression_type=None, buffer_size=None, num_parallel_reads=None)\n", "        tfrpath = os.path.join(src_dir, tfr_file)\n", "        raw_image_dataset = tf.data.TFRecordDataset(tfrpath) # <TFRecordDatasetV2 shapes: (), types: tf.string>\n", "        image_feature_description = {\n", "            'shape': tf.io.FixedLenFeature([3], tf.int64),\n", "            'data': tf.io.FixedLenFeature([], tf.string),\n", "        }\n", "        def _parse_image_function(example_proto):\n", "            return tf.io.parse_single_example(example_proto, image_feature_description)        \n", "        parsed_dataset = raw_image_dataset.map(_parse_image_function)\n", "        for idx, dataitem in enumerate(parsed_dataset):\n", "            tfshape = dataitem['shape']\n", "            shape = tfshape.numpy()\n", "            tfdata = dataitem['data']\n", "            data = tfdata.numpy()\n", "            size = (shape[1], shape[2])\n", "            mode = 'RGB' if shape[0] == 3 else 'RGBA'\n", "            img = np.array(data)\n", "            channels = shape[0]\n", "            width = shape[1]\n", "            height = shape[2]\n", "            bytes_needed = int(width * height * channels)  # tfr 9: 512x512x3\n", "            bytesq = len(data) # tfr 9: 512x512x3\n", "            b = np.frombuffer(data, dtype=np.uint8)\n", "            img_arr =  b.reshape(shape[0], shape[1], shape[2]) # 3x3 b/w\n", "            img_arr = img_arr.transpose([1, 2, 0])\n", "            Onplot.cv_rgb(img_arr)\n", "    @staticmethod   \n", "    def cv_path(path, size = 512, title='img', wait=2000):\n", "        img = cv2.imread(path, cv2.IMREAD_COLOR)\n", "        img = cv2.resize(img, (size, int((np.shape(img)[0]/np.shape(img)[1]) * size)))\n", "        img = Onvgg.vgg_preprocess(img)\n", "        img = Onvgg.vgg_deprocess(img)\n", "        cv2.imshow(title, img) # keep open per wait\n", "        cv2.waitKey(wait)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    @staticmethod  \n", "    def cv_resize(img, max_size= None, dim=None):\n", "        if max_size:\n", "            img = cv2.resize(img, (max_size, int((np.shape(img)[0]/np.shape(img)[1]) * max_size)))\n", "        \n", "        if dim:\n", "            img = cv2.resize(img, (\n", "                dim[0] if dim[0] > 0 else img.size[0],\n", "                dim[1] if dim[1] > 0 else img.size[1]\n", "                ), Image.ANTIALIAS)            \n", "        return img"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    def cv_rgb(rgb, wait=2000):\n", "        rgb = cv2.cvtColor(rgb, cv2.COLOR_RGB2BGR)\n", "        cv2.imshow('img', rgb)\n", "        if wait:\n", "            cv2.waitKey(wait) "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    @staticmethod   \n", "    def cv_nba(img, title=\"img\", wait=0):\n", "        img = Onformat.nnba_to_rgb(img)\n", "        cv2.imshow(title, img)\n", "        cv2.waitKey(0)\n", "    @staticmethod   \n", "    def cv_img(img, title=\"img\", wait=0):\n", "        if Onutil.incolab():\n", "            from google.colab.patches import cv2_imshow\n", "            cv2_imshow(img)\n", "            cv2.waitKey(wait)\n", "            cv2.destroyAllWindows()\n", "        else:\n", "            cv2.imshow(title, img)\n", "            cv2.waitKey(wait)\n", "            cv2.destroyAllWindows()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["  ******************<br>\n", "  FUNS FORMAT<br>\n", "<br>\n", "  ******************"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class Onformat:\n", "    @staticmethod\n", "    def cvt_to_rgb(cvt):\n", "        img=np.array(cvt, dtype=np.float32)\n", "        img = img[0]\n", "        img = (img / 255 + 1.0)/2.0\n", "        return img\n", "    @staticmethod\n", "    def pil_to_cvi(img):\n", "        img = np.array(img) # [[[155  91  69]\n", "        img = img[:, :, ::-1] # val: [[[ 69  91 155]\n", "        return img\n", "    @staticmethod\n", "    def pil_to_nua(img):\n", "        img = img.convert(\"RGB\")\n", "        img = np.asarray(img, dtype=np.float32) / 255    \n", "        return img\n", "    @staticmethod\n", "    def nua_to_pil(nua):\n", "        nua = nua*255\n", "        nua = np.array(nua, dtype=np.uint8)\n", "        if np.ndim(nua)>3:\n", "            assert nua.shape[0] == 1\n", "            nua = nua[0]\n", "        return PIL.Image.fromarray(nua)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    @staticmethod\n", "    def pil_to_rgb(img):\n", "        img = img.convert(\"RGB\")\n", "        img = np.asarray(img)\n", "        return img\n", "    @staticmethod\n", "    def nba_to_nnba(img):\n", "        return img[np.newaxis,:,:,:]\n", "    \n", "    @staticmethod\n", "    def tnua_to_nua(img):\n", "        # np.array (by default) will make a copy of the object, \n", "        # while np.asarray will not unless necessary\n", "        img = np.asarray(img) # img = np.array(img)\n", "        return img\n", "    @staticmethod\n", "    def rgb_to_pil(img):\n", "        img = PIL.Image.fromarray(np.array(img, dtype=np.uint8))\n", "        return img\n", "    @staticmethod\n", "    def rgb_to_nba(img):\n", "        # normalizing the images to [-1, 1]\n", "        img = tf.cast(img, tf.float32) # _e_\n", "        img = (img / 127.5) - 1\n", "        return img\n", "        \n", "    @staticmethod\n", "    def _rgbs_to_nbas(input_image, real_image):\n", "        # normalizing the images to [-1, 1]\n", "        input_image = tf.cast(input_image, tf.float32) # _e_\n", "        real_image = tf.cast(real_image, tf.float32)   # _e_\n", "        input_image = (input_image / 127.5) - 1\n", "        real_image = (real_image / 127.5) - 1\n", "        return input_image, real_image\n", "    @staticmethod\n", "    def rgbs_to_nbas(imgs):\n", "        res = []\n", "        for img in imgs:\n", "            img = Onformat.rgb_to_nba(img)\n", "            res.append(img)\n", "        return res\n", "    @staticmethod\n", "    def rgbs_to_nuas_batch(imgs, num, flip = True):\n", "        idx = np.random.randint(0, imgs.shape[0] - 1, num)\n", "        out = []\n", "        for i in idx:\n", "            out.append(imgs[i])\n", "            if flip and np.random.uniform(()) < 0.5:  # flip as arg\n", "                out[-1] = np.flip(out[-1], 1)\n", "        return np.array(out).astype('float32') / 255.0   \n", "    @staticmethod\n", "    def nua_to_rgb(img):\n", "        img = img*255\n", "        rgb = np.array(img, dtype=np.uint8)\n", "        if np.ndim(img)>3:\n", "            assert img.shape[0] == 1\n", "            rgb = img[0]\n", "        return rgb\n", "    @staticmethod\n", "    def nua_to_pil(img):\n", "        img = Onformat.nua_to_rgb(img)\n", "        img = PIL.Image.fromarray(img)\n", "        return img\n", "    @staticmethod\n", "    def nua_to_rgb(nua):\n", "        res = nua*255\n", "        res = np.array(res, dtype=np.uint8)\n", "        if np.ndim(res)>3:\n", "            assert res.shape[0] == 1\n", "            res = res[0]\n", "        return res\n", "    @staticmethod\n", "    def nuas_to_rgbs(nuas):\n", "        imgs=[]\n", "        for nua in nuas:\n", "            imgs.append(Onformat.nua_to_rgb(nua))\n", "        return imgs\n", "    @staticmethod\n", "    def names_to_nnuas(img_names=[], img_dir = \"./\", max_size = None, img_nrows = None, img_ncols = None):\n", "        _imgs = []\n", "        for img_name in img_names:\n", "            fil = os.path.join(img_dir, img_name)\n", "            img = Onfile.path_to_nnua(fil, max_size, img_nrows, img_ncols)\n", "            _imgs.append(img)\n", "        return _imgs\n", "    @staticmethod\n", "    def nnba_to_rgb(img):\n", "        img = img[0,...]\n", "        img = (img + 1.0)/2.0\n", "        img = np.array(255 * img, dtype=np.uint8)\n", "        return img\n", "    @staticmethod\n", "    def nba_to_rgb(img):\n", "        img = 255*(img + 1.0)/2.0\n", "        return tf.cast(img, tf.uint8)\n", "    @staticmethod\n", "    def bgr_to_nua(img):\n", "        img = (img / 255 + 1.0)/2.0\n", "        return img\n", "    @staticmethod\n", "    def nba_to_nua(img): # [-1,1] => [0,255]\n", "        img = (img + 1.0)/2.0\n", "        return img\n", "    @staticmethod\n", "    def tnua_resize(image, width, height):\n", "        image = tf.cast(image, tf.float32)\n", "        image = tf.image.resize(image, (width, height))\n", "        # image = image[None, ...]\n", "        return image\n", "    @staticmethod\n", "    def cvt_to_nua(cvt):\n", "        img=np.array(cvt, dtype=np.float32)\n", "        img = img[0] # squeeze dim\n", "        img = (img / 255 + 1.0)/2.0\n", "        return img\n", "    @staticmethod\n", "    def imgs_to_tiling(imgs, imgpath, qsegs=1, save=True):\n", "        qtiles = qsegs * qsegs  # will predict images\n", "        r = []\n", "        for i in range(0, qtiles, qsegs): # for each row\n", "            r.append(np.concatenate(imgs[i:i+qsegs], axis = 0)) # concat cols\n", "        c1 = np.concatenate(r, axis = 1)\n", "        c1 = np.clip(c1, 0.0, 1.0)\n", "        x = Image.fromarray(np.uint8(c1*255))\n", "        if save:\n", "            x.save(imgpath)\n", "        return x\n", "    @staticmethod\n", "    def dnua_to_nua(tnua):\n", "        nua = tnua\n", "        if len(tnua.shape) > 3:\n", "            assert tnua.shape[0] == 1\n", "            nua = tf.squeeze(tnua, axis=0)\n", "        nua = np.asarray(nua)        \n", "        return nua\n", "    @staticmethod\n", "    def dnuas_to_nuas(tnuas):\n", "        nuas=[]\n", "        for item in tnuas:\n", "            nuas.append(Onformat.dnua_to_nua(item))\n", "        return nuas\n", "    @staticmethod\n", "    def dnuas_to_pils(nuas):\n", "        imgs=[]\n", "        for nua in nuas:\n", "            imgs.append(Onformat.nua_to_pil(nua))\n", "        return imgs\n", "    \n", "    @staticmethod\n", "    def rgb_to_bgr(img):\n", "        img = np.array(img) # [[[155  91  69]\n", "        img = img[:, :, ::-1] # val: [[[ 69  91 155]\n", "        return img\n", "    @staticmethod\n", "    def rgb_to_dnua(img):\n", "        img = img/255.0\n", "        img = img[np.newaxis,:,:,:]\n", "        return img\n", "    @staticmethod\n", "    def pil_to_dnua(img):\n", "        img=np.array(img, dtype=np.float32)\n", "        img = img/255.0\n", "        img = img[np.newaxis,:,:,:]\n", "        return img\n", "    @staticmethod\n", "    def pils_to_dnuas(pils):\n", "        dnuas=[]\n", "        for img in pils:\n", "            nua = Onformat.pil_to_dnua(img)\n", "            dnuas.append(nua)\n", "        return dnuas\n", "    @staticmethod\n", "    def cvi_to_pil(img):\n", "        img = img[...,::-1] # bgr => rgb\n", "        img = Image.fromarray((img).astype(np.uint8))\n", "        img = np.array(img)\n", "        img = PIL.Image.fromarray(img)\n", "        return img"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    @staticmethod\n", "    def cvis_to_pils(imgs):\n", "        pils=[]\n", "        for img in imgs:\n", "            pil = Onformat.cvi_to_pil(img)\n", "            pils.append(pil)\n", "        return pils\n", "    @staticmethod\n", "    def bgr_cv2_rgb(img):\n", "        return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n", "    @staticmethod\n", "    def path_to_nbt_with_tf(img, height=256, width=256):\n", "        img = Onfile.path_to_rgb(img)\n", "        img = tf.image.resize(img, [height, width], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)        \n", "        img = Onformat.rgb_to_nba(img)\n", "        return img"]}, {"cell_type": "markdown", "metadata": {}, "source": ["  ******************<br>\n", "  FUNS FILE<br>\n", "<br>\n", "  ******************"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class Onfile:\n", "    @staticmethod\n", "    def rgbs_to_file(rgbs, scale=1, rows=1, save_path='./img.png',):\n", "        pils = []\n", "        for img in rgbs:\n", "            pils.append(PIL.Image.fromarray(np.array(img, dtype=np.uint8)))\n", "        w,h = pils[0].size\n", "        w = int(w*scale)\n", "        h = int(h*scale)\n", "        height = rows*h\n", "        cols = int(math.ceil(len(pils) / rows))\n", "        width = cols*w\n", "        canvas = PIL.Image.new('RGBA', (width,height), 'white')\n", "        for i,img in enumerate(pils):\n", "            img = img.resize((w,h), PIL.Image.ANTIALIAS)\n", "            canvas.paste(img, (w*(i % cols), h*(i // cols))) \n", "        canvas.save(save_path)\n", "    @staticmethod\n", "    def path_to_nba(img, height=256, width=256):\n", "        img = Onfile.path_to_rgb(img)\n", "        img = tf.image.resize(img, [height, width], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n", "        img = Onformat.rgb_to_nba(img)\n", "        return img\n", "    @staticmethod\n", "    def path_to_tnua_with_cv(path):\n", "        img = cv2.imread(path, cv2.IMREAD_COLOR)\n", "        img = img.astype(np.float32)\n", "        img = img[...,::-1]\n", "        # shape (h, w, d) to (1, h, w, d)\n", "        img = img[np.newaxis,:,:,:]\n", "        img -= np.array([123.68, 116.779, 103.939]).reshape((1,1,1,3))\n", "        return img\n", "    @staticmethod\n", "    def path_to_cvi(path,  max_size=None):\n", "        # bgr image\n", "        img = cv2.imread(path, cv2.IMREAD_COLOR)\n", "        if max_size:\n", "            h, w, d = img.shape\n", "            mx = max_size\n", "            # resize if > max size\n", "            if h > w and h > mx:\n", "                w = (float(mx) / float(h)) * w\n", "                img = cv2.resize(img, dsize=(int(w), mx), interpolation=cv2.INTER_AREA)\n", "            if w > mx:\n", "                h = (float(mx) / float(w)) * h\n", "                img = cv2.resize(img, dsize=(mx, int(h)), interpolation=cv2.INTER_AREA)\n", "        return img"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    @staticmethod\n", "    def path_cv_pil(path):\n", "        img = cv2.imread(path, cv2.IMREAD_COLOR)\n", "        img = img[...,::-1] # bgr => rgb\n", "        img = np.array(Image.fromarray((img).astype(np.uint8)))\n", "        img = PIL.Image.fromarray(img)\n", "        return img\n", "    @staticmethod\n", "    def path_to_tvgg(img_path, tileimg=None, scale=None, max_size=None ):\n", "        print(\"get init with cv2\")\n", "        img = Onfile.path_to_cvi(img_path,max_size=max_size)\n", "        img = Onvgg.vgg_preprocess(img)    \n", "        return img\n", "    @staticmethod\n", "    def path_to_nua(img_path, max_size = None, img_nrows = None, img_ncols = None):\n", "        assert os.path.isfile(img_path), f\"path_to_nnua {img_path} not found\"\n\n", "        # <class 'tensorflow.python.framework.ops.EagerTensor'> ()\n", "        # tf.Tensor(b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\n", "        img = tf.io.read_file(img_path)\n", "        img = tf.image.decode_image(img, channels=3) # _e_\n", "        img = tf.image.convert_image_dtype(img, tf.float32)\n", "        shape = tf.cast(tf.shape(img)[:-1], tf.float32) # \n", "        long_dim = max(shape)\n", "        scale = max_size / long_dim if max_size else 1\n", "        new_shape = tf.cast(shape * scale, tf.int32)\n", "        if (img_nrows and img_ncols): new_shape = tf.cast((img_nrows, img_ncols), tf.int32)\n", "        img = tf.image.resize(img, new_shape)\n", "        return img\n", "    @staticmethod\n", "    def path_to_nnua(img_path, max_size = None, img_nrows = None, img_ncols = None):\n", "        img = Onfile.path_to_nua(img_path, max_size, img_nrows, img_ncols)\n", "        img = img[tf.newaxis, :] # b, h, w, c\n", "        return img\n", "    @staticmethod\n", "    def names_to_nuas_with_tf(imgs_names, img_dir, args=None):\n", "        imgs = []\n", "        for item in imgs_names:\n", "            path = os.path.join(img_dir, item)\n", "            img = Onfile.path_to_tnua_with_tf(path, args)\n", "            imgs.append(img)\n", "        return imgs\n", "    @staticmethod\n", "    def names_to_paths(imgs_names, img_dir):\n", "        paths = []\n", "        for item in imgs_names:\n", "            path = os.path.join(img_dir, item)\n", "            paths.append(path)\n", "        return paths\n", "    @staticmethod\n", "    def folder_to_tnuas(folder, patt='*.jpg', max_size = None, img_nrows = None, img_ncols = None):\n", "        paths = glob.glob(os.path.join(folder, patt))\n", "        tnuas = []\n", "        for path in paths:\n", "            nua = Onfile.path_to_nnua(path, max_size, img_nrows, img_ncols)\n", "            tnuas.append(nua)\n", "        return tnuas\n", "    @staticmethod\n", "    def path_to_tnua_with_tf(path, args=None):\n", "            \n", "        max_size = args.max_size \n", "        assert os.path.isfile(path), f\"path_to_tnua_with_tf img {path} not found\"\n", "        parts = tf.strings.split(path, os.sep)\n", "        label = parts[-2]    \n\n", "        # <class 'tensorflow.python.framework.ops.EagerTensor'>  () tf.Tensor(b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\n", "        img = tf.io.read_file(path)\n", "        img = tf.image.decode_image(img, channels=3)\n", "        img = tf.image.convert_image_dtype(img, tf.float32)\n", "        shape = tf.cast(tf.shape(img)[:-1], tf.float32) #  \n", "        long_dim = max(shape)\n", "        scale = max_size / long_dim if max_size else 1\n", "        new_shape = tf.cast(shape * scale, tf.int32)\n\n", "        # <class 'tensorflow.python.framework.ops.EagerTensor'>  (336, 512, 3) tf.Tensor([[[0.60938966 0.36011618 0.27445853]    \n", "        img = tf.image.resize(img, new_shape)\n", "        img = img[tf.newaxis, :]\n", "        return img\n", "    @staticmethod\n", "    def pil_to_file_with_cv(path, img):\n", "        cv2.imwrite(path, Onformat.pil_to_cvi(img))\n", "    @staticmethod\n", "    def pil_to_file(path, img):\n", "        img.save(path)\n", "    @staticmethod\n", "    def path_to_bgr(path): # _e_\n", "        # bgr image \n", "        img = cv2.imread(path, cv2.IMREAD_COLOR)\n", "        img = img.astype(np.float32)\n", "        # img = Onformat.vgg_preprocess(img)\n", "        return img\n", "    @staticmethod\n", "    def names_to_pils(imgs,dst_dir= './',img_name_frmt='img{}.jpg',zfill = 4,):\n", "        for i,img in enumerate(imgs):\n", "            img_name = img_name_frmt.format(str(i).zfill(zfill))\n", "            path = os.path.join(dst_dir, img_name)\n", "            tft = img # <class 'tensorflow.python.framework.ops.EagerTensor'> (256, 256, 3)\n", "            arr = img.numpy().astype(np.uint8) # <class 'numpy.ndarray'> (256, 256, 3)\n", "            img = Image.fromarray(arr)\n", "            img = img.convert(\"RGB\")\n", "            img.save(path)\n", "    @staticmethod\n", "    def path_cv2_dnua(path):  #  _e_\n", "        img = cv2.imread(path, cv2.IMREAD_COLOR)\n", "        img = Onformat.vgg_preprocess(img)\n", "        img = Onformat.vgg_deprocess(img)\n", "        img = Onformat.pil_to_dnua(img)\n", "        return img\n", "    \n", "    @staticmethod\n", "    def cvs_to_folder(imgs, path, img_format='img{}.jpg', zfill=4):\n", "        for i,img in enumerate(imgs):\n", "            Onfile.cv_to_path(img, os.path.join(path, img_format.format(str(i).zfill(zfill))))\n", "    @staticmethod\n", "    def cv_to_path(img, path):\n", "        saved = cv2.imwrite(path, img)\n", "        return saved\n", "    @staticmethod\n", "    def cv_to_file(path, img):\n", "        cv2.imwrite(path, Onformat.rgb_to_bgr(img))\n", "    @staticmethod\n", "    def path_to_cv(path, max_size=512):\n\n", "        # bgr image\n", "        img = cv2.imread(path, cv2.IMREAD_COLOR)\n", "        h, w, d = img.shape\n", "        mx = max_size\n", "        # resize if > max size\n", "        if h > w and h > mx:\n", "            w = (float(mx) / float(h)) * w\n", "            img = cv2.resize(img, dsize=(int(w), mx), interpolation=cv2.INTER_AREA)\n", "        if w > mx:\n", "            h = (float(mx) / float(w)) * h\n", "            img = cv2.resize(img, dsize=(mx, int(h)), interpolation=cv2.INTER_AREA)\n", "        return img"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    @staticmethod\n", "    def paths_to_cvs(paths):\n", "        imgs = []\n", "        for path in paths:\n", "            imgs.append(Onfile.path_to_cv(path))\n", "        return imgs\n", "    @staticmethod\n", "    def paths_to_folder_with_cv(paths, folder, img_format='img{}.jpg', zfill=4):\n", "        imgs = []\n", "        for i,path in enumerate(paths):\n", "            img = Onfile.path_to_cv(path)\n", "            img_path = os.path.join(folder, img_format.format(str(i).zfill(zfill)))\n", "            if 1:\n", "                print(f'save {i} to {img_path}')\n", "            Onfile.cv_to_file(img_path, img)\n", "        return imgs\n", "    @staticmethod\n", "    def folder_to_cvs(path):\n", "        paths = Onfile.folder_to_paths(path)\n", "        imgs = Onfile.paths_to_cvs(paths)\n", "        return imgs\n", "    @staticmethod\n", "    def folder_to_cv_name_pairs(path, args=None):\n", "        pairs = []\n", "        for root, subdirs, files in os.walk(path):\n", "            if(args.verbose): print('folder_to_cv_name_pairs --\\nroot = ' + root)\n", "            for subdir in subdirs:\n", "                if(args.verbose): print('\\t- subdirectory ' + subdir)\n", "            for filename in files:\n", "                if not filename.startswith('.'):\n", "                    file_path = os.path.join(root, filename)\n", "                    if(args.verbose): print('\\t- file %s (full path: %s)' % (filename, file_path))\n", "                    \n", "                    pairs.append([cv2.imread(file_path),filename])\n", "        return pairs\n", "    @staticmethod\n", "    def cv_name_pairs_to_folder(pairs, args=None):\n", "        folder = args.output_folder\n", "        for pair in pairs:\n", "            img = pair[0]\n", "            filename = pair[1]\n", "            if(args.file_extension == \"png\"):\n", "                new_file = os.path.splitext(filename)[0] + \".png\"\n", "                cv2.imwrite(os.path.join(folder, new_file), img, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n", "            else:\n", "                new_file = os.path.splitext(filename)[0] + \".jpg\"\n", "                cv2.imwrite(os.path.join(folder, new_file), img, [cv2.IMWRITE_JPEG_QUALITY, 90])\n", "    @staticmethod\n", "    def path_to_pil(path):\n", "        img = Image.open(path)\n", "        return img\n", "    @staticmethod\n", "    def folder_to_paths(path, \n", "            exts=['jpg', 'jpeg', 'png'], \n", "            n=-1\n", "        ):\n", "        import glob\n", "        paths = [] # <class 'list'>\n", "        for ext in exts:\n", "            paths += glob.glob(os.path.join(path, f\"*.{ext}\"))\n", "            if 0 < n and n < len(paths):\n", "                break            \n", "        return paths\n", "    @staticmethod\n", "    def folder_to_paths(path, \n", "            exts=['jpg', 'jpeg', 'png'], \n", "            n=-1\n", "        ):\n", "        paths=[]\n", "        for root, dirs, files in os.walk(path):\n", "            for name in files:\n", "                if name.endswith(tuple(exts)):\n", "                    target_path = os.path.join(path, name)\n", "                    paths.append(target_path)\n", "                    if 0 < n and n < len(paths):\n", "                        break\n", "                else:\n", "                    pass # print('Only image')          \n", "        return paths"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    @staticmethod\n", "    def copyfolder(input_folder, output_folder, deep=True):\n", "        for filename in os.listdir(input_folder):\n", "            input_path = os.path.join(input_folder, filename)\n", "            try:\n", "                if os.path.isfile(input_path) or os.path.islink(input_path):\n", "                    output_path = os.path.join(output_folder, filename)\n", "                    shutil.copyfile(input_path, output_path)\n", "                elif os.path.isdir(input_path):\n", "                    if deep:\n", "                        Onfile.copyfolder(input_path, output_folder)\n", "            except Exception as e:\n", "                print(f'Failed to copy {input_path}. Reason: {e}')\n", "                \n", "    @staticmethod\n", "    def clearfolder(folder, inkey=''):\n", "        if inkey and inkey in folder:\n", "            print(f\"|===> clearfolder: {folder} has key {inkey}. will clear\")\n", "            for filename in os.listdir(folder):\n", "                file_path = os.path.join(folder, filename)\n", "                try:\n", "                    if os.path.isfile(file_path) or os.path.islink(file_path):\n", "                        os.unlink(file_path)\n", "                    elif os.path.isdir(file_path):\n", "                        shutil.rmtree(file_path)\n", "                except Exception as e:\n", "                    print('Failed to delete %s. Reason: %s' % (file_path, e))\n", "        else:\n", "            print(f\"|===> clearfolder: {folder} has no key {inkey}\")\n", "    @staticmethod\n", "    def qfolders(folder, topdown=False):\n", "        q = 0\n", "        if os.path.exists(folder):        \n", "            for root, dirs, files in os.walk(folder, topdown=topdown):\n", "                for name in dirs:\n", "                    q += 1\n", "        return q\n", "    @staticmethod\n", "    def qfiles(folder, patts=None):\n", "        howmany = 0\n", "        if not patts:\n", "            howmany = len(os.listdir(folder))\n", "        elif type(patts) is list: \n", "            paths = []\n", "            howmany = len(paths)\n", "            for patt in patts:\n", "                infolder = os.path.join(folder, patt)\n", "                pathsinfolder = glob.glob(infolder)\n", "                paths = paths + pathsinfolder\n", "                howmany = len(paths)\t\t\n", "        else:\n", "            files = glob.glob(os.path.join(folder, patts))\n", "            howmany = len(files)\n", "        return howmany"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    @staticmethod\n", "    def path_to_paths(path, patts=None): # ['*.jpg', '*.jpeg', '*.png']\n", "        paths = []\n", "        if patts:\n", "            for patt in patts:\n", "                inpath = os.path.join(path, patt)\n", "                new = glob.glob(inpath)\n", "                paths = paths + new\n", "        else:\n", "            for entry in os.listdir(path):\n", "                full_path = os.path.join(path, entry)\n", "                if os.path.isfile(full_path):\n", "                    paths.append(full_path)\n", "        return paths\n", "    @staticmethod\n", "    def folder_to_pils(src_dir, n=-1):\n", "        if 0: print(f\"folder_to_pils: was asked to get {n} imgs from: {src_dir}\")\n", "        imgs = []\n", "        import glob\n", "        jpgs = glob.glob(os.path.join(src_dir, \"*.jpg\"))\n", "        pngs = glob.glob(os.path.join(src_dir, \"*.png\"))\n", "        fs = jpgs + pngs  # <class 'list'>\n", "        for i,f in enumerate(fs):\n", "            if (n<0 or i<n):\n", "                img = Image.open(f)\n", "                imgs.append(img)\n", "        if 0: print(f\"folder_to_pils: got {len(imgs)} imgs from: {src_dir}\")            \n", "        return imgs\n", "    @staticmethod\n", "    def pils_to_folder(imgs, dest_dir, img_format = 'img{}.jpg', zfill=4, verbose=False):\n", "        for i, pil in enumerate(imgs):        \n", "            img_name = img_format.format(str(i).zfill(zfill))                \n", "            outpath = os.path.join(dest_dir, img_name)\n", "            if 0: \n", "                print(f\"save image {i} to {outpath}\")\n", "            pil.save(outpath, 'JPEG', quality=90) "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    @staticmethod\n", "    def folder_to_named_files(src_dir, dst_dir, img_format= 'img{}.jpg', zfill= 4, n=-1, verbose=False):\n", "        paths=[]\n", "        imgs=[]\n", "        idx = 0\n", "        for root, dirs, files in os.walk(src_dir):\n", "            for name in files:\n", "                if name.endswith((\".png\", \".jpg\")):\n", "                    src_path = os.path.join(src_dir, name)\n", "                    newname = img_format.format(str(idx).zfill(zfill))       \n", "                    target_path = os.path.join(dst_dir, newname)\n", "                    img = Image.open(src_path)\n", "                    paths.append(target_path)\n", "                    if verbose: \n", "                        print(f\"save image {idx} to {target_path}\")\n", "                    img.save(target_path, 'JPEG', quality=90) \n", "                    if -1 < n and n < len(paths):\n", "                        break\n", "                    idx += 1\n", "                else:\n", "                    print('get only image files')          \n", "        return paths\n", "    @staticmethod\n", "    def folder_to_rgbs(src_dir, qimgs=-1):\n", "        if 0: print(f\"folder_to_rgbs q:{qimgs} from: {src_dir}\")\n", "        imgs = Onfile.folder_to_pils(src_dir, qimgs)\n", "        res=[]\n", "        for img in imgs:\n", "            img = np.asarray(img)\n", "            res.append(img)\n", "        return res\n", "    @staticmethod\n", "    def folder_to_nuas(src_dir, qimgs=-1):\n", "        if 0: print(f\"folder_to_nuas q:{qimgs} from: {src_dir}\")\n", "        imgs = Onfile.folder_to_rgbs(src_dir, qimgs)\n", "        res=[]\n", "        for img in imgs:\n", "            img = img.astype(np.float32)\n", "            img = img / 255\n", "            res.append(img)\n", "        return np.asarray(res)\n", "    @staticmethod\n", "    def tfts_to_files(imgs,dst_dir= './',img_name_frmt='img{}.jpg',zfill = 4,):\n", "        for i,img in enumerate(imgs):\n", "            img_name = img_name_frmt.format(str(i).zfill(zfill))\n", "            path = os.path.join(dst_dir, img_name)\n", "            tft = img # <class 'tensorflow.python.framework.ops.EagerTensor'> (256, 256, 3)\n", "            arr = img.numpy().astype(np.uint8) # <class 'numpy.ndarray'> (256, 256, 3)\n", "            img = Image.fromarray(arr)\n", "            img = img.convert(\"RGB\")\n", "            img.save(path)\n", "    @staticmethod\n", "    def path_of_paired_to_rgbs(path):\n", "        image = tf.io.read_file(path) # => dtype=string\n", "        image = tf.image.decode_jpeg(image) # => shape=(256, 512, 3), dtype=uint8)\n", "        w = tf.shape(image)[1]\n", "        w = w // 2\n", "        real_image = image[:, :w, :] # real comes left \n", "        input_image = image[:, w:, :] \n", "        return input_image, real_image\n", "    @staticmethod\n", "    def path_to_rgb(path):\n", "        img = tf.io.read_file(path) # => dtype=string\n", "        img = tf.image.decode_jpeg(img) # => shape=(256, 512, 3), dtype=uint8)\n", "        return img\n", "    @staticmethod\n", "    def path_to_rgbt(path):\n", "        return Onfile.path_to_rgb(path)\n", "    @staticmethod\n", "    def path_to_tnua_with_tf(path, args=None):\n", "        max_size = args.max_size \n", "        assert os.path.isfile(path), f\"path_to_tnua_with_tf img {path} not found\"\n", "        parts = tf.strings.split(path, os.sep)\n", "        label = parts[-2]    \n\n", "        # <class 'tensorflow.python.framework.ops.EagerTensor'>  () tf.Tensor(b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\n", "        img = tf.io.read_file(path)\n", "        img = tf.image.decode_image(img, channels=3)\n", "        img = tf.image.convert_image_dtype(img, tf.float32)\n", "        shape = tf.cast(tf.shape(img)[:-1], tf.float32) #  \n", "        long_dim = max(shape)\n", "        scale = max_size / long_dim if max_size else 1\n", "        new_shape = tf.cast(shape * scale, tf.int32)\n\n", "        # <class 'tensorflow.python.framework.ops.EagerTensor'>  (336, 512, 3) tf.Tensor([[[0.60938966 0.36011618 0.27445853]    \n", "        img = tf.image.resize(img, new_shape)\n", "        img = img[tf.newaxis, :]\n", "        return img\n", "    @staticmethod\n", "    def names_tf_tnuas(imgs_names, img_dir, args=None):\n", "        imgs = []\n", "        for item in imgs_names:\n", "            path = os.path.join(img_dir, item)\n", "            img = Onfile.path_to_tnua_with_tf(path, args)\n", "            imgs.append(img)\n", "        return imgs\n\n", "    # https://github.com/rosasalberto/StyleGAN2-TensorFlow-2.x\n", "    @staticmethod\n", "    def generate_and_save_images(images, it, plot_fig=True, outdir='./'):\n", "        plt.close() \n", "        fig = plt.figure(figsize=(9,9))\n", "        for i in range(images.shape[0]):\n", "            plt.subplot(2, 2, i+1)\n", "            plt.imshow(images[i])\n", "            plt.axis('off')\n\n", "        # tight_layout minimizes the overlap between 2 sub-plots\n", "        fig.tight_layout()\n", "        imgoutname = 'image_at_iter_{:04d}.png'.format(it)\n", "        imgoutpath = os.path.join(outdir, imgoutname)\n", "        plt.savefig(imgoutpath)\n", "        if plot_fig: plt.show()\n", "    @staticmethod\n", "    def rgb_cv2_file(rgb, path): # to jpg\n", "        im_bgr = cv2.cvtColor(rgb, cv2.COLOR_RGB2BGR)\n", "        cv2.imwrite(path, im_bgr)   "]}, {"cell_type": "markdown", "metadata": {}, "source": ["  ******************<br>\n", "  FUNS Onimg<br>\n", "<br>\n", "  ******************"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class Onimg:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    @staticmethod\n", "    def img_to_mask(img, outpath=None, \n", "                    height=None, width=None, \n", "                    threshold=76, maxVal=255, \n", "                    thresmode=cv2.THRESH_BINARY,\n", "                    visual=0, verbose=0,\n", "                ):\n", "        #https://answers.opencv.org/question/228538/how-to-create-a-binary-mask-for-medical-images/\n", "        if verbose > -1:\n", "            print(f'|---> img_to_mask {np.shape(img)}')\n\n", "        #cv2.resize(src, dsize[, dst[, fx[, fy[, interpolation]]]])\n", "        if height and width:\n", "            (h1, w1) = (height, width)\n", "            img = cv2.resize(img, (w1, h1))\n", "        elif height:\n", "            h0 = np.shape(img)[0] # 384\n", "            w0 = np.shape(img)[1] # 512\n", "            h1 = height\n", "            w1 = int(w0  * (h1/h0))\n", "            img = cv2.resize(img, (w1, h1))\n", "        elif width:\n", "            h0 = np.shape(img)[0] # 384\n", "            w0 = np.shape(img)[1] # 512\n", "            w1 = width\n", "            h1 = int(h0  * (w1/w0))\n", "            dim = (w1, h1)\n", "            img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n", "        else:\n", "            pass\n", "        image_contours = np.zeros((img.shape[0], img.shape[1], 1), np.uint8)\n", "        image_binary = np.zeros((img.shape[0], img.shape[1], 1), np.uint8)\n", "        for channel in range(img.shape[2]):\n", "            ret, image_thresh = cv2.threshold(img[:, :, channel],\n", "                                            threshold, maxVal,\n", "                                            thresmode)\n", "            contours = cv2.findContours(image_thresh, 1, 1)[0]   \n", "            cv2.drawContours(image_contours,\n", "                            contours, -1,\n", "                            (255,255,255), 3)\n", "        contours = cv2.findContours(image_contours, cv2.RETR_LIST,\n", "                                cv2.CHAIN_APPROX_SIMPLE)[0]\n", "        cv2.drawContours(image_binary, [max(contours, key = cv2.contourArea)],\n", "                        -1, (255, 255, 255), -1)\n", "        if outpath:\n", "            outbasename = os.path.basename(outpath)\n", "            outdirname = os.path.dirname(outpath)\n", "            assert os.path.exists(outdirname), f\"outdirname {outdirname} does not exist\"\n", "            cv2.imwrite(outpath, image_binary)\n", "        if visual > 0:\n", "            cv2.imshow('inimg', img)            \n", "            cv2.imshow('outimg', image_binary)\n", "            cv2.waitKey(0) & 0xFF is 27\n", "            cv2.destroyAllWindows()\n", "        return image_binary"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    @staticmethod\n", "    def name_to_maskname(name):\n", "        name_base = os.path.splitext(name)[0]\n", "        name_ext = os.path.splitext(name)[1]\n", "        print(\"|...> name_base\", name_base, name_ext)\n", "        name_mask = f'{name_base}_mask{name_ext}'\n", "        return name_mask\n", "        \n", "    @staticmethod\n", "    def name_to_unmaskname(name):\n", "        name_base = os.path.splitext(name)[0]\n", "        name_ext = os.path.splitext(name)[1]\n", "        print(\"|...> name_base\", name_base, name_ext)\n", "        basename_unmask = name_base.replace('_mask', '')\n", "        name_unmask = f'{basename_unmask}{name_ext}'\n", "        return name_unmask\n", "        \n", "    @staticmethod\n", "    def path_to_maskpath(path):\n", "        dirname = os.path.dirname(path)\n", "        basename  =os.path.basename(path)\n", "        maskname = Onimg.name_to_maskname(basename)\n", "        maskpath = os.path.join(dirname, maskname)\n", "        return maskpath\n", "    @staticmethod\n", "    def path_to_mask(inpath, outpath, height = None, width = None, ml=2*38, mh=255, visual=0):\n", "        #https://answers.opencv.org/question/228538/how-to-create-a-binary-mask-for-medical-images/\n", "        inbasename = os.path.basename(inpath)\n", "        assert os.path.exists(inpath), f\"inpath {inpath} does not exist\"\n", "        img = cv2.imread(inpath)\n", "        image_binary = img_to_mask(img, outpath, height, width, ml, mh, visual)\n", "        return image_binary"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    @staticmethod\n", "    def tf_resize_nua(nua, args=None):\n", "            \n", "        max_size = args.max_size \n", "        shape = np.shape(nua)\n", "        (d,w,h,c) = shape\n", "        dim = (w,h)\n", "        long_dim = max(w,h)\n", "        scale = max_size / long_dim if max_size else 1\n", "        new_dim = (int(w * scale), int(h * scale))\n", "        print(f\"|===> tf_resize_nua \\n \\\n", "            nua type: {type(nua)} \\n \\\n", "            shape: {shape} \\n \\\n", "            max_size: {max_size} \\n \\\n", "            long_dim: {long_dim} \\n \\\n", "            scale: {scale} \\n \\\n", "            dim: {dim} \\n \\\n", "            new_dim: {new_dim} \\n \\\n", "        \")\n", "        nua = tf.image.resize(nua, new_dim)\n", "        #nua = nua[tf.newaxis, :]\n", "        print(f\"|... tf_resize_nua \\n \\\n", "            nua type: {type(nua)} \\n \\\n", "            shape: {np.shape(nua)} \\n \\\n", "        \")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        return nua"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    @staticmethod\n", "    def cvi_mask_to_cvi(img, mask, op=2):\n", "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n", "        \n", "        if op < 0: # reverse mask\n", "            mask = cv2.bitwise_not(mask)\n", "            op = abs(op)\n", "        if op == 1: # bitwise_and\n", "            mask = cv2.cvtColor(mask, cv2.COLOR_GRAY2RGB)\n", "            img = cv2.bitwise_and(img, mask)\n", "        elif op == 2: # bitwise_or\n", "            mask = cv2.cvtColor(mask, cv2.COLOR_GRAY2RGB)\n", "            img = cv2.bitwise_or(img, mask)\n", "        elif op == 3: # bitwise_xor\n", "            mask = cv2.cvtColor(mask, cv2.COLOR_GRAY2RGB)\n", "            img = cv2.bitwise_xor(img, mask)\n", "        elif op == 4: # bitwise_not\n", "            mask = cv2.cvtColor(mask, cv2.COLOR_GRAY2RGB)\n", "            img = cv2.bitwise_not(img, mask)\n", "        elif op == 5: # addWeighted\n", "            mask = cv2.cvtColor(mask, cv2.COLOR_GRAY2RGB)\n", "            img = cv2.addWeighted(img, 0.5, mask, 0.5, 0)\n", "        elif op == 6: # thresh\n", "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n", "            blur = cv2.GaussianBlur(gray, (13,13), 0)\n", "            thresh = cv2.adaptiveThreshold(blur,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV,51,7)\n\n", "            # Morph close\n", "            kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n", "            close = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel, iterations=1)\n\n", "            # Find contours, sort for largest contour, draw contour\n", "            cnts = cv2.findContours(close, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n", "            cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n", "            cnts = sorted(cnts, key=cv2.contourArea, reverse=True)\n", "            for c in cnts:\n", "                cv2.drawContours(thresh, [c], -1, (36,255,12), 2)\n", "                break\n", "            img = thresh"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n", "        return img"]}, {"cell_type": "markdown", "metadata": {}, "source": ["  ******************<br>\n", "  FUNS ONVID<br>\n", "<br>\n", "  ******************"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class Onvid:\n", "    @staticmethod\n", "    def vid_to_frames(video_path, frames_dir='./', frame_format= 'frame{}.jpg', zfill= 4, target = 1):\n", "        video = cv2.VideoCapture(video_path)      \n", "        success, frame = video.read() # Capture frame-by-frame\n", "        currentFrame = 0\n", "        counter = 0\n", "        addframe = 0\n", "        start = time.time()\n", "        while(success):\n", "            if currentFrame % target ==0:\n", "                name = frames_dir + '/frame' + \"{:04d}\".format(currentFrame) + '.jpg'\n", "                if 0: print (f'Creating... {currentFrame} {name}')\n", "                cv2.imwrite(name, frame)\n", "                success,frame = video.read()\n", "                if 0: print (f'will create... {currentFrame}')\n", "                currentFrame += 1\n", "                counter = 0\n", "                addframe += 1\n", "            else:\n", "                ret = video.grab()\n", "                currentFrame += 1\n", "                counter += 1\n", "        end = time.time()\n", "        seconds = end - start\n", "        num_frames = currentFrame\n", "        fps  = addframe / (seconds * target)\n", "        print (f\"|... Estimated frames per second : {int(round(fps))}\")\n", "        video.release() # When everything done, release the capture\n", "        cv2.destroyAllWindows()\n", "    @staticmethod\n", "    def frames_to_video(inputpath, outputpath, fps):\n", "        DWITH_FFMPEG=\"ON\"    \n", "        image_array = []\n", "        files = [f for f in os.listdir(inputpath) if os.path.isfile(os.path.join(inputpath, f))]\n", "        \n", "        # files.sort(key = lambda x: int(x[5:-4]))\n", "        if 1:\n", "            for i in range(len(files)):\n", "                img_path = os.path.join(inputpath,files[i] )\n", "                print(f'|---> frames_to_video img_path: {img_path}')\n", "                img = cv2.imread(img_path)\n", "                size =  (img.shape[1],img.shape[0])\n", "                img = cv2.resize(img,size)\n", "                image_array.append(img)\n", "            fourcc = cv2.VideoWriter_fourcc('D', 'I', 'V', 'X')\n", "            print(f'|---> frames_to_video outputpath: {outputpath}')            \n", "            out = cv2.VideoWriter(outputpath, fourcc, fps, size) # VideoWriter(filename, cv2.CAP_OPENCV_MJPEG, ...)\n", "            for i in range(len(image_array)):\n", "                out.write(image_array[i])     \n", "            out.release()\n", "        else:\n", "            with imageio.get_writer(outputpath, mode='I') as writer:\n", "                for filename in files:\n", "                    img_path = os.path.join(inputpath,filename)\n", "                    image = imageio.imread(img_path)\n", "                    writer.append_data(image)   \n", "    @staticmethod\n", "    def folder_to_movie(images, out_dir, out_name):\n", "        temp_dir = 'frames%06d'%int(1000000*random.random())\n", "        os.system('mkdir %s'%temp_dir)\n", "        for idx in tqdm(range(len(images))):\n", "            Image.fromarray(images[idx], 'RGB').save('%s/frame%05d.png' % (temp_dir, idx))\n", "        cmd = 'ffmpeg -i %s/frame%05d.png -c:v libx264 -pix_fmt yuv420p %s/%s.mp4' % (temp_dir, out_dir, out_name)\n", "        print(cmd)\n", "        os.system(cmd)\n", "        os.system('rm -rf %s'%temp_dir)\n", "    @staticmethod\n", "    def folder_to_vid(fromfolder, dstfile, ext='png', save=True, args=None):\n", "        srcpath = fromfolder\n", "        anifile = dstfile\n", "        size=(640, 480)\n", "        fps=20\n", "        if 1: # args.verbose: \n", "            print(f'|--->  folder_to_vid  \\n \\\n", "                srcpath:         {srcpath} \\n \\\n", "                anifile:         {anifile} \\n \\\n", "            ')            \n\n", "        # anime.anigif(srcpath, anifile)\n", "        fig = plt.figure()\n", "        fig.set_size_inches(size[0] / 100, size[1] / 100)\n", "        ax = fig.add_axes([0, 0, 1, 1], frameon=False, aspect=1)\n", "        ax.set_xticks([])\n", "        ax.set_yticks([])\n", "        images = []\n", "        imgnames = [img for img in os.listdir(srcpath) if img.endswith(ext)]\n", "        for i,imgname in enumerate(imgnames):\n", "            imgpath = os.path.join(srcpath, imgname)\n", "            img = imageio.imread(imgpath)\n", "            label=' '\n", "            plt_im = plt.imshow(img, animated=True)\n", "            plt_txt = plt.text(10, 310, label, color='black')\n", "            images.append([plt_im, plt_txt])\n\n", "        # animated_gif.save(anipath + \"/ani.gif\")\n", "        # MovieWriter imagemagick unavailable; \n", "        # trying to use <class 'matplotlib.animation.PillowWriter'> instead\n", "        if 1: #  args.verbose:\n", "            print(f'|...>  folder_to_vid: call anim.ArtistAnimation  \\n \\\n", "                images len:      {len(images)} \\n \\\n", "            ')\n", "        import matplotlib.animation as anim\n", "        ani = anim.ArtistAnimation(fig, images, \n", "            interval=20, blit=True, repeat_delay=1000)\n", "        if save:\n", "            ani.save(dstfile, writer='imagemagick')  \n", "        return ani\n", "    @staticmethod\n", "    def folder_to_gif(fromfolder, dstpath='./out.gif', patts=None):\n", "        paths = Onfile.path_to_paths(fromfolder, patts)\n", "        paths = sorted(paths)\n", "        print(f'---> folder_to_gif \\n \\\n", "            fromfolder: {fromfolder} \\n \\\n", "            dstpath: {dstpath} \\n \\\n", "            patts: {patts} \\n \\\n", "            paths: {len(paths)} \\n \\\n", "        ')\n", "        with imageio.get_writer(dstpath, mode='I') as writer:\n", "            for i,filename in enumerate(paths):\n", "                # if i % 8 != 0: continue\n", "                img = imageio.imread(filename)\n", "                writer.append_data(img)\n", "            #image = imageio.imread(filename)\n", "            #writer.append_data(image)\n", "    @staticmethod\n", "    def vid_show(path):\n", "        print(\"show anigif\")\n", "        anim_file = path\n", "        cap = cv2.VideoCapture(anim_file)\n", "        ret, frame = cap.read()\n", "        while(1):\n", "            ret, frame = cap.read()\n", "            if (not frame is None):\n", "                cv2.imshow('frame',frame)\n", "                if cv2.waitKey(1) & 0xFF == ord('q') or ret==False :\n", "                    cap.release()\n", "                    cv2.destroyAllWindows()\n", "                    break\n", "                cv2.imshow('frame',frame)\n", "    @staticmethod\n", "    def imgs_to_tiling(imgs, imgpath, qsegs=1, save=True):\n", "        qcells = qsegs * qsegs  # will predict images\n", "        r = []\n", "        for i in range(0, qcells, qsegs): # for each row\n", "            r.append(np.concatenate(imgs[i:i+qsegs], axis = 0)) # concat cols\n", "        c1 = np.concatenate(r, axis = 1)\n", "        c1 = np.clip(c1, 0.0, 1.0)\n", "        x = Image.fromarray(np.uint8(c1*255))\n", "        if save:\n", "            x.save(imgpath)\n", "        return x    \n\n", "    # rolux\n", "    @staticmethod\n", "    def render_video(src_file, dst_dir, tmp_dir, num_frames, mode, size, fps, codec, bitrate):\n", "        import PIL.Image\n", "        import moviepy.editor\n", "        def render_frame(t):\n", "            frame = np.clip(np.ceil(t * fps), 1, num_frames)\n", "            image = PIL.Image.open('%s/video/%08d.png' % (tmp_dir, frame))\n", "            if mode == 1:\n", "                canvas = image\n", "            else:\n", "                canvas = PIL.Image.new('RGB', (2 * src_size, src_size))\n", "                canvas.paste(src_image, (0, 0))\n", "                canvas.paste(image, (src_size, 0))\n", "            if size != src_size:\n", "                canvas = canvas.resize((mode * size, size), PIL.Image.LANCZOS)\n", "            return np.array(canvas)\n", "        src_image = PIL.Image.open(src_file)\n", "        src_size = src_image.size[1]\n", "        duration = num_frames / fps\n", "        filename = os.path.join(dst_dir, os.path.basename(src_file)[:-4] + '.mp4')\n", "        video_clip = moviepy.editor.VideoClip(render_frame, duration=duration)\n", "        video_clip.write_videofile(filename, fps=fps, codec=codec, bitrate=bitrate)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    # dvschultz\n", "    @staticmethod\n", "    def create_mp4(\n", "            src_dir, \n", "            dest_dir, \n", "            steppattern=\"*step*.png\",\n", "            tgtpattern=\"*target*.png\",\n", "            moviename = \"movie.mp4\",\n", "        ):\n\n", "        # Create video \n", "        import glob\n", "        imgspattern = os.path.join(src_dir, steppattern)\n", "        imgs = sorted(glob.glob(imgspattern))\n", "        targetpattern = os.path.join(src_dir, tgtpattern)\n", "        target_imgs = sorted(glob.glob(targetpattern))\n", "        assert len(target_imgs) == 1, \"More than one target found?\"\n", "        target_img = imageio.imread(target_imgs[0])\n", "        \n", "        moviepath = os.path.join(dest_dir, moviename)\n", "        with imageio.get_writer(moviepath, mode='I') as writer:\n", "            for filename in imgs:\n", "                image = imageio.imread(filename)\n", "                # Concatenate images with original target image\n", "                w,h = image.shape[0:2]\n", "                canvas = PIL.Image.new('RGBA', (w*2,h), 'white')\n", "                canvas.paste(Image.fromarray(target_img), (0, 0))\n", "                canvas.paste(Image.fromarray(image), (w, 0))\n", "                writer.append_data(np.array(canvas))\n", "    @staticmethod\n", "    def vid_to_file(\n", "            frame, \n", "            output_img, \n", "            video_output_dir= './',\n", "            frame_content_frmt='frame{}.jpg',\n", "            zfill = 4,\n", "        ):\n", "        print(f\"|---> vid_to_file frame {frame}\")\n", "        fn = frame_content_frmt.format(str(frame).zfill(zfill))\n", "        path = os.path.join(video_output_dir, fn)\n", "        save_cv2(path, output_img)\n", "    @staticmethod\n", "    def frame_cv2_rgb_vgg(frame, frames_dir, args):\n", "        frame_content_frmt = args.frame_content_frmt\n", "        max_size = args.max_size\n", "        zfill = args.zfill\n", "        frame_name = args.frame_content_frmt.format(str(frame).zfill(zfill))\n", "        frame_img_path = os.path.join(frames_dir, frame_name)\n", "        print(\"frame_img_path\", frame_img_path)\n", "        img = cv2.imread(frame_img_path, cv2.IMREAD_COLOR)\n", "        img = onvgg.vgg_preprocess(img)\n", "        # img = onvgg.vgg_deprocess(img)\n", "        # cv2.imshow('img', img)\n", "        # cv2.waitKey(2000)    \n", "        return img\n", "    @staticmethod\n", "    def get_Lucas_Kanade_Optical_Flow(path):\n", "        cap = cv2.VideoCapture(path)\n\n", "        # params for ShiTomasi corner detection\n", "        feature_params = dict( maxCorners = 100,\n", "                            qualityLevel = 0.3,\n", "                            minDistance = 7,\n", "                            blockSize = 7 )\n\n", "        # Parameters for lucas kanade optical flow\n", "        lk_params = dict( winSize  = (15,15),\n", "                        maxLevel = 2,\n", "                        criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n\n", "        # Create some random colors\n", "        color = np.random.randint(0,255,(100,3))\n\n", "        # Take first frame and find corners in it\n", "        ret, old_frame = cap.read()\n", "        old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n", "        p0 = cv2.goodFeaturesToTrack(old_gray, mask = None, **feature_params)\n\n", "        # Create a mask image for drawing purposes\n", "        mask = np.zeros_like(old_frame)\n", "        while(1):\n", "            ret,frame = cap.read()\n", "            frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n\n", "            # calculate optical flow\n", "            p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)\n\n", "            # Select good points\n", "            good_new = p1[st==1]\n", "            good_old = p0[st==1]\n\n", "            # draw the tracks\n", "            for i,(new,old) in enumerate(zip(good_new,good_old)):\n", "                a,b = new.ravel()\n", "                c,d = old.ravel()\n", "                mask = cv2.line(mask, (a,b),(c,d), color[i].tolist(), 2)\n", "                frame = cv2.circle(frame,(a,b),5,color[i].tolist(),-1)\n", "            img = cv2.add(frame,mask)\n", "            cv2.imshow('frame',img)\n", "            k = cv2.waitKey(30) & 0xff\n", "            if k == 27:\n", "                break\n\n", "            # Now update the previous frame and previous points\n", "            old_gray = frame_gray.copy()\n", "            p0 = good_new.reshape(-1,1,2)\n", "        cv2.destroyAllWindows()\n", "        cap.release()\n", "    \n", "    @staticmethod\n", "    def get_dense_Optical_Flow(path):\n", "        cap = cv2.VideoCapture(path)\n", "        ret, frame1 = cap.read()\n", "        prvs = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n", "        hsv = np.zeros_like(frame1)\n", "        hsv[...,1] = 255\n", "        while(1):\n", "            ret, frame2 = cap.read()\n", "            next = cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY)\n", "            flow = cv2.calcOpticalFlowFarneback(prvs,next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n", "            mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])\n", "            hsv[...,0] = ang*180/np.pi/2\n", "            hsv[...,2] = cv2.normalize(mag,None,0,255,cv2.NORM_MINMAX)\n", "            rgb = cv2.cvtColor(hsv,cv2.COLOR_HSV2BGR)\n", "            cv2.imshow('frame2',rgb)\n", "            k = cv2.waitKey(30) & 0xff\n", "            if k == 27:\n", "                break\n", "            elif k == ord('s'):\n", "                cv2.imwrite('opticalfb.png',frame2)\n", "                cv2.imwrite('opticalhsv.png',rgb)\n", "            prvs = next\n", "        cap.release()\n", "        cv2.destroyAllWindows()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["  ******************<br>\n", "   Ondata<br>\n", "  ******************"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class Ondata:\n", "    @staticmethod\n", "    def pil_scale(img, scale=1):\n", "        img.thumbnail((img.size[0]*scale, img.size[1]*scale), Image.LANCZOS) \n", "        return img\n", "    @staticmethod\n", "    def pil_resize(img, ps=(-1, -1)):\n", "        img = img.resize((\n", "            ps[0] if ps[0] > 0 else img.size[0],\n", "            ps[1] if ps[1] > 0 else img.size[1]\n", "            ), Image.ANTIALIAS)\n", "        return img\n", "    @staticmethod\n", "    def resize_tf_hwc(image, width, height):\n", "        # Resized images will be distorted if their original aspect ratio is not the same as size. \n", "        # To avoid distortions see tf.image.resize_with_pad\n", "        image = tf.cast(image, tf.float32)\n", "        image = tf.image.resize(image, (width, height))\n", "        return image\n", "    @staticmethod\n", "    def resize_tf_bhwc(image, width, height):\n", "        Ondata.resize_tf_hwc(image, width, height)\n", "    \n", "    @staticmethod\n", "    def crop_image(img,tol=0):\n", "        # https://www.youtube.com/watch?v=weRmcRzMfUQ\n", "        # https://codereview.stackexchange.com/questions/132914/crop-black-border-of-image-using-numpy\n", "        # https://www.youtube.com/user/bustbright/videos\n", "        # img is 2D or 3D image data\n", "        # tol  is tolerance\n", "        mask = img>tol\n", "        if img.ndim==3:\n", "            mask = mask.all(2)\n", "        mask0,mask1 = mask.any(0),mask.any(1)\n", "        return img[np.ix_(mask0,mask1)]\n", "    @staticmethod\n", "    def crop_img_only_outside(img,tol=0):\n", "        # img is 2D or 3D image data\n", "        # tol  is tolerance\n", "        mask = img>tol\n", "        if img.ndim==3:\n", "            mask = mask.all(2)\n", "        m,n = mask.shape\n", "        mask0,mask1 = mask.any(0),mask.any(1)\n", "        col_start,col_end = mask0.argmax(),n-mask0[::-1].argmax()\n", "        row_start,row_end = mask1.argmax(),m-mask1[::-1].argmax()\n", "        return img[row_start:row_end,col_start:col_end]\n", "    @staticmethod\n", "    def random_crop_with_tf(img, h, w):\n", "        stacked_image = tf.stack([img], axis=0)\n", "        cropped_image = tf.image.random_crop(stacked_image, size=[1, h, w, 3])\n", "        return cropped_image[0]\n", "    @staticmethod\n", "    def resize_with_tf(img, height, width):\n", "        img = tf.image.resize(img, [height, width],\n", "            method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n", "        return img\n", "    @staticmethod\n", "    def img_to_sqr_pils(img, qslices=1, eps = 0.5, clip = (512, 512)):\n", "        newimgs = []\n", "        img_data = np.array(list(img.getdata())).reshape( (img.size[1],img.size[0],-1) ) # y,x\n", "        for n in range(qslices):\n", "            rx = int(( ( img.size[0]-clip[0] ) / 2 ) + eps * np.random.randint( ( img.size[0]-clip[0] ) / 2 )) if img.size[0]> clip[0] + 2 else 0\n", "            ry = int(( ( img.size[1]-clip[1] ) / 2 ) + eps * np.random.randint( ( img.size[1]-clip[0] ) / 2 )) if img.size[1]> clip[1] + 2 else 0\n", "            print(f\"|... img_to_sqr_pils tile {n}: {ry}, {ry+clip[1]}, {rx}, {rx+clip[0]}\")\n", "            sub = np.copy(img_data[ry:ry+clip[1], rx:rx+clip[0]]).astype(np.uint8) # y,x\n", "            sub = sub[:,:,:3]\n\n", "            # append\n", "            newimg = Image.fromarray(sub)\n", "            newimgs.append(newimg)\n", "        return newimgs\n", "    @staticmethod\n", "    def img_to_tiled_pils(img, tile = (512, 512)):\n", "        img_data = np.asarray(img.convert(\"RGB\")).reshape( (img.size[1],img.size[0],-1) )\n", "        shape = np.shape(img_data)\n", "        hb,wb  = shape[0], shape[1]\n", "        hb2,wb2 = int(hb/2), int(wb/2)\n", "        hs, ws = tile[0], tile[1]\n", "        hs2, ws2 = int(hs/2), int(ws/2)\n", "        hr, wr = ((hb2-hs2))/hs, ((wb2-ws2))/ws\n", "        hn, wn = math.floor(hr), math.floor(wr)\n", "        newimgs=[]\n", "        if wn >= 0 and hn >= 0:\n", "            rx = wb2 + (0 - 1) * ws2\n", "            ry = hb2 + (0 - 1) * hs2\n", "            sub = np.copy(img_data[ry:ry+hs, rx:rx+ws]).astype(np.uint8) # y,x\n", "            newimg = Image.fromarray(sub[:,:,:3])\n", "            if 0:\n", "                print(f\"|... img_to_tiled_pils r0 ==> {0}, {0}: {[ry, rx]}: {np.shape(newimg)}\")\n", "            newimgs.append(newimg)\n", "        for i in range(wn+1):\n", "            for j in range(hn+1):\n", "                wi = i\n", "                hi = j\n", "                if wi > 0:\n", "                    # -x-|---\n", "                    rx = wb2 + (-wi - 0) * ws2\n", "                    ry = hb2 + (+hi - 0) * hs2\n", "                    sub = np.copy(img_data[\n", "                                ry:ry+hs, \n", "                                rx:rx+ws\n", "                                ]).astype(np.uint8) # y,x\n", "                    newimg = Image.fromarray(sub[:,:,:3])\n", "                    # pil_show_rgb(newimg)\n", "                    newimgs.append(newimg)\n", "                    if 0:\n", "                        print(f\"|... img_to_tiled_pils r2 ==> {wi}, {hi}: {[ry, rx]}: {np.shape(newimg)}\")\n", "                    # ---|-x-\n", "                    rx = wb2 + (+wi - 0) * ws2\n", "                    ry = hb2 + (+hi - 0) * hs2\n", "                    sub = np.copy(img_data[\n", "                                ry:ry+hs, \n", "                                rx:rx+ws\n", "                                ]).astype(np.uint8) # y,x\n", "                    newimg = Image.fromarray(sub[:,:,:3])\n", "                    # pil_show_rgb(newimg)\n", "                    newimgs.append(newimg)\n", "                    if 0:\n", "                        print(f\"|... img_to_tiled_pils r2 ==> {wi}, {hi}: {[ry, rx]}: {np.shape(newimg)}\")\n", "                if hi > 0:\n", "                    #  ---^\n", "                    rx = wb2 + (+wi - 0) * ws2\n", "                    ry = hb2 + (-hi - 0) * hs2 \n", "                    sub = np.copy(img_data[\n", "                                ry:ry+hs, \n", "                                rx:rx+ws\n", "                                ]).astype(np.uint8) # y,x\n", "                    newimg = Image.fromarray(sub[:,:,:3])\n", "                    # pil_show_rgb(newimg)\n", "                    if 0:\n", "                        print(f\" r3 ==> {wi}, {hi}: {[ry, rx]}: {np.shape(newimg)}\")\n", "                    newimgs.append(newimg)\n", "                    #  ---_\n", "                    rx = wb2 + (+wi - 0) * ws2\n", "                    ry = hb2 + (+hi - 0) * hs2 \n", "                    sub = np.copy(img_data[\n", "                                ry:ry+hs, \n", "                                rx:rx+ws\n", "                                ]).astype(np.uint8) # y,x\n", "                    newimg = Image.fromarray(sub[:,:,:3])\n", "                    # pil_show_rgb(newimg)\n", "                    if 0:\n", "                        print(f\"|... img_to_tiled_pils r3 ==> {wi}, {hi}: {[ry, rx]}: {np.shape(newimg)}\")\n", "                    newimgs.append(newimg)\n", "                if wi > 0 and hi > 0:\n", "                    rx = wb2 + (-wi - 0) * ws2\n", "                    ry = hb2 + (-hi - 0) * hs2 \n", "                    sub = np.copy(img_data[\n", "                                ry:ry+hs, \n", "                                rx:rx+ws\n", "                                ]).astype(np.uint8) # y,x\n", "                    newimg = Image.fromarray(sub[:,:,:3])\n", "                    if 0:\n", "                        print(f\"|... img_to_tiled_pils r4 ==> {wi}, {hi}: {[ry, rx]}: {np.shape(newimg)}\")\n", "                    # pil_show_rgb(newimg)\n", "                    newimgs.append(newimg)\n", "        print(f\"|... img_to_tiled_pils new imgs q: {len(newimgs)}\")\n", "        return newimgs\n", "    @staticmethod\n", "    def random_jitter(img, throughsize=(286, 286), tosize=(256, 256)):\n", "        # resizing to 286 x 286 x 3\n", "        img = Ondata.resize_with_tf(img, throughsize[0], throughsize[1])\n\n", "        # randomly cropping to 256 x 256 x 3\n", "        img = Ondata.random_crop_with_tf(img, tosize[0], tosize[1])\n", "        if np.random.uniform(()) > 0.5: # tf _e_\n", "            # random mirroring\n", "            img = tf.image.flip_left_right(img)\n", "            real_image = tf.image.flip_left_right(real_image)\n", "        \n", "        return img\n", "    @staticmethod\n", "    def folder_to_formed_rgbs(\n", "        src_dir,\n", "        qimgs = -1,          # number of images to get from src\n", "        scale = 1,          # will scale by scale\n", "        ps = (-1, -1),      # will resize images if sizes in N\n", "        qslices = 1,         # will generte slices per images\n", "        eps = 0.0,          # will deviate from the center of th image\n", "        clip = (512, 512),  # will generate slices of clip size   \n", "    ):\n", "        imgs = Ondata.folder_to_formed_pils(src_dir,qimgs,scale,ps,qslices,eps,clip)\n", "        arrs = [np.array(img) for img in imgs]\n", "        return arrs\n", "    @staticmethod\n", "    def folder_to_formed_nuas(\n", "        src_dir,\n", "        qimgs = -1,          # number of images to get from src\n", "        scale = 1,          # will scale by scale\n", "        ps = (-1, -1),      # will resize images if sizes in N\n", "        qslices = 1,         # will generte slices per images\n", "        eps = 0.0,          # will deviate from the center of th image\n", "        clip = (512, 512),  # will generate slices of clip size   \n", "    ):\n", "        rgbs = Ondata.folder_to_formed_rgbs(src_dir,qimgs,scale,ps,qslices,eps,clip)\n", "        narrs = [rgb / 255 for rgb in rgbs]\n", "        return narrs\n", "    @staticmethod\n", "    def folder_to_formed_pils(\n", "        src_dir,\n", "        qimgs = -1,         # number of images to get from src\n", "        scale = 1,          # will scale by scale\n", "        ps = (-1, -1),      # will resize images if sizes in N\n", "        qslices = 1,        # will generte slices per images\n", "        eps = 0.0,          # will deviate from the center of th image\n", "        clip = (512, 512),  # will generate slices of clip size   \n", "    ):\n", "        assert os.path.exists(src_dir), \"src_dir does not exist\"\n", "        newimgs = []\n", "        items = Onfile.folder_to_pils(src_dir, qimgs)\n", "        for i,img in enumerate(items):\n", "            img = Ondata.pil_scale(img, scale)\n", "            print(f\"|... folder_to_formed_pils after-scale img shape: {np.shape(img)}\")\n", "            img = Ondata.pil_resize(img, ps)\n", "            print(f\"|... folder_to_formed_pils alter-resize img shape: {np.shape(img)}\")\n", "            tiledimgs = Ondata.img_to_sqr_pils(img,qslices,eps,clip)\n", "            newimgs += tiledimgs\n", "        return newimgs\n", "    @staticmethod\n", "    def path_to_formed_pair(path, dim=512, do_crop=False, canny_thresh1=100, canny_thresh2=200):\n", "        # https://github.com/memo/webcam-pix2pix-tensorflow/blob/master/preprocess.py\n", "        print(f'|... path_to_formed_pair {path}')\n", "        out_shape = (dim, dim)\n", "        im = PIL.Image.open(path)\n", "        im = im.convert('RGB')\n", "        if do_crop:\n", "            resize_shape = list(out_shape)\n", "            if im.width < im.height:\n", "                resize_shape[1] = int(round(float(im.height) / im.width * dim))\n", "            else:\n", "                resize_shape[0] = int(round(float(im.width) / im.height * dim))\n", "            im = im.resize(resize_shape, PIL.Image.BICUBIC)\n", "            hw = int(im.width / 2)\n", "            hh = int(im.height / 2)\n", "            hd = int(dim/2)\n", "            area = (hw-hd, hh-hd, hw+hd, hh+hd)\n", "            im = im.crop(area)            \n", "                \n", "        else:\n", "            im = im.resize(out_shape, PIL.Image.BICUBIC)\n", "            \n", "        a1 = np.array(im) \n", "        a2 = cv2.Canny(a1, canny_thresh1, canny_thresh2)\n", "        a2 = cv2.cvtColor(a2, cv2.COLOR_GRAY2RGB)                 \n", "        a3 = np.concatenate((a1,a2), axis=1)\n", "        im = PIL.Image.fromarray(a3)                     \n", "                        \n", "        # im.save(os.path.join(out_path, out_fname))\n", "        # print(f\"save {os.path.join(out_path, out_fname)})\n", "        return im"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    @staticmethod\n", "    def path_to_formed_pil(path, dim=None, do_crop=False):\n", "        # https://github.com/memo/webcam-pix2pix-tensorflow/blob/master/preprocess.py\n", "        if 0: print(f'|... path_to_formed_pil {path}')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        im = PIL.Image.open(path)\n", "        im = im.convert('RGB')\n", "        if do_crop:\n", "            assert dim, \"dim must be defined\"\n", "            resize_shape = list((dim, dim))\n", "            if im.width < im.height:\n", "                resize_shape[1] = int(round(float(im.height) / im.width * dim))\n", "            else:\n", "                resize_shape[0] = int(round(float(im.width) / im.height * dim))\n", "            im = im.resize(resize_shape, PIL.Image.BICUBIC)\n", "            hw = int(im.width / 2)\n", "            hh = int(im.height / 2)\n", "            hd = int(dim/2)\n", "            area = (hw-hd, hh-hd, hw+hd, hh+hd)\n", "            im = im.crop(area)            \n", "                \n", "        elif dim:\n", "            out_shape = (dim, dim)\n", "            im = im.resize(out_shape, PIL.Image.BICUBIC)\n", "            \n", "        return im\n", "    @staticmethod\n", "    def folder_to_formed_data(\n", "        src_dir,\n", "        dest_dir,\n", "        qimgs = -1,         # number of images to get from src\n", "        scale = 1,          # will scale by scale\n", "        ps = (-1, -1),      # will resize images if sizes in N\n", "        qslices = 2,        # will generte slices per images\n", "        eps = 0.5,          # will deviate from the center of th image\n", "        clip = (512, 512),  # will generate slices of clip size   \n", "        img_format = 'img{}.jpg', zfill=4,\n", "        verbose=False\n", "    ):\n", "        assert os.path.exists(src_dir), \"src_dir does not exist\"\n", "        newimgs = []\n", "        imgs = []\n", "        jpgs = glob.glob(os.path.join(src_dir, \"*.jpg\"))\n", "        pngs = glob.glob(os.path.join(src_dir, \"*.png\"))\n", "        fs = jpgs + pngs  # <class 'list'>\n", "        newimgidx = 0\n", "        for i,f in enumerate(fs):\n", "            if (qimgs<0 or i<qimgs):\n", "                img = Image.open(f)\n", "                img = Ondata.pil_scale(img, scale)\n", "                img = Ondata.pil_resize(img, ps)\n", "                if verbose:\n", "                    print(f\"folder_to_formed_pils alter-resize img shape: {np.shape(img)}\")\n", "                tiledimgs = Ondata.img_to_sqr_pils(img,qslices,eps,clip)\n", "                for newimg in tiledimgs:\n", "                    img_name = img_format.format(str(newimgidx).zfill(zfill))                \n", "                    outpath = os.path.join(dest_dir, img_name)\n", "                    if verbose:\n", "                        print(f\"save image {newimgidx} to {outpath}\")\n", "                    newimg.save(outpath, 'JPEG', quality=90) \n", "                    newimgidx = newimgidx + 1\n", "    @staticmethod\n", "    def downsample(filters, size, apply_batchnorm=True):\n", "        initializer = tf.random_normal_initializer(0., 0.02)\n", "        result = tf.keras.Sequential()\n", "        result.add(\n", "            tf.keras.layers.Conv2D(filters, size, strides=2, padding='same',\n", "                kernel_initializer=initializer, use_bias=False))\n", "        if apply_batchnorm:\n", "            result.add(tf.keras.layers.BatchNormalization())\n", "        result.add(tf.keras.layers.LeakyReLU())\n", "        return result\n", "    @staticmethod\n", "    def upsample(filters, size, apply_dropout=False):\n", "        initializer = tf.random_normal_initializer(0., 0.02)\n", "        result = tf.keras.Sequential()\n", "        result.add(\n", "            tf.keras.layers.Conv2DTranspose(filters, \n", "                size, \n", "                strides=2,\n", "                padding='same',\n", "                kernel_initializer=initializer,\n", "                use_bias=False))\n", "        result.add(tf.keras.layers.BatchNormalization())\n", "        if apply_dropout:\n", "            result.add(tf.keras.layers.Dropout(0.5))\n", "        result.add(tf.keras.layers.ReLU())\n", "        return result\n", "    @staticmethod\n", "    def rgbs_to_nuas_batch(imgs, num, flip = True):\n", "        idx = np.random.randint(0, imgs.shape[0] - 1, num)\n", "        out = []\n", "        for i in idx:\n", "            out.append(imgs[i])\n", "            if flip and np.random.uniform(()) < 0.5:  # flip as arg\n", "                out[-1] = np.flip(out[-1], 1)\n", "        return np.array(out).astype('float32') / 255.0"]}, {"cell_type": "markdown", "metadata": {}, "source": ["  *******************<br>\n", "  ONSET<br>\n", "<br>\n", "  *******************"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class Onset:\n", "# https://github.com/dvschultz/dataset-tools\n", "# dataset-tools/dataset-tools.py\n", "    @staticmethod\n", "    def image_resize(image, width = None, height = None, max = None):\n", "        inter = cv2.INTER_CUBIC\n\n", "        # initialize the dimensions of the image to be resized and\n", "        # grab the image size\n", "        dim = None\n", "        (h, w) = image.shape[:2]\n", "        if max is not None:\n", "            if w > h:\n", "                # produce\n", "                r = max / float(w)\n", "                dim = (max, int(h * r))\n", "            elif h > w:\n", "                r = max / float(h)\n", "                dim = (int(w * r), max)\n", "            else :\n", "                dim = (max, max)\n", "        else: \n", "            # if both the width and height are None, then return the\n", "            # original image\n", "            if width is None and height is None:\n", "                return image\n\n", "            # check to see if the width is None\n", "            if width is None:\n", "                # calculate the ratio of the height and construct the\n", "                # dimensions\n", "                r = height / float(h)\n", "                dim = (int(w * r), height)\n\n", "            # otherwise, the height is None\n", "            else:\n", "                # calculate the ratio of the width and construct the\n", "                # dimensions\n", "                r = width / float(w)\n", "                dim = (width, int(h * r))\n\n", "        # resize the image\n", "        resized = cv2.resize(image, dim, interpolation = inter)\n\n", "        # return the resized image\n", "        return resized\n", "    @staticmethod\n", "    def image_scale(image, scalar = 1.0):\n", "        (h, w) = image.shape[:2]\n", "        dim = (int(w*scalar),int(h*scalar))\n", "        # resize the image\n", "        resized = cv2.resize(image, dim, interpolation = inter)\n", "        \n", "        # return the resized image\n", "        return resized\n", "    @staticmethod\n", "    def arbitrary_crop(img, h_crop,w_crop, args=None):\n", "        error = False\n", "        bType = cv2.BORDER_REPLICATE\n", "        if(args.border_type == 'solid'):\n", "            bType = cv2.BORDER_CONSTANT\n", "        elif (args.border_type == 'reflect'):\n", "            bType = cv2.BORDER_REFLECT\n", "        (h, w) = img.shape[:2]\n", "        if(h>h_crop):\n", "            hdiff = int((h-h_crop)/2) + args.shift_y\n", "            if( ((hdiff+h_crop) > h) or (hdiff < 0)):\n", "                print(\"error! crop settings are too much for this image\")\n", "                error = True\n", "            else:\n", "                img = img[hdiff:hdiff+h_crop,0:w]\n", "        if(w>w_crop):\n", "            wdiff = int((w-w_crop)/2) + args.shift_x\n", "            \n", "            if( ((wdiff+w_crop) > w) or (wdiff < 0) ):\n", "                print(\"error! crop settings are too much for this image\")\n", "                error = True\n", "            else:\n", "                img = img[0:h_crop,wdiff:wdiff+w_crop]\n", "        return img, error\n", "    @staticmethod\n", "    def crop_to_square(img, args=None):\n", "        (h, w) = img.shape[:2]\n", "        \n", "        cropped = img.copy()\n", "        if w > h:\t\n", "            if (args.h_align=='left'):\n", "                print('here first')\n", "                cropped = img[:h,:h]\n", "            elif (args.h_align=='right'):\n", "                cropped = img[0:h, w-h:w]\n", "            else:\n", "                diff = int((w-h)/2)\n", "                cropped = img[0:h, diff:diff+h]\n", "        elif h > w:\n", "            if (args.v_align=='top'):\n", "                cropped = img[:w, :w]\n", "            elif (args.v_align=='bottom'):\n", "                cropped = img[h-w:h, 0:w]\n", "            else:\n", "                diff = int((h-w)/2)\n", "                cropped = img[diff:diff+w, 0:w]\n", "            \n", "        return cropped\n", "    @staticmethod\n", "    def crop_square_patch(img, imgSize):\n", "        (h, w) = img.shape[:2]\n", "        rH = random.randint(0,h-imgSize)\n", "        rW = random.randint(0,w-imgSize)\n", "        cropped = img[rH:rH+imgSize,rW:rW+imgSize]\n", "        return cropped\n", "    @staticmethod\n", "    def processCanny(img, args=None):\n", "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n", "        \n", "        if(args.blur_type=='gaussian'):\n", "            gray = cv2.GaussianBlur(gray, (args.blur_amount, args.blur_amount), 0)\n", "        elif(args.blur_type=='median'):\n", "            gray = cv2.medianBlur(gray,args.blur_amount)\n", "        gray = cv2.Canny(gray,100,300)\n", "        return gray\n", "    @staticmethod\n", "    def makeResize(img,filename,scale, args=None):\n", "        remakePath = args.output_folder + str(scale)+\"/\"\n", "        if(args.keep_folder==True): remakePath = args.output_folder\n", "        if not os.path.exists(remakePath):\n", "            os.makedirs(remakePath)\n", "        img_copy = img.copy()\n", "        img_copy = Onset.image_resize(img_copy, max = scale)\n", "        if(args.file_extension == \"png\"):\n", "            new_file = os.path.splitext(filename)[0] + \".png\"\n", "            cv2.imwrite(os.path.join(remakePath, new_file), img_copy, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n", "        elif(args.file_extension == \"jpg\"):\n", "            new_file = os.path.splitext(filename)[0] + \".jpg\"\n", "            cv2.imwrite(os.path.join(remakePath, new_file), img_copy, [cv2.IMWRITE_JPEG_QUALITY, 90])\n", "        if (args.mirror): Onset.flipImage(img_copy,new_file,remakePath, args)\n", "        if (args.rotate): Onset.rotateImage(img_copy,new_file,remakePath, args)\n", "    @staticmethod\n", "    def makeDistance(img,filename,scale, args=None):\n", "        makePath = args.output_folder + \"distance-\"+ str(args.max_size)+\"/\"\n", "        if(args.keep_folder==True): makePath = args.output_folder\n", "        if not os.path.exists(makePath):\n", "            os.makedirs(makePath)\n", "        img_copy = img.copy()\n", "        img_copy = Onset.image_resize(img_copy, max = scale)\n", "        BW = img_copy[:,:,0] > 127\n", "        G_channel = pyimg.distance_transform_edt(BW)\n", "        G_channel[G_channel>32]=32\n", "        B_channel = pyimg.distance_transform_edt(1-BW)\n", "        B_channel[B_channel>200]=200\n", "        img_copy[:,:,1] = G_channel.astype('uint8')\n", "        img_copy[:,:,0] = B_channel.astype('uint8')\n", "        if(args.file_extension == \"png\"):\n", "            new_file = os.path.splitext(filename)[0] + \".png\"\n", "            cv2.imwrite(os.path.join(makePath, new_file), img_copy, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n", "        elif(args.file_extension == \"jpg\"):\n", "            new_file = os.path.splitext(filename)[0] + \".jpg\"\n", "            cv2.imwrite(os.path.join(makePath, new_file), img_copy, [cv2.IMWRITE_JPEG_QUALITY, 90])\n", "        if (args.mirror): Onset.flipImage(img_copy,new_file,makePath)\n", "        if (args.rotate): Onset.rotateImage(img_copy,new_file,makePath)\n", "    @staticmethod\n", "    def makeScale(img,filename,scale, args=None):\n", "        remakePath = args.output_folder + \"scale_\"+str(scale)+\"/\"\n", "        if(args.keep_folder==True): remakePath = args.output_folder\n", "        if not os.path.exists(remakePath):\n", "            os.makedirs(remakePath)\n", "        img_copy = img.copy()\n", "        \n", "        img_copy = image_scale(img_copy, scale)\n", "        new_file = os.path.splitext(filename)[0] + \".png\"\n", "        cv2.imwrite(os.path.join(remakePath, new_file), img_copy, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n", "        if (args.mirror): Onset.flipImage(img_copy,new_file,remakePath)\n", "        if (args.rotate): Onset.rotateImage(img_copy,new_file,remakePath)\n", "    @staticmethod\n", "    def makeSquare(img,filename,scale, args=None):\n", "        sqPath = args.output_folder + \"sq-\"+str(scale)+\"/\"\n", "        if(args.keep_folder==True): sqPath = args.output_folder\n", "        if not os.path.exists(sqPath):\n", "            os.makedirs(sqPath)\n", "        bType = cv2.BORDER_REPLICATE\n", "        if(args.border_type == 'solid'):\n", "            bType = cv2.BORDER_CONSTANT\n", "        elif (args.border_type == 'reflect'):\n", "            bType = cv2.BORDER_REFLECT\n", "        img_sq = img.copy()\n", "        (h, w) = img_sq.shape[:2]\n", "        if((h < scale) and (w < scale)):\n", "            if args.verbose > 1: print('skip resize')\n", "        else:\n", "            img_sq = Onset.image_resize(img_sq, max = scale)\n", "        bColor = [int(item) for item in args.border_color.split(',')]\n", "        (h, w) = img_sq.shape[:2]\n", "        if(h > w):\n", "            # pad left/right\n", "            diff = h-w\n", "            if(diff%2 == 0):\n", "                img_sq = cv2.copyMakeBorder(img_sq, 0, 0, int(diff/2), int(diff/2), bType,value=bColor)\n", "            else:\n", "                img_sq = cv2.copyMakeBorder(img_sq, 0, 0, int(diff/2)+1, int(diff/2), bType,value=bColor)\n", "        elif(w > h):\n", "            # pad top/bottom\n", "            diff = w-h\n", "            if(diff%2 == 0):\n", "                img_sq = cv2.copyMakeBorder(img_sq, int(diff/2), int(diff/2), 0, 0, bType,value=bColor)\n", "            else:\n", "                img_sq = cv2.copyMakeBorder(img_sq, int(diff/2), int(diff/2)+1, 0, 0, bType,value=bColor)\n", "        else:\n", "            diff = scale-h\n", "            if(diff%2 == 0):\n", "                img_sq = cv2.copyMakeBorder(img_sq, int(diff/2), int(diff/2), int(diff/2), int(diff/2), bType,value=bColor)\n", "            else:\n", "                img_sq = cv2.copyMakeBorder(img_sq, int(diff/2), int(diff/2)+1, int(diff/2), int(diff/2)+1, bType,value=bColor)\n", "        if(args.file_extension == \"png\"):\n", "            new_file = os.path.splitext(filename)[0] + \".png\"\n", "            cv2.imwrite(os.path.join(sqPath, new_file), img_sq, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n", "        elif(args.file_extension == \"jpg\"):\n", "            new_file = os.path.splitext(filename)[0] + \".jpg\"\n", "            cv2.imwrite(os.path.join(sqPath, new_file), img_sq, [cv2.IMWRITE_JPEG_QUALITY, 90])\n", "        if (args.mirror): Onset.flipImage(img_sq,new_file,sqPath,args)\n", "        if (args.rotate): Onset.rotateImage(img_sq,new_file,sqPath,args)\n", "    @staticmethod        \n", "    def makeCanny(img,filename,scale, args=None):\n", "        make_path = args.output_folder + \"canny-\"+str(scale)+\"/\"\n", "        if(args.keep_folder==True): make_path = args.output_folder\n", "        if not os.path.exists(make_path):\n", "            os.makedirs(make_path)\n", "        img_copy = img.copy()\n", "        img_copy = Onset.image_resize(img_copy, max = scale)\n", "        gray = Onset.processCanny(img_copy, args)\n\n", "        # save out\n", "        if(args.file_extension == \"png\"):\n", "            new_file = os.path.splitext(filename)[0] + \".png\"\n", "            cv2.imwrite(os.path.join(make_path, new_file), gray, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n", "        elif(args.file_extension == \"jpg\"):\n", "            new_file = os.path.splitext(filename)[0] + \".jpg\"\n", "            cv2.imwrite(os.path.join(make_path, new_file), gray, [cv2.IMWRITE_JPEG_QUALITY, 90])\n", "        if (args.mirror): Onset.flipImage(img_copy,new_file,make_path,args)\n", "        if (args.rotate): Onset.rotateImage(img_copy,new_file,make_path,args)\n", "    @staticmethod\n", "    def makeCrop(img,filename, args=None):\n", "        make_path = args.output_folder + \"crop-\"+str(args.height)+\"x\"+str(args.width)+\"/\"\n", "        if(args.keep_folder==True): make_path = args.output_folder\n", "            \n", "        if not os.path.exists(make_path):\n", "            os.makedirs(make_path)\n", "        img_copy = img.copy()\n", "        img_copy,error = arbitrary_crop(img_copy,args.height,args.width)\n", "        if (error==False):\n", "            if(args.file_extension == \"png\"):\n", "                new_file = os.path.splitext(filename)[0] + \".png\"\n", "                cv2.imwrite(os.path.join(make_path, new_file), img_copy, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n", "            elif(args.file_extension == \"jpg\"):\n", "                new_file = os.path.splitext(filename)[0] + \".jpg\"\n", "                cv2.imwrite(os.path.join(make_path, new_file), img_copy, [cv2.IMWRITE_JPEG_QUALITY, 90])\n", "            if (args.mirror): Onset.flipImage(img_copy,new_file,make_path,args)\n", "            if (args.rotate): Onset.rotateImage(img_copy,new_file,make_path,args)\n", "        else:\n", "            if(args.verbose): print(filename+\" returned an error\")\n", "    @staticmethod\n", "    def makeSquareCrop(img,filename,scale, args=None):\n", "        make_path = args.output_folder + \"sq-\"+str(scale)+\"/\"\n", "        if(args.keep_folder==True): make_path = args.output_folder    \n", "        if not os.path.exists(make_path):\n", "            os.makedirs(make_path)\n", "        img_copy = img.copy()\n", "        img_copy = Onset.crop_to_square(img_copy, args)\n", "        img_copy = Onset.image_resize(img_copy, max = scale)\n", "        if(args.file_extension == \"png\"):\n", "            new_file = os.path.splitext(filename)[0] + \".png\"\n", "            cv2.imwrite(os.path.join(make_path, new_file), img_copy, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n", "        elif(args.file_extension == \"jpg\"):\n", "            new_file = os.path.splitext(filename)[0] + \".jpg\"\n", "            cv2.imwrite(os.path.join(make_path, new_file), img_copy, [cv2.IMWRITE_JPEG_QUALITY, 90])\n", "        if (args.mirror): Onset.flipImage(img_copy,new_file,make_path,args)\n", "        if (args.rotate): Onset.rotateImage(img_copy,new_file,make_path,args)\n", "    @staticmethod\n", "    def makeManySquares(img,filename,scale,args=None):\n", "        make_path = args.output_folder + \"many_squares-\"+str(scale)+\"/\"\n", "        if(args.keep_folder==True): make_path = args.output_folder    \n", "        if not os.path.exists(make_path):\n", "            os.makedirs(make_path)\n", "        img_copy = img.copy()\n", "        (h, w) = img_copy.shape[:2]\n", "        img_ratio = h/w\n", "        if(img_ratio >= 1.25):\n\n", "            #crop images from top and bottom\n", "            crop = img_copy[0:w,0:w]\n", "            crop = Onset.image_resize(crop, max = scale)\n", "            new_file = os.path.splitext(filename)[0] + \"-1.png\"\n", "            cv2.imwrite(os.path.join(make_path, new_file), crop, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n", "            if (args.mirror): Onset.flipImage(crop,new_file,make_path,args)\n", "            if (args.rotate): Onset.rotateImage(crop,filename,make_path,args)\n", "            crop = img_copy[h-w:h,0:w]\n", "            crop = Onset.image_resize(crop, max = scale)\n", "            new_file = os.path.splitext(filename)[0] + \"-2.png\"\n", "            cv2.imwrite(os.path.join(make_path, new_file), crop, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n", "            if (args.mirror): Onset.flipImage(crop,new_file,make_path,args)\n", "            if (args.rotate): Onset.rotateImage(crop,filename,make_path,args)\n", "        elif(img_ratio <= .8):\n", "            #crop images from left and right\n", "            print(os.path.splitext(filename)[0] + ': wide image')\n", "            crop = img_copy[0:h,0:h]\n", "            crop = Onset.image_resize(crop, max = scale)\n", "            new_file = os.path.splitext(filename)[0] + \"-wide1.png\"\n", "            cv2.imwrite(os.path.join(make_path, new_file), crop, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n", "            if (args.mirror): Onset.flipImage(crop,new_file,make_path)\n", "            if (args.rotate): Onset.rotateImage(crop,filename,make_path)\n", "            crop = img_copy[0:h,w-h:w]\n", "            crop = Onset.image_resize(crop, max = scale)\n", "            new_file = os.path.splitext(filename)[0] + \"-wide2.png\"\n", "            cv2.imwrite(os.path.join(make_path, new_file), crop, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n", "            if (args.mirror): Onset.flipImage(crop,new_file,make_path)\n", "            if (args.rotate): Onset.rotateImage(crop,filename,make_path)\n", "        else:\n", "            img_copy = Onset.crop_to_square(img_copy, args)\n", "            img_copy = Onset.image_resize(img_copy, max = scale)\n", "            new_file = os.path.splitext(filename)[0] + \".png\"\n", "            cv2.imwrite(os.path.join(make_path, new_file), img_copy, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n", "            if (args.mirror): Onset.flipImage(img_copy,new_file,make_path)\n", "            if(args.rotate): Onset.rotateImage(img_copy,filename,make_path)\n", "            \n", "    @staticmethod\n", "    def makeSquareCropPatch(img,filename,scale,args=None):\n", "        make_path = args.output_folder + \"sq-\"+str(scale)+\"/\"\n", "        if(args.keep_folder==True): make_path = args.output_folder    \n", "        if not os.path.exists(make_path):\n", "            os.makedirs(make_path)\n", "        img_copy = img.copy()\n", "        img_copy = crop_square_patch(img_copy,args.max_size)\n", "        new_file = os.path.splitext(filename)[0] + \".png\"\n", "        cv2.imwrite(os.path.join(make_path, new_file), img_copy, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n", "        if (args.mirror): Onset.flipImage(img_copy,new_file,make_path,args)\n", "        if (args.rotate): Onset.rotateImage(img_copy,new_file,make_path,args)\n", "    @staticmethod\n", "    def makePix2Pix(img,filename,scale,direction=\"BtoA\",value=[0,0,0],args=None):\n", "        img_p2p = img.copy()\n", "        img_p2p = Onset.image_resize(img_p2p, max = scale)\n", "        (h, w) = img_p2p.shape[:2]\n", "        bType = cv2.BORDER_CONSTANT\n", "        \n", "        make_path = args.output_folder + \"pix2pix-\"+str(h)+\"/\"\n", "        if(args.keep_folder==True): make_path = args.output_folder    \n", "        if not os.path.exists(make_path):\n", "            os.makedirs(make_path)\n", "        canny = cv2.cvtColor(Onset.processCanny(img_p2p,args),cv2.COLOR_GRAY2RGB)\n", "        \n", "        if(direction==\"BtoA\"):\n", "            img_p2p = cv2.copyMakeBorder(img_p2p, 0, 0, w, 0, bType, None, value)\n", "            img_p2p[0:h,0:w] = canny\n", "        \n", "        if(args.file_extension == \"png\"):\n", "            new_file = os.path.splitext(filename)[0] + \".png\"\n", "            cv2.imwrite(os.path.join(make_path, new_file), img_p2p, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n", "        elif(args.file_extension == \"jpg\"):\n", "            new_file = os.path.splitext(filename)[0] + \".jpg\"\n", "            cv2.imwrite(os.path.join(make_path, new_file), img_p2p, [cv2.IMWRITE_JPEG_QUALITY, 90])\n", "    @staticmethod\n", "    def flipImage(img,filename,path,args=None):\n", "        flip_img = cv2.flip(img, 1)\n", "        flip_file = os.path.splitext(filename)[0] + \"-flipped.png\"\n", "        cv2.imwrite(os.path.join(path, flip_file), flip_img, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n", "    @staticmethod\n", "    def rotateImage(img,filename,path, args=None):\n", "        r = img.copy() \n", "        r = imutils.rotate_bound(r, 90)\n", "        if(args.file_extension == \"png\"):\n", "            r_file = os.path.splitext(filename)[0] + \"-rot90.png\"\n", "            cv2.imwrite(os.path.join(path, r_file), r, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n", "        elif(args.file_extension == \"jpg\"):\n", "            r_file = os.path.splitext(filename)[0] + \"-rot90.jpg\"\n", "            cv2.imwrite(os.path.join(path, r_file), r, [cv2.IMWRITE_JPEG_QUALITY, 90])\n", "        r = imutils.rotate_bound(r, 90)\n", "        if(args.file_extension == \"png\"):\n", "            r_file = os.path.splitext(filename)[0] + \"-rot180.png\"\n", "            cv2.imwrite(os.path.join(path, r_file), r, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n", "        elif(args.file_extension == \"jpg\"):\n", "            r_file = os.path.splitext(filename)[0] + \"-rot180.jpg\"\n", "            cv2.imwrite(os.path.join(path, r_file), r, [cv2.IMWRITE_JPEG_QUALITY, 90])\n", "        r = imutils.rotate_bound(r, 90)\n", "        if(args.file_extension == \"png\"):\n", "            r_file = os.path.splitext(filename)[0] + \"-rot270.png\"\n", "            cv2.imwrite(os.path.join(path, r_file), r, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n", "        elif(args.file_extension == \"jpg\"):\n", "            r_file = os.path.splitext(filename)[0] + \"-rot270.jpg\"\n", "            cv2.imwrite(os.path.join(path, r_file), r, [cv2.IMWRITE_JPEG_QUALITY, 90])\n", "    @staticmethod\n", "    def processImage(img,filename, args=None):\n", "        if args.process_type == \"resize\":\t\n", "            Onset.makeResize(img,filename,args.max_size, args)\n", "        if args.process_type == \"resize_pad\":\t\n", "            Onset.makeResizePad(img,filename,args.max_size, args)\n", "        if args.process_type == \"square\":\n", "            Onset.makeSquare(img,filename,args.max_size, args)\n", "        if args.process_type == \"crop_to_square\":\n", "            Onset.makeSquareCrop(img,filename,args.max_size, args)\n", "        if args.process_type == \"canny\":\n", "            Onset.makeCanny(img,filename,args.max_size, args)\n", "        if args.process_type == \"canny-pix2pix\":\n", "            Onset.makePix2Pix(img,filename,args.max_size, args=args)\n", "        if args.process_type == \"crop_square_patch\":\n", "            Onset.makeSquareCropPatch(img,filename,args.max_size, args)\n", "        if args.process_type == \"scale\":\n", "            Onset.makeScale(img,filename,args.scale, args)\n", "        if args.process_type == \"many_squares\":\n", "            Onset.makeManySquares(img,filename,args.max_size, args)\n", "        if args.process_type == \"crop\":\n", "            Onset.makeCrop(img,filename, args)\n", "        if args.process_type == \"distance\":\n", "            Onset.makeDistance(img,filename,args.max_size, args)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    @staticmethod\n", "    def processFolder(args=None):\n", "        count = int(0)\n", "        inter = cv2.INTER_CUBIC\n", "        ''' filter files '''\n", "        patt = re.compile(\".*\")\n", "        try:\n", "            if args.filepatt:\n", "                patt = re.compile(args.filepatt)\t# file name pattern\n", "        except:\n", "            pass"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        for root, subdirs, files in os.walk(args.input_folder):\n", "            if args.verbose > 0: print(f'processFolder {root}')\n", "            for subdir in subdirs:\n", "                if(args.verbose): print('\\t- subdirectory ' + subdir)\n", "            exclude = []\n", "            try:\n", "                exclude = args.exclude\n", "            except:\n", "                pass\n", "            if 0: print(f\"|.... exclude {exclude}\")\n", "            for filename in files:\n", "                if patt.match(filename) and not filename in exclude: # file name pattern mach\n", "                    if 0: print(f\"|.... filename {filename} not in exclude\")\n", "                    file_path = os.path.join(root, filename)\n", "                    if args.verbose > 0: print('\\t- file %s (full path: %s)' % (filename, file_path))\n", "                    \n", "                    img = cv2.imread(file_path)\n", "                    if hasattr(img, 'copy'):\n", "                        if args.name:\n", "                            if args.verbose > 1: \n", "                                print(f'|... processing image name: {filename}')\n", "                            Onset.processImage(img,filename, args)\n", "                        else:\n", "                            if args.verbose > 1: \n", "                                print(f'|... processing image idx: {str(count)}')\n", "                            zfill=0\n", "                            try:\n", "                                zfill = args.zfill\n", "                            except:\n", "                                pass\n", "                            Onset.processImage(img,str(count).zfill(zfill), args)\n", "                        count = count + int(1)\n", "                else:\n", "                    if 0: print(f\"|.... filename {filename} EXCLUDED\")\n\n", "    # https://github.com/dvschultz/dataset-tools/dedupe.py\n\n", "        # input_folder = './input/'\n", "        # output_folder = './output/'\n", "        # process_type = 'exclude'\n", "        # file_extension = 'png'\n", "        # avg_match = 1.0\n\n", "        # absolute = True\n", "        # relative = True\n", "    @staticmethod\n", "    def compare(img1,img2, args=None):\n", "        test = False\n", "        difference = cv2.absdiff(img1, img2)\n", "        if(args.absolute):\t\n", "            return not np.any(difference)\n", "        else:\n", "            return np.divide(np.sum(difference),img1.shape[0]*img1.shape[1]) <= args.avg_match\n\n", "            #way too greedy\n", "            #return np.allclose(img1,img2,2,2)\n", "    @staticmethod\n", "    def exclude(imgs,args=None):\n", "        expath = args.output_folder + \"exclude/\"\n", "        if not os.path.exists(expath):\n", "            os.makedirs(expath)\n", "        i = 0\n", "        print(\"avg_match\" + str(args.avg_match))\n", "        print(\"processing...\")\n", "        print(\"total images: \" + str(len(imgs)))\n", "        while i < len(imgs):\n", "            img = imgs[i][0]\n", "            filename = imgs[i][1]\n", "            if 0:\n", "                print( f\"{str(i)}/{str(len(imgs))} matching to: {filename}\")\n", "            i2 = i+1\n", "            while i2 < len(imgs):\n", "                popped = False\n", "                img2 = imgs[i2][0]\n", "                filename2 = imgs[i2][1]\n", "                # print ('comparing '+filename + \" to \" + filename2)\n", "                if Onset.compare(img,img2, args):\n", "                    print (f\">>> {filename} matches {filename2}, pop <<<\")\n", "                    popped = True \n", "                    imgs.pop(i2)\n", "                else:\n", "                    pass\n", "                    # print (f\"imgs do not match\")\n", "                if not popped:\n", "                    i2 += 1\n", "                else:\n", "                    # copy dup to exclude\n", "                    if(args.file_extension == \"png\"):\n", "                        new_file = os.path.splitext(filename2)[0] + \".png\"\n", "                        cv2.imwrite(os.path.join(expath, new_file), img2, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n", "                    else:\n", "                        new_file = os.path.splitext(filename2)[0] + \".jpg\"\n", "                        cv2.imwrite(os.path.join(expath, new_file), img2, [cv2.IMWRITE_JPEG_QUALITY, 90])\n", "            i += 1\n", "        \n", "        return imgs\n", "    @staticmethod\n", "    def sort(imgs):\n", "        #TODO\n", "        print(\"skip\")\n", "        make_path1 = args.output_folder + \"yes/\"\n", "        make_path2 = args.output_folder + \"no/\"\n", "        if not os.path.exists(make_path1):\n", "            os.makedirs(make_path1)\n", "        if not os.path.exists(make_path2):\n", "            os.makedirs(make_path2)\n", "        (h, w) = img.shape[:2]\n", "        ratio = h/w\n", "        if(args.exact == True):\n", "            if((ratio >= 1.0) and (h == args.max_size) and (w == args.min_size)):\n", "                path = make_path1\n", "            elif((ratio < 1.0) and (w == args.max_size) and (h == args.min_size)):\n", "                path = make_path1\n", "            else:\n", "                path = make_path2\n", "        else:\n", "            #only works with ratio right now\n", "            if(ratio>=args.min_ratio):\n", "                path = make_path1\n", "            else:\n", "                path = make_path2\n", "        if(args.file_extension == \"png\"):\n", "            new_file = os.path.splitext(filename)[0] + \".png\"\n", "            cv2.imwrite(os.path.join(path, new_file), img, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n", "        else:\n", "            new_file = os.path.splitext(filename)[0] + \".jpg\"\n", "            cv2.imwrite(os.path.join(path, new_file), img, [cv2.IMWRITE_JPEG_QUALITY, 90])\n", "    @staticmethod\n", "    def dedupe(imgs,filenames, args=None):\n", "        if args.process_type == \"exclude\":\t\n", "            exclude(imgs,filenames)\n", "        if args.process_type == \"sort\":\t\n", "            sort(imgs,filenames)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["  ******************<br>\n", "  ONRECORD<br>\n", "<br>\n", "  ******************"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class Onrecord:\n", "    @staticmethod   \n", "    def folder_to_tfrecord_paths(path):\n", "        trf_paths = sorted(glob.glob(os.path.join(path, '*.tfrecords')))\n", "        return trf_paths\n", "    @staticmethod   \n", "    def tfrecord_show(tfrpath):\n", "        dataset = tf.data.TFRecordDataset(tfrpath) # <TFRecordDatasetV2 shapes: (), types: tf.string>\n", "        print(\"dataset type\", type(dataset)) #  <class 'tensorflow.python.\n", "        image_feature_description = {\n", "            'shape': tf.io.FixedLenFeature([3], tf.int64),\n", "            'data': tf.io.FixedLenFeature([], tf.string),\n", "        }\n\n", "        # Parse the input tf.Example proto using the dictionary above\n", "        # https://www.tensorflow.org/api_docs/python/tf/io/parse_single_example\n", "        def _parse_image_function(example_proto):\n", "            return tf.io.parse_single_example(example_proto, image_feature_description)\n\n", "        # parse raw dataset\n", "        parsed_dataset = dataset.map(_parse_image_function)\n", "        print(\"parsed_dataset: \", parsed_dataset)\n", "        for idx, dataitem in enumerate(parsed_dataset):\n", "            print(\"image record id:\", idx)\n", "            tfshape = dataitem['shape']\n", "            print(\"tfshape type: \", type(tfshape))\n", "            print(\"tfshape shape: \", tfshape.shape)\n", "            print(\"shape: \", tfshape) # tf.Tensor([  3 256 256], shape=(3,), dtype=int64)\n", "            shape = tfshape.numpy() # [  3 256 256]\n", "            tfdata = dataitem['data'] # () EagerTensor\n", "            data = tfdata.numpy()\n", "            # print(\"data type: \", type(data)) # <class 'bytes'>\n", "            # display.display(display.Image(data=data))\n", "            # image = Image.fromarray(data, 'RGB')\n", "            # image = Image.open(StringIO.StringIO(data))\n\n", "            # https://www.programcreek.com/python/example/89944/PIL.Image.frombytes\n", "            # https://pillow.readthedocs.io/en/3.3.x/handbook/concepts.html#concept-modes\n", "            size = (shape[1], shape[2])\n", "            mode = 'RGB' if shape[0] == 3 else 'RGBA'\n", "            img = np.array(data)\n", "            channels = shape[0]\n", "            width = shape[1]\n", "            height = shape[2]\n", "            bytes_needed = int(width * height * channels)  # tfr 9: 512x512x3\n", "            bytesq = len(data) # tfr 9: 512x512x3\n", "            # read from string buffer into int8 array\n", "            b = np.frombuffer(data, dtype=np.uint8)\n", "            # group int8 array to CHW format\n", "            img_arr =  b.reshape(shape[0], shape[1], shape[2]) # 3x3 b/w\n", "            # transpose int array to HWC, CHW => HWC\n", "            img_arr = img_arr.transpose([1, 2, 0])\n", "            cv_rgb(img_arr)\n", "    @staticmethod\n", "    def rgbs_to_npy(imgs,npyfolder,\n", "            im_size=256,\n", "            mss=(1024 ** 3),\n", "            verbose=False,\n", "            npy_file_frmt='data{}.npy',\n", "            zfill=4\n", "        ):\n", "        segment_length = mss // (im_size * im_size * 3)\n", "        np.random.shuffle(imgs)\n", "        if verbose:\n", "            print(f\"{str(len(imgs))} imgs to npy\")\n", "        kn = 0  # image in segment\n", "        sn = 0  # segment - segment_length = mss // (im_size * im_size * 3)\n", "        segment = []\n", "        for item in imgs:        \n", "            if verbose:\n", "                print('\\r' + str(sn) + \" // \" + str(kn) + \"\\t\", end = '\\r')\n", "            segment.append(item)\n", "            kn = kn + 1\n", "            if kn >= segment_length:\n", "                npyfile = npy_file_frmt.format(str(sn).zfill(zfill))\n", "                # npyfile = \"data-\"+str(sn)+\".npy\"\n", "                npydst = os.path.join(npyfolder, npyfile)\n", "                np.save(npydst, np.array(segment))\n", "                segment = []\n", "                kn = 0\n", "                sn = sn + 1\n", "        npyfile = npy_file_frmt.format(str(sn).zfill(zfill))\n", "        npydst = os.path.join(npyfolder, npyfile)\n", "        print(\"sn.kn %d %d\" %(sn,kn))\n", "        print(f\"array_to_npy save to {npydst}\")\n", "        np.save(npydst, np.array(segment))\n", "    @staticmethod\n", "    def folder_to_npy(data_org, data_npy, im_size = 256, mss = (1024 ** 3), verbose = True):\n", "    # https://github.com/manicman1999/StyleGAN2-Tensorflow-2.0/blob/master/datagen.py\n", "        imgs = Onfile.folder_to_pils(data_org)\n", "        Onrecord.pils_to_npy(imgs, data_npy, im_size, mss, verbose)\n", "    @staticmethod\n", "    def _folder_to_npy(data_dir, npy_folder, im_size, mss=(1024 ** 3), verbose=True):\n", "        def snname(sn):\n", "            return \"data-\"+str(sn)+\".npy\"\n", "        os.makedirs(npy_folder, exist_ok=True)\n", "        if verbose:\n", "            print(f\"Converting from images in {data_dir} to numpy files... onto {npy_folder}\")\n", "        names = []\n", "        for dirpath, dirnames, filenames in os.walk(data_dir):\n", "            for filename in [f for f in filenames if (f.endswith(\".jpg\") or f.endswith(\".png\") or f.endswith(\".JPEG\"))]:\n", "                fname = os.path.join(dirpath, filename)\n", "                names.append(fname)\n", "        np.random.shuffle(names)\n", "        if verbose:\n", "            print(str(len(names)) + \" images.\")\n", "        kn = 0\n", "        sn = 0\n", "        segment = []\n", "        for fname in names:\n", "            if verbose:\n", "                print('\\r' + str(sn) + \" // \" + str(kn) + \"\\t\", end = '\\r')\n", "            try:\n", "                temp = Image.open(fname).convert('RGB').resize((im_size, im_size), Image.BILINEAR)\n", "            except:\n", "                print(\"Importing image failed on\", fname)\n", "            temp = np.array(temp, dtype='uint8')\n", "            segment.append(temp)\n", "            kn = kn + 1\n", "            segment_length = mss // (im_size * im_size * 3)\n", "            if kn >= segment_length:\n", "                \n", "                target = os.path.join(npy_folder,snname(sn))\n", "                np.save(target, np.array(segment))\n", "                segment = []\n", "                kn = 0\n", "                sn = sn + 1\n", "        target = os.path.join(npy_folder,snname(sn))\n", "        np.save(target, np.array(segment))\n", "    @staticmethod\n", "    def pils_to_npy(pils, data_npy, im_size = 256, mss = (1024 ** 3), verbose = True):\n", "        npyfolder = data_npy\n", "        if verbose:\n", "            print(\"datagene.folder_to_npy:images.q: %s\" %(str(len(pils))))\n", "        \n", "        segment_length = mss // (im_size * im_size * 3)\n", "        print(f\"pils_to_npy segment_length: {segment_length}\")\n", "        np.random.shuffle(pils)\n", "        kn = 0  # image in segment\n", "        sn = 0  # segment where segment_length: mss // (im_size * im_size * 3)\n", "        segment = []\n", "        # for img in pils:\n", "        for img in pils:        \n", "            if 0:\n", "                print(f\"img type: {type(img)} {np.shape(img)}\")\n", "                print('\\r' + str(sn) + \" // \" + str(kn) + \"\\t\", end = '\\r')\n", "            img = img.convert('RGB').resize((im_size, im_size), Image.BILINEAR)\n", "            rgb = np.array(img, dtype='uint8')\n", "            \n", "            # print(\"folder_to_npy img type\", type(img)) # <class 'numpy.ndarray'>\n", "            # print(\"folder_to_npy img shape\", img.shape) # (256, 256, 3)\n", "            segment.append(rgb)\n", "            kn = kn + 1\n", "            if kn >= segment_length:\n", "                npyfile = \"data-\"+str(sn)+\".npy\"\n", "                npydst = os.path.join(npyfolder, npyfile)\n", "                np.save(npydst, np.array(segment))\n", "                segment = []\n", "                kn = 0\n", "                sn = sn + 1\n", "        npyfile = \"data-\"+str(sn)+\".npy\"\n", "        npydst = os.path.join(npyfolder, npyfile)\n", "        np.save(npydst, np.array(segment))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    @staticmethod\n", "    def npys_folder_to_pils(folder):\n", "    #  https://github.com/manicman1999/StyleGAN2-Tensorflow-2.0/blob/master/datagen.py\n", "        pils=[]\n", "        segments = []\n", "        for dirpath, dirnames, filenames in os.walk(folder):\n", "            for filename in [f for f in filenames if f.endswith(\".npy\")]:\n", "                segments.append(os.path.join(dirpath, filename))\n", "        for i in range(len(segments)):\n", "            tmp = np.load(segments[i])\n", "            for j in range(len(tmp)):\n", "                rgb = tmp[j]\n", "                pil = Image.fromarray(rgb)\n", "                pils.append(pil)\n", "        \n", "        return pils\n", "    @staticmethod\n", "    def npys_folder_to_rgbs(folder):\n", "        segments = []\n", "        for dirpath, dirnames, filenames in os.walk(folder):\n", "            for filename in [f for f in filenames if f.endswith(\".npy\")]:\n", "                segments.append(os.path.join(dirpath, filename))\n", "        import random\n", "        segment_num = random.randint(0, len(segments) - 1)\n", "        imgs = np.load(segments[segment_num])\n", "        return imgs\n", "    @staticmethod\n", "    def load_from_npy(folder, segments):\n", "        # for dirpath, dirnames, filenames in os.walk(\"data/\" + folder + \"-npy-\" + str(self.im_size)):\n", "        for dirpath, dirnames, filenames in os.walk(folder):\n", "            for filename in [f for f in filenames if f.endswith(\".npy\")]:\n", "                segments.append(os.path.join(dirpath, filename))\n", "        return Onrecord.load_segment(segments)\n", "    @staticmethod\n", "    def load_segment(segments):\n", "        segment_num =np.random.randint(0, len(segments))\n", "        images = np.load(segments[segment_num])\n", "        return images\n", "    @staticmethod\n", "    def folder_to_labels(data_dir='./', xSize=128, ySize=128, qslices=100, resize=0.75, eps = 1):\n", "        \n", "        arrs = folder_to_formed_nuas(data_dir, xSize, ySize, qslices, resize, eps)\n", "        labels = [[arr[0], arr[1]] for arr in arrs]\n", "        return labels\n", "    @staticmethod\n", "    def folder_to_tfrecords(src_dir, target_dir):\n", "        assert os.path.exists(src_dir), f\"src dir {src_dir} does not exist\"\n", "        assert os.path.exists(target_dir), f\"src dir {target_dir} does not exist\"\n", "        imgs = Onfile.folder_to_rgbs(src_dir)\n", "        Onrecord.imgs_to_tfrecords(imgs, target_dir)\n", "    @staticmethod\n", "    # relux\n", "    def create_from_images(tfrecord_dir, image_dir, shuffle):\n", "        print('Loading images from \"%s\"' % image_dir)\n", "        image_filenames = sorted(glob.glob(os.path.join(image_dir, '*')))\n", "        if len(image_filenames) == 0:\n", "            Onutil.error('No input images found')\n", "        img = np.asarray(PIL.Image.open(image_filenames[0]))\n", "        resolution = img.shape[0]\n", "        print(\"create_from_images resolution\", resolution)\n", "        channels = img.shape[2] if img.ndim == 3 else 1\n", "        if img.shape[1] != resolution:\n", "             Onutil.error('Input images must have the same width and height')\n", "        if resolution != 2 ** int(np.floor(np.log2(resolution))):\n", "             Onutil.error('Input image resolution must be a power-of-two')\n", "        if channels not in [1, 3]:\n", "             Onutil.error('Input images must be stored as RGB or grayscale')\n", "        with TFRecordExporter(tfrecord_dir, len(image_filenames)) as tfr:\n", "            order = tfr.choose_shuffled_order() if shuffle else np.arange(len(image_filenames))\n", "            for idx in range(order.size):\n", "                img = np.asarray(PIL.Image.open(image_filenames[order[idx]]))\n", "                if channels == 1:\n", "                    img = img[np.newaxis, :, :] # HW => CHW\n", "                else:\n", "                    img = img.transpose([2, 0, 1]) # HWC => CHW\n", "                tfr.add_image(img)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    @staticmethod\n", "    def imgs_to_tfrecords(imgs, target_dir, shuffle=False):\n", "        assert os.path.exists(target_dir), f\"src dir {target_dir} does not exist\"\n\n", "        # write imgs to tfrecord\n", "        with TFRecordExporter(target_dir, len(imgs)) as tfr:\n", "            order = tfr.choose_shuffled_order() if shuffle else np.arange(len(imgs))\n", "            for idx in range(order.size):\n", "                img = imgs[idx]\n", "                channels = img.shape[2] if img.ndim == 3 else 1\n", "                if channels == 1:\n", "                    img = img[np.newaxis, :, :] # HW => CHW\n", "                else:\n", "                    img = img.transpose([2, 0, 1]) # HWC => CHW\n", "                img = img / 255 # normalize\n", "                tfr.add_image(img)\n", "    @staticmethod\n", "    def show_tfrecord_from_file(src_dir,tfr_file):\n", "        images = []\n", "        tfr_files = sorted(glob.glob(os.path.join(src_dir, '*.tfrecords')))\n", "        dataset = tf.data.TFRecordDataset(src_dir, compression_type=None, buffer_size=None, num_parallel_reads=None)\n", "        # tfrpath = os.path.join(src_dir, tfr_file)\n", "        # dataset = tf.data.TFRecordDataset(tfrpath) # <TFRecordDatasetV2 shapes: (), types: tf.string>\n", "        Onrecord.show_tfrecord(dataset)\n", "    @staticmethod\n", "    def show_tfrecord(dataset):\n", "        image_feature_description = {\n", "            'shape': tf.io.FixedLenFeature([3], tf.int64),\n", "            'data': tf.io.FixedLenFeature([], tf.string),\n", "        }\n", "        def _parse_image_function(example_proto):\n", "            return tf.io.parse_single_example(example_proto, image_feature_description)        \n", "        parsed_dataset = dataset.map(_parse_image_function)\n", "        for idx, dataitem in enumerate(parsed_dataset):\n", "            tfshape = dataitem['shape']\n", "            shape = tfshape.numpy()\n", "            tfdata = dataitem['data']\n", "            data = tfdata.numpy()\n", "            size = (shape[1], shape[2])\n", "            mode = 'RGB' if shape[0] == 3 else 'RGBA'\n", "            img = np.array(data)\n", "            channels = shape[0]\n", "            width = shape[1]\n", "            height = shape[2]\n", "            bytes_needed = int(width * height * channels)  # tfr 9: 512x512x3\n", "            bytesq = len(data) # tfr 9: 512x512x3\n", "            b = np.frombuffer(data, dtype=np.uint8)\n", "            img_arr =  b.reshape(shape[0], shape[1], shape[2]) # 3x3 b/w\n", "            img_arr = img_arr.transpose([1, 2, 0])\n", "            cv_rgb(img_arr)\n", "    @staticmethod\n", "    def get_dataset(tfrecord_base_dir, res, buffer_size, batch_size, epochs=None, name=None):\n", "        # _p_ https://github.com/moono/stylegan2-tf-2.x/blob/master/dataset_ffhq.py\n", "        fn_index = int(np.log2(res))\n", "        if name:\n", "            prefix=name\n", "        else:\n", "            prefix='*'\n", "        # tfrecord_fn = os.path.join(tfrecord_base_dir, 'ffhq-r{:02d}.tfrecords'.format(fn_index))\n", "        files = glob.glob(os.path.join(tfrecord_base_dir, prefix + '-r{:02d}.tfrecords'.format(fn_index)))\n", "        tfrecord_fn = files[0]\n", "        with tf.device('/cpu:0'):\n", "            dataset = tf.data.TFRecordDataset(tfrecord_fn)\n", "            dataset = dataset.map(map_func=Onrecord.parse_tfrecord_tf, num_parallel_calls=8)\n", "            dataset = dataset.shuffle(buffer_size=buffer_size)\n", "            dataset = dataset.repeat(epochs)\n", "            dataset = dataset.batch(batch_size)\n", "            dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n", "        return dataset\n", "    @staticmethod\n", "    def parse_tfrecord_tf(record):\n", "        # n_samples = 70000    \n", "        features = tf.io.parse_single_example(record, features={\n", "            'shape': tf.io.FixedLenFeature([3], tf.dtypes.int64),\n", "            'data': tf.io.FixedLenFeature([], tf.dtypes.string)\n", "        })\n\n", "        # [0 ~ 255] uint8\n", "        images = tf.io.decode_raw(features['data'], tf.dtypes.uint8)\n", "        images = tf.reshape(images, features['shape'])\n\n", "        # [0.0 ~ 255.0] float32\n", "        images = tf.cast(images, tf.dtypes.float32)\n", "        return images\n", "    @staticmethod\n", "    def tfts_to_files(imgs,dst_dir= './',img_name_frmt='img{}.jpg',zfill = 4,):\n", "        for i,img in enumerate(imgs):\n", "            img_name = img_name_frmt.format(str(i).zfill(zfill))\n", "            path = os.path.join(dst_dir, img_name)\n", "            tft = img # <class 'tensorflow.python.framework.ops.EagerTensor'> (256, 256, 3)\n", "            arr = img.numpy().astype(np.uint8) # <class 'numpy.ndarray'> (256, 256, 3)\n", "            img = Image.fromarray(arr)\n", "            img = img.convert(\"RGB\")\n", "            img.save(path)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["  ******************<br>\n", "  ONCHECK<br>\n", "  ******************"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class Oncheck(tf.keras.models.Model):\n", "    def __init__(self,\n", "                 model,\n", "                 ckpt_dir = 'ckpt',\n", "                 clear = True):\n", "        \n", "        super(Oncheck, self).__init__()\n", "        \n", "        self.clear = clear\n", "        self.model = model\n", "        self.ckpt_dir = ckpt_dir\n", "        self.step = 1"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    def getckptidx(self, ckptname): # ckpt-98, None, ckpt--1\n", "        idx = None\n", "        if ckptname:\n", "            m = re.search(r'([a-zA-Z_]*)-(.*)', ckptname)\n", "            if m and m.group(2):\n", "                idx = m.group(2)\n", "        return idx"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    def ckpt_sample(self):\n", "        ckpt = tf.train.Checkpoint(v=tf.Variable(0.))\n", "        mgr = tf.train.CheckpointManager(ckpt, '/tmp/tfckpts', max_to_keep=5)\n", "        @tf.function\n", "        def train_fn():\n", "            data = tf.data.Dataset.range(10)\n", "            for item in data:\n", "                ckpt.v.assign_add(tf.cast(item, tf.float32))\n", "                tf.py_function(mgr.save, [], [tf.string])\n", "        train_fn()\n", "    def get_ckpt_prefix(self):\n", "        ckpt_dir = self.ckpt_dir\n", "        return ckpt_dir\n", "    def get_checkpoint(self):\n", "        model = self.model\n", "        p = model.chkpt\n", "        ckpt = tf.train.Checkpoint(**p)\n", "        return ckpt\n", "    def get_weights(self):\n", "        model = self.model\n", "        ws = model.ws\n", "        wspath = model.wspath\n", "        for w in ws:\n", "            wfile = wspath + \"/\" + w\n", "            if os.path.exists(wfile):\n", "                print(\"load weights %s\" %wfile)\n", "                ws[w] = model[w]\n", "                model[w].load_weights(wfile)\n", "                model[w] = ws[w]\n", "            else:\n", "                print(\"weights not found: %s\" %wfile)            \n", "    def get_manager(self, ckpt):\n", "        model = self.model\n", "        ckpt_dir = model.ckpt_dir\n", "        max_to_keep = 3\n", "        if self.clear:\n", "            if os.path.exists(ckpt_dir):\n", "                for root, dirs, files in os.walk(ckpt_dir, topdown=False):\n", "                    print(\"clear ckpt dir: %s\" %root)\n", "                    for name in files:\n", "                        os.remove(os.path.join(root, name))\n", "                    for name in dirs:\n", "                        os.rmdir(os.path.join(root, name))\n", "                \n", "        manager = tf.train.CheckpointManager(ckpt, \n", "                                             ckpt_dir, \n", "                                             max_to_keep)\n", "        return manager"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    #   ******************\n", "    #   restore\n", "    #\n", "    #   if a checkpoint exists, restore the latest checkpoint\n", "    #   eg:\n", "    #       ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n", "    #       if ckpt_manager.latest_checkpoint:\n", "    #           ckpt.restore(ckpt_manager.latest_checkpoint)\n", "    #           print ('Latest checkpoint restored!!')\n", "    #\n", "    def restore(self, ckpt):\n", "        model = self.model\n", "        ckpt_dir = self.ckpt_dir\n", "         \n", "        print(\"checkpoint restore %s\" %ckpt)\n", "        res = ckpt.restore(tf.train.latest_checkpoint(ckpt_dir))\n", "        print(\"res: in % s checkpoint: %s\" %(ckpt_dir, res))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["  ******************<br>\n", "  ONCUDA<br>\n", "<br>\n", "  ******************"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class Oncuda:\n\n", "    # Internal helper funcs.\n", "    @staticmethod\n", "    def _find_compiler_bindir():\n", "        for compiler_path in compiler_bindir_search_path:\n", "            if os.path.isdir(compiler_path):\n", "                return compiler_path\n", "        return None\n", "    @staticmethod\n", "    def _get_compute_cap(device):\n", "        caps_str = device.physical_device_desc\n", "        m = re.search('compute capability: (\\\\d+).(\\\\d+)', caps_str)\n", "        major = m.group(1)\n", "        minor = m.group(2)\n", "        return (major, minor)\n", "    @staticmethod\n", "    def _get_cuda_gpu_arch_string():\n", "        gpus = [x for x in device_lib.list_local_devices() if x.device_type == 'GPU']\n", "        if len(gpus) == 0:\n", "            raise RuntimeError('No GPU devices found')\n", "        (major, minor) = Oncuda._get_compute_cap(gpus[0])\n", "        return 'sm_%s%s' % (major, minor)\n", "    @staticmethod\n", "    def _run_cmd(cmd):\n", "        with os.popen(cmd) as pipe:\n", "            output = pipe.read()\n", "            status = pipe.close()\n", "        if status is not None:\n", "            raise RuntimeError('NVCC returned an error. See below for full command line and output log:\\n\\n%s\\n\\n%s' % (cmd, output))\n", "    @staticmethod\n", "    def _prepare_nvcc_cli(opts):\n", "        # cmd = 'nvcc --std=c++11 -DNDEBUG ' + opts.strip()\n", "        cmd = 'nvcc -DNDEBUG ' + opts.strip()\n", "        cmd += ' --disable-warnings'\n", "        cmd += ' --include-path \"%s\"' % tf.sysconfig.get_include()\n", "        cmd += ' --include-path \"%s\"' % os.path.join(tf.sysconfig.get_include(), 'external', 'protobuf_archive', 'src')\n", "        cmd += ' --include-path \"%s\"' % os.path.join(tf.sysconfig.get_include(), 'external', 'com_google_absl')\n", "        cmd += ' --include-path \"%s\"' % os.path.join(tf.sysconfig.get_include(), 'external', 'eigen_archive')\n", "        compiler_bindir = Oncuda._find_compiler_bindir()\n", "        if compiler_bindir is None:\n", "            # Require that _find_compiler_bindir succeeds on Windows.  Allow\n", "            # nvcc to use whatever is the default on Linux.\n", "            if os.name == 'nt':\n", "                raise RuntimeError('Could not find MSVC/GCC/CLANG installation on this computer. Check compiler_bindir_search_path list in \"%s\".' % __file__)\n", "        else:\n", "            cmd += ' --compiler-bindir \"%s\"' % compiler_bindir\n", "        cmd += ' 2>&1'\n", "        return cmd\n", "    @staticmethod\n", "    def get_plugin(cuda_file, verbose=False):\n", "        # print(\"=========================> custom_ops.py get_plugin \", cuda_file)\n", "        cuda_file_base = os.path.basename(cuda_file)\n", "        cuda_file_name, cuda_file_ext = os.path.splitext(cuda_file_base)\n\n", "        # Already in cache?\n", "        if cuda_file in _plugin_cache:\n", "            return _plugin_cache[cuda_file]\n\n", "        # Setup plugin.\n", "        if verbose:\n", "            print('Setting up TensorFlow plugin \"%s\": ' % cuda_file_base, end='', flush=True)\n", "        try:\n", "            # -----------------------------------------------------\n", "            # Hash CUDA source.\n", "            with open(cuda_file, 'wb') as f:\n", "                f.write(Oncuda.get_kernel_upfirdn().encode('utf-8'))\n", "            md5 = hashlib.md5()\n", "            with open(cuda_file, 'rb') as f:\n", "                md5.update(f.read())\n", "            md5.update(b'\\n')\n", "            # -----------------------------------------------------\n\n", "            # Hash headers included by the CUDA code by running it through the preprocessor.\n", "            if not do_not_hash_included_headers:\n", "                if verbose:\n", "                    print('Preprocessing... ', end='', flush=True)\n", "                with tempfile.TemporaryDirectory() as tmp_dir:\n", "                    os.makedirs(tmp_dir, exist_ok=True)\n", "                    tmp_file = os.path.join(tmp_dir, cuda_file_name + '_tmp' + cuda_file_ext)\n", "                    _run_cmd(Oncuda._prepare_nvcc_cli('\"%s\" --preprocess -o \"%s\" --keep --keep-dir \"%s\"' % (cuda_file, tmp_file, tmp_dir)))\n", "                    with open(tmp_file, 'rb') as f:\n", "                        bad_file_str = ('\"' + cuda_file.replace('\\\\', '/') + '\"').encode('utf-8') # __FILE__ in error check macros\n", "                        good_file_str = ('\"' + cuda_file_base + '\"').encode('utf-8')\n", "                        for ln in f:\n", "                            if not ln.startswith(b'# ') and not ln.startswith(b'#line '): # ignore line number pragmas\n", "                                ln = ln.replace(bad_file_str, good_file_str)\n", "                                md5.update(ln)\n", "                        md5.update(b'\\n')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["            # Select compiler options.\n", "            compile_opts = ''\n", "            if os.name == 'nt':\n", "                compile_opts += '\"%s\"' % os.path.join(tf.sysconfig.get_lib(), 'python', '_pywrap_tensorflow_internal.lib')\n", "            elif os.name == 'posix':\n", "                compile_opts += '\"%s\"' % os.path.join(tf.sysconfig.get_lib(), 'python', '_pywrap_tensorflow_internal.so')\n", "                compile_opts += ' --compiler-options \\'-fPIC -D_GLIBCXX_USE_CXX11_ABI=0\\''\n", "            else:\n", "                assert False # not Windows or Linux, w00t?\n", "            compile_opts += ' --gpu-architecture=%s' % Oncuda._get_cuda_gpu_arch_string()\n", "            compile_opts += ' --use_fast_math'\n", "            nvcc_cmd = Oncuda._prepare_nvcc_cli(compile_opts)\n\n", "            # Hash build configuration.\n", "            md5.update(('nvcc_cmd: ' + nvcc_cmd).encode('utf-8') + b'\\n')\n", "            md5.update(('tf.VERSION: ' + tf.__version__).encode('utf-8') + b'\\n')\n", "            md5.update(('cuda_cache_version_tag: ' + cuda_cache_version_tag).encode('utf-8') + b'\\n')\n\n", "            # Compile if not already compiled.\n", "            bin_file_ext = '.dll' if os.name == 'nt' else '.so'\n", "            bin_file = os.path.join(cuda_cache_path, cuda_file_name + '_' + md5.hexdigest() + bin_file_ext)\n", "            if not os.path.isfile(bin_file):\n", "                if verbose:\n", "                    print('Compiling... ', end='', flush=True)\n", "                with tempfile.TemporaryDirectory() as tmp_dir:\n", "                    tmp_file = os.path.join(tmp_dir, cuda_file_name + '_tmp' + bin_file_ext)\n", "                    Oncuda._run_cmd(nvcc_cmd + ' \"%s\" --shared -o \"%s\" --keep --keep-dir \"%s\"' % (cuda_file, tmp_file, tmp_dir))\n", "                    os.makedirs(cuda_cache_path, exist_ok=True)\n", "                    intermediate_file = os.path.join(cuda_cache_path, cuda_file_name + '_' + uuid.uuid4().hex + '_tmp' + bin_file_ext)\n", "                    shutil.copyfile(tmp_file, intermediate_file)\n", "                    os.rename(intermediate_file, bin_file) # atomic\n\n", "            # Load.\n", "            if verbose:\n", "                print('Loading... ', end='', flush=True)\n", "            plugin = tf.load_op_library(bin_file)\n", "            keys = plugin.__dict__.keys()        \n\n", "            # Add to cache.\n", "            _plugin_cache[cuda_file] = plugin\n", "            if verbose:\n", "                print('Done.', flush=True)\n", "            return plugin\n", "        except:\n", "            if verbose:\n", "                print('Failed!', flush=True)\n", "            raise\n", "    @staticmethod\n", "    def _get_plugin(plg=None):\n", "        # return custom_ops.get_plugin(os.path.splitext(__file__)[0] + '.cu')\n", "        # upfirdn_2d.cu\n", "        # cufile = os.path.splitext(__file__)[0] + '.cu'   # _e_\n", "        cufile = plg + '.cu'   # _e_\n", "        return Oncuda.get_plugin(cufile)\n", "    @staticmethod\n", "    def upfirdn_2d(x, k, upx=1, upy=1, downx=1, downy=1, padx0=0, padx1=0, pady0=0, pady1=0, impl='cuda', gpu=True):\n", "        r\"\"\"Pad, upsample, FIR filter, and downsample a batch of 2D images.\n", "        Accepts a batch of 2D images of the shape `[majorDim, inH, inW, minorDim]`\n", "        and performs the following operations for each image, batched across\n", "        `majorDim` and `minorDim`:\n", "        1. Pad the image with zeros by the specified number of pixels on each side\n", "        (`padx0`, `padx1`, `pady0`, `pady1`). Specifying a negative value\n", "        corresponds to cropping the image.\n", "        2. Upsample the image by inserting the zeros after each pixel (`upx`, `upy`).\n", "        3. Convolve the image with the specified 2D FIR filter (`k`), shrinking the\n", "        image so that the footprint of all output pixels lies within the input image.\n", "        4. Downsample the image by throwing away pixels (`downx`, `downy`).\n", "        This sequence of operations bears close resemblance to scipy.signal.upfirdn().\n", "        The fused op is considerably more efficient than performing the same calculation\n", "        using standard TensorFlow ops. It supports gradients of arbitrary order.\n", "        Args:\n", "            x:      Input tensor of the shape `[majorDim, inH, inW, minorDim]`.\n", "            k:      2D FIR filter of the shape `[firH, firW]`.\n", "            upx:    Integer upsampling factor along the X-axis (default: 1).\n", "            upy:    Integer upsampling factor along the Y-axis (default: 1).\n", "            downx:  Integer downsampling factor along the X-axis (default: 1).\n", "            downy:  Integer downsampling factor along the Y-axis (default: 1).\n", "            padx0:  Number of pixels to pad on the left side (default: 0).\n", "            padx1:  Number of pixels to pad on the right side (default: 0).\n", "            pady0:  Number of pixels to pad on the top side (default: 0).\n", "            pady1:  Number of pixels to pad on the bottom side (default: 0).\n", "            impl:   Name of the implementation to use. Can be `\"ref\"` or `\"cuda\"` (default).\n", "        Returns:\n", "            Tensor of the shape `[majorDim, outH, outW, minorDim]`, and same datatype as `x`.\n", "        \"\"\"\n", "        impl_dict = {\n", "            'ref':  Oncuda._upfirdn_2d_ref,\n", "            'cuda': Oncuda._upfirdn_2d_cuda,\n", "        }\n", "        return impl_dict[impl](x=x, k=k, upx=upx, upy=upy, downx=downx, downy=downy, padx0=padx0, padx1=padx1, pady0=pady0, pady1=pady1, gpu=gpu)\n\n", "    #----------------------------------------------------------------------------\n", "    @staticmethod\n", "    def _upfirdn_2d_ref(x, k, upx, upy, downx, downy, padx0, padx1, pady0, pady1, gpu=True):\n", "        \"\"\"Slow reference implementation of `upfirdn_2d()` using standard TensorFlow ops.\"\"\"\n", "        x = tf.convert_to_tensor(x)\n", "        k = np.asarray(k, dtype=np.float32)\n", "        assert x.shape.rank == 4\n", "        inH = x.shape[1]\n", "        inW = x.shape[2]\n", "        minorDim = Oncuda._shape(x, 3)\n", "        kernelH, kernelW = k.shape\n", "        assert inW >= 1 and inH >= 1\n", "        assert kernelW >= 1 and kernelH >= 1\n", "        assert isinstance(upx, int) and isinstance(upy, int)\n", "        assert isinstance(downx, int) and isinstance(downy, int)\n", "        assert isinstance(padx0, int) and isinstance(padx1, int)\n", "        assert isinstance(pady0, int) and isinstance(pady1, int)\n\n", "        # Upsample (insert zeros).\n", "        x = tf.reshape(x, [-1, inH, 1, inW, 1, minorDim])\n", "        x = tf.pad(x, [[0, 0], [0, 0], [0, upy - 1], [0, 0], [0, upx - 1], [0, 0]])\n", "        x = tf.reshape(x, [-1, inH * upy, inW * upx, minorDim])\n\n", "        # Pad (crop if negative).\n", "        x = tf.pad(x, [[0, 0], [max(pady0, 0), max(pady1, 0)], [max(padx0, 0), max(padx1, 0)], [0, 0]])\n", "        x = x[:, max(-pady0, 0) : x.shape[1] - max(-pady1, 0), max(-padx0, 0) : x.shape[2] - max(-padx1, 0), :]\n\n", "        # Convolve with filter.\n", "        x = tf.transpose(x, [0, 3, 1, 2])\n", "        x = tf.reshape(x, [-1, 1, inH * upy + pady0 + pady1, inW * upx + padx0 + padx1])\n", "        w = tf.constant(k[::-1, ::-1, np.newaxis, np.newaxis], dtype=x.dtype)\n", "        if gpu:\n", "            x = tf.nn.conv2d(x, w, strides=[1,1,1,1], padding='VALID', data_format='NCHW')\n", "        else:\n", "            x = tf.transpose(x, [0, 2, 3, 1])\n", "            x = tf.nn.conv2d(x, w, strides=[1,1,1,1], padding='VALID', data_format='NHWC')\n", "            x = tf.transpose(x, [0, 3, 1, 2])     \n", "        x = tf.reshape(x, [-1, minorDim, inH * upy + pady0 + pady1 - kernelH + 1, inW * upx + padx0 + padx1 - kernelW + 1])\n", "        x = tf.transpose(x, [0, 2, 3, 1])\n\n", "        # Downsample (throw away pixels).\n", "        return x[:, ::downy, ::downx, :]\n\n", "    #----------------------------------------------------------------------------\n", "    @staticmethod\n", "    def _upfirdn_2d_cuda(x, k, upx, upy, downx, downy, padx0, padx1, pady0, pady1, gpu=True):\n", "        \"\"\"Fast CUDA implementation of `upfirdn_2d()` using custom ops.\"\"\"\n", "        x = tf.convert_to_tensor(x)\n", "        k = np.asarray(k, dtype=np.float32)\n", "        majorDim, inH, inW, minorDim = x.shape.as_list()\n", "        kernelH, kernelW = k.shape\n", "        assert inW >= 1 and inH >= 1\n", "        assert kernelW >= 1 and kernelH >= 1\n", "        assert isinstance(upx, int) and isinstance(upy, int)\n", "        assert isinstance(downx, int) and isinstance(downy, int)\n", "        assert isinstance(padx0, int) and isinstance(padx1, int)\n", "        assert isinstance(pady0, int) and isinstance(pady1, int)\n", "        outW = (inW * upx + padx0 + padx1 - kernelW) // downx + 1\n", "        outH = (inH * upy + pady0 + pady1 - kernelH) // downy + 1\n", "        assert outW >= 1 and outH >= 1\n", "        kc = tf.constant(k, dtype=x.dtype)\n", "        gkc = tf.constant(k[::-1, ::-1], dtype=x.dtype)\n", "        gpadx0 = kernelW - padx0 - 1\n", "        gpady0 = kernelH - pady0 - 1\n", "        gpadx1 = inW * upx - outW * downx + padx0 - upx + 1\n", "        gpady1 = inH * upy - outH * downy + pady0 - upy + 1\n\n", "        # add plugin _e_\n", "        @tf.custom_gradient\n", "        def func(x):\n", "            y = Oncuda._get_plugin('upfirdn_2d').up_fir_dn2d(x=x, k=kc, upx=upx, upy=upy, downx=downx, downy=downy, padx0=padx0, padx1=padx1, pady0=pady0, pady1=pady1)\n", "            y.set_shape([majorDim, outH, outW, minorDim])\n", "            @tf.custom_gradient\n", "            def grad(dy):\n", "                dx = Oncuda._get_plugin('upfirdn_2d').up_fir_dn2d(x=dy, k=gkc, upx=downx, upy=downy, downx=upx, downy=upy, padx0=gpadx0, padx1=gpadx1, pady0=gpady0, pady1=gpady1)\n", "                dx.set_shape([majorDim, inH, inW, minorDim])\n", "                return dx, func\n", "            return y, grad\n", "        return func(x)\n\n", "    #----------------------------------------------------------------------------\n", "    @staticmethod\n", "    def filter_2d(x, k, gain=1, data_format='NCHW', impl='cuda'):\n", "        r\"\"\"Filter a batch of 2D images with the given FIR filter.\n", "        Accepts a batch of 2D images of the shape `[N, C, H, W]` or `[N, H, W, C]`\n", "        and filters each image with the given filter. The filter is normalized so that\n", "        if the input pixels are constant, they will be scaled by the specified `gain`.\n", "        Pixels outside the image are assumed to be zero.\n", "        Args:\n", "            x:            Input tensor of the shape `[N, C, H, W]` or `[N, H, W, C]`.\n", "            k:            FIR filter of the shape `[firH, firW]` or `[firN]` (separable).\n", "            gain:         Scaling factor for signal magnitude (default: 1.0).\n", "            data_format:  `'NCHW'` or `'NHWC'` (default: `'NCHW'`).\n", "            impl:         Name of the implementation to use. Can be `\"ref\"` or `\"cuda\"` (default).\n", "        Returns:\n", "            Tensor of the same shape and datatype as `x`.\n", "        \"\"\"\n", "        k = Oncuda._setup_kernel(k) * gain\n", "        p = k.shape[0] - 1\n", "        return Oncuda._simple_upfirdn_2d(x, k, pad0=(p+1)//2, pad1=p//2, data_format=data_format, impl=impl)\n\n", "    #----------------------------------------------------------------------------\n", "    @staticmethod\n", "    def upsample_2d(x, k=None, factor=2, gain=1, data_format='NCHW', impl='cuda', gpu=True):\n", "        r\"\"\"Upsample a batch of 2D images with the given filter.\n", "        Accepts a batch of 2D images of the shape `[N, C, H, W]` or `[N, H, W, C]`\n", "        and upsamples each image with the given filter. The filter is normalized so that\n", "        if the input pixels are constant, they will be scaled by the specified `gain`.\n", "        Pixels outside the image are assumed to be zero, and the filter is padded with\n", "        zeros so that its shape is a multiple of the upsampling factor.\n", "        Args:\n", "            x:            Input tensor of the shape `[N, C, H, W]` or `[N, H, W, C]`.\n", "            k:            FIR filter of the shape `[firH, firW]` or `[firN]` (separable).\n", "                        The default is `[1] * factor`, which corresponds to nearest-neighbor\n", "                        upsampling.\n", "            factor:       Integer upsampling factor (default: 2).\n", "            gain:         Scaling factor for signal magnitude (default: 1.0).\n", "            data_format:  `'NCHW'` or `'NHWC'` (default: `'NCHW'`).\n", "            impl:         Name of the implementation to use. Can be `\"ref\"` or `\"cuda\"` (default).\n", "        Returns:\n", "            Tensor of the shape `[N, C, H * factor, W * factor]` or\n", "            `[N, H * factor, W * factor, C]`, and same datatype as `x`.\n", "        \"\"\"\n", "        assert isinstance(factor, int) and factor >= 1\n", "        if k is None:\n", "            k = [1] * factor\n", "        k = Oncuda._setup_kernel(k) * (gain * (factor ** 2))\n", "        p = k.shape[0] - factor\n", "        return Oncuda._simple_upfirdn_2d(x, k, up=factor, pad0=(p+1)//2+factor-1, pad1=p//2, data_format=data_format, impl=impl, gpu=gpu)\n\n", "    #----------------------------------------------------------------------------\n", "    @staticmethod\n", "    def downsample_2d(x, k=None, factor=2, gain=1, data_format='NCHW', impl='cuda'):\n", "        r\"\"\"Downsample a batch of 2D images with the given filter.\n", "        Accepts a batch of 2D images of the shape `[N, C, H, W]` or `[N, H, W, C]`\n", "        and downsamples each image with the given filter. The filter is normalized so that\n", "        if the input pixels are constant, they will be scaled by the specified `gain`.\n", "        Pixels outside the image are assumed to be zero, and the filter is padded with\n", "        zeros so that its shape is a multiple of the downsampling factor.\n", "        Args:\n", "            x:            Input tensor of the shape `[N, C, H, W]` or `[N, H, W, C]`.\n", "            k:            FIR filter of the shape `[firH, firW]` or `[firN]` (separable).\n", "                        The default is `[1] * factor`, which corresponds to average pooling.\n", "            factor:       Integer downsampling factor (default: 2).\n", "            gain:         Scaling factor for signal magnitude (default: 1.0).\n", "            data_format:  `'NCHW'` or `'NHWC'` (default: `'NCHW'`).\n", "            impl:         Name of the implementation to use. Can be `\"ref\"` or `\"cuda\"` (default).\n", "        Returns:\n", "            Tensor of the shape `[N, C, H // factor, W // factor]` or\n", "            `[N, H // factor, W // factor, C]`, and same datatype as `x`.\n", "        \"\"\"\n", "        assert isinstance(factor, int) and factor >= 1\n", "        if k is None:\n", "            k = [1] * factor\n", "        k = Oncuda._setup_kernel(k) * gain\n", "        p = k.shape[0] - factor\n", "        return Oncuda._simple_upfirdn_2d(x, k, down=factor, pad0=(p+1)//2, pad1=p//2, data_format=data_format, impl=impl)\n\n", "    #----------------------------------------------------------------------------\n", "    @staticmethod\n", "    def upsample_conv_2d(x, w, k=None, factor=2, gain=1, data_format='NCHW', impl='cuda', gpu=True):\n", "        r\"\"\"Fused `upsample_2d()` followed by `tf.nn.conv2d()`.\n", "        Padding is performed only once at the beginning, not between the operations.\n", "        The fused op is considerably more efficient than performing the same calculation\n", "        using standard TensorFlow ops. It supports gradients of arbitrary order.\n", "        Args:\n", "            x:            Input tensor of the shape `[N, C, H, W]` or `[N, H, W, C]`.\n", "            w:            Weight tensor of the shape `[filterH, filterW, inChannels, outChannels]`.\n", "                        Grouped convolution can be performed by `inChannels = x.shape[0] // numGroups`.\n", "            k:            FIR filter of the shape `[firH, firW]` or `[firN]` (separable).\n", "                        The default is `[1] * factor`, which corresponds to nearest-neighbor\n", "                        upsampling.\n", "            factor:       Integer upsampling factor (default: 2).\n", "            gain:         Scaling factor for signal magnitude (default: 1.0).\n", "            data_format:  `'NCHW'` or `'NHWC'` (default: `'NCHW'`).\n", "            impl:         Name of the implementation to use. Can be `\"ref\"` or `\"cuda\"` (default).\n", "        Returns:\n", "            Tensor of the shape `[N, C, H * factor, W * factor]` or\n", "            `[N, H * factor, W * factor, C]`, and same datatype as `x`.\n", "        \"\"\"\n", "        assert isinstance(factor, int) and factor >= 1\n\n", "        # Check weight shape.\n", "        w = tf.convert_to_tensor(w)\n", "        assert w.shape.rank == 4\n", "        convH = w.shape[0]\n", "        convW = w.shape[1]\n", "        inC = Oncuda._shape(w, 2)\n", "        outC = Oncuda._shape(w, 3)\n", "        assert convW == convH\n\n", "        # Setup filter kernel.\n", "        if k is None:\n", "            k = [1] * factor\n", "        k = Oncuda._setup_kernel(k) * (gain * (factor ** 2))\n", "        p = (k.shape[0] - factor) - (convW - 1)\n\n", "        # Determine data dimensions.\n", "        if data_format == 'NCHW':\n", "            stride = [1, 1, factor, factor]\n", "            output_shape = [Oncuda._shape(x, 0), outC, (Oncuda._shape(x, 2) - 1) * factor + convH, (Oncuda._shape(x, 3) - 1) * factor + convW]\n", "            num_groups = Oncuda._shape(x, 1) // inC\n", "        else:\n", "            stride = [1, factor, factor, 1]\n", "            output_shape = [Oncuda._shape(x, 0), (Oncuda._shape(x, 1) - 1) * factor + convH, (Oncuda._shape(x, 2) - 1) * factor + convW, outC]\n", "            num_groups = Oncuda._shape(x, 3) // inC\n\n", "        # Transpose weights.\n", "        w = tf.reshape(w, [convH, convW, inC, num_groups, -1])\n", "        w = tf.transpose(w[::-1, ::-1], [0, 1, 4, 3, 2])\n", "        w = tf.reshape(w, [convH, convW, -1, num_groups * inC])\n\n", "        # Execute.\n", "        x = tf.nn.conv2d_transpose(x, w, output_shape=output_shape, strides=stride, padding='VALID', data_format=data_format)\n", "        return Oncuda._simple_upfirdn_2d(x, k, pad0=(p+1)//2+factor-1, pad1=p//2+1, data_format=data_format, impl=impl, gpu=gpu)\n\n", "    #----------------------------------------------------------------------------\n", "    @staticmethod\n", "    def conv_downsample_2d(x, w, k=None, factor=2, gain=1, data_format='NCHW', impl='cuda', gpu=True):\n", "        r\"\"\"Fused `tf.nn.conv2d()` followed by `downsample_2d()`.\n", "        Padding is performed only once at the beginning, not between the operations.\n", "        The fused op is considerably more efficient than performing the same calculation\n", "        using standard TensorFlow ops. It supports gradients of arbitrary order.\n", "        Args:\n", "            x:            Input tensor of the shape `[N, C, H, W]` or `[N, H, W, C]`.\n", "            w:            Weight tensor of the shape `[filterH, filterW, inChannels, outChannels]`.\n", "                        Grouped convolution can be performed by `inChannels = x.shape[0] // numGroups`.\n", "            k:            FIR filter of the shape `[firH, firW]` or `[firN]` (separable).\n", "                        The default is `[1] * factor`, which corresponds to average pooling.\n", "            factor:       Integer downsampling factor (default: 2).\n", "            gain:         Scaling factor for signal magnitude (default: 1.0).\n", "            data_format:  `'NCHW'` or `'NHWC'` (default: `'NCHW'`).\n", "            impl:         Name of the implementation to use. Can be `\"ref\"` or `\"cuda\"` (default).\n", "        Returns:\n", "            Tensor of the shape `[N, C, H // factor, W // factor]` or\n", "            `[N, H // factor, W // factor, C]`, and same datatype as `x`.\n", "        \"\"\"\n", "        assert isinstance(factor, int) and factor >= 1\n", "        w = tf.convert_to_tensor(w)\n", "        convH, convW, _inC, _outC = w.shape.as_list()\n", "        assert convW == convH\n", "        if k is None:\n", "            k = [1] * factor\n", "        k = Oncuda._setup_kernel(k) * gain\n", "        p = (k.shape[0] - factor) + (convW - 1)\n", "        if data_format == 'NCHW':\n", "            s = [1, 1, factor, factor]\n", "        else:\n", "            s = [1, factor, factor, 1]\n", "        x = Oncuda._simple_upfirdn_2d(x, k, pad0=(p+1)//2, pad1=p//2, data_format=data_format, impl=impl, gpu=gpu)\n", "        return tf.nn.conv2d(x, w, strides=s, padding='VALID', data_format=data_format)\n\n", "    #----------------------------------------------------------------------------\n", "    # Internal helper funcs.\n", "    @staticmethod\n", "    def _shape(tf_expr, dim_idx):\n", "        if tf_expr.shape.rank is not None:\n", "            dim = tf_expr.shape[dim_idx]\n", "            if dim is not None:\n", "                return dim\n", "        return tf.shape(tf_expr)[dim_idx]\n", "    @staticmethod\n", "    def _setup_kernel(k):\n", "        k = np.asarray(k, dtype=np.float32)\n", "        if k.ndim == 1:\n", "            k = np.outer(k, k)\n", "        k /= np.sum(k)\n", "        assert k.ndim == 2\n", "        assert k.shape[0] == k.shape[1]\n", "        return k\n", "    @staticmethod\n", "    def _simple_upfirdn_2d(x, k, up=1, down=1, pad0=0, pad1=0, data_format='NCHW', impl='cuda', gpu=True):\n", "        assert data_format in ['NCHW', 'NHWC']\n", "        assert x.shape.rank == 4\n", "        y = x\n", "        if data_format == 'NCHW':\n", "            y = tf.reshape(y, [-1, Oncuda._shape(y, 2), Oncuda._shape(y, 3), 1])\n", "        y = Oncuda.upfirdn_2d(y, k, upx=up, upy=up, downx=down, downy=down, padx0=pad0, padx1=pad1, pady0=pad0, pady1=pad1, impl=impl, gpu=gpu)\n", "        if data_format == 'NCHW':\n", "            y = tf.reshape(y, [-1, Oncuda._shape(x, 1), Oncuda._shape(y, 1), Oncuda._shape(y, 2)])\n", "        return y"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    #   ******************\n", "    #   dnnlib/ops/upfirdn_2d.cu - get raw\n", "    #\n\n", "    # _e_\n", "    # ERROR in Eigen C++ file named Tensor\n", "    # ref: https://github.com/tensorflow/tensorflow/issues/40148\n", "    # ref: https://github.com/tensorflow/tensorflow/issues/39829\n", "    # C:/Users/xxx/AppData/Local/Programs/Python/Python36/lib/site-packages/tensorflow/include/unsupported/Eigen/CXX11/Tensor    \n", "    #     {port}/Anaconda3/envs/{env}/lib/site-packages/tensorflow/include/unsupported/Eigen/CXX11/Tensor(74): fatal error C1083: Cannot open include file: 'unistd.h': No such file or directory\n", "    #     _pywrap_tensorflow_internal.lib\n", "    #     upfirdn_2d.cu\n", "    # python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\" \n", "    @staticmethod    \n", "    def get_kernel_upfirdn():\n", "        res=\"\"\"// Copyright (c) 2019, NVIDIA Corporation. All rights reserved.\n", "//\n", "// This work is made available under the Nvidia Source Code License-NC.\n", "// To view a copy of this license, visit\n", "// https://nvlabs.github.io/stylegan2/license.html"]}, {"cell_type": "markdown", "metadata": {}, "source": ["efine EIGEN_USE_GPU<br>\n", "efine __CUDA_INCLUDE_COMPILER_INTERNAL_HEADERS__<br>\n", "nclude \"tensorflow/core/framework/op.h\"<br>\n", "nclude \"tensorflow/core/framework/op_kernel.h\"<br>\n", "nclude \"tensorflow/core/framework/shape_inference.h\"<br>\n", "nclude <stdio.h>"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["using namespace tensorflow;\n", "using namespace tensorflow::shape_inference;"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["//------------------------------------------------------------------------\n", "// Helpers."]}, {"cell_type": "markdown", "metadata": {}, "source": ["efine OP_CHECK_CUDA_ERROR(CTX, CUDA_CALL) do { cudaError_t err = CUDA_CALL; OP_REQUIRES(CTX, err == cudaSuccess, errors::Internal(cudaGetErrorName(err))); } while (false)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["static __host__ __device__ __forceinline__ int floorDiv(int a, int b)\n", "{\n", "    int c = a / b;\n", "    if (c * b > a)\n", "        c--;\n", "    return c;\n", "}"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["//------------------------------------------------------------------------\n", "// CUDA kernel params."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["template <class T>\n", "struct UpFirDn2DKernelParams\n", "{\n", "    const T*    x;          // [majorDim, inH, inW, minorDim]\n", "    const T*    k;          // [kernelH, kernelW]\n", "    T*          y;          // [majorDim, outH, outW, minorDim]\n", "    int         upx;\n", "    int         upy;\n", "    int         downx;\n", "    int         downy;\n", "    int         padx0;\n", "    int         padx1;\n", "    int         pady0;\n", "    int         pady1;\n", "    int         majorDim;\n", "    int         inH;\n", "    int         inW;\n", "    int         minorDim;\n", "    int         kernelH;\n", "    int         kernelW;\n", "    int         outH;\n", "    int         outW;\n", "    int         loopMajor;\n", "    int         loopX;\n", "};"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["//------------------------------------------------------------------------\n", "// General CUDA implementation for large filter kernels."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["template <class T>\n", "static __global__ void UpFirDn2DKernel_large(const UpFirDn2DKernelParams<T> p)\n", "{\n", "    // Calculate thread index.\n", "    int minorIdx = blockIdx.x * blockDim.x + threadIdx.x;\n", "    int outY = minorIdx / p.minorDim;\n", "    minorIdx -= outY * p.minorDim;\n", "    int outXBase = blockIdx.y * p.loopX * blockDim.y + threadIdx.y;\n", "    int majorIdxBase = blockIdx.z * p.loopMajor;\n", "    if (outXBase >= p.outW || outY >= p.outH || majorIdxBase >= p.majorDim)\n", "        return;\n", "    // Setup Y receptive field.\n", "    int midY = outY * p.downy + p.upy - 1 - p.pady0;\n", "    int inY = min(max(floorDiv(midY, p.upy), 0), p.inH);\n", "    int h = min(max(floorDiv(midY + p.kernelH, p.upy), 0), p.inH) - inY;\n", "    int kernelY = midY + p.kernelH - (inY + 1) * p.upy;\n", "    // Loop over majorDim and outX.\n", "    for (int loopMajor = 0, majorIdx = majorIdxBase; loopMajor < p.loopMajor && majorIdx < p.majorDim; loopMajor++, majorIdx++)\n", "    for (int loopX = 0, outX = outXBase; loopX < p.loopX && outX < p.outW; loopX++, outX += blockDim.y)\n", "    {\n", "        // Setup X receptive field.\n", "        int midX = outX * p.downx + p.upx - 1 - p.padx0;\n", "        int inX = min(max(floorDiv(midX, p.upx), 0), p.inW);\n", "        int w = min(max(floorDiv(midX + p.kernelW, p.upx), 0), p.inW) - inX;\n", "        int kernelX = midX + p.kernelW - (inX + 1) * p.upx;\n", "        // Initialize pointers.\n", "        const T* xp = &p.x[((majorIdx * p.inH + inY) * p.inW + inX) * p.minorDim + minorIdx];\n", "        const T* kp = &p.k[kernelY * p.kernelW + kernelX];\n", "        int xpx = p.minorDim;\n", "        int kpx = -p.upx;\n", "        int xpy = p.inW * p.minorDim;\n", "        int kpy = -p.upy * p.kernelW;\n", "        // Inner loop.\n", "        float v = 0.0f;\n", "        for (int y = 0; y < h; y++)\n", "        {\n", "            for (int x = 0; x < w; x++)\n", "            {\n", "                v += (float)(*xp) * (float)(*kp);\n", "                xp += xpx;\n", "                kp += kpx;\n", "            }\n", "            xp += xpy - w * xpx;\n", "            kp += kpy - w * kpx;\n", "        }\n", "        // Store result.\n", "        p.y[((majorIdx * p.outH + outY) * p.outW + outX) * p.minorDim + minorIdx] = (T)v;\n", "    }\n", "}"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["//------------------------------------------------------------------------\n", "// Specialized CUDA implementation for small filter kernels."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["template <class T, int upx, int upy, int downx, int downy, int kernelW, int kernelH, int tileOutW, int tileOutH>\n", "static __global__ void UpFirDn2DKernel_small(const UpFirDn2DKernelParams<T> p)\n", "{\n", "    //assert(kernelW % upx == 0);\n", "    //assert(kernelH % upy == 0);\n", "    const int tileInW = ((tileOutW - 1) * downx + kernelW - 1) / upx + 1;\n", "    const int tileInH = ((tileOutH - 1) * downy + kernelH - 1) / upy + 1;\n", "    __shared__ volatile float sk[kernelH][kernelW];\n", "    __shared__ volatile float sx[tileInH][tileInW];\n", "    // Calculate tile index.\n", "    int minorIdx = blockIdx.x;\n", "    int tileOutY = minorIdx / p.minorDim;\n", "    minorIdx -= tileOutY * p.minorDim;\n", "    tileOutY *= tileOutH;\n", "    int tileOutXBase = blockIdx.y * p.loopX * tileOutW;\n", "    int majorIdxBase = blockIdx.z * p.loopMajor;\n", "    if (tileOutXBase >= p.outW | tileOutY >= p.outH | majorIdxBase >= p.majorDim)\n", "        return;\n", "    // Load filter kernel (flipped).\n", "    for (int tapIdx = threadIdx.x; tapIdx < kernelH * kernelW; tapIdx += blockDim.x)\n", "    {\n", "        int ky = tapIdx / kernelW;\n", "        int kx = tapIdx - ky * kernelW;\n", "        float v = 0.0f;\n", "        if (kx < p.kernelW & ky < p.kernelH)\n", "            v = (float)p.k[(p.kernelH - 1 - ky) * p.kernelW + (p.kernelW - 1 - kx)];\n", "        sk[ky][kx] = v;\n", "    }\n", "    // Loop over majorDim and outX.\n", "    for (int loopMajor = 0, majorIdx = majorIdxBase; loopMajor < p.loopMajor & majorIdx < p.majorDim; loopMajor++, majorIdx++)\n", "    for (int loopX = 0, tileOutX = tileOutXBase; loopX < p.loopX & tileOutX < p.outW; loopX++, tileOutX += tileOutW)\n", "    {\n", "        // Load input pixels.\n", "        int tileMidX = tileOutX * downx + upx - 1 - p.padx0;\n", "        int tileMidY = tileOutY * downy + upy - 1 - p.pady0;\n", "        int tileInX = floorDiv(tileMidX, upx);\n", "        int tileInY = floorDiv(tileMidY, upy);\n", "        __syncthreads();\n", "        for (int inIdx = threadIdx.x; inIdx < tileInH * tileInW; inIdx += blockDim.x)\n", "        {\n", "            int relInY = inIdx / tileInW;\n", "            int relInX = inIdx - relInY * tileInW;\n", "            int inX = relInX + tileInX;\n", "            int inY = relInY + tileInY;\n", "            float v = 0.0f;\n", "            if (inX >= 0 & inY >= 0 & inX < p.inW & inY < p.inH)\n", "                v = (float)p.x[((majorIdx * p.inH + inY) * p.inW + inX) * p.minorDim + minorIdx];\n", "            sx[relInY][relInX] = v;\n", "        }\n", "        // Loop over output pixels.\n", "        __syncthreads();\n", "        for (int outIdx = threadIdx.x; outIdx < tileOutH * tileOutW; outIdx += blockDim.x)\n", "        {\n", "            int relOutY = outIdx / tileOutW;\n", "            int relOutX = outIdx - relOutY * tileOutW;\n", "            int outX = relOutX + tileOutX;\n", "            int outY = relOutY + tileOutY;\n", "            // Setup receptive field.\n", "            int midX = tileMidX + relOutX * downx;\n", "            int midY = tileMidY + relOutY * downy;\n", "            int inX = floorDiv(midX, upx);\n", "            int inY = floorDiv(midY, upy);\n", "            int relInX = inX - tileInX;\n", "            int relInY = inY - tileInY;\n", "            int kernelX = (inX + 1) * upx - midX - 1; // flipped\n", "            int kernelY = (inY + 1) * upy - midY - 1; // flipped\n", "            // Inner loop.\n", "            float v = 0.0f;\n", "            #pragma unroll\n", "            for (int y = 0; y < kernelH / upy; y++)\n", "                #pragma unroll\n", "                for (int x = 0; x < kernelW / upx; x++)\n", "                    v += sx[relInY + y][relInX + x] * sk[kernelY + y * upy][kernelX + x * upx];\n", "            // Store result.\n", "            if (outX < p.outW & outY < p.outH)\n", "                p.y[((majorIdx * p.outH + outY) * p.outW + outX) * p.minorDim + minorIdx] = (T)v;\n", "        }\n", "    }\n", "}"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["//------------------------------------------------------------------------\n", "// TensorFlow op."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["template <class T>\n", "struct UpFirDn2DOp : public OpKernel\n", "{\n", "    UpFirDn2DKernelParams<T> m_attribs;\n", "    UpFirDn2DOp(OpKernelConstruction* ctx) : OpKernel(ctx)\n", "    {\n", "        memset(&m_attribs, 0, sizeof(m_attribs));\n", "        OP_REQUIRES_OK(ctx, ctx->GetAttr(\"upx\", &m_attribs.upx));\n", "        OP_REQUIRES_OK(ctx, ctx->GetAttr(\"upy\", &m_attribs.upy));\n", "        OP_REQUIRES_OK(ctx, ctx->GetAttr(\"downx\", &m_attribs.downx));\n", "        OP_REQUIRES_OK(ctx, ctx->GetAttr(\"downy\", &m_attribs.downy));\n", "        OP_REQUIRES_OK(ctx, ctx->GetAttr(\"padx0\", &m_attribs.padx0));\n", "        OP_REQUIRES_OK(ctx, ctx->GetAttr(\"padx1\", &m_attribs.padx1));\n", "        OP_REQUIRES_OK(ctx, ctx->GetAttr(\"pady0\", &m_attribs.pady0));\n", "        OP_REQUIRES_OK(ctx, ctx->GetAttr(\"pady1\", &m_attribs.pady1));\n", "        OP_REQUIRES(ctx, m_attribs.upx >= 1 && m_attribs.upy >= 1, errors::InvalidArgument(\"upx and upy must be at least 1x1\"));\n", "        OP_REQUIRES(ctx, m_attribs.downx >= 1 && m_attribs.downy >= 1, errors::InvalidArgument(\"downx and downy must be at least 1x1\"));\n", "    }\n", "    void Compute(OpKernelContext* ctx)\n", "    {\n", "        UpFirDn2DKernelParams<T> p = m_attribs;\n", "        cudaStream_t stream = ctx->eigen_device<Eigen::GpuDevice>().stream();\n", "        const Tensor& x = ctx->input(0); // [majorDim, inH, inW, minorDim]\n", "        const Tensor& k = ctx->input(1); // [kernelH, kernelW]\n", "        p.x = x.flat<T>().data();\n", "        p.k = k.flat<T>().data();\n", "        OP_REQUIRES(ctx, x.dims() == 4, errors::InvalidArgument(\"input must have rank 4\"));\n", "        OP_REQUIRES(ctx, k.dims() == 2, errors::InvalidArgument(\"kernel must have rank 2\"));\n", "        OP_REQUIRES(ctx, x.NumElements() <= kint32max, errors::InvalidArgument(\"input too large\"));\n", "        OP_REQUIRES(ctx, k.NumElements() <= kint32max, errors::InvalidArgument(\"kernel too large\"));\n", "        p.majorDim  = (int)x.dim_size(0);\n", "        p.inH       = (int)x.dim_size(1);\n", "        p.inW       = (int)x.dim_size(2);\n", "        p.minorDim  = (int)x.dim_size(3);\n", "        p.kernelH   = (int)k.dim_size(0);\n", "        p.kernelW   = (int)k.dim_size(1);\n", "        OP_REQUIRES(ctx, p.kernelW >= 1 && p.kernelH >= 1, errors::InvalidArgument(\"kernel must be at least 1x1\"));\n", "        p.outW = (p.inW * p.upx + p.padx0 + p.padx1 - p.kernelW + p.downx) / p.downx;\n", "        p.outH = (p.inH * p.upy + p.pady0 + p.pady1 - p.kernelH + p.downy) / p.downy;\n", "        OP_REQUIRES(ctx, p.outW >= 1 && p.outH >= 1, errors::InvalidArgument(\"output must be at least 1x1\"));\n", "        Tensor* y = NULL; // [majorDim, outH, outW, minorDim]\n", "        TensorShape ys;\n", "        ys.AddDim(p.majorDim);\n", "        ys.AddDim(p.outH);\n", "        ys.AddDim(p.outW);\n", "        ys.AddDim(p.minorDim);\n", "        OP_REQUIRES_OK(ctx, ctx->allocate_output(0, ys, &y));\n", "        p.y = y->flat<T>().data();\n", "        OP_REQUIRES(ctx, y->NumElements() <= kint32max, errors::InvalidArgument(\"output too large\"));\n", "        // Choose CUDA kernel to use.\n", "        void* cudaKernel = (void*)UpFirDn2DKernel_large<T>;\n", "        int tileOutW = -1;\n", "        int tileOutH = -1;\n", "        if (p.upx == 1 && p.upy == 1 && p.downx == 1 && p.downy == 1 && p.kernelW <= 7 && p.kernelH <= 7) { cudaKernel = (void*)UpFirDn2DKernel_small<T, 1,1, 1,1, 7,7, 64,16>; tileOutW = 64; tileOutH = 16; }\n", "        if (p.upx == 1 && p.upy == 1 && p.downx == 1 && p.downy == 1 && p.kernelW <= 6 && p.kernelH <= 6) { cudaKernel = (void*)UpFirDn2DKernel_small<T, 1,1, 1,1, 6,6, 64,16>; tileOutW = 64; tileOutH = 16; }\n", "        if (p.upx == 1 && p.upy == 1 && p.downx == 1 && p.downy == 1 && p.kernelW <= 5 && p.kernelH <= 5) { cudaKernel = (void*)UpFirDn2DKernel_small<T, 1,1, 1,1, 5,5, 64,16>; tileOutW = 64; tileOutH = 16; }\n", "        if (p.upx == 1 && p.upy == 1 && p.downx == 1 && p.downy == 1 && p.kernelW <= 4 && p.kernelH <= 4) { cudaKernel = (void*)UpFirDn2DKernel_small<T, 1,1, 1,1, 4,4, 64,16>; tileOutW = 64; tileOutH = 16; }\n", "        if (p.upx == 1 && p.upy == 1 && p.downx == 1 && p.downy == 1 && p.kernelW <= 3 && p.kernelH <= 3) { cudaKernel = (void*)UpFirDn2DKernel_small<T, 1,1, 1,1, 3,3, 64,16>; tileOutW = 64; tileOutH = 16; }\n", "        if (p.upx == 2 && p.upy == 2 && p.downx == 1 && p.downy == 1 && p.kernelW <= 8 && p.kernelH <= 8) { cudaKernel = (void*)UpFirDn2DKernel_small<T, 2,2, 1,1, 8,8, 64,16>; tileOutW = 64; tileOutH = 16; }\n", "        if (p.upx == 2 && p.upy == 2 && p.downx == 1 && p.downy == 1 && p.kernelW <= 6 && p.kernelH <= 6) { cudaKernel = (void*)UpFirDn2DKernel_small<T, 2,2, 1,1, 6,6, 64,16>; tileOutW = 64; tileOutH = 16; }\n", "        if (p.upx == 2 && p.upy == 2 && p.downx == 1 && p.downy == 1 && p.kernelW <= 4 && p.kernelH <= 4) { cudaKernel = (void*)UpFirDn2DKernel_small<T, 2,2, 1,1, 4,4, 64,16>; tileOutW = 64; tileOutH = 16; }\n", "        if (p.upx == 2 && p.upy == 2 && p.downx == 1 && p.downy == 1 && p.kernelW <= 2 && p.kernelH <= 2) { cudaKernel = (void*)UpFirDn2DKernel_small<T, 2,2, 1,1, 2,2, 64,16>; tileOutW = 64; tileOutH = 16; }\n", "        if (p.upx == 1 && p.upy == 1 && p.downx == 2 && p.downy == 2 && p.kernelW <= 8 && p.kernelH <= 8) { cudaKernel = (void*)UpFirDn2DKernel_small<T, 1,1, 2,2, 8,8, 32,8>;  tileOutW = 32; tileOutH = 8;  }\n", "        if (p.upx == 1 && p.upy == 1 && p.downx == 2 && p.downy == 2 && p.kernelW <= 6 && p.kernelH <= 6) { cudaKernel = (void*)UpFirDn2DKernel_small<T, 1,1, 2,2, 6,6, 32,8>;  tileOutW = 32; tileOutH = 8;  }\n", "        if (p.upx == 1 && p.upy == 1 && p.downx == 2 && p.downy == 2 && p.kernelW <= 4 && p.kernelH <= 4) { cudaKernel = (void*)UpFirDn2DKernel_small<T, 1,1, 2,2, 4,4, 32,8>;  tileOutW = 32; tileOutH = 8;  }\n", "        if (p.upx == 1 && p.upy == 1 && p.downx == 2 && p.downy == 2 && p.kernelW <= 2 && p.kernelH <= 2) { cudaKernel = (void*)UpFirDn2DKernel_small<T, 1,1, 2,2, 2,2, 32,8>;  tileOutW = 32; tileOutH = 8;  }\n", "        // Choose launch params.\n", "        dim3 blockSize;\n", "        dim3 gridSize;\n", "        if (tileOutW > 0 && tileOutH > 0) // small\n", "        {\n", "            p.loopMajor = (p.majorDim - 1) / 16384 + 1;\n", "            p.loopX = 1;\n", "            blockSize = dim3(32 * 8, 1, 1);\n", "            gridSize = dim3(((p.outH - 1) / tileOutH + 1) * p.minorDim, (p.outW - 1) / (p.loopX * tileOutW) + 1, (p.majorDim - 1) / p.loopMajor + 1);\n", "        }\n", "        else // large\n", "        {\n", "            p.loopMajor = (p.majorDim - 1) / 16384 + 1;\n", "            p.loopX = 4;\n", "            blockSize = dim3(4, 32, 1);\n", "            gridSize = dim3((p.outH * p.minorDim - 1) / blockSize.x + 1, (p.outW - 1) / (p.loopX * blockSize.y) + 1, (p.majorDim - 1) / p.loopMajor + 1);\n", "        }\n", "        // Launch CUDA kernel.\n", "        void* args[] = {&p};\n", "        OP_CHECK_CUDA_ERROR(ctx, cudaLaunchKernel(cudaKernel, gridSize, blockSize, args, 0, stream));\n", "    }\n", "};"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["REGISTER_OP(\"UpFirDn2D\")\n", "    .Input      (\"x: T\")\n", "    .Input      (\"k: T\")\n", "    .Output     (\"y: T\")\n", "    .Attr       (\"T: {float, half}\")\n", "    .Attr       (\"upx: int = 1\")\n", "    .Attr       (\"upy: int = 1\")\n", "    .Attr       (\"downx: int = 1\")\n", "    .Attr       (\"downy: int = 1\")\n", "    .Attr       (\"padx0: int = 0\")\n", "    .Attr       (\"padx1: int = 0\")\n", "    .Attr       (\"pady0: int = 0\")\n", "    .Attr       (\"pady1: int = 0\");\n", "REGISTER_KERNEL_BUILDER(Name(\"UpFirDn2D\").Device(DEVICE_GPU).TypeConstraint<float>(\"T\"), UpFirDn2DOp<float>);\n", "REGISTER_KERNEL_BUILDER(Name(\"UpFirDn2D\").Device(DEVICE_GPU).TypeConstraint<Eigen::half>(\"T\"), UpFirDn2DOp<Eigen::half>);"]}, {"cell_type": "markdown", "metadata": {}, "source": ["//------------------------------------------------------------------------\n<br>\n", "        return res<br>\n", "#   ******************<br>\n", "#   FUNS ONROSA<br>\n", "#   ******************<br>\n", "class Onrosa:<br>\n", "    # _p_ https://github.com/moono/stylegan2-tf-2.x/blob/master/stylegan2/utils.py<br>\n", "    @staticmethod<br>\n", "    def get_weight_initializer_runtime_coef(shape, gain=1, use_wscale=True, lrmul=1):<br>\n", "      \n get initializer and lr coef for different weights shapes\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        fan_in = np.prod(shape[:-1]) # [kernel, kernel, fmaps_in, fmaps_out] or [in, out]\n", "        he_std = gain / np.sqrt(fan_in) # He init\n\n", "        # Equalized learning rate and custom learning rate multiplier.\n", "        if use_wscale:\n", "            init_std = 1.0 / lrmul\n", "            runtime_coef = he_std * lrmul\n", "        else:\n", "            init_std = he_std / lrmul\n", "            runtime_coef = lrmul\n", "        \n", "        return init_std, runtime_coef\n", "    @staticmethod\n", "    def convert_images_to_uint8(images, drange=[-1, 1], nchw_to_nhwc=False, shrink=1, uint8_cast=True):\n", "        \"\"\"Convert a minibatch of images from float32 to uint8 with configurable dynamic range.\n", "        Can be used as an output transformation for Network.run().\n", "        \"\"\"\n", "        images = tf.cast(images, tf.float32)\n", "        if shrink > 1:\n", "            ksize = [1, 1, shrink, shrink]\n", "            images = tf.nn.avg_pool(images, ksize=ksize, strides=ksize, \n", "                                    padding=\"VALID\", data_format=\"NCHW\")\n", "        if nchw_to_nhwc:\n", "            images = tf.transpose(images, [0, 2, 3, 1])\n", "        scale = 255 / (drange[1] - drange[0])\n", "        images = images * scale + (0.5 - drange[0] * scale)\n", "        if uint8_cast:\n", "            images = tf.saturate_cast(images, tf.uint8)\n", "        return images\n", "    @staticmethod\n", "    def nf(stage, fmap_base=16 << 10, fmap_decay=1.0, fmap_min=1, fmap_max=512): \n", "        return np.clip(int(fmap_base / (2.0 ** (stage * fmap_decay))), fmap_min, fmap_max)\n", "    # utils_stylegan2.py <=    "]}, {"cell_type": "markdown", "metadata": {}, "source": ["  ******************<br>\n", "  FUNS ONROLUX<br>\n", "  /rolux/stylegan2encoder/dnnlib/util.py<br>\n", "  ******************"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class Onrolux:\n\n", "    # Functionality to import modules/objects by name, and call functions by name\n", "    # ------------------------------------------------------------------------------------------\n", "    @staticmethod\n", "    def get_module_from_obj_name(obj_name: str) -> Tuple[types.ModuleType, str]:\n", "        \"\"\"Searches for the underlying module behind the name to some python object.\n", "        Returns the module and the object name (original name with module part removed).\"\"\"\n\n", "        # allow convenience shorthands, substitute them by full names\n", "        obj_name = re.sub(\"^np.\", \"numpy.\", obj_name)\n", "        obj_name = re.sub(\"^tf.\", \"tensorflow.\", obj_name)\n\n", "        # list alternatives for (module_name, local_obj_name)\n", "        parts = obj_name.split(\".\")\n", "        name_pairs = [(\".\".join(parts[:i]), \".\".join(parts[i:])) for i in range(len(parts), 0, -1)]\n\n", "        # try each alternative in turn\n", "        for module_name, local_obj_name in name_pairs:\n", "            try:\n", "                module = importlib.import_module(module_name) # may raise ImportError\n", "                get_obj_from_module(module, local_obj_name) # may raise AttributeError\n", "                return module, local_obj_name\n", "            except:\n", "                pass\n\n", "        # maybe some of the modules themselves contain errors?\n", "        for module_name, _local_obj_name in name_pairs:\n", "            try:\n", "                importlib.import_module(module_name) # may raise ImportError\n", "            except ImportError:\n", "                if not str(sys.exc_info()[1]).startswith(\"No module named '\" + module_name + \"'\"):\n", "                    raise\n\n", "        # maybe the requested attribute is missing?\n", "        for module_name, local_obj_name in name_pairs:\n", "            try:\n", "                module = importlib.import_module(module_name) # may raise ImportError\n", "                get_obj_from_module(module, local_obj_name) # may raise AttributeError\n", "            except ImportError:\n", "                pass\n\n", "        # we are out of luck, but we have no idea why\n", "        raise ImportError(obj_name)\n", "    @staticmethod\n", "    def get_obj_from_module(module: types.ModuleType, obj_name: str) -> Any:\n", "        \"\"\"Traverses the object name and returns the last (rightmost) python object.\"\"\"\n", "        if obj_name == '':\n", "            return module\n", "        obj = module\n", "        for part in obj_name.split(\".\"):\n", "            obj = getattr(obj, part)\n", "        return obj\n", "    @staticmethod\n", "    def get_obj_by_name(name: str) -> Any:\n", "        \"\"\"Finds the python object with the given name.\"\"\"\n", "        module, obj_name = Onrolux.get_module_from_obj_name(name)\n", "        return get_obj_from_module(module, obj_name)\n", "    @staticmethod\n", "    def call_func_by_name(*args, func_name: str = None, **kwargs) -> Any:\n", "        \"\"\"Finds the python object with the given name and calls it as a function.\"\"\"\n", "        assert func_name is not None\n", "        func_obj = get_obj_by_name(func_name)\n", "        assert callable(func_obj)\n", "        return func_obj(*args, **kwargs)\n", "    @staticmethod\n", "    def get_module_dir_by_obj_name(obj_name: str) -> str:\n", "        \"\"\"Get the directory path of the module containing the given object name.\"\"\"\n", "        module, _ = Onrolux.get_module_from_obj_name(obj_name)\n", "        return os.path.dirname(inspect.getfile(module))\n", "    @staticmethod\n", "    def is_top_level_function(obj: Any) -> bool:\n", "        \"\"\"Determine whether the given object is a top-level function, i.e., defined at module scope using 'def'.\"\"\"\n", "        return callable(obj) and obj.__name__ in sys.modules[obj.__module__].__dict__\n", "    @staticmethod\n", "    def get_top_level_function_name(obj: Any) -> str:\n", "        \"\"\"Return the fully-qualified name of a top-level function.\"\"\"\n", "        assert is_top_level_function(obj)\n", "        return obj.__module__ + \".\" + obj.__name__\n\n", "    # rolux/stylegan2encoder/dnnlib/tflib/tfutil.py\n", "    def set_vars(var_to_value_dict: dict) -> None:\n", "        [tf.assign(var, value) for var, value in var_to_value_dict.items()]\n", "    def create_var_with_large_initial_value(initial_value: np.ndarray, *args, **kwargs):\n", "        \"\"\"Create tf.Variable with large initial value without bloating the tf graph.\"\"\"\n", "        assert isinstance(initial_value, np.ndarray)\n", "        zeros = tf.zeros(initial_value.shape, initial_value.dtype)\n", "        var = tf.Variable(zeros, *args, **kwargs)\n", "        # Onrolux.set_vars({var: initial_value})\n", "        return var"]}, {"cell_type": "markdown", "metadata": {}, "source": ["  ******************<br>\n", "  ONMOONO<br>\n", "<br>\n", "  ******************"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class Onmoono:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["  ******************<br>\n", "<br>\n", "   -> https://github.com/moono/stylegan2-tf-2.x/tree/master/stylegan2/upfirdn_2d.py <-<br>\n", "<br>\n", "  ******************"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    @staticmethod\n", "    def setup_resample_kernel(k):\n", "        k = np.asarray(k, dtype=np.float32)\n", "        if k.ndim == 1:\n", "            k = np.outer(k, k)\n", "        k /= np.sum(k)\n", "        return k\n", "    @staticmethod\n", "    def upfirdn_ref(x, k, up_x, up_y, down_x, down_y, pad_x0, pad_x1, pad_y0, pad_y1):\n", "        in_height, in_width = tf.shape(x)[1], tf.shape(x)[2]\n", "        minor_dim = tf.shape(x)[3]\n", "        kernel_h, kernel_w = k.shape\n\n", "        # Upsample (insert zeros).\n", "        x = tf.reshape(x, [-1, in_height, 1, in_width, 1, minor_dim])\n", "        x = tf.pad(x, [[0, 0], [0, 0], [0, up_y - 1], [0, 0], [0, up_x - 1], [0, 0]])\n", "        x = tf.reshape(x, [-1, in_height * up_y, in_width * up_x, minor_dim])\n\n", "        # Pad (crop if negative).\n", "        x = tf.pad(x, [\n", "            [0, 0], \n", "            [tf.math.maximum(pad_y0, 0), tf.math.maximum(pad_y1, 0)], \n", "            [tf.math.maximum(pad_x0, 0), tf.math.maximum(pad_x1, 0)], \n", "            [0, 0]\n", "        ])\n", "        x = x[:, tf.math.maximum(-pad_y0, 0): tf.shape(x)[1] - tf.math.maximum(-pad_y1, 0),\n", "            tf.math.maximum(-pad_x0, 0): tf.shape(x)[2] - tf.math.maximum(-pad_x1, 0), :]\n\n", "        # Convolve with filter.\n", "        x = tf.transpose(x, [0, 3, 1, 2])\n", "        x = tf.reshape(x, [-1, 1, in_height * up_y + pad_y0 + pad_y1, in_width * up_x + pad_x0 + pad_x1])\n", "        w = tf.constant(k[::-1, ::-1, np.newaxis, np.newaxis], dtype=x.dtype)\n", "        x = tf.nn.conv2d(x, w, strides=[1, 1, 1, 1], padding='VALID', data_format='NCHW')\n", "        x = tf.reshape(x, [-1,\n", "                        minor_dim,\n", "                        in_height * up_y + pad_y0 + pad_y1 - kernel_h + 1,\n", "                        in_width * up_x + pad_x0 + pad_x1 - kernel_w + 1])\n", "        x = tf.transpose(x, [0, 2, 3, 1])\n\n", "        # Downsample (throw away pixels).\n", "        return x[:, ::down_y, ::down_x, :]\n", "    @staticmethod\n", "    def simple_upfirdn_2d(x, k, up=1, down=1, pad0=0, pad1=0):\n", "        output_channel = tf.shape(x)[1]\n", "        x = tf.reshape(x, [-1, tf.shape(x)[2], tf.shape(x)[3], 1])\n", "        x = Onmoono.upfirdn_ref(x, k,\n", "                        up_x=up, up_y=up, down_x=down, down_y=down, pad_x0=pad0, pad_x1=pad1, pad_y0=pad0, pad_y1=pad1)\n", "        x = tf.reshape(x, [-1, output_channel, tf.shape(x)[1], tf.shape(x)[2]])\n", "        return x\n", "    @staticmethod\n", "    def upsample_conv_2d(x, k, weight, factor, gain):\n", "        x_height, x_width = tf.shape(x)[2], tf.shape(x)[3]\n", "        w_height, w_width = tf.shape(weight)[0], tf.shape(weight)[1]\n", "        w_ic, w_oc = tf.shape(weight)[2], tf.shape(weight)[3]\n\n", "        # Setup filter kernel.\n", "        k = k * (gain * (factor ** 2))\n", "        p = (k.shape[0] - factor) - (w_width - 1)\n", "        pad0 = (p + 1) // 2 + factor - 1\n", "        pad1 = p // 2 + 1\n\n", "        # Determine data dimensions.\n", "        strides = [1, 1, factor, factor]\n", "        output_shape = [1, w_oc, (x_height - 1) * factor + w_height, (x_width - 1) * factor + w_width]\n", "        num_groups = tf.shape(x)[1] // w_ic\n\n", "        # Transpose weights.\n", "        weight = tf.reshape(weight, [w_height, w_width, w_ic, num_groups, -1])\n", "        weight = tf.transpose(weight[::-1, ::-1], [0, 1, 4, 3, 2])\n", "        weight = tf.reshape(weight, [w_height, w_width, -1, num_groups * w_ic])\n\n", "        # Execute.\n", "        x = tf.nn.conv2d_transpose(x, weight, output_shape, strides, padding='VALID', data_format='NCHW')\n", "        x = Onmoono.simple_upfirdn_2d(x, k, pad0=pad0, pad1=pad1)\n", "        return x\n", "    @staticmethod\n", "    def conv_downsample_2d(x, k, weight, factor, gain):\n", "        w_height, w_width = tf.shape(weight)[0], tf.shape(weight)[1]\n\n", "        # Setup filter kernel.\n", "        k = k * gain\n", "        p = (k.shape[0] - factor) + (w_width - 1)\n", "        pad0 = (p + 1) // 2\n", "        pad1 = p // 2\n", "        strides = [1, 1, factor, factor]\n", "        x = Onmoono.simple_upfirdn_2d(x, k, pad0=pad0, pad1=pad1)\n", "        x = tf.nn.conv2d(x, weight, strides, padding='VALID', data_format='NCHW')\n", "        return x\n", "    @staticmethod\n", "    def upsample_2d(x, k, factor, gain):\n", "        # Setup filter kernel.\n", "        k = k * (gain * (factor ** 2))\n", "        p = k.shape[0] - factor\n", "        pad0 = (p + 1) // 2 + factor - 1\n", "        pad1 = p // 2\n", "        x = Onmoono.simple_upfirdn_2d(x, k, up=factor, pad0=pad0, pad1=pad1)\n", "        return x\n", "    @staticmethod\n", "    def downsample_2d(x, k, factor, gain):\n", "        # Setup filter kernel.\n", "        k = k * gain\n", "        p = k.shape[0] - factor\n", "        pad0 = (p + 1) // 2\n", "        pad1 = p // 2\n", "        x = Onmoono.simple_upfirdn_2d(x, k, down=factor, pad0=pad0, pad1=pad1)\n", "        return x"]}, {"cell_type": "markdown", "metadata": {}, "source": ["  ******************<br>\n", "<br>\n", "   -> https://github.com/moono/stylegan2-tf-2.x/tree/master/stylegan2/custom_layers.py <-<br>\n", "<br>\n", "  ******************"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    @staticmethod\n", "    def compute_runtime_coef(weight_shape, gain, lrmul):\n", "        fan_in = np.prod(weight_shape[:-1])  # [kernel, kernel, fmaps_in, fmaps_out] or [in, out]\n", "        he_std = gain / np.sqrt(fan_in)\n", "        init_std = 1.0 / lrmul\n", "        runtime_coef = he_std * lrmul\n", "        return init_std, runtime_coef"]}, {"cell_type": "markdown", "metadata": {}, "source": ["  ******************<br>\n", "<br>\n", "   -> https://github.com/moono/stylegan2-tf-2.x/blob/master/stylegan2/utils.py <-<br>\n", "<br>\n", "  ******************"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    @staticmethod\n", "    def lerp(a, b, t):\n", "        out = a + (b - a) * t\n", "        return out\n", "    @staticmethod\n", "    def lerp_clip(a, b, t):\n", "        out = a + (b - a) * tf.clip_by_value(t, 0.0, 1.0)\n", "        return out\n", "    @staticmethod\n", "    def adjust_dynamic_range(images, range_in, range_out, out_dtype):\n", "        scale = (range_out[1] - range_out[0]) / (range_in[1] - range_in[0])\n", "        bias = range_out[0] - range_in[0] * scale\n", "        images = images * scale + bias\n", "        images = tf.clip_by_value(images, range_out[0], range_out[1])\n", "        images = tf.cast(images, dtype=out_dtype)\n", "        return images\n", "    @staticmethod\n", "    def random_flip_left_right_nchw(images):\n", "        s = tf.shape(images)\n", "        mask = tf.random.uniform([s[0], 1, 1, 1], 0.0, 1.0)\n", "        mask = tf.tile(mask, [1, s[1], s[2], s[3]])\n", "        images = tf.where(mask < 0.5, images, tf.reverse(images, axis=[3]))\n", "        return images\n", "    @staticmethod\n", "    def preprocess_fit_train_image(images, res):\n", "        images = Onmoono.adjust_dynamic_range(images, range_in=(0.0, 255.0), range_out=(-1.0, 1.0), out_dtype=tf.dtypes.float32)\n", "        images = Onmoono.random_flip_left_right_nchw(images)\n", "        images.set_shape([None, 3, res, res])\n", "        return images\n", "    @staticmethod\n", "    def postprocess_images(images):\n", "        images = Onmoono.adjust_dynamic_range(images, range_in=(-1.0, 1.0), range_out=(0.0, 255.0), out_dtype=tf.dtypes.float32)\n", "        images = tf.transpose(images, [0, 2, 3, 1])\n", "        images = tf.cast(images, dtype=tf.dtypes.uint8)\n", "        return images\n", "    @staticmethod\n", "    def merge_batch_images(images, res, rows, cols):\n", "        batch_size = images.shape[0]\n", "        assert rows * cols == batch_size\n", "        canvas = np.zeros(shape=[res * rows, res * cols, 3], dtype=np.uint8)\n", "        for row in range(rows):\n", "            y_start = row * res\n", "            for col in range(cols):\n", "                x_start = col * res\n", "                index = col + row * cols\n", "                canvas[y_start:y_start + res, x_start:x_start + res, :] = images[index, :, :, :]\n", "        return canvas"]}, {"cell_type": "markdown", "metadata": {}, "source": ["  ******************<br>\n", "<br>\n", "   -> https://github.com/moono/stylegan2-tf-2.x/blob/master/train.py <-<br>\n", "<br>\n", "  ******************"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    @staticmethod\n", "    def filter_resolutions_featuremaps(resolutions, featuremaps, res):\n", "        index = resolutions.index(res)\n", "        filtered_resolutions = resolutions[:index + 1]\n", "        filtered_featuremaps = featuremaps[:index + 1]\n", "        return filtered_resolutions, filtered_featuremaps"]}, {"cell_type": "markdown", "metadata": {}, "source": ["  ******************<br>\n", "  Moono<br>\n", "  https://github.com/moono/stylegan2-encoder/blob/master/utils.py<br>\n", "  https://github.com/moono/stylegan2-tf-2.x/tree/master/stylegan2/tf_utils/utils.py<br>\n", "<br>\n", "  ******************"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    @staticmethod\n", "    def allow_memory_growth():\n", "        gpus = tf.config.experimental.list_physical_devices('GPU')\n", "        if gpus:\n", "            try:\n", "                # Currently, memory growth needs to be the same across GPUs\n", "                for gpu in gpus:\n", "                    tf.config.experimental.set_memory_growth(gpu, True)\n", "                logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n", "                print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n", "            except RuntimeError as e:\n", "                # Memory growth must be set before GPUs have been initialized\n", "                print(e)\n", "        return\n", "    @staticmethod\n", "    def adjust_dynamic_range(images, range_in, range_out, out_dtype):\n", "        scale = (range_out[1] - range_out[0]) / (range_in[1] - range_in[0])\n", "        bias = range_out[0] - range_in[0] * scale\n", "        images = images * scale + bias\n", "        images = tf.clip_by_value(images, range_out[0], range_out[1])\n", "        images = tf.cast(images, dtype=out_dtype)\n", "        return images"]}, {"cell_type": "markdown", "metadata": {}, "source": ["  ******************<br>\n", "  Moono<br>\n", "  https://github.com/lllyasviel/DanbooRegion/<br>\n", "  see licensing terms in https://github.com/lllyasviel/DanbooRegion<br>\n", "<br>\n", "  ******************<br>\n", "<br>\n", "  ******************"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class Onlllyas:\n", "    #   https://github.com/lllyasviel/DanbooRegion/blob/master/code/tricks.py\n", "    @staticmethod\n", "    def thinning(fillmap, max_iter=100):\n", "        \"\"\"Fill area of line with surrounding fill color.\n", "        # Arguments\n", "            fillmap: an image.\n", "            max_iter: max iteration number.\n", "        # Returns\n", "            an image.\n", "        \"\"\"\n", "        line_id = 0\n", "        h, w = fillmap.shape[:2]\n", "        result = fillmap.copy()\n", "        for iterNum in range(max_iter):\n", "            # Get points of line. if there is not point, stop.\n", "            line_points = np.where(result == line_id)\n", "            if not len(line_points[0]) > 0:\n", "                break\n\n", "            # Get points between lines and fills.\n", "            line_mask = np.full((h, w), 255, np.uint8)\n", "            line_mask[line_points] = 0\n", "            line_border_mask = cv2.morphologyEx(line_mask, cv2.MORPH_DILATE,\n", "                                                cv2.getStructuringElement(cv2.MORPH_CROSS, (3, 3)), anchor=(-1, -1),\n", "                                                iterations=1) - line_mask\n", "            line_border_points = np.where(line_border_mask == 255)\n", "            result_tmp = result.copy()\n", "            # Iterate over points, fill each point with nearest fill's id.\n", "            for i, _ in enumerate(line_border_points[0]):\n", "                x, y = line_border_points[1][i], line_border_points[0][i]\n", "                if x - 1 > 0 and result[y][x - 1] != line_id:\n", "                    result_tmp[y][x] = result[y][x - 1]\n", "                    continue\n", "                if x - 1 > 0 and y - 1 > 0 and result[y - 1][x - 1] != line_id:\n", "                    result_tmp[y][x] = result[y - 1][x - 1]\n", "                    continue\n", "                if y - 1 > 0 and result[y - 1][x] != line_id:\n", "                    result_tmp[y][x] = result[y - 1][x]\n", "                    continue\n", "                if y - 1 > 0 and x + 1 < w and result[y - 1][x + 1] != line_id:\n", "                    result_tmp[y][x] = result[y - 1][x + 1]\n", "                    continue\n", "                if x + 1 < w and result[y][x + 1] != line_id:\n", "                    result_tmp[y][x] = result[y][x + 1]\n", "                    continue\n", "                if x + 1 < w and y + 1 < h and result[y + 1][x + 1] != line_id:\n", "                    result_tmp[y][x] = result[y + 1][x + 1]\n", "                    continue\n", "                if y + 1 < h and result[y + 1][x] != line_id:\n", "                    result_tmp[y][x] = result[y + 1][x]\n", "                    continue\n", "                if y + 1 < h and x - 1 > 0 and result[y + 1][x - 1] != line_id:\n", "                    result_tmp[y][x] = result[y + 1][x - 1]\n", "                    continue\n", "            result = result_tmp.copy()\n", "        return result\n", "    @staticmethod\n", "    def topo_compute_normal(dist):\n", "        c = cv2.filter2D(dist, cv2.CV_32F, np.array([[-1, +1]]))\n", "        r = cv2.filter2D(dist, cv2.CV_32F, np.array([[-1], [+1]]))\n", "        h = np.zeros_like(c + r, dtype=np.float32) + 0.75\n", "        normal_map = np.stack([h, r, c], axis=2)\n", "        normal_map /= np.sum(normal_map ** 2.0, axis=2, keepdims=True) ** 0.5\n", "        return normal_map"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    @staticmethod    \n", "    #@njit\n", "    def count_all(labeled_array, all_counts):\n", "        #labeled_array:  [[[0 0 1]\n", "        #                  [0 0 1]\n", "        #                  [0 0 1]\n", "        #                  ...\n", "        M = labeled_array.shape[0] # 2048\n", "        N = labeled_array.shape[1] # 2048\n", "        print(\"count_all MN \", M, N)\n", "        for x in range(M):\n", "            for y in range(N):\n", "                i = labeled_array[x, y] - 1 # [-1 -1  0]\n", "                if i > -1:\n", "                    all_counts[i] = all_counts[i] + 1\n", "        return"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    @staticmethod    \n", "    @njit\n", "    def trace_all(labeled_array, xs, ys, cs):\n", "        M = labeled_array.shape[0]\n", "        N = labeled_array.shape[1]\n", "        for x in range(M):\n", "            for y in range(N):\n", "                current_label = labeled_array[x, y] - 1\n", "                if current_label > -1:\n", "                    current_label_count = cs[current_label]\n", "                    xs[current_label][current_label_count] = x\n", "                    ys[current_label][current_label_count] = y\n", "                    cs[current_label] = current_label_count + 1\n", "        return\n", "    @staticmethod\n", "    def find_all(labeled_array):\n", "        hist_size = int(np.max(labeled_array))\n", "        if hist_size == 0:\n", "            return []\n", "        all_counts = [0 for _ in range(hist_size)]\n", "        Onlllyas.count_all(labeled_array, all_counts)\n", "        xs = [np.zeros(shape=(item, ), dtype=np.uint32) for item in all_counts]\n", "        ys = [np.zeros(shape=(item, ), dtype=np.uint32) for item in all_counts]\n", "        cs = [0 for item in all_counts]\n", "        Onlllyas.trace_all(labeled_array, xs, ys, cs)\n", "        filled_area = []\n", "        for _ in range(hist_size):\n", "            filled_area.append((xs[_], ys[_]))\n", "        return filled_area\n", "    @staticmethod\n", "    def mk_resize(x, k):\n", "        if x.shape[0] < x.shape[1]:\n", "            s0 = k\n", "            s1 = int(x.shape[1] * (k / x.shape[0]))\n", "            s1 = s1 - s1 % 128\n", "            _s0 = 32 * s0\n", "            _s1 = int(x.shape[1] * (_s0 / x.shape[0]))\n", "            _s1 = (_s1 + 64) - (_s1 + 64) % 128\n", "        else:\n", "            s1 = k\n", "            s0 = int(x.shape[0] * (k / x.shape[1]))\n", "            s0 = s0 - s0 % 128\n", "            _s1 = 32 * s1\n", "            _s0 = int(x.shape[0] * (_s1 / x.shape[1]))\n", "            _s0 = (_s0 + 64) - (_s0 + 64) % 128\n", "        new_min = min(_s1, _s0)\n", "        raw_min = min(x.shape[0], x.shape[1])\n", "        if new_min < raw_min:\n", "            interpolation = cv2.INTER_AREA\n", "        else:\n", "            interpolation = cv2.INTER_LANCZOS4\n", "        y = cv2.resize(x, (_s1, _s0), interpolation=interpolation)\n", "        return y\n", "    @staticmethod\n", "    def k_resize(x, k):\n", "        if x.shape[0] < x.shape[1]:\n", "            s0 = k\n", "            s1 = int(x.shape[1] * (k / x.shape[0]))\n", "            s1 = s1 - s1 % 64\n", "            _s0 = 16 * s0\n", "            _s1 = int(x.shape[1] * (_s0 / x.shape[0]))\n", "            _s1 = (_s1 + 32) - (_s1 + 32) % 64\n", "        else:\n", "            s1 = k\n", "            s0 = int(x.shape[0] * (k / x.shape[1]))\n", "            s0 = s0 - s0 % 64\n", "            _s1 = 16 * s1\n", "            _s0 = int(x.shape[0] * (_s1 / x.shape[1]))\n", "            _s0 = (_s0 + 32) - (_s0 + 32) % 64\n", "        new_min = min(_s1, _s0)\n", "        raw_min = min(x.shape[0], x.shape[1])\n", "        if new_min < raw_min:\n", "            interpolation = cv2.INTER_AREA\n", "        else:\n", "            interpolation = cv2.INTER_LANCZOS4\n", "        y = cv2.resize(x, (_s1, _s0), interpolation=interpolation)\n", "        return y\n", "    @staticmethod\n", "    def sk_resize(x, k):\n", "        if x.shape[0] < x.shape[1]:\n", "            s0 = k\n", "            s1 = int(x.shape[1] * (k / x.shape[0]))\n", "            s1 = s1 - s1 % 16\n", "            _s0 = 4 * s0\n", "            _s1 = int(x.shape[1] * (_s0 / x.shape[0]))\n", "            _s1 = (_s1 + 8) - (_s1 + 8) % 16\n", "        else:\n", "            s1 = k\n", "            s0 = int(x.shape[0] * (k / x.shape[1]))\n", "            s0 = s0 - s0 % 16\n", "            _s1 = 4 * s1\n", "            _s0 = int(x.shape[0] * (_s1 / x.shape[1]))\n", "            _s0 = (_s0 + 8) - (_s0 + 8) % 16\n", "        new_min = min(_s1, _s0)\n", "        raw_min = min(x.shape[0], x.shape[1])\n", "        if new_min < raw_min:\n", "            interpolation = cv2.INTER_AREA\n", "        else:\n", "            interpolation = cv2.INTER_LANCZOS4\n", "        y = cv2.resize(x, (_s1, _s0), interpolation=interpolation)\n", "        return y\n", "    @staticmethod\n", "    def d_resize(x, d, fac=1.0):\n", "        new_min = min(int(d[1] * fac), int(d[0] * fac))\n", "        raw_min = min(x.shape[0], x.shape[1])\n", "        if new_min < raw_min:\n", "            interpolation = cv2.INTER_AREA\n", "        else:\n", "            interpolation = cv2.INTER_LANCZOS4\n", "        y = cv2.resize(x, (int(d[1] * fac), int(d[0] * fac)), interpolation=interpolation)\n", "        return y\n", "    @staticmethod\n", "    def n_resize(x, d):\n", "        y = cv2.resize(x, (d[1], d[0]), interpolation=cv2.INTER_NEAREST)\n", "        return y\n", "    @staticmethod\n", "    def s_resize(x, s):\n", "        if x.shape[0] < x.shape[1]:\n", "            s0 = x.shape[0]\n", "            s1 = int(float(s0) / float(s[0]) * float(s[1]))\n", "        else:\n", "            s1 = x.shape[1]\n", "            s0 = int(float(s1) / float(s[1]) * float(s[0]))\n", "        new_max = max(s1, s0)\n", "        raw_max = max(x.shape[0], x.shape[1])\n", "        if new_max < raw_max:\n", "            interpolation = cv2.INTER_AREA\n", "        else:\n", "            interpolation = cv2.INTER_LANCZOS4\n", "        y = cv2.resize(x, (s1, s0), interpolation=interpolation)\n", "        return y\n", "    @staticmethod\n", "    def min_resize(x, m):\n", "        if x.shape[0] < x.shape[1]:\n", "            s0 = m\n", "            s1 = int(float(m) / float(x.shape[0]) * float(x.shape[1]))\n", "        else:\n", "            s0 = int(float(m) / float(x.shape[1]) * float(x.shape[0]))\n", "            s1 = m\n", "        new_max = max(s1, s0)\n", "        raw_max = max(x.shape[0], x.shape[1])\n", "        if new_max < raw_max:\n", "            interpolation = cv2.INTER_AREA\n", "        else:\n", "            interpolation = cv2.INTER_LANCZOS4\n", "        y = cv2.resize(x, (s1, s0), interpolation=interpolation)\n", "        return y\n", "    @staticmethod\n", "    def n_min_resize(x, m):\n", "        if x.shape[0] < x.shape[1]:\n", "            s0 = m\n", "            s1 = int(float(m) / float(x.shape[0]) * float(x.shape[1]))\n", "        else:\n", "            s0 = int(float(m) / float(x.shape[1]) * float(x.shape[0]))\n", "            s1 = m\n", "        new_max = max(s1, s0)\n", "        raw_max = max(x.shape[0], x.shape[1])\n", "        y = cv2.resize(x, (s1, s0), interpolation=cv2.INTER_NEAREST)\n", "        return y\n", "    @staticmethod\n", "    def h_resize(x, m):\n", "        s0 = m\n", "        s1 = int(float(m) / float(x.shape[0]) * float(x.shape[1]))\n", "        new_max = max(s1, s0)\n", "        raw_max = max(x.shape[0], x.shape[1])\n", "        if new_max < raw_max:\n", "            interpolation = cv2.INTER_AREA\n", "        else:\n", "            interpolation = cv2.INTER_LANCZOS4\n", "        y = cv2.resize(x, (s1, s0), interpolation=interpolation)\n", "        return y\n", "    @staticmethod\n", "    def w_resize(x, m):\n", "        s0 = int(float(m) / float(x.shape[1]) * float(x.shape[0]))\n", "        s1 = m\n", "        new_max = max(s1, s0)\n", "        raw_max = max(x.shape[0], x.shape[1])\n", "        if new_max < raw_max:\n", "            interpolation = cv2.INTER_AREA\n", "        else:\n", "            interpolation = cv2.INTER_LANCZOS4\n", "        y = cv2.resize(x, (s1, s0), interpolation=interpolation)\n", "        return y\n", "    @staticmethod\n", "    def max_resize(x, m):\n", "        if x.shape[0] > x.shape[1]:\n", "            s0 = m\n", "            s1 = int(float(m) / float(x.shape[0]) * float(x.shape[1]))\n", "        else:\n", "            s0 = int(float(m) / float(x.shape[1]) * float(x.shape[0]))\n", "            s1 = m\n", "        new_max = max(s1, s0)\n", "        raw_max = max(x.shape[0], x.shape[1])\n", "        if new_max < raw_max:\n", "            interpolation = cv2.INTER_AREA\n", "        else:\n", "            interpolation = cv2.INTER_LANCZOS4\n", "        y = cv2.resize(x, (s1, s0), interpolation=interpolation)\n", "        return y\n", "    @staticmethod\n", "    def vis(region_map, color_map):\n", "        color = Onlllyas.d_resize(color_map, region_map.shape)\n", "        indexs = (region_map.astype(np.float32)[:, :, 0] * 255 + region_map.astype(np.float32)[:, :, 1]) * 255 + region_map.astype(np.float32)[:, :, 2]\n", "        result = np.zeros_like(color, dtype=np.uint8)\n", "        for ids in [np.where(indexs == idsn) for idsn in np.unique(indexs).tolist()]:\n", "            result[ids] = np.median(color[ids], axis=0)\n", "        return result"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    # https://github.com/lllyasviel/DanbooRegion/blob/master/code/skeletonize.py\n", "    @staticmethod   \n", "    def get_skeleton(region_map, filterstrength=5.0):\n", "        from skimage.morphology import skeletonize, dilation    \n", "        Xp = np.pad(region_map, [[0, 1], [0, 0], [0, 0]], 'symmetric').astype(np.float32)\n", "        Yp = np.pad(region_map, [[0, 0], [0, 1], [0, 0]], 'symmetric').astype(np.float32)\n", "        X = np.sum((Xp[1:, :, :] - Xp[:-1, :, :]) ** 2.0, axis=2) ** 0.5\n", "        Y = np.sum((Yp[:, 1:, :] - Yp[:, :-1, :]) ** 2.0, axis=2) ** 0.5\n", "        edge = np.zeros_like(region_map)[:, :, 0]\n", "        edge[X > 0] = 255\n", "        edge[Y > 0] = 255\n", "        edge[0, :] = 255\n", "        edge[-1, :] = 255\n", "        edge[:, 0] = 255\n", "        edge[:, -1] = 255\n", "        skeleton = 1.0 - dilation(edge.astype(np.float32) / 255.0)\n", "        skeleton = skeletonize(skeleton)\n", "        skeleton = (skeleton * 255.0).clip(0, 255).astype(np.uint8)\n", "        field = np.random.uniform(low=0.0, high=255.0, size=edge.shape).clip(0, 255).astype(np.uint8)\n", "        field[skeleton > 0] = 255\n", "        field[edge > 0] = 0\n", "        filter = np.array([\n", "            [0, 1, 0],\n", "            [1, 1, 1],\n", "            [0, 1, 0]],\n", "            dtype=np.float32) / filterstrength\n", "        height = np.random.uniform(low=0.0, high=255.0, size=field.shape).astype(np.float32)\n", "        for _ in range(512):\n", "            height = cv2.filter2D(height, cv2.CV_32F, filter)\n", "            height[skeleton > 0] = 255.0\n", "            height[edge > 0] = 0.0\n", "        return height.clip(0, 255).astype(np.uint8)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    # https://github.com/lllyasviel/DanbooRegion/blob/master/code/skeleton2regions.py\n", "    @staticmethod \n", "    def skeleton_to_regions(skeleton_map): # get_regions\n", "        marker = skeleton_map[:, :, 0]\n", "        normal = Onlllyas.topo_compute_normal(marker) * 127.5 + 127.5\n", "        marker[marker > 100] = 255\n", "        marker[marker < 255] = 0\n", "        labels, nil = label(marker / 255)\n", "        water = cv2.watershed(normal.clip(0, 255).astype(np.uint8), labels.astype(np.int32)) + 1\n", "        water = Onlllyas.thinning(water)\n", "        all_region_indices = Onlllyas.find_all(water)\n", "        regions = np.zeros_like(skeleton_map, dtype=np.uint8)\n", "        for region_indices in all_region_indices:\n", "            regions[region_indices] = np.random.randint(low=0, high=255, size=(3,)).clip(0, 255).astype(np.uint8)\n", "        return regions"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    # https://github.com/lllyasviel/DanbooRegion/blob/master/code/rotate.py\n", "    @staticmethod \n", "    def rotate_image(image, angle):\n", "        \"\"\"\n", "        Rotates an OpenCV 2 / NumPy image about it's centre by the given angle\n", "        (in degrees). The returned image will be large enough to hold the entire\n", "        new image, with a black background\n", "        \"\"\"\n\n", "        # Get the image size\n", "        # No that's not an error - NumPy stores image matricies backwards\n", "        image_size = (image.shape[1], image.shape[0])\n", "        image_center = tuple(np.array(image_size) / 2)\n\n", "        # Convert the OpenCV 3x2 rotation matrix to 3x3\n", "        rot_mat = np.vstack(\n", "            [cv2.getRotationMatrix2D(image_center, angle, 1.0), [0, 0, 1]]\n", "        )\n", "        rot_mat_notranslate = np.matrix(rot_mat[0:2, 0:2])\n\n", "        # Shorthand for below calcs\n", "        image_w2 = image_size[0] * 0.5\n", "        image_h2 = image_size[1] * 0.5\n\n", "        # Obtain the rotated coordinates of the image corners\n", "        rotated_coords = [\n", "            (np.array([-image_w2,  image_h2]) * rot_mat_notranslate).A[0],\n", "            (np.array([ image_w2,  image_h2]) * rot_mat_notranslate).A[0],\n", "            (np.array([-image_w2, -image_h2]) * rot_mat_notranslate).A[0],\n", "            (np.array([ image_w2, -image_h2]) * rot_mat_notranslate).A[0]\n", "        ]\n\n", "        # Find the size of the new image\n", "        x_coords = [pt[0] for pt in rotated_coords]\n", "        x_pos = [x for x in x_coords if x > 0]\n", "        x_neg = [x for x in x_coords if x < 0]\n", "        y_coords = [pt[1] for pt in rotated_coords]\n", "        y_pos = [y for y in y_coords if y > 0]\n", "        y_neg = [y for y in y_coords if y < 0]\n", "        right_bound = max(x_pos)\n", "        left_bound = min(x_neg)\n", "        top_bound = max(y_pos)\n", "        bot_bound = min(y_neg)\n", "        new_w = int(abs(right_bound - left_bound))\n", "        new_h = int(abs(top_bound - bot_bound))\n\n", "        # We require a translation matrix to keep the image centred\n", "        trans_mat = np.matrix([\n", "            [1, 0, int(new_w * 0.5 - image_w2)],\n", "            [0, 1, int(new_h * 0.5 - image_h2)],\n", "            [0, 0, 1]\n", "        ])\n\n", "        # Compute the tranform for the combined rotation and translation\n", "        affine_mat = (np.matrix(trans_mat) * np.matrix(rot_mat))[0:2, :]\n\n", "        # Apply the transform\n", "        result = cv2.warpAffine(\n", "            image,\n", "            affine_mat,\n", "            (new_w, new_h),\n", "            flags=cv2.INTER_LINEAR\n", "        )\n", "        return result\n", "    @staticmethod \n", "    def largest_rotated_rect(w, h, angle):\n", "        \"\"\"\n", "        Given a rectangle of size wxh that has been rotated by 'angle' (in\n", "        radians), computes the width and height of the largest possible\n", "        axis-aligned rectangle within the rotated rectangle.\n", "        Original JS code by 'Andri' and Magnus Hoff from Stack Overflow\n", "        Converted to Python by Aaron Snoswell\n", "        \"\"\"\n", "        quadrant = int(math.floor(angle / (math.pi / 2))) & 3\n", "        sign_alpha = angle if ((quadrant & 1) == 0) else math.pi - angle\n", "        alpha = (sign_alpha % math.pi + math.pi) % math.pi\n", "        bb_w = w * math.cos(alpha) + h * math.sin(alpha)\n", "        bb_h = w * math.sin(alpha) + h * math.cos(alpha)\n", "        gamma = math.atan2(bb_w, bb_w) if (w < h) else math.atan2(bb_w, bb_w)\n", "        delta = math.pi - alpha - gamma\n", "        length = h if (w < h) else w\n", "        d = length * math.cos(alpha)\n", "        a = d * math.sin(alpha) / math.sin(delta)\n", "        y = a * math.cos(gamma)\n", "        x = y * math.tan(gamma)\n", "        return (\n", "            bb_w - 2 * x,\n", "            bb_h - 2 * y\n", "        )\n", "    @staticmethod \n", "    def crop_around_center(image, width, height):\n", "        \"\"\"\n", "        Given a NumPy / OpenCV 2 image, crops it to the given width and height,\n", "        around it's centre point\n", "        \"\"\"\n", "        image_size = (image.shape[1], image.shape[0])\n", "        image_center = (int(image_size[0] * 0.5), int(image_size[1] * 0.5))\n", "        if(width > image_size[0]):\n", "            width = image_size[0]\n", "        if(height > image_size[1]):\n", "            height = image_size[1]\n", "        x1 = int(image_center[0] - width * 0.5)\n", "        x2 = int(image_center[0] + width * 0.5)\n", "        y1 = int(image_center[1] - height * 0.5)\n", "        y2 = int(image_center[1] + height * 0.5)\n", "        return image[y1:y2, x1:x2]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    # https://github.com/lllyasviel/DanbooRegion/blob/master/code/datasets.py\n", "    @staticmethod \n", "    def np_RGB2GRAY(img):\n", "        R = img[:, :, 0].astype(np.float32)\n", "        G = img[:, :, 1].astype(np.float32)\n", "        B = img[:, :, 2].astype(np.float32)\n", "        r = np.random.rand()\n", "        g = np.random.rand()\n", "        b = np.random.rand()\n", "        s = r + g + b\n", "        r /= s\n", "        g /= s\n", "        b /= s\n", "        light = R * r + G * g + B * b\n", "        light -= np.min(light)\n", "        light /= np.max(light)\n", "        a = np.random.rand() * 0.4\n", "        b = 1 - np.random.rand() * 0.4\n", "        light = light.clip(a, b)\n", "        light -= np.min(light)\n", "        light /= np.max(light)\n", "        light = light.clip(0, 1)\n", "        light = (light * 255.0).astype(np.uint8)\n", "        return light\n", "    @staticmethod \n", "    def handle_next():\n", "        indice = np.random.randint(low=0, high=3377)\n", "        paint_r_mat = cv2.imread('./DanbooRegion2020/train/' + str(indice) + '.image.png')\n", "        sketch_r_mat = cv2.imread('./DanbooRegion2020/train/' + str(indice) + '.skeleton.png')\n", "        image_height, image_width = sketch_r_mat.shape[0:2]\n", "        paint_r_mat = Onlllyas.d_resize(paint_r_mat, sketch_r_mat.shape)\n", "        if np.random.rand() < 0.5:\n", "            ri = np.random.rand() * 360.0\n", "            paint_r_mat = crop_around_center(rotate_image(paint_r_mat, ri), *largest_rotated_rect(image_width, image_height, math.radians(ri)))\n", "            sketch_r_mat = crop_around_center(rotate_image(sketch_r_mat, ri), *largest_rotated_rect(image_width, image_height, math.radians(ri)))\n", "            kernel = np.random.randint(520, 650)\n", "        else:\n", "            kernel = np.random.randint(520, 1024)\n", "        raw_s0 = float(paint_r_mat.shape[0])\n", "        raw_s1 = float(paint_r_mat.shape[1])\n", "        if raw_s0 < raw_s1:\n", "            new_s0 = int(kernel)\n", "            new_s1 = int(kernel / raw_s0 * raw_s1)\n", "        else:\n", "            new_s1 = int(kernel)\n", "            new_s0 = int(kernel / raw_s1 * raw_s0)\n", "        c0 = int(np.random.rand() * float(new_s0 - 512))\n", "        c1 = int(np.random.rand() * float(new_s1 - 512))\n", "        paint_mat = Onlllyas.d_resize(paint_r_mat, (new_s0, new_s1))[c0:c0 + 512, c1:c1 + 512, :]\n", "        sketch_mat = Onlllyas.d_resize(sketch_r_mat, (new_s0, new_s1))[c0:c0 + 512, c1:c1 + 512, 0:1]\n", "        if np.random.rand() < 0.5:\n", "            sketch_mat = np.fliplr(sketch_mat)\n", "            paint_mat = np.fliplr(paint_mat)\n", "        if np.random.rand() < 0.5:\n", "            sketch_mat = np.flipud(sketch_mat)\n", "            paint_mat = np.flipud(paint_mat)\n", "        if np.random.rand() < 0.5:\n", "            paint_mat = np.stack([np_RGB2GRAY(paint_mat), np_RGB2GRAY(paint_mat), np_RGB2GRAY(paint_mat)], axis=2)\n", "        if np.random.rand() < 0.5:\n", "            for _ in range(int(np.random.randint(low=0, high=5))):\n", "                paint_mat = cv2.GaussianBlur(paint_mat, (0, 0), 2.0)\n", "        if np.random.rand() < 0.5:\n", "            for _ in range(int(np.random.randint(low=0, high=5))):\n", "                paint_mat = cv2.medianBlur(paint_mat, 3)\n", "        return sketch_mat, paint_mat\n", "    @staticmethod \n", "    def handle_batch(batch_size=4):\n", "        sketch_batch = []\n", "        paint_batch = []\n", "        for _ in range(batch_size):\n", "            sketch_mat, paint_mat = handle_next()\n", "            sketch_batch.append(sketch_mat)\n", "            paint_batch.append(paint_mat)\n", "        sketch_batch = np.stack(sketch_batch, axis=0)\n", "        paint_batch = np.stack(paint_batch, axis=0)\n", "        return sketch_batch, paint_batch"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    # https://github.com/lllyasviel/DanbooRegion/blob/master/code/segment.py\n", "    @staticmethod     \n", "    def go_flipped_vector(x):\n", "        #a = go_vector(x)\n", "        #b = np.fliplr(go_vector(np.fliplr(x)))\n", "        #c = np.flipud(go_vector(np.flipud(x)))\n", "        #d = np.flipud(np.fliplr(go_vector(np.flipud(np.fliplr(x)))))\n", "        print(f'go_flipped_vector: {type(x)} {np.shape(x)}')\n", "        a = x # <class 'numpy.ndarray'> (2944, 2048, 3)\n", "        b = np.fliplr(np.fliplr(x))\n", "        c = np.flipud(np.flipud(x))\n", "        d = np.flipud(np.fliplr(np.flipud(np.fliplr(x))))\n", "        return (a + b + c + d) / 4.0\n", "    @staticmethod \n", "    def go_transposed_vector(x):\n", "        a = Onlllyas.go_flipped_vector(x)\n", "        b = np.transpose(Onlllyas.go_flipped_vector(np.transpose(x, [1, 0, 2])), [1, 0, 2])\n", "        return (a + b) / 2.0"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    #https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.label.html\n", "    from scipy.ndimage import label\n", "    @staticmethod \n", "    def get_fill(image):\n", "        labeled_array, num_features = label(image / 255)\n", "        # num_features: 357\n", "        # labeled_array: <class 'numpy.ndarray'> (2048, 2048, 3)\n", "        # labeled_array: [[[0 0 1] [0 0 1] [0 0 1] ...\n", "        filled_area = Onlllyas.find_all(labeled_array)\n", "        return filled_area\n", "    @staticmethod \n", "    def up_fill(fills, cur_fill_map):\n", "        new_fillmap = cur_fill_map.copy()\n", "        padded_fillmap = np.pad(cur_fill_map, [[1, 1], [1, 1]], 'constant', constant_values=0)\n", "        max_id = np.max(cur_fill_map)\n", "        for item in fills:\n", "            points0 = padded_fillmap[(item[0] + 1, item[1] + 0)]\n", "            points1 = padded_fillmap[(item[0] + 1, item[1] + 2)]\n", "            points2 = padded_fillmap[(item[0] + 0, item[1] + 1)]\n", "            points3 = padded_fillmap[(item[0] + 2, item[1] + 1)]\n", "            all_points = np.concatenate([points0, points1, points2, points3], axis=0)\n", "            pointsets, pointcounts = np.unique(all_points[all_points > 0], return_counts=True)\n", "            if len(pointsets) == 1 and item[0].shape[0] < 128:\n", "                new_fillmap[item] = pointsets[0]\n", "            else:\n", "                max_id += 1\n", "                new_fillmap[item] = max_id\n", "        return new_fillmap\n", "    @staticmethod \n", "    def segment(image):\n", "        #raw_img = go_srcnn(Onlllyas.min_resize(image, 512)).clip(0, 255).astype(np.uint8)\n", "        raw_img = image\n", "        img_2048 = Onlllyas.min_resize(raw_img, 2048)\n", "        height = Onlllyas.d_resize(Onlllyas.go_transposed_vector(Onlllyas.mk_resize(raw_img, 64)), img_2048.shape) * 255.0\n", "        final_height = height.copy()\n", "        height += (height - cv2.GaussianBlur(height, (0, 0), 3.0)) * 10.0\n", "        height = height.clip(0, 255).astype(np.uint8)\n", "        marker = height.copy()\n", "        marker[marker > 135] = 255\n", "        marker[marker < 255] = 0\n", "        fills = Onlllyas.get_fill(marker / 255)\n", "        for fill in fills:\n", "            if fill[0].shape[0] < 64:\n", "                marker[fill] = 0\n", "        filter = np.array([\n", "            [0, 1, 0],\n", "            [1, 1, 1],\n", "            [0, 1, 0]],\n", "            dtype=np.uint8)\n", "        big_marker = cv2.erode(marker, filter, iterations=5)\n", "        fills = Onlllyas.get_fill(big_marker / 255)\n", "        for fill in fills:\n", "            if fill[0].shape[0] < 64:\n", "                big_marker[fill] = 0\n", "        big_marker = cv2.dilate(big_marker, filter, iterations=5)\n", "        small_marker = marker.copy()\n", "        small_marker[big_marker > 127] = 0\n", "        fin_labels, nil = label(big_marker / 255)\n", "        fin_labels = up_fill(Onlllyas.get_fill(small_marker), fin_labels)\n", "        water = cv2.watershed(img_2048.clip(0, 255).astype(np.uint8), fin_labels.astype(np.int32)) + 1\n", "        water = Onlllyas.thinning(water)\n", "        all_region_indices = Onlllyas.find_all(water)\n", "        regions = np.zeros_like(img_2048, dtype=np.uint8)\n", "        for region_indices in all_region_indices:\n", "            regions[region_indices] = np.random.randint(low=0, high=255, size=(3,)).clip(0, 255).astype(np.uint8)\n", "        result = np.zeros_like(img_2048, dtype=np.uint8)\n", "        for region_indices in all_region_indices:\n", "            result[region_indices] = np.median(img_2048[region_indices], axis=0)\n", "        return final_height.clip(0, 255).astype(np.uint8), regions.clip(0, 255).astype(np.uint8), result.clip(0, 255).astype(np.uint8)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["  ******************<br>\n", "  CLS ONVGG<br>\n", "<br>\n", "  ******************"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class Onvgg:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    @staticmethod\n", "    def vgg_deprocess(img):\n", "        VGG_RGB_MEAN = [123.68, 116.78, 103.94]\n", "        vgg_rgb_mean_arr = np.array(VGG_RGB_MEAN)\n", "        imgpost = np.copy(img)\n", "        imgpost += vgg_rgb_mean_arr.reshape((1,1,1,3))\n", "        \n", "        imgpost = imgpost[0] # (1, h, w, d) +> (h, w, d)\n", "        imgpost = np.clip(imgpost, 0, 255).astype('uint8')\n", "        \n", "        imgpost = imgpost[...,::-1] # RGB => BGR\n", "        return imgpost\n", "    @staticmethod\n", "    def vgg_preprocess(img):\n", "        VGG_RGB_MEAN = [123.68, 116.779, 103.939]\n", "        vgg_rgb_mean_arr = np.array(VGG_RGB_MEAN).reshape((1,1,1,3))\n", "        imgpre = np.copy(img)\n", "        imgpre = imgpre[...,::-1] # BGR to RGB\n", "        imgpre = imgpre.astype(np.float32) # _e_\n", "        imgpre = imgpre[np.newaxis,:,:,:] # (h, w, d) => (1, h, w, d)\n", "        imgpre -= vgg_rgb_mean_arr\n", "        return imgpre"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    @staticmethod\n", "    def path_to_tvgg(image_path): # _e_\n", "        # Util function to open, resize and format pictures into appropriate tensors\n", "        img = tf.keras.preprocessing.image.load_img(image_path, target_size=(img_nrows, img_ncols))\n", "        img = tf.keras.preprocessing.image.img_to_array(img)\n", "        img = np.expand_dims(img, axis=0)\n", "        img = vgg19.preprocess_input(img)\n", "        return tf.convert_to_tensor(img)\n", "    @staticmethod   \n", "    def cv2_trgb(img, title=\"img\", wait=3000):\n", "        img = Onformat.vgg_deprocess(img)\n", "        cv_img(img, title, wait)\n", "    @staticmethod\n", "    def cv2_path(path): #  _e_\n", "        img = cv2.imread(path, cv2.IMREAD_COLOR)\n", "        img = Onformat.vgg_preprocess(img)\n", "        img = Onformat.vgg_deprocess(img)\n", "        cv2.imshow('img', img)\n", "        cv2.waitKey(2000)   \n", "    @staticmethod\n", "    def bgr_to_rgb_vgg(img):\n", "        VGG_RGB_MEAN = [123.68, 116.779, 103.939]\n", "        vgg_rgb_mean_arr = np.array(VGG_RGB_MEAN)\n", "        imgpre = np.copy(img)\n", "        # bgr to rgb\n", "        imgpre = imgpre[...,::-1]\n", "        # shape (h, w, d) to (1, h, w, d)\n", "        imgpre = imgpre[np.newaxis,:,:,:]\n", "        imgpre -= vgg_rgb_mean_arr.reshape((1,1,1,3))\n", "        return imgpre\n", "    @staticmethod\n", "    def tbgr_to_trgb_vgg(img):\n", "        # Keras works with batches of images\n", "        # So, the first dimension is used for the number of samples (or images)\n", "        # vgg_mean = np.array([123.68, 116.779, 103.939], dtype=np.float32).reshape((3,1,1))\n", "        VGG_BGR_MEAN = [103.939, 116.779, 123.68]\n", "        vgg_bgr_mean_arr = np.array(VGG_BGR_MEAN)\n\n", "        # img = img[0] # np.squeeze(img, axis = 0) # \n", "        img = img[...,::-1] # bgr to rgb\n", "        # img = img[np.newaxis,:,:,:] # shape (h, w, d) to (1, h, w, d)\n", "        img -= vgg_bgr_mean_arr.reshape((1,1,1,3))\n", "        img = tf.convert_to_tensor(img)\n", "        return img\n", "    @staticmethod\n", "    def bgr_to_tnua_2_vgg(img):\n", "        VGG_RGB_MEAN = [123.68, 116.779, 103.939]\n", "        vgg_rgb_mean_arr = np.array(VGG_RGB_MEAN)\n\n", "        # bgr to rgb\n", "        img = img[...,::-1]\n", "        # shape (h, w, d) to (1, h, w, d)\n", "        img = img[np.newaxis,:,:,:]\n", "        img -= vgg_rgb_mean_arr.reshape((1,1,1,3))\n", "        return img\n", "    @staticmethod\n", "    def tbgr_to_tnua_2_vgg(img):\n", "        VGG_RGB_MEAN = [123.68, 116.779, 103.939]\n", "        vgg_rgb_mean_arr = np.array(VGG_RGB_MEAN)    \n", "        img += vgg_rgb_mean_arr.reshape((1,1,1,3))\n", "        # shape (1, h, w, d) to (h, w, d)\n", "        img = img[0]\n", "        img = np.clip(img, 0, 255).astype('uint8')\n", "        # rgb to bgr\n", "        img = img[...,::-1]\n", "        return img\n", "    @staticmethod\n", "    def bgrs_to_tnuas(inputs):\n", "        pretensors = []\n", "        for item in inputs:\n", "            preitem = Onformat.tbgr_to_trgb_vgg(item)\n", "            pretensors.append(preitem)\n", "        return pretensors\n", "    @staticmethod\n", "    def bgrs_to_tnuas(inputs):\n", "        pretensors = []\n", "        for item in inputs:\n", "            preitem = Onformat.tbgr_to_trgb_vgg(item)\n", "            pretensors.append(preitem)\n", "        return pretensors\n", "    @staticmethod\n", "    def tnua_to_vgg(tnua, width=512, height=512):\n", "        tnua = tf.image.resize(tnua, (width, height))\n", "        bgr = tnua*255.0 \n", "        vgg = Onvgg.tbgr_to_trgb_vgg(bgr)\n", "        return vgg"]}, {"cell_type": "markdown", "metadata": {}, "source": ["  ******************<br>\n", "   TFRecordExporter: export images to tf records<br>\n", "      relux<br>\n", "      https://github.com/rolux/stylegan2encoder/dataset_tool.py<br>\n", "<br>\n", "  ******************"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class TFRecordExporter:\n", "    def __init__(self, \n", "        tfrecord_dir, \n", "        expected_images, \n", "        tfr_prefix='tfrecord', \n", "        progress_interval=10,\n", "        verbose = True):\n", "        self.tfrecord_dir       = tfrecord_dir\n", "        self.tfr_prefix         = tfr_prefix\n", "        self.expected_images    = expected_images\n", "        self.cur_images         = 0\n", "        self.shape              = None\n", "        self.resolution_log2    = None\n", "        self.tfr_writers        = []\n", "        self.verbose     = verbose\n", "        self.progress_interval  = progress_interval\n", "        if self.verbose:\n", "            print(f'Creating dataset in {tfrecord_dir}')\n", "        os.makedirs(tfrecord_dir, exist_ok=True)\n", "    def close(self):\n", "        if self.verbose:\n", "            print('%-40s\\r' % 'Flushing data...', end='', flush=True)\n", "        for tfr_writer in self.tfr_writers:\n", "            tfr_writer.close()\n", "        self.tfr_writers = []\n", "        if self.verbose:\n", "            print('%-40s\\r' % '', end='', flush=True)\n", "            print('Added %d image%s.' % (self.cur_images, 's'[:self.cur_images > 1]))\n", "    def choose_shuffled_order(self): # Note: Images and labels must be added in shuffled order.\n", "        order = np.arange(self.expected_images)\n", "        np.random.RandomState(123).shuffle(order)\n", "        return order\n", "    def add_image(self, img):\n", "        if self.verbose and self.cur_images % self.progress_interval == 0:\n", "            print('%d / %d\\r' % (self.cur_images, self.expected_images), end='', flush=True)\n", "        if self.shape is None:\n", "            self.shape = img.shape\n", "            self.resolution_log2 = int(np.log2(self.shape[1]))\n\n", "            # print(\"add_image shape[1]: %s\" %self.shape[1])\n", "            # print(\"add_image resolution_log2: %s\" %self.resolution_log2)\n", "            assert self.shape[0] in [1, 3], f\"shape[0] assertion failed\"\n", "            assert self.shape[1] == self.shape[2], f\"shape[1]:shape[2] assertion failed\"\n", "            assert self.shape[1] == 2**self.resolution_log2, f\"shape is pow(2) assertion failed\"\n", "            tfr_opt = tf.io.TFRecordOptions(compression_type = None)\n", "            for lod in range(self.resolution_log2 - 1):\n", "                tfr_file = os.path.join(self.tfrecord_dir, self.tfr_prefix + '-r%02d.tfrecords' % (self.resolution_log2 - lod))\n", "                self.tfr_writers.append(tf.io.TFRecordWriter(tfr_file, tfr_opt))\n", "        assert img.shape == self.shape, \"image shapes are not equal\"\n", "        for lod, tfr_writer in enumerate(self.tfr_writers):\n", "            if lod:\n", "                img = img.astype(np.float32)\n", "                img = (img[:, 0::2, 0::2] + img[:, 0::2, 1::2] + img[:, 1::2, 0::2] + img[:, 1::2, 1::2]) * 0.25\n\n", "            # assume normalized input\n", "            quant = np.rint(img * 255).clip(0, 255).astype(np.uint8) # img * 255  # _e_\n", "            ex = tf.train.Example(features=tf.train.Features(feature={\n", "                'shape': tf.train.Feature(int64_list=tf.train.Int64List(value=quant.shape)),\n", "                'data': tf.train.Feature(bytes_list=tf.train.BytesList(value=[quant.tostring()]))}))\n", "                \n", "            # https://www.tensorflow.org/tutorials/load_data/tfrecord \n", "            feature = ex.SerializeToString()\n", "            tfr_writer.write(feature)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": [" \n", "            example_proto = tf.train.Example.FromString(feature)           \n\n", "            # feature_description = {\n", "            #     'shape': tf.io.FixedLenFeature([3], tf.int64),\n", "            #     'data': tf.io.FixedLenFeature([], tf.string),\n", "            # }\n", "            # def _parse_function(example_proto):\n", "            #     # Parse the input `tf.Example` proto using the dictionary above.\n", "            #     return tf.io.parse_single_example(example_proto, feature_description)\n", "            # parsed_dataset = example_proto.map(_parse_function)\n", "            # print(parsed_dataset)\n", "            examples = []\n", "            data = example_proto.features.feature[\"data\"]\n", "            shape = example_proto.features.feature[\"shape\"]\n", "            shape = shape.int64_list.value"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["            ndata = np.frombuffer(data.bytes_list.value[0], dtype=np.uint8)\n", "            im_arr =  ndata.reshape(shape[0], shape[1], shape[2])\n\n", "            # im_arr = im_arr.reshape(shape[2], shape[0], shape[1])\n", "            # im_arr = im_arr / 255\n", "            im_arr = im_arr.transpose([1, 2, 0])\n", "            imgstoplot = []\n", "            imgstoplot.append(Image.fromarray(im_arr))\n\n", "            # plt.imshow(im_arr)\n", "            # image = Image.fromarray(im_arr)\n", "            # image = im_arr\n", "            # plt.show()\n", "        self.cur_images += 1\n", "    def add_labels(self, labels):\n", "        if self.verbose:\n", "            print('%-40s\\r' % 'Saving labels...', end='', flush=True)\n", "        assert labels.shape[0] == self.cur_images\n", "        with open(self.tfr_prefix + '-rxx.labels', 'wb') as f:\n", "            np.save(f, labels.astype(np.float32))\n", "    def __enter__(self):\n", "        return self\n", "    def __exit__(self, *args):\n", "        self.close()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# -*- coding: utf-8 -*-\n", "# \n", "# # Copyright (c) 2019, NVIDIA Corporation. All rights reserved.\n", "#\n", "import os\n", "import io\n", "from io import StringIO\n", "import time\n", "import argparse\n", "import functools\n", "import errno\n", "import scipy\n", "import scipy.io\n", "import requests\n", "import zipfile\n", "import random\n", "import datetime\n", "        \n", "from functools import partial\n", "from importlib import import_module"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import logging\n", "logging.getLogger('tensorflow').setLevel(logging.ERROR)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "from numpy import *"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import math\n", "from math import floor, log2\n", "from random import random\n", "from pylab import *"]}, {"cell_type": "markdown", "metadata": {}, "source": ["import IPython.display as display"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from IPython.core.display import display"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import PIL\n", "from PIL import Image\n", "PIL.Image.MAX_IMAGE_PIXELS = 933120000"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import scipy.ndimage as pyimg"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import cv2\n", "import imageio\n", "import glob"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import matplotlib as mpl\n", "import matplotlib.pyplot as plt \n", "import matplotlib.image as mgimg\n", "import matplotlib.animation as anim\n", "mpl.rcParams['figure.figsize'] = (12,12)\n", "mpl.rcParams['axes.grid'] = False"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import shutil\n", "import gdown"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import sys"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import tensorflow as tf \n", "from tensorflow.keras import initializers, regularizers, constraints\n", "from tensorflow.keras import backend as K\n", "from tensorflow.keras import layers\n", "from tensorflow.keras.layers import Layer, InputSpec\n", "from tensorflow.keras.layers import BatchNormalization, Activation, ZeroPadding2D, UpSampling2D, Conv2D\n", "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout, LeakyReLU\n", "from tensorflow.keras.models import Sequential, Model\n", "from tensorflow.keras.optimizers import Adam\n", "from tensorflow.python.keras.utils import conv_utils"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from tensorflow.keras.layers import Lambda\n", "from tensorflow.keras.layers import add\n", "from tensorflow.keras.layers import AveragePooling2D\n", "from tensorflow.keras.initializers import VarianceScaling\n", "from tensorflow.keras.models import clone_model\n", "from tensorflow.keras.models import model_from_json"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["tf.get_logger().setLevel('ERROR')\n", "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(f'|---> {tf.__version__}')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["  ******************<br>\n", "  FUNS<br>\n", "<br>\n", "  ******************"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["try:\n", "    # check if base.Onpyon is defined\n", "    var = Onpyon()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["except NameError:\n", "    # Onpyon not defined\n", "    sys.path.append('../')  # if called from eon, modules are in parallel folder\n", "    sys.path.append('./')  #  if called from dnns, modules are in folder\n", "    from base import *"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["onutil = Onutil()\n", "onplot = Onplot()\n", "onformat = Onformat()\n", "onfile = Onfile()\n", "onvid = Onvid()\n", "ondata = Ondata()\n", "onset = Onset()\n", "onrecord = Onrecord()\n", "ontree = Ontree()\n", "onlllyas = Onlllyas()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["  *******************<br>\n", "  CONTEXT<br>\n", "<br>\n", "  *******************"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def getap():\n", "    cp = {\n", "        \"primecmd\": 'nndanboo', # 'nncrys', #  \n", "        \"MNAME\": \"pix2pix\",\n", "        \"AUTHOR\": \"tensorflow2\",\n", "        \"PROJECT\": \"facades\",   # python pix2pix/pix2pix.py --PROJECT=facades --DATASET=facades nnfacades\n", "        \"GITPOD\": \"facades\",\n", "        \"DATASET\": \"facades\",\n", "        \"GDRIVE\": 1,            # mount gdrive: gdata, gwork    \n", "        \"TRAINDO\": 1,      \n", "        \"MAKEGIF\": 1,      \n", "        \"RUNGIF\": 0,      \n", "        \"CLEARTMP\": 0,      \n", "        \"REGET\": 0,             # get again data \n", "        \"ING\": 1,               # ckpt in gwork\n", "        \"MODITEM\": \"\",          # will look into module\n", "        \"RESETCODE\": 0,\n", "        \"LOCALDATA\": 0,\n", "        \"LOCALMODELS\": 0,\n", "        \"LOCALLAB\": 1,\n", "        \"grel_infix\": '../..',            # relative path to content \n", "        \"net_prefix\": '//enas/hdrive',     \n", "        \"gdrive_prefix\": '/content/drive/My Drive',     \n", "        \"gcloud_prefix\": '/content',     \n", "    }\n", "    local_prefix = os.path.abspath('')\n", "    try:\n", "            local_prefix = os.path.dirname(os.path.realpath(__file__)) # script dir\n", "    except:\n", "            pass\n", "    cp[\"local_prefix\"] = local_prefix\n", "    \n", "    hp = {\n", "        \"verbose\": 1, # [0,n]\n", "        \"visual\": 1, # [0,n]\n\n", "        # train\n", "        \"batch_size\": 1,\n", "        \"img_width\": 256,\n", "        \"img_height\": 256,\n", "        \"buffer_size\": 1000,\n", "        \"input_channels\": 3,\n", "        \"output_channels\": 3,\n", "        \"max_epochs\": 200,\n", "        \"n_iterations\": 10, # iters for snapshot\n\n", "        # dataset.py args\n", "        \"input_folder\": './input/',\n", "        \"output_folder\": './output/',\n", "        \"keep_folder\": 0,\n", "        \"process_type\": 'resize',\n", "        \"blur_type\": \"\", # [\"\",\"gaussian\",\"median\"]\n", "        \"blur_amount\": 1,\n", "        \"max_size\": 256,\n", "        \"height\": 256,\n", "        \"width\": 256,\n", "        \"shift_y\": 0,\n", "        \"v_align\": 'center',\n", "        \"h_align\": 'center',\n", "        \"shift_x\": 0,\n", "        \"scale\": 2.0,\n", "        \"direction\": 'AtoB',\n", "        \"border_type\": 'stretch',\n", "        \"border_color\": '255,255,255',\n", "        \"mirror\": 0,\n", "        \"rotate\": 0,\n", "        \"file_extension\": 'png',\n\n", "        # var\n", "        \"name\": 0, # use counter\n", "        \"keep_name\": 0, # _e_\n", "        \"numbered\": 1, # _e_\n", "        \"zfill\": 4, # zfill name counter\n", "    }\n", "    ap = {}\n", "    for key in cp.keys():\n", "        ap[key] = cp[key]\n", "    for key in hp.keys():\n", "        ap[key] = hp[key]\n", "    return ap"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def getxp(cp):\n", "    yp={}\n", "    xp={}\n", "    for key in cp.keys():\n", "        xp[key] = cp[key]\n", "    tree = ontree.tree(cp)\n", "    for key in tree.keys():\n", "        xp[key] = tree[key]\n", "    for key in yp.keys():\n", "        xp[key] = yp[key]\n", "   \n", "    return xp"]}, {"cell_type": "markdown", "metadata": {}, "source": ["  ******************<br>\n", "  FUNS SEGMENT<br>\n", "<br>\n", "  https://github.com/lllyasviel/DanbooRegion/blob/master/code/segment.py"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def go_vector(x):\n", "    return x[None, :, :, :]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def go_flipped_vector(x):\n", "    a = go_vector(x)\n", "    b = np.fliplr(go_vector(np.fliplr(x))) # numpy.fliplr(m: marray_like) -> fndarray\n", "    c = np.flipud(go_vector(np.flipud(x)))\n", "    d = np.flipud(np.fliplr(go_vector(np.flipud(np.fliplr(x)))))\n", "    return (a + b + c + d) / 4.0"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def go_transposed_vector(x):\n", "    a = go_flipped_vector(x)\n", "    b = np.transpose(go_flipped_vector(np.transpose(x, [1, 0, 2])), [1, 0, 2])\n", "    return (a + b) / 2.0"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def get_fill(image):\n", "    labeled_array, num_features = label(image / 255)\n", "    filled_area = onlllyas.find_all(labeled_array)\n", "    return filled_area"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def up_fill(fills, cur_fill_map):\n", "    new_fillmap = cur_fill_map.copy()\n", "    padded_fillmap = np.pad(cur_fill_map, [[1, 1], [1, 1]], 'constant', constant_values=0)\n", "    max_id = np.max(cur_fill_map)\n", "    for item in fills:\n", "        points0 = padded_fillmap[(item[0] + 1, item[1] + 0)]\n", "        points1 = padded_fillmap[(item[0] + 1, item[1] + 2)]\n", "        points2 = padded_fillmap[(item[0] + 0, item[1] + 1)]\n", "        points3 = padded_fillmap[(item[0] + 2, item[1] + 1)]\n", "        all_points = np.concatenate([points0, points1, points2, points3], axis=0)\n", "        pointsets, pointcounts = np.unique(all_points[all_points > 0], return_counts=True)\n", "        if len(pointsets) == 1 and item[0].shape[0] < 128:\n", "            new_fillmap[item] = pointsets[0]\n", "        else:\n", "            max_id += 1\n", "            new_fillmap[item] = max_id\n", "    return new_fillmap"]}, {"cell_type": "markdown", "metadata": {}, "source": ["  ******************<br>\n", "  NETS<br>\n", "<br>\n", "  ******************"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class GAN(object):\n", "    def __init__(self, \n", "    \n", "            models_dir = './',\n", "            logs_dir = './',\n", "            ckptidx = None,\n", "            ckpt_dir = './',\n", "            ckpt_prefix = 'ckpt-',\n", "            results_dir = './results',\n", "            input_shape = [256,256,3],\n", "            output_shape = [256,256,3],\n", "    ):\n", "        print(f'|---> sg2pix2pix.GAN')\n", "        self.input_shape = input_shape\n", "        self.output_shape = output_shape\n", "        self.models_dir = models_dir\n", "        self.logs_dir = logs_dir\n", "        self.results_dir = results_dir\n", "        self.ckptidx = ckptidx\n", "        self.ckpt_dir = ckpt_dir\n", "        self.ckpt_prefix = ckpt_prefix\n", "        self.generator = self.Generator(input_shape=input_shape)\n", "        self.discriminator = self.Discriminator(output_shape=output_shape)   \n", "        self.generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n", "        self.discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n", "        self.step = tf.Variable(0)\n", "        self.checkpoint = tf.train.Checkpoint(\n", "            generator_optimizer=self.generator_optimizer,\n", "            discriminator_optimizer=self.discriminator_optimizer,\n", "            generator=self.generator,\n", "            discriminator=self.discriminator,\n", "            step=self.step\n", "        )"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        self.restore_checkpoint()\n\n", "    # Build the Generator\n", "    #     The architecture of generator is a modified U-Net.\n", "    #     Each block in the encoder is (Conv -> Batchnorm -> Leaky ReLU)\n", "    #     Each block in the decoder is (Transposed Conv -> Batchnorm -> Dropout(applied to the first 3 blocks) -> ReLU)\n", "    #     There are skip connections between the encoder and decoder (as in U-Net)\n", "    def Generator(self, input_shape=[256,256,3]):\n", "        print(f'|---> Generator instance with input_shape: {input_shape}')\n", "        inputs = tf.keras.layers.Input(input_shape)\n", "        down_stack = [\n", "            ondata.downsample(64, 4, apply_batchnorm=False), # (bs, 128, 128, 64)\n", "            ondata.downsample(128, 4), # (bs, 64, 64, 128)\n", "            ondata.downsample(256, 4), # (bs, 32, 32, 256)\n", "            ondata.downsample(512, 4), # (bs, 16, 16, 512)\n", "            ondata.downsample(512, 4), # (bs, 8, 8, 512)\n", "            ondata.downsample(512, 4), # (bs, 4, 4, 512)\n", "            ondata.downsample(512, 4), # (bs, 2, 2, 512)\n", "            ondata.downsample(512, 4), # (bs, 1, 1, 512)\n", "        ]\n", "        up_stack = [\n", "            ondata.upsample(512, 4, apply_dropout=True), # (bs, 2, 2, 1024)\n", "            ondata.upsample(512, 4, apply_dropout=True), # (bs, 4, 4, 1024)\n", "            ondata.upsample(512, 4, apply_dropout=True), # (bs, 8, 8, 1024)\n", "            ondata.upsample(512, 4), # (bs, 16, 16, 1024)\n", "            ondata.upsample(256, 4), # (bs, 32, 32, 512)\n", "            ondata.upsample(128, 4), # (bs, 64, 64, 256)\n", "            ondata.upsample(64, 4), # (bs, 128, 128, 128)\n", "        ]\n", "        initializer = tf.random_normal_initializer(0., 0.02)\n", "        last = tf.keras.layers.Conv2DTranspose(\n", "            3, # output_channels, # filters\n", "            4,  # kernel_size\n", "            strides=2,\n", "            padding='same',\n", "            kernel_initializer=initializer,\n", "            activation='tanh') # (bs, 256, 256, 3)\n\n", "        # concat = tf.keras.layers.Concatenate()\n\n", "        # inputs = tf.keras.layers.Input(input_shape=[None, None, 3])\n", "        x = inputs\n\n", "        # Downsampling through the model\n", "        skips = []\n", "        for down in down_stack:\n", "                x = down(x)\n", "                skips.append(x)\n", "        skips = reversed(skips[:-1])\n\n", "        # Upsampling and establishing the skip connections\n", "        for up, skip in zip(up_stack, skips):\n", "                x = up(x)\n", "                x = tf.keras.layers.Concatenate()([x, skip])\n", "        x = last(x)\n", "        return tf.keras.Model(inputs=inputs, outputs=x)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    # Discriminator\n", "    #     The Discriminator is a PatchGAN.\n", "    #     Each block in the discriminator is (Conv -> BatchNorm -> Leaky ReLU)\n", "    #     The shape of the output after the last layer is (batch_size, 30, 30, 1)\n", "    #     Each 30x30 patch of the output classifies a 70x70 portion of the input image (such an architecture is called a PatchGAN).\n", "    #     Discriminator receives 2 inputs.\n", "    #         Input image and the target image, which it should classify as real.\n", "    #         Input image and the generated image (output of generator), which it should classify as fake.\n", "    #         We concatenate these 2 inputs together in the code (tf.concat([inp, tar], axis=-1))\n", "    def Discriminator(self, output_shape):\n", "            initializer = tf.random_normal_initializer(0., 0.02)\n", "            inp = tf.keras.layers.Input(shape=output_shape, name='output_image')\n", "            tar = tf.keras.layers.Input(shape=output_shape, name='target_image')\n", "            x = tf.keras.layers.concatenate([inp, tar]) # (bs, 256, 256, input_channels*2)\n", "            down1 = ondata.downsample(64, 4, False)(x) # (bs, 128, 128, 64)\n", "            down2 = ondata.downsample(128, 4)(down1) # (bs, 64, 64, 128)\n", "            down3 = ondata.downsample(256, 4)(down2) # (bs, 32, 32, 256)\n", "            zero_pad1 = tf.keras.layers.ZeroPadding2D()(down3) # (bs, 34, 34, 256)\n", "            conv = tf.keras.layers.Conv2D(512, 4, strides=1,\n", "                            kernel_initializer=initializer,\n", "                            use_bias=False)(zero_pad1) # (bs, 31, 31, 512)\n", "            batchnorm1 = tf.keras.layers.BatchNormalization()(conv)\n", "            leaky_relu = tf.keras.layers.LeakyReLU()(batchnorm1)\n", "            zero_pad2 = tf.keras.layers.ZeroPadding2D()(leaky_relu) # (bs, 33, 33, 512)\n", "            last = tf.keras.layers.Conv2D(1, 4, strides=1,\n", "                            kernel_initializer=initializer)(zero_pad2) # (bs, 30, 30, 1)\n", "            return tf.keras.Model(inputs=[inp, tar], outputs=last)\n\n", "    # discriminator loss\n", "    #     The discriminator loss function takes 2 inputs; real images, generated images\n", "    #     real_loss is a sigmoid cross entropy loss of the real images and an array of ones(since these are the real images)\n", "    #     generated_loss is a sigmoid cross entropy loss of the generated images and an array of zeros(since these are the fake images)\n", "    #     Then the total_loss is the sum of real_loss and the generated_loss\n", "    def discriminator_loss(self, disc_real_output, disc_generated_output,\n", "            loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n", "    ):\n", "        real_loss = loss_object(tf.ones_like(disc_real_output), disc_real_output)\n", "        generated_loss = loss_object(tf.zeros_like(disc_generated_output), disc_generated_output)\n", "        total_disc_loss = real_loss + generated_loss\n", "        return total_disc_loss\n\n", "    # generator loss\n", "    #     It is a sigmoid cross entropy loss of the generated images and an array of ones.\n", "    #     The paper also includes L1 loss which is MAE (mean absolute error) between the generated image and the target image.\n", "    #     This allows the generated image to become structurally similar to the target image.\n", "    #     The formula to calculate the total generator loss = gan_loss + LAMBDA * l1_loss, where LAMBDA = 100. This value was decided by the authors of the paper.\n", "    def generator_loss(self, disc_generated_output, gen_output, target, lda = 100, \n", "            loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n", "    ):\n", "        LAMBDA = lda # LAMBDA = 100\n", "        gan_loss = loss_object(tf.ones_like(disc_generated_output), disc_generated_output)\n\n", "        # mean absolute error\n", "        l1_loss = tf.reduce_mean(tf.abs(target - gen_output))\n", "        total_gen_loss = gan_loss + (LAMBDA * l1_loss)\n", "        return total_gen_loss, gan_loss, l1_loss\n", "            \n", "    # @tf.function\n", "    def train_step(self, input_image, target, epoch, summary_writer, args=None):\n", "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n", "            gen_output = self.generator(input_image, training=True)\n", "            disc_real_output = self.discriminator([input_image, target], training=True)\n", "            disc_generated_output = self.discriminator([input_image, gen_output], training=True)\n", "            gen_total_loss, gen_gan_loss, gen_l1_loss = self.generator_loss(disc_generated_output, gen_output, target)\n", "            disc_loss = self.discriminator_loss(disc_real_output, disc_generated_output)\n", "        generator_gradients = gen_tape.gradient(gen_total_loss, self.generator.trainable_variables)\n", "        discriminator_gradients = disc_tape.gradient(disc_loss, self.discriminator.trainable_variables)\n", "        self.generator_optimizer.apply_gradients(zip(generator_gradients, self.generator.trainable_variables))\n", "        self.discriminator_optimizer.apply_gradients(zip(discriminator_gradients, self.discriminator.trainable_variables))\n", "        with summary_writer.as_default():\n", "            tf.summary.scalar('gen_total_loss', gen_total_loss, step=epoch)\n", "            tf.summary.scalar('gen_gan_loss', gen_gan_loss, step=epoch)\n", "            tf.summary.scalar('gen_l1_loss', gen_l1_loss, step=epoch)\n", "            tf.summary.scalar('disc_loss', disc_loss, step=epoch)    "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    def fit(self, train_ds, test_ds=None, args = None, ):\n", "        max_epochs = args.max_epochs\n", "        n_iterations  = args.n_iterations\n", "        print(f'|---> fit \\n \\\n", "            max_epochs: {max_epochs} \\n \\\n", "            n_iterations: {n_iterations} \\n \\\n", "            test_ds: {1 if test_ds else 0} \\n \\\n", "        ')\n\n", "        # tensorboard\n", "        summary_writer = tf.summary.create_file_writer(\n", "            os.path.join(self.logs_dir, \"fit\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")))\n", "        for epoch in range(max_epochs):\n", "            start = time.time()\n\n", "            # \tSTEP per batches in dataset\n", "            for n, (input_image, target) in train_ds.enumerate():\n", "                ''' {np.shape(input_image)}\" (1, 512, 512, 3) '''\n", "                print('.', end='')\n", "                if (n+1) % 100 == 0:\n", "                    print() # cr after 100 interations\n", "                self.train_step(input_image, target, epoch, summary_writer, args)\n", "            print()\n", "          \n", "            # \tsave step (epoch)\n", "            self.step.assign_add(1)\n\n", "            # \tsave checkpoint\n", "            if (epoch + 1) % n_iterations == 1:\n", "                print(f'|... saving (checkpoint) the model every {n_iterations} max_epochs to {self.ckpt_prefix}')\n", "                file_prefix = os.path.join(self.ckpt_dir, self.ckpt_prefix)\n", "                self.checkpoint.save(file_prefix = file_prefix)\n", " \n", "            #   save generated images           \n", "            if 0 and test_ds and (epoch + 1) % n_iterations == 1:\n", "                print(f'|... savings images every for epoch {epoch}')\n", "                self.generate_images(test_ds, epoch, args)\n", "            print ('Time taken for epoch {} is {} sec\\n'.format(epoch + 1, time.time()-start))\n", "        file_prefix = os.path.join(self.ckpt_dir, self.ckpt_prefix)\n", "        self.checkpoint.save(file_prefix = file_prefix)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    def generate_images(self, test_dataset, epoch, args=None ):\n", "        generator = self.generator\n", "        results_dir = self.results_dir\n", "        zfill = args.zfill\n", "        print(f\"|===> generate_images \\n \\\n", "            results_dir: {results_dir} \\n \\\n", "            zfill: {zfill} \\n \\\n", "        \")\n", "        idx = 0\n", "        for n, (img_input, img_target) in test_dataset.enumerate():\n", "            img_prediction = generator(img_input, training=True) # _e_\n", "            display_list = [\n", "                onformat.nnba_to_rgb(img_input),\n", "                onformat.nnba_to_rgb(img_target), \n", "                onformat.nnba_to_rgb(img_prediction)\n", "            ]\n", "            titles = ['Input Image', 'Ground Truth', 'Predicted Image']\n", "            if args.visual > 1:\n", "                    print(f'generated image {idx} in epoch {epoch}')\n", "                    onplot.pil_show_rgbs(display_list, scale=1, rows=1)   \n", "    \n", "            filename = f'{str(idx).zfill(zfill)}_{str(epoch).zfill(zfill)}.png'\n", "            if args.verbose > 2:\n", "                print(f'|===> generate_images save \\n \\\n", "                    n: {n} \\n \\\n", "                    idx: {idx} \\n \\\n", "                    results_dir: {results_dir} \\n \\\n", "                    filename: {filename} \\n \\\n", "                ')            \n", "            save_image_path = os.path.join(results_dir, filename)\n", "            onfile.rgbs_to_file(display_list, scale=1, rows=1, save_path=save_image_path)\n", "            idx += 1\n", "        \n", "    def restore_checkpoint(self, ckptidx=None, max_to_keep=5):\n", "        print(f'|===> model.restore_checkpoint \\n \\\n", "            self.checkpoint: {self.checkpoint} \\n \\\n", "            self.ckptidx: {self.ckptidx} \\n \\\n", "            self.ckpt_dir: {self.ckpt_dir} \\n \\\n", "            self.ckpt_prefix = {self.ckpt_prefix} \\n \\\n", "            max_to_keep: {max_to_keep} \\n \\\n", "        ')\n", "        self.ckpt_manager = ckpt_manager = tf.train.CheckpointManager(\n", "            self.checkpoint, \n", "            self.ckpt_dir, \n", "            max_to_keep=max_to_keep\n", "        )\n", "        # if a checkpoint exists, restore the latest checkpoint.\n", "        \n\n", "        # self.ckptidx: {None => last, ckptidx-n => n, ckptidx--n => none}\n", "        if self.ckptidx == None:\n", "            fromcheckpoint = ckpt_manager.latest_checkpoint\n", "            self.ckptidx = fromcheckpoint.split('-')[-1]\n", "        elif int(self.ckptidx) < 0:\n", "            fromcheckpoint = None\n", "            self.ckptidx = fromcheckpoint\n", "        elif int(self.ckptidx) >= 0:\n", "            fromcheckpoint = os.path.join(self.ckpt_dir, f'{self.ckpt_prefix}{self.ckptidx}')\n", "            self.ckptidx = self.ckptidx\n", "        print(f'|...> model.restore_checkpoint fetch ckptidx {self.ckptidx} \\n')\n", "        if fromcheckpoint:\n", "            self.checkpoint.restore(fromcheckpoint)\n", "            print(f'|...> model.restore_checkpoint checkpoint restored from {fromcheckpoint} !!! \\n')\n", "            return fromcheckpoint\n", "        else:\n", "            print(f'|...> model.restore_checkpoint checkpoint not found')\n", "            return None"]}, {"cell_type": "markdown", "metadata": {}, "source": ["  ******************<br>\n", "  FUNS PRJ<br>\n", "<br>\n", "  ******************"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def path_to_pair(path, height=None, width=None, exotor=1.0):\n", "    print(f\"|---> path_to_pair 11: {path}\")\t\n", "    imgs = path_to_decoded(path)\n", "    imgs = imgs_process(imgs, height, width, exotor)\n", "    return imgs"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def paths_to_pair(paths, height=None, width=None, exotor=1.0):\n", "    print(f'|---> paths_to_pair (22): {paths}')\n", "    imgs = paths_to_decoded(paths)\n", "    imgs = imgs_process(imgs, height, width, exotor)\n", "    return imgs"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def path_to_decoded(path, rate=0.5):\n", "    print(f'|---> ********************** path_to_decoded: {path}')\n", "    imgs = []\n", "    img = tf.io.read_file(path) # => dtype=string\n", "    if 0: \n", "        print(f'|... img: {type(img)} {np.shape(img)}')    \n", "    img = tf.image.decode_jpeg(img) # => shape=(256, 512, 3), dtype=uint8)\n", "    img = tf.cast(img, tf.float32)\n", "    w = tf.shape(img)[1]\n", "    w = w // 2\n", "    img1 = img[:, :w, :] # real comes left \n", "    imgs.append(img1)\n", "    img2 = img[:, w:, :] \n", "    imgs.append(img2)\n", "    return imgs"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def paths_to_decoded(paths, rate=2):\n", "    print(f'|---> paths_to_decoded: {paths}')\n", "    imgs = []\n", "    for path in paths:\n", "        img = tf.io.read_file(path) # => dtype=string\n", "        if 0: \n", "            print(f'|... img: {type(img)} {np.shape(img)}')\n", "        img = tf.image.decode_jpeg(img) # => shape=(256, 512, 3), dtype=uint8)\n", "        img = tf.cast(img, tf.float32)\n", "        imgs.append(img)\n", "    return imgs"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Random jittering:<br>\n", "Resize an image to bigger height and width<br>\n", "Randomly crop to the target size<br>\n", "Randomly flip the image horizontally<br>\n", "the image is resized to 286 x 286 and then randomly cropped to 256 x 256"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def probe_dataset_11(dataset, dst_dir):\n", "    print(f'|---> probe_dataset_11')\t\t\t\n", "    i = 0\n", "    for sample_inp, sample_re in dataset.take(3):\n", "        inp, re = sample_inp, sample_re\n", "        plt.figure()\n", "        plt.imshow(inp[0] * 0.5 + 0.5)\n", "        print(f'|... save to {i}_example_input.png')\n", "        plt.savefig(os.path.join(dst_dir, f'{i}_example_input.png'))\n", "        plt.figure()\n", "        plt.imshow(re[0] * 0.5 + 0.5)\n", "        print(f'|... save to {i}_example_target.png')        \n", "        plt.savefig(os.path.join(dst_dir, f'{i}_example_target.png'))\n", "        i += 1"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def path_to_dataset_from_src(path, patt, \n", "        batch_size=None, height=None, width=None, buffer_size=None):\n", "    print(f'|---> path_to_dataset_from_src ')\n", "    if type(patt) == str:\n", "        print('|...> get files from one source: input and real in one file')\n", "        #dataset = path_to_dataset_11(path, patt, \n", "        dataset = paths_to_dataset(path, patt, \n", "            height=height, width=width, buffer_size=buffer_size, batch_size=batch_size)\n", "    elif isinstance(patt, list): \n", "        print('|...> get files from two sources')\n", "        #dataset = paths_to_dataset_22(path, patt, \n", "        dataset = paths_to_dataset(path, patt, \n", "            height=height, width=width, buffer_size=buffer_size, batch_size=batch_size)\n", "    return dataset"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def paths_to_dataset(pths, patts, \n", "        batch_size=None, height=None, width=None, buffer_size=None,\n", "        exotor=1.2):\n", "    pathsIsArr = isinstance(pths, list)\n", "    pattsIsArr = isinstance(patts, list)\n", "    print(f'|---> paths_to_dataset:   \\n \\\n", "        pths: {pths} \\n \\\n", "        patts: {patts} \\n \\\n", "        height: {height} \\n \\\n", "        width: {width} \\n \\\n", "        buffer_size: {buffer_size} \\n \\\n", "        batch_size: {batch_size} \\n \\\n", "        pathsIsArr: {pathsIsArr} \\n \\\n", "        pattsIsArr: {pattsIsArr} \\n \\\n", "    ')\n", "    if pathsIsArr and pattsIsArr: # arrays 22 \n", "        print(f'|---> paths_to_dataset 22')\n", "        lti_two = (lambda x: paths_to_pair(x, height, width, exotor))\n", "        a = tf.data.Dataset.list_files(os.path.join(pths[0], patts[0]), shuffle=False)\n", "        b = tf.data.Dataset.list_files(os.path.join(pths[1], patts[1]), shuffle=False)\n", "        c = tf.data.Dataset.zip((a, b))\n\n", "        # each element in the dataset is a list of two imgs\n", "        dataset = c.map(lambda x,y: lti_two([x,y]), num_parallel_calls=tf.data.experimental.AUTOTUNE)\n", "    elif not pathsIsArr and not pattsIsArr: # not arrays 11\n", "        print(f'|---> paths_to_dataset 11')\n", "        lti_one = (lambda x: path_to_pair(x, height, width))\n", "        c = tf.data.Dataset.list_files(os.path.join(pths, patts))\n\n", "        # each element in the dataset is a file with two imgs\n", "        dataset = c.map(lambda x: lti_one(x), num_parallel_calls=tf.data.experimental.AUTOTUNE)\n", "    dataset = dataset.batch(batch_size)\n", "    if 1: # list batches\n", "        for n, (inp, re) in dataset.enumerate():\n", "            ''' {np.shape(input_image)}\" (n, 512, 512, 3) '''\n", "            if n < 2:\n", "                print(f'|... path_to_dataset batch {n}: {np.shape(inp)} {np.shape(re)}')\n", "    return dataset"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def path_process(path, height=256, width=256, exotor=1.0, flip=0):\n", "    print(f'|---> path_process')\n", "    img = tf.io.read_file(path)\n", "    img = tf.image.decode_jpeg(img)\n", "    img = tf.cast(img, tf.float32)\n", "    img = img_process(img, height, width, exotor, flip)\n", "    return img"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def img_process(img, height=256, width=256, exotor=1.0, flip=0):\n", "    print(f'|---> img_process')\n", "    img = tnua_resize(img, int(exotor * height), int(exotor * width))\n", "    img = img_crop(img, height, width)\n", "    if flip > 0:\n", "        img = img_random_flip(img)\n", "    img = onformat.rgb_to_nba(img)  \n", "    return img"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def imgs_process(imgs, height=256, width=256, exotor=1.0, flip=0):\n", "    print(f'|---> imgs_process')\n", "    imgs = imgs_resize_with_tf(imgs, int(exotor * height), int(exotor * width))\n", "    imgs = imgs_crop_random(imgs, height, width)\n", "    if flip > 0:\n", "        imgs = imgs_random_flip(imgs)\n", "    imgs = onformat.rgbs_to_nbas(imgs)\n", "    return imgs"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def tnua_resize(img, height, width, method=tf.image.ResizeMethod.NEAREST_NEIGHBOR):\n", "    print(f'|---> tnua_resize {np.shape(img)} ')\t\t\t\n", "    img = tf.image.resize(img, [height, width],\n", "        method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n", "    return img"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def imgs_resize_with_tf(imgs, height, width, method=tf.image.ResizeMethod.AREA):\n", "    print(f'|---> imgs_resize_with_tf: {np.shape(imgs)}')\t\n", "    res = []\n", "    for i,img in enumerate(imgs):\n", "        print(f'|... imgs_resize_with_tf {i} {np.shape(img)}')\n", "        img = tnua_resize(img, height, width, method)\n", "        res.append(img)\t\t\n", "    return res"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def img_crop(img, height, width):\n", "    imgs = [img]\n", "    print(f'|---> img_crop: {np.shape(imgs)}')\t\n", "    stacked_image = tf.stack(imgs, axis=0)\n", "    b = len(imgs)\n", "    cropped_image = tf.image.random_crop(\n", "        stacked_image, size=[b, height, width, 3])\n", "    return cropped_image[0] # _e_"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def img_crop_random(img, height, width):\n", "    shape = np.shape(img)\n", "    print(f'|---> img_crop_random {shape}, {height}, {width}')\n", "    \t\n", "    img = tf.image.random_crop(img, size=[height, width, 3])\n", "    print(f'|... img_crop_random {np.shape(img)}, {height}, {width}')\t\n", "    return img"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def imgs_crop_random(imgs, height, width):\n", "    print(f'|---> imgs_crop_random: {np.shape(imgs)}')\t\n", "    stacked_images = tf.stack(imgs, axis=0)\n", "    b = len(imgs)\n", "    cropped_images = tf.image.random_crop( # Tensor\n", "        stacked_images, size=[b, height, width, 3])\n", "    res = cropped_images[0], cropped_images[1]  # _e_\n", "    return res"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def img_random_flip(img):\n", "    imgs = [img]\n", "    imgs = imgs_random_flip(imgs)\n", "    return imgs[0]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def imgs_random_flip(imgs):\n", "    print(f'|---> imgs_random_flip')\t\n", "    _imgs = []\n", "    if tf.random.uniform(()) > 0.5: # random mirroring\n", "        for item in imgs:\n", "            item = tf.image.flip_left_right(item)\n", "            _imgs.append(item)\n", "    return imgs"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def img_jitter_random(img, height, width):\n", "    print(f'|---> img_jitter_random {np.shape(img)}')\t\t\n", "    img = img_crop_random(img, height, width)\n", "    return img"]}, {"cell_type": "markdown", "metadata": {}, "source": ["----<br>\n", "https://github.com/phillipi/pix2pix"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def load_predefined_image_data_by_task_name(task_name,\n", "                                            predefined_task_name_list=None,):\n", "    \"\"\"Data from https://people.eecs.berkeley.edu/~tinghuiz/projects/pix2pix/datasets/\n", "    View sample images here, https://github.com/yuanxiaosc/DeepNude-an-Image-to-Image-technology/tree/master/Pix2Pix\"\"\"\n", "    print(f\"|---> load_predefined_image_data_by_task_name: {task_name}\") \n", "    if task_name in predefined_task_name_list: # 'edges2shoes.tar.gz'\n", "        _URL = f'https://people.eecs.berkeley.edu/~tinghuiz/projects/pix2pix/datasets/{task_name}.tar.gz'\n", "        path_to_zip = tf.keras.utils.get_file(f'{task_name}.tar.gz', origin=_URL, extract=True)\n", "        PATH = os.path.join(os.path.dirname(path_to_zip), f'{task_name}/')\n", "        print(f\"Store {task_name} raw data to {PATH}\")\n", "    else:\n", "        raise ValueError(f\"Predefined tasks do not include this {task_name} task!\")\n", "    return PATH"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def download_and_processing_pix2pix_dataset(data_dir_or_predefined_task_name=None,\n", "                                            predefined_task_name_list=None,\n", "                                            args=None):\n", "    print(f'|---> download_and_processing_pix2pix_dataset: {data_dir_or_predefined_task_name}')\n", "    if data_dir_or_predefined_task_name in predefined_task_name_list:\n", "        PATH = load_predefined_image_data_by_task_name(\n", "                data_dir_or_predefined_task_name,\n", "                predefined_task_name_list,\n", "                )\n", "        print(\"|... prepare data from task_name\")\n", "    elif os.path.exists(data_dir_or_predefined_task_name):\n", "        PATH = data_dir_or_predefined_task_name\n", "        print(\"|... prepare data from data_dir\")\n", "    else:\n", "        raise ValueError(\"Task_name error and data_dir does not exist!\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["  ******************<br>\n", "  CMDS<br>\n", "<br>\n", "  ******************"]}, {"cell_type": "markdown", "metadata": {}, "source": ["  ******************<br>\n", "  nnzip<br>\n", "  "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def nnzip(args, kwargs):\n", "    args = onutil.pargs(vars(args))\n", "    args.PROJECT = 'enzip'\n", "    args.DATASET = 'facades'\n", "    xp = getxp(vars(args))\n", "    args = onutil.pargs(xp)\n", "    onutil.ddict(vars(args), 'args')\n", "    print(f\"|---> nnzip: {args.PROJECT}:   \\n \")\n", "    if 1: # tree\n", "        args.dataorg_train_dir = os.path.join(args.dataorg_dir, 'train')\n", "        args.dataorg_test_dir = os.path.join(args.dataorg_dir, 'test')\n", "        assert(os.path.exists(args.dataorg_dir))\n", "        assert(os.path.exists(args.dataorg_train_dir))\n", "        assert(os.path.exists(args.dataorg_test_dir))\n", "        args.ckpt_dir = args.models_dir\n", "        args.ckpt_prefix = os.path.join(args.ckpt_dir, \"ckpt-\")\n", "        ''' train/test images in origin with pattern '''\n", "        args.data_train_B_dir = os.path.join(args.data_dir, 'train_B')\n", "        args.data_train_A_dir = os.path.join(args.data_dir, 'train_A')\n", "        args.data_test_B_dir = os.path.join(args.data_dir, 'test_B')\n", "        args.data_test_A_dir = os.path.join(args.data_dir, 'test_A')\n", "        args.dataset_train_B_dir = os.path.join(args.dataset_dir, 'train_B')\n", "        args.dataset_train_A_dir = os.path.join(args.dataset_dir, 'train_A')\n", "        args.dataset_test_B_dir = os.path.join(args.dataset_dir, 'test_B')\n", "        args.dataset_test_A_dir = os.path.join(args.dataset_dir, 'test_A')\n", "        args.zipfile = os.path.join(args.dataorg_dir, f'{args.DATASET}.zip')\n", "        os.makedirs(args.data_train_B_dir, exist_ok=True) \n", "        os.makedirs(args.data_train_A_dir, exist_ok=True) \n", "        os.makedirs(args.data_test_B_dir, exist_ok=True) \n", "        os.makedirs(args.data_test_A_dir, exist_ok=True) \n", "        os.makedirs(args.dataset_train_B_dir, exist_ok=True) \n", "        os.makedirs(args.dataset_train_A_dir, exist_ok=True) \n", "        os.makedirs(args.dataset_test_B_dir, exist_ok=True) \n", "        os.makedirs(args.dataset_test_A_dir, exist_ok=True) \n", "        os.makedirs(args.models_dir, exist_ok=True)\n", "        os.makedirs(args.logs_dir, exist_ok=True)\n", "        os.makedirs(args.tmp_dir, exist_ok=True)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    if args.verbose: print(f\"|---> tree: {args.PROJECT}:   \\n \\\n", "        args.PROJECT:    \t  {args.PROJECT} \\n \\\n", "        args.DATASET:    \t  {args.DATASET} \\n \\\n", "        cwd:     \t\t\t\t{os.getcwd()} \\n \\\n", "        args.dataorg_dir:     {args.dataorg_dir} \\n \\\n", "        args.dataorg_train_dir: {args.dataorg_train_dir} \\n \\\n", "        args.dataorg_test_dir: {args.dataorg_test_dir} \\n \\\n", "        args.ckpt_dir:  {args.ckpt_dir} \\n \\\n", "        args.logs_dir:        {args.logs_dir} \\n \\\n", "        args.tmp_dir:        {args.tmp_dir} \\n \\\n", "        args.zipfile:         {args.zipfile} \\n \\\n", "        args.verbose:         {args.verbose}, \\n \\\n", "        args.visual:          {args.visual}, \\n \\\n", "    \")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    if 1: # config\n", "        args.height = args.img_height\n", "        args.width = args.img_width\n", "        args.buffer_size = args.buffer_size\n", "        args.batch_size = args.batch_size\n", "        args.input_channels = args.input_channels\n", "        args.input_shape = [args.height, args.width, args.input_channels]\n", "        if 0:\n", "            ''' copy org to same data folder'''\n", "            args.patts = ['*in.png', '*re.png']\n", "        else:\n", "            ''' will separate images in data'''\n", "            args.patts = ['*.png', '*.png']\n", "    if args.verbose: print(f\"|---> nnleonardo config:   \\n \\\n", "        args.max_epochs:            {args.max_epochs}, \\n \\\n", "        args.output_channels:\t{args.output_channels} \\n \\\n", "        args.height: \t\t\t{args.height} \\n \\\n", "        args.width: \t\t\t{args.width} \\n \\\n", "        args.input_channels: \t{args.input_channels} \\n \\\n", "        args.buffer_size: \t\t{args.buffer_size} \\n \\\n", "        args.batch_size: \t\t{args.batch_size} \\n \\\n", "        args.input_shape: \t\t{args.input_shape} \\n \\\n", "        args.patts:     \t\t{args.patts}, \\n \\\n", "    \")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    if 1: # remote data to local\n\n", "        #args.DATASET = 'facades'\n", "        dat = 'facades'\n", "        dats=['facades']\n", "        if 0: # create zip\n", "            tarfolder = os.path.join(args.data_dir, dat)\n", "            print(f'|===> create zip from {tarfolder} folder')\n", "            tarfile = os.path.join(args.data_dir, 'test.gz')\n", "            onutil.tenzip(tarfile, tarfolder)\n", "        print(f'|===> download google folder by id')\n", "        if 0: \n", "            URL='https://drive.google.com/drive/folders/'\n", "            gid = '1vTa_y5RYvzk6BPDXQ7HrXfhp8BgjzoKv'\n", "            onutil.gdownid(URL, gid, args.data_dir)\n", "        print(f'|===> download from a set of files on remote server')\n", "        print(f'|... chech that remote is url')\n", "        dats=['cityscapes', 'night2day', 'edges2handbags', 'edges2shoes', 'facades', 'maps']\n", "        url = 'http://efrosgans.eecs.berkeley.edu/pix2pix/datasets'\n", "        #url = args.dataorg_dir\n", "        zexts = ['.tar.gz', '.tar', '.tgz', '.zip']\n", "        print(f'|... chech that remote is path')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        local_tar_path = None\n", "        if 1:\n", "            print(f'|... look for tar in local site {args.data_dir}')\t\t\n", "            print(len(dats), len(zexts))\n", "            it1 = ((i, j) for i in range(len(dats)) for j in range(len(zexts)))\n", "            for i, j in it1:\n", "                dat_path = os.path.join(args.data_dir, f'{dats[i]}{zexts[j]}')\n", "                print(f'|.... look for {dat_path}')\n", "                if os.path.exists(dat_path):\n", "                    local_tar_path = dat_path\n", "                    print(f'|.... local {dat_path} already EXISTS !!! ')\n", "                    break\n", "        remote_tar_path = None\n", "        if not local_tar_path:\n", "            print(f'|... look for tar in remote site {args.dataorg_dir}')\t\n", "            print(len(dats), len(zexts))\n", "            it2 = ((i, j) for i in range(len(dats)) for j in range(len(zexts)))\n", "            for i, j in it2:\n", "                dat_path = os.path.join(args.gdata, f'{dats[i]}{zexts[j]}')\n", "                if os.path.exists(dat_path):\n", "                    remote_tar_path = dat_path\n", "                    print(f'|... remote {dat_path} already EXISTS !!! ')\n", "                    break\n", "        print(f'|... local_tar_path EXISTS : {local_tar_path}')\n", "        print(f'|... remote_tar_path EXISTS : {remote_tar_path}')\n", "        if remote_tar_path and not local_tar_path:\n", "            print(f'|===> remote {remote_tar_path} to local {local_tar_path}')\n", "            tarname = os.path.basename(os.path.normpath(remote_tar_path))\n", "            print(tarname)\n", "            local_tar_path = os.path.join(args.data_dir, tarname)\n", "            print(f'|... copy {remote_tar_path} to {local_tar_path}')\n", "            from shutil import copyfile\n", "            copyfile(remote_tar_path, local_tar_path)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        if local_tar_path:\n", "            print(\"|... unzip to data\")\n", "            tree_root = None\n", "            print(f'|... unzip to data local_tar_path {local_tar_path}')\n", "            # onutil.gunzip(file_basename, file_id, destination, results_dir)\n", "            onutil.tunzip(None, local_tar_path, args.data_dir, tree_root)\n", "    \n", "        # check data folder\n", "        untarfolder = os.path.join(args.data_dir, dat)\n", "        print(f'|... untar folder {untarfolder} exists\" {os.path.exists(untarfolder)}')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["  ******************<br>\n", "  nndanboo<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def nndanboo(args, kwargs):\n", "    \n", "    if onutil.incolab():\n", "        args = onutil.pargs(vars(args))\n", "        args.AUTHOR = 'lllyasviel'\n", "        args.PROJECT = 'nndanboo'\n", "        args.GITPOD = 'DanbooRegion'\n", "        args.DATASET = 'DanbooRegion2020'\n", "        xp = getxp(vars(args))\n", "        args = onutil.pargs(xp)\n", "        onutil.ddict(vars(args), 'args')\n", "    else:\n", "        args = onutil.pargs(vars(args))\n", "        args.AUTHOR  = 'lllyasviel'\n", "        args.PROJECT = 'danregion'\n", "        args.GITPOD = 'DanbooRegion'\n", "        args.DATASET = 'danregion' # 'DanbooRegion2020'\n", "        xp = getxp(vars(args))\n", "        args = onutil.pargs(xp)\n", "        onutil.ddict(vars(args), 'args')        \n", "    print(f\"|---> nndanboo: {args.PROJECT}  \\n \")\n", "    if 1: # tree\n", "        # [1] https://github.com/lllyasviel/DanbooRegion\n", "        # [2] https://drive.google.com/drive/folders/1ihLt6P7UQRlaFtZUEclXkWC9grmEXEUK?usp=sharing\n", "        assert(os.path.exists(args.dataorg_dir))\n", "        args.dataorg_train_dir = os.path.join(args.dataorg_dir, 'train')\n", "        args.dataorg_test_dir = os.path.join(args.dataorg_dir, 'test')\n", "        args.download_dir = os.path.join(args.proj_dir, 'download')\n", "        args.results_dir = os.path.join(args.proj_dir, 'results') # in project dir\n", "        args.code_dir = os.path.join(args.proj_dir, 'code') # inside project dir"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        args.data_train_dir = os.path.join(args.data_dir, 'train')\n", "        args.data_test_dir = os.path.join(args.data_dir, 'test')\n", "        args.data_val_dir = os.path.join(args.data_dir, 'val')\n", "        if onutil.incolab():\n", "            args.ckpt_dir = args.models_dir\n", "        else:\n", "            _glab = os.path.join(args.gdata, '../glab/', args.MNAME, args.PROJECT)\n", "            args.ckpt_dir = os.path.normpath(os.path.join(_glab, 'Models'))\n", "        args.ckpt_prefix = os.path.normpath(os.path.join(args.ckpt_dir, \"ckpt-\"))\n", "        args.data_dir = os.path.join(args.data_dir, '') # in project dir\n", "        args.data_train_pict_dir = os.path.join(args.data_train_dir, 'pict')\n", "        args.data_train_draw_dir = os.path.join(args.data_train_dir, 'draw')\n", "        args.data_test_pict_dir = os.path.join(args.data_test_dir, 'pict')\n", "        args.data_test_draw_dir = os.path.join(args.data_test_dir, 'draw')\n", "        args.data_test_predict_dir = os.path.join(args.data_test_dir, 'predict')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        print(f\"|---> nndanboo tree:  \\n \\\n", "        cwd: {os.getcwd()} \\n \\\n", "        args.proto_dir: {args.proto_dir} \\n \\\n", "        args.code_dir: {args.code_dir} \\n \\\n", "        args.ckpt_dir: {args.ckpt_dir} \\n \\\n", "        args.ckpt_prefix: {args.ckpt_prefix} \\n \\\n", "        \\n \\\n", "        args.dataorg_dir: {args.dataorg_dir}, {onfile.qfiles(args.dataorg_dir, '*.png')}\\n \\\n", "        args.dataorg_train_dir: {args.dataorg_train_dir}, {onfile.qfiles(args.dataorg_train_dir, '*.png')}\\n \\\n", "        args.dataorg_test_dir: {args.dataorg_test_dir}, {onfile.qfiles(args.dataorg_test_dir, '*.png')}\\n \\\n", "        \\n \\\n", "        args.data_dir: {args.data_dir}, \\n \\\n", "        args.data_train_dir: {args.data_train_dir}, {onfile.qfiles(args.data_train_dir, '*.png')}\\n \\\n", "        args.data_train_dir (images): {args.data_train_dir}, {onfile.qfiles(args.data_train_dir, '*.image.png')} \\n \\\n", "        args.data_train_dir (regions): {args.data_train_dir}, {onfile.qfiles(args.data_train_dir, '*.region.png')} \\n \\\n", "        args.data_train_dir (skels): {args.data_train_dir}, {onfile.qfiles(args.data_train_dir, '*.skeleton.png')} \\n \\\n", "        args.data_test_dir: {args.data_test_dir}, {onfile.qfiles(args.data_test_dir, '*.png')}\\n \\\n", "        args.data_val_dir: {args.data_val_dir}, {onfile.qfiles(args.data_val_dir, '*.png')}\\n \\\n", "        \")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        args.dataorg_dir = os.path.join(args.dataorg_dir, '')\n", "        if not os.path.exists(args.dataorg_dir):\n", "            print(f'org data missing \\n \\\n", "                the org data folder: {args.dataorg_dir} was not found !!! \\n \\\n", "                set args.dataorg_dir if needed and \\n \\\n", "                download the dataset following instructions in \\n \\\n", "                    https://github.com/lllyasviel/DanbooRegion : \\n \\\n", "                Download the dataset from:\\n \\\n", "                    https://drive.google.com/drive/folders/1ihLt6P7UQRlaFtZUEclXkWC9grmEXEUK?usp=sharing\\n \\\n", "                For linux then run: (Windows does not need this step.)\\n \\\n", "                    cat DanbooRegion2020.zip.* > DanbooRegion2020.zip\\n \\\n", "                    zip -FF DanbooRegion2020.zip --out DanbooRegion2020_FF.zip\\n \\\n", "                    unzip DanbooRegion2020_FF.zip\\n \\\n", "            ')\n", "            exit()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        os.makedirs(args.proj_dir, exist_ok=True) \n", "        os.makedirs(args.code_dir, exist_ok=True) \n", "        os.makedirs(args.results_dir, exist_ok=True) \n", "        os.makedirs(args.download_dir, exist_ok=True) \n", "        os.makedirs(args.data_train_dir, exist_ok=True) \n", "        os.makedirs(args.data_train_pict_dir, exist_ok=True) \n", "        os.makedirs(args.data_train_draw_dir, exist_ok=True) \n", "        os.makedirs(args.data_test_dir, exist_ok=True) \n", "        os.makedirs(args.data_test_pict_dir, exist_ok=True) \n", "        os.makedirs(args.data_test_draw_dir, exist_ok=True) \n", "        os.makedirs(args.data_test_predict_dir, exist_ok=True) "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    if 1: # config\n", "        args.ckpt_prefix = 'ckpt-'\n", "        args.dim = 512\n", "        args.show_size = 512\n", "        args.height = 512\n", "        args.width = 512\n", "        args.max_size = None # control set resize\n", "        args.buffer_size = 10000\n", "        args.batch_size = 1\n", "        args.max_epochs = 601\n", "        args.gpu = 1 # _e_\n", "        args.input_shape = [args.height, args.width, args.input_channels]\t\t\n", "    print(f\"|---> nndanboo config:  \\n \\\n", "        args.show_size: {args.show_size}, \\n \\\n", "        args.batch_size: {args.batch_size}, \\n \\\n", "        args.gpu: {args.gpu}, \\n \\\n", "        args.height: {args.height}, \\n \\\n", "        args.width: {args.width}, \\n \\\n", "        args.buffer_size: {args.buffer_size}, \\n \\\n", "        args.batch_size: {args.batch_size}, \\n \\\n", "        args.input_shape: {args.input_shape}, \\n \\\n", "    \")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    if 1: # git\n", "        onutil.get_git(args.AUTHOR, args.GITPOD, args.code_dir)\n", "    assert os.path.exists(args.code_dir), \"code_dir not found\"        \n", "    os.chdir(args.code_dir) # _e_ not std\n", "    if args.visual > 1: # visualize region image with image color map\n", "        if 0:\n", "            cmd = f\"python visualize.py ./X.image.png ./X.region.png\"\n", "            print(\"cmd %s\" %cmd)\n", "            os.system(cmd)\n", "        else:\n", "            color_map = cv2.imread('./X.image.png') # _e_\n", "            region_map = cv2.imread('./X.region.png')\n", "            cv2.imshow('vis', onlllyas.vis(region_map, color_map))\n", "            cv2.waitKey(0)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    if 1: # org to _train_ data \n", "        print(f'|---> nndanregion: org => data train \\n \\\n", "            \\n \\\n", "            org image: {onfile.qfiles(args.dataorg_train_dir, \"*.png\")} \\n \\\n", "            train: {onfile.qfiles(args.data_train_pict_dir, \"*.png\")} \\n \\\n", "        ')\n", "        args.keep_folder=True    \n", "        args.process_type='resize'\n", "        args.file_extension= 'png'\n", "        args.name=1 # if 0: calculate name on index\n", "        args.input_folder = args.dataorg_train_dir\n", "        args.filepatt = f'.*{args.file_extension}'\n", "        args.output_folder = args.data_train_pict_dir\n", "        qinfiles = onfile.qfiles(args.input_folder, f'*{args.file_extension}')\n", "        qoutfiles = onfile.qfiles(args.output_folder)\n", "        print(f\"|---> nndanregion train copy: {args.process_type} \\n \\\n", "            {args.input_folder} (q: {qinfiles})  \\n \\\n", "            \\t ==> {args.output_folder} (q: {qoutfiles}) \\n \\\n", "        \")\n\n", "        # count max and exclude list _e_\n", "        if  qinfiles > qoutfiles:\n", "            print(f'|... processFolder from ({qinfiles}) onto ({qoutfiles}) files ')\n", "            args.exclude = [os.path.basename(item) for item in onfile.path_to_paths(args.output_folder)]\n", "            if args.verbose > 2: \n", "                print(args.exclude)\n", "            onset.processFolder(args) # copy inputs to train\n", "        else:\n", "            print(f'|... train no processFolder !!!!. files already there ')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    if 1: # org to _test_ data \n", "        print(f'|---> nndanregion org test to data q: \\n \\\n", "            org image: {onfile.qfiles(args.dataorg_test_dir, \"*.png\")} \\n \\\n", "            test re: {onfile.qfiles(args.data_test_pict_dir, \"*.png\")} \\n \\\n", "        ')\n", "        args.keep_folder=True    \n", "        args.process_type='resize' # just copy\n", "        args.file_extension= 'png'\n", "        args.name=1\n", "        args.zfill=4\n", "        args.input_folder = args.dataorg_test_dir\n", "        args.filepatt = f'.*{args.file_extension}'\n", "        args.output_folder = args.data_test_pict_dir\n", "        qinfiles = onfile.qfiles(args.input_folder, f'*{args.file_extension}')\n", "        qoutfiles = onfile.qfiles(args.output_folder)\n", "        print(f\"|---> test copy: {args.process_type} \\n \\\n", "            {args.input_folder} (q: {qinfiles})  \\n \\\n", "            \\t ==> {args.output_folder} (q: {qoutfiles}) \\n \\\n", "        \")\n", "        if  qinfiles > qoutfiles:\n", "            args.exclude = [os.path.basename(item) for item in onfile.path_to_paths(args.output_folder)]\n", "            onset.processFolder(args) # copy inputs to test\n", "        else:\n", "            print(f'|... test no processFolder !!!!. files already there ')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    if 0: # probe images to skeletons\n", "        basename = 'region_test.png'\n", "        imgpath = os.path.join(args.code_dir, basename)\n", "        \n", "        print(f'|---> skeletonize test png \\n \\\n", "            cwd: {os.getcwd()} \\n \\\n", "            args.proto_dir: {args.proto_dir} \\n \\\n", "            args.code_dir: {args.code_dir} \\n \\\n", "            basename: {basename} \\n \\\n", "            imgpath: {imgpath} \\n \\\n", "        ')\n", "        from skimage.morphology import thin as skeletonize\n", "        if 0:\n", "            cmd = f\"python skeletonize.py {imgpath}\"\n", "            print(\"cmd %s\" %cmd)\n", "            os.system(cmd)\n", "        else:\n", "            region_map = cv2.imread(imgpath)\n", "            cv2.imshow(basename, onlllyas.get_skeleton(region_map, filterstrength=1.0))\n", "            cv2.waitKey(0)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    if 1: # (train) data to skeletons\n", "        print(f'|===> skeletonize_all')\n", "        linpatts = ['*.region.png']\n", "        fromdir = args.data_train_pict_dir\n", "        input_region_train_paths = onfile.path_to_paths(fromdir, linpatts)\n", "        train_paths = input_region_train_paths[0:len(input_region_train_paths)]\n", "        qinfiles = len(train_paths)\n", "        todir = args.data_train_draw_dir\n", "        qoutfiles = onfile.qfiles(todir)\n", "        \n", "        filterstrengths = [5.0] # {1.0,5.0}\n", "        print(f'|...>  skeletonize_all \\n \\\n", "            from {fromdir} ({qinfiles}) \\n \\\n", "            to {todir} ({qoutfiles}) \\n \\\n", "            to filterstrengths: {filterstrengths} \\n \\\n", "        ')\n", "        for filterstrength in filterstrengths:\n", "            _todir = f'{todir}' # {int(filterstrength)}\n", "            os.makedirs(_todir, exist_ok=True)\n", "            loutpatt = f'.skeleton'\n", "            patt = f'*{loutpatt}*' # look for skels with strength\n", "            qoutfiles = onfile.qfiles(_todir, patt)\n", "            outprefixes = [os.path.basename(item).split('.')[0] for item in onfile.path_to_paths(_todir)]\n", "            \n", "            if qinfiles > qoutfiles: # files in outdir with loutpatt\n", "                print(f'|...>  raw to data ({qinfiles}) to ({qoutfiles})')\n", "                for i,path in enumerate(train_paths):\n", "                    filename = os.path.basename(path)\n", "                    ext = filename.split('.')[-1]\t# maintain ext\n", "                    prefix = filename.split('.')[0] # get left to dot\n", "                    if prefix not in outprefixes: # exclude\n", "                        out_path = os.path.join(_todir,f'{prefix}{loutpatt}.{ext}',)\n", "                        region = cv2.imread(path)\n", "                        if 0: print(f'|...> skeleton  region  {np.shape(region)} to {_todir}')\n", "                        skeleton = onlllyas.get_skeleton(region, \n", "                            filterstrength=filterstrength\n", "                        )\n", "                        if 0: print(f'|...> skeleton  shape  {np.shape(skeleton)}')\n", "                        print(f'|...> write   {out_path}   {str(i + 1)} /{qinfiles}')\n", "                        skeleton = cv2.cvtColor(skeleton,cv2.COLOR_GRAY2RGB)\t\t\t\t\t\n", "                        cv2.imwrite(out_path, skeleton)\n", "                    else:\n", "                        print(f'prefix: {prefix} already in target')\n", "            else:\n", "                print(f'|... no process. out files {qoutfiles} in')\n", "    \n", "    if 0: # skeletom to regions show\n", "        basename = 'danskel.jpg'\n", "        skeleton_path = os.path.join(args.code_dir, basename)\n", "        assert os.path.exists(skeleton_path), f\"skeleton_path {skeleton_path} does not exist\"\n", "        print(f'|---> skeletom to regions \\n \\\n", "            skeleton_path: {skeleton_path} \\n \\\n", "        ')\n\n", "        #skeleton_path = os.path.join(args.code_dir, 'skeleton_test.png')\n", "        skeleton_map = cv2.imread(skeleton_path)\n", "        img = onlllyas.skeleton_to_regions(skeleton_map)\n", "        if onutil.incolab():\n", "            from google.colab.patches import cv2_imshow\n", "            cv2_imshow(img)\n", "            cv2.waitKey(0)            \n", "        else:\n", "            cv2.imshow(basename, img)\n", "            cv2.waitKey(0)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    if 1: # model\n", "        if args.verbose: print(f'|===> model:   \\n \\\n", "            models_dir = {args.models_dir},\\n \\\n", "            logs_dir = {args.logs_dir},\\n \\\n", "            results_dir = {args.results_dir},\\n \\\n", "            ckpt_dir = {args.ckpt_dir},\\n \\\n", "            ckpt_prefix = {args.ckpt_prefix},\\n \\\n", "            input_shape = {args.input_shape},\\n \\\n", "            output_shape = {args.input_shape},\\n \\\n", "        ')\n", "        model = GAN(\n", "            models_dir = args.models_dir,\n", "            logs_dir = args.logs_dir,\n", "            results_dir = args.results_dir,\n", "            ckpt_dir = args.ckpt_dir,\n", "            ckpt_prefix = args.ckpt_prefix,\n", "            ckptidx = -1,   # ****\n", "            input_shape = args.input_shape,\n", "            output_shape = args.input_shape,\n", "        )\n", "    \n\n", "    # 3. segment\n", "    \n", "    if 1:\t# python segment.py ./emilia.jpg\n", "        path = os.path.join(args.code_dir, 'emilia.jpg')\n", "        path = os.path.join(args.code_dir, 'danimage.jpg')\n", "        path = os.path.join(args.code_dir, 'danskel.jpg')\n", "        assert os.path.exists(path), f'{path} could not be found'\n", "        basename = os.path.basename(path)\n", "        assert os.path.exists(path), f\"path {path} does not exist\"\n", "        print(f'|---> segment \\n \\\n", "            basename: {basename} \\n \\\n", "            skeleton_path: {path} \\n \\\n", "        ')\n", "        img = cv2.imread(path)\n", "        img = onlllyas.skeleton_to_regions(img)\n", "        img = onlllyas.min_resize(img, 512)\n", "        if 0: onplot.cv_img(img, title=f'regions {basename}')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": [" \n", "        #raw_img = cv2.imread(path, cv2.IMREAD_GRAYSCALE) # go_srcnn\n", "        raw_img = cv2.imread(path) # go_srcnn\n", "        raw_img = onlllyas.min_resize(raw_img, 512)\n", "        if 0: onplot.cv_img(raw_img, title=f'raw_img {basename} ')\n\n", "        #raw_img = raw_img.clip(0, 255)\n", "        #raw_img = raw_img.astype(np.uint8) # (512, 512, 3)\n", "        #if 0: onplot.pil_show_rgb(raw_img)\n\n", "        #pads = 7\n", "        #raw_img = raw_img[np.newaxis,:,:,:]\n", "        #raw_img = tf.pad(raw_img / 255.0, [[0, 0], [pads, pads], [pads, pads], [0, 0]], 'REFLECT')\n", "        #if 1: onplot.pil_show_nba(raw_img)\n", "        \n", "        #img = model.generator(raw_img, training=True)       \n", "        #img = img[:, pads * 2:-pads * 2, pads * 2:-pads * 2, :][:, 1:-1, 1:-1, :] * 255.0"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        img = img[np.newaxis,:,:,:]\n", "        img = model.generator(img, training=True)\n", "        img_rgb = onformat.nnba_to_rgb(img)\n", "        if 1: onplot.cv_img(img_rgb, title=f'gen rgb img')            "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        img_2048 = onlllyas.min_resize(raw_img, 2048)        \n", "        if 0: onplot.cv_img(img_2048, title=f'img_2048')\n", "        \n", "        transposed = onlllyas.go_transposed_vector(onlllyas.mk_resize(raw_img, 64))\n", "        height = onlllyas.d_resize(transposed, img_2048.shape) * 255.0\n", "        #height = onlllyas.d_resize(go_transposed_vector(onlllyas.mk_resize(raw_img, 64)), img_2048.shape) * 255.0"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        final_height = height.copy()\n", "        height += (height - cv2.GaussianBlur(height, (0, 0), 3.0)) * 10.0\n", "        height = height.clip(0, 255).astype(np.uint8)\n", "        if 1: onplot.cv_img(height, title=f'height')\n", "        marker = height.copy() # (2048, 2048, 3)\n", "        marker[marker > 135] = 255\n", "        marker[marker < 255] = 0"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        marker = cv2.cvtColor(marker, cv2.COLOR_BGR2GRAY) # marker gray\n", "        fills = onlllyas.get_fill(marker / 255)\n", "        if 0:\n", "            print(f'segment fills: {fills}')\n\n", "        ## *********************************************\n", "        for fill in fills:\n", "            if fill[0].shape[0] < 64:\n", "                marker[fill] = 0\n", "        filter = np.array([\n", "            [0, 1, 0],\n", "            [1, 1, 1],\n", "            [0, 1, 0]],\n", "            dtype=np.uint8)\n", "        big_marker = cv2.erode(marker, filter, iterations=5)\n", "        fills = onlllyas.get_fill(big_marker / 255)\n", "        for fill in fills:\n", "            if fill[0].shape[0] < 64:\n", "                big_marker[fill] = 0\n", "        big_marker = cv2.dilate(big_marker, filter, iterations=5)\n", "        small_marker = marker.copy()\n", "        small_marker[big_marker > 127] = 0\n", "        fin_labels, nil = label(big_marker / 255)\n", "        fin_labels = up_fill(onlllyas.get_fill(small_marker), fin_labels)\n", "        water = cv2.watershed(img_2048.clip(0, 255).astype(np.uint8), fin_labels.astype(np.int32)) + 1\n", "        water = onlllyas.thinning(water)\n", "        all_region_indices = onlllyas.find_all(water)\n", "        regions = np.zeros_like(img_2048, dtype=np.uint8)\n", "        for region_indices in all_region_indices:\n", "            regions[region_indices] = np.random.randint(low=0, high=255, size=(3,)).clip(0, 255).astype(np.uint8)\n", "        result = np.zeros_like(img_2048, dtype=np.uint8)\n", "        for region_indices in all_region_indices:\n", "            result[region_indices] = np.median(img_2048[region_indices], axis=0)\n", "        \n", "        skeleton = final_height.clip(0, 255).astype(np.uint8)\n", "        region = regions.clip(0, 255).astype(np.uint8)\n", "        flatten = result.clip(0, 255).astype(np.uint8)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        skeleton_path = os.path.join(args.results_dir, 'current_skeleton.png')\n", "        region_path = os.path.join(args.results_dir, 'current_region.png')\n", "        flatten_path = os.path.join(args.results_dir, 'current_flatten.png')\n", "        if 1: onplot.cv_img(skeleton, title=f'skeleton')\n", "        if 1: onplot.cv_img(region, title=f'region')\n", "        if 1: onplot.cv_img(flatten, title=f'flatten')\n", "        print(f'save {skeleton_path}')\n", "        print(f'save {region_path}')\n", "        print(f'save {flatten_path}')\n", "        cv2.imwrite(skeleton_path, skeleton)\n", "        cv2.imwrite(region_path, region)\n", "        cv2.imwrite(flatten_path, flatten)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    # 3b. predict test images\n", "    \n", "    if 0:\t# \n", "        \n", "        paths = Onfile.folder_to_paths(args.data_test_pict_dir)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        idx = 0\n", "        for n, path in enumerate(paths):\n", "            basename = os.path.basename(os.path.normpath(path))\n", "            print(f'|===> predict test images path {path}')\n\n", "            #img = tf.io.read_file(path)\n", "            #img = tf.image.decode_jpeg(img)\n", "            #img = tf.cast(img, tf.float32)\n", "            #img = tf.image.resize(img, [512, 512])\n", "            #img = onformat.rgb_to_nba(img)\n", "            #img = img[np.newaxis,:,:,:]\n", "            img = path_process(path, height=512, width=512)\n", "            img = img[np.newaxis,:,:,:]\n", "            img = model.generator(img, training=True) # _e_\n", "            img = onformat.nnba_to_rgb(img)\n", "            try:\n", "                from google.colab.patches import cv2_imshow\n", "                cv2_imshow(img)\n", "                cv2.waitKey(0)            \n", "            except:\n", "                cv2.imshow(basename, img)\n", "                cv2.waitKey(0)\n", "            save_image_path = os.path.join(args.data_test_predict_dir, basename)\n", "            print(f'|... save {save_image_path}')            \n", "            onfile.rgbs_to_file([img], scale=1, rows=1, save_path=save_image_path)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["  \n", "    if 0: # train\n", "        if 1: #  data => dataset (train) # paths_to_dataset_22\n\n", "            #pths_train = [args.data_train_draw_dir, args.data_train_pict_dir]\n", "            #patts = ['*.skeleton.png', '*.region.png']\n", "            pths_train = [args.data_train_pict_dir, args.data_train_draw_dir]\n", "            patts = ['*.region.png', '*.skeleton.png']\n", "            print(f'|===> nndanregion train dataset:  \\n \\\n", "                pths_train {pths_train} \\n \\\n", "                train_draw ({onfile.qfiles(args.data_train_draw_dir, \"*.png\")}) \\n \\\n", "                train_pict ({onfile.qfiles(args.data_train_pict_dir, \"*.png\")}) \\n \\\n", "            ')\n\n", "            #train_dataset = paths_to_dataset_22(pths_train, patts, # BatchDataset\n", "            train_dataset = paths_to_dataset(pths_train, patts, # BatchDataset\n", "                height=args.height, width=args.width, \n", "                buffer_size=args.buffer_size, batch_size=args.batch_size)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        if 1: #  data => dataset (test) --- # paths_to_dataset_22\n", "            print(f'|---> nndanregion datasets:  \\n \\\n", "                test_draw ({onfile.qfiles(args.data_test_draw_dir, \"*.png\")}) \\n \\\n", "                test_pict ({onfile.qfiles(args.data_test_pict_dir, \"*.png\")}) \\n \\\n", "            ')\n", "            if 0:\n", "                pths_test = [args.data_train_draw_dir, args.data_train_pict_dir]\n", "                patts = ['*.skeleton.png', '*.region.png']\n", "            else:\n", "                pths_test = [args.data_train_pict_dir, args.data_train_draw_dir]\n", "                patts = ['*.region.png', '*.skeleton.png']\n\n", "            #test_dataset = paths_to_dataset_22(pths_test, patts,\n", "            test_dataset = paths_to_dataset(pths_test, patts,\n", "                height=args.height, width=args.width, \n", "                buffer_size=args.buffer_size, batch_size=1) # 1 per batch in test dataset _e_"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        if 0: # probe train dataset\n", "            print(f'|===> probe nndanregion train dataset')\n", "            for im,re in train_dataset.take(1):\n", "                print(f'|... item shape in dataset: {np.shape(im)} {np.shape(re)}')\n", "                img1 = onformat.nnba_to_rgb(im)\n", "                img2 = onformat.nnba_to_rgb(re)\n", "                display_list = [img1, img2]\n", "                onplot.pil_show_rgbs(display_list, scale=1, rows=1) "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        print(f'|===> training loop:')\n", "        model.fit(train_dataset, test_dataset, args)     # , summary_writer"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    print('|===> end danboo')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["  ******************<br>\n", "  nnart<br>\n", "  ******************"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def nnart(args, kwargs):\n", "# https://github.com/memo/webcam-pix2pix-tensorflow\n", "    args = onutil.pargs(vars(args))\n", "    args.PROJECT = 'art'\n", "    args.DATASET = 'danregion'\n", "    xp = getxp(vars(args))\n", "    args = onutil.pargs(xp)\n", "    onutil.ddict(vars(args), 'args')\n", "    print(f\"|---> nnart: {args.PROJECT}:  \\n \")\n", "    if 1: # tree\n", "        # ckpt_dir\n", "        ckpt_dir = args.models_dir\n", "        ckpt_prefix = 'ckpt-'\n\n", "        # data\n", "        args.data_train_dir = os.path.join(args.data_dir, 'train')\n", "        args.data_test_dir = os.path.join(args.data_dir, 'test')\n\n", "        # dataset\n", "        args.dataset_train_B_dir = os.path.join(args.dataset_dir, 'train_B_dir')\n", "        args.dataset_train_A_dir = os.path.join(args.dataset_dir, 'train_A_dir')\n", "        args.dataset_test_B_dir = os.path.join(args.dataset_dir, 'test_B_dir')\n", "        args.dataset_test_A_dir = os.path.join(args.dataset_dir, 'test_A_dir')\n", "        os.makedirs(args.models_dir, exist_ok=True)\n", "        os.makedirs(args.logs_dir, exist_ok=True)\n\n", "        # raw data src\n", "        os.makedirs(args.dataorg_dir, exist_ok=True)\n", "        os.makedirs(args.data_dir, exist_ok=True)\n", "        os.makedirs(args.data_train_dir, exist_ok=True) \n", "        os.makedirs(args.data_test_dir, exist_ok=True)\t\n", "        os.makedirs(args.dataset_dir, exist_ok=True)\n", "        os.makedirs(args.dataset_train_B_dir, exist_ok=True) \n", "        os.makedirs(args.dataset_train_A_dir, exist_ok=True) \n", "        os.makedirs(args.dataset_test_B_dir, exist_ok=True) \n", "        os.makedirs(args.dataset_test_A_dir, exist_ok=True) \n", "        os.makedirs(args.records_dir, exist_ok=True)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    if args.verbose: print(f\"|---> nnart tree: {args.PROJECT}:  \\n \\\n", "    cwd: {os.getcwd()} \\n \\\n", "    args.PROJECT:        {args.PROJECT} \\n \\\n", "    args.DATASET:        {args.DATASET} \\n \\\n", "    args.proj_dir:       {args.proj_dir}, data and code will be in args.proj_dir\\n \\\n", "    args.logs_dir:       {args.logs_dir} {onfile.qfiles(args.models_dir, '*')} logs \\n \\\n", "    args.records_dir:    {args.records_dir} :-: {onfile.qfiles(args.records_dir, '*')} files \\n \\\n", "    args.models_dir (ckpts): {args.models_dir} :-: {onfile.qfiles(args.models_dir, '*.index')} \\n \\\n", "    args.dataorg_dir:    {args.dataorg_dir} :-: {onfile.qfiles(args.dataorg_dir, '*.jpg')}  jpgs \\n \\\n", "    \\n \\\n", "    args.data_dir:       {args.data_dir}: {onfile.qfiles(args.data_dir, '*')} files \\n \\\n", "    args.data_train_dir: {args.data_train_dir} :-: {onfile.qfiles(args.data_train_dir, '*.jpg')} \\n \\\n", "    args.data_test_dir:  {args.data_test_dir} :-: {onfile.qfiles(args.data_test_dir, '*.jpg')} \\n \\\n", "    \\n \\\n", "    args.dataset_dir:    {args.dataset_dir} :-: {onfile.qfolders(args.dataset_dir)} folders\\n \\\n", "    args.dataset_train_B_dir (re): {args.dataset_train_B_dir} :-: {onfile.qfiles(args.dataset_train_B_dir, '*.jpg')}  \\n \\\n", "    args.dataset_train_A_dir (in): {args.dataset_train_A_dir} :-: {onfile.qfiles(args.dataset_train_A_dir, '*.jpg')}  \\n \\\n", "    args.dataset_test_B_dir (re): {args.dataset_test_B_dir} :-: {onfile.qfiles(args.dataset_test_B_dir, '*.jpg')}  \\n \\\n", "    args.dataset_test_A_dir (in): {args.dataset_test_A_dir} :-: {onfile.qfiles(args.dataset_test_A_dir, '*.jpg')}  \\n \\\n", "    \")\n", "    if 0: # clear tree\n", "        print(f'|---> clear tree at {args.proj_dir}')\n", "        onfile.clearfolder(args.proj_dir, inkey=args.PROJECT)\n", "    if 1: # data params\n", "        args.img_height = 512\n", "        args.img_width = 512\n", "        args.max_size=512\n", "        args.height=args.img_height\n", "        args.width=args.img_height\n", "        args.input_shape = [args.height, args.width, args.input_channels]\n", "    if args.verbose: print(f\"|---> config  \\n \\\n", "        args.height:         {args.height} \\n \\\n", "        args.width:          {args.width} \\n \\\n", "        args.input_channels: {args.input_channels} \\n \\\n", "        args.buffer_size:    {args.buffer_size} \\n \\\n", "        args.batch_size:     {args.batch_size} \\n \\\n", "        args.input_shape:    {args.input_shape} \\n \\\n", "    \")\n", "    if 1: # raw to paths\n", "        trainpc = 0.9\n", "        testpc = 0.1\n", "        forcecopy = 0\n", "        input_paths = onfile.path_to_paths(args.dataorg_dir, patts=['*.jpg', '*.jpeg', '*.png'])\n", "        qimgs = len(input_paths)\n", "        q_train_imgs = int(qimgs * trainpc )\n", "        q_test_imgs = int(qimgs * testpc )\t\t\n", "        train_paths = input_paths[0:q_train_imgs]\n", "        test_paths = input_paths[q_train_imgs:qimgs]\t\t\n", "        print(f'|--->  raw to data - keep img file names \\n \\\n", "        from {args.dataorg_dir}, {qimgs} images \\n \\\n", "            to data_train_dir: {args.data_train_dir} {q_train_imgs} ({trainpc} %) \\n \\\n", "            to data_test_dir:  {args.data_test_dir}  {q_test_imgs} ({testpc} %)\\n \\\n", "        ')\n", "        \n", "        train_roots = [onutil.get_rootid(path) for path in train_paths]\n", "        if all(root.isdigit() for root in train_roots):\n", "            print(f'|---> sort numeric')\n", "            train_paths = sorted(train_paths, key=lambda path: int(onutil.get_rootid(path)))\n", "        else:\n", "            print(f'|---> sort alphabetic')\n", "            train_paths = sorted(train_paths)\n", "        assert len(train_paths) > 0, f'train files missing'\n", "        test_roots = [onutil.get_rootid(path) for path in test_paths]\n", "        if all(root.isdigit() for root in test_roots):\n", "            test_paths = sorted(test_paths, key=lambda path: int(onutil.get_rootid(path)))\n", "        else:\n", "            test_paths = sorted(test_paths)\n", "        assert len(test_paths) >= 0, f'test files may be missing'"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    if 0: # raw to formed data (dataorg_dir => data_train_dir, data_test_dir)\n", "        for i,path in enumerate(train_paths):\n", "            rootid = int(onutil.get_rootid(path))\n", "            rootfilled = onutil.nameint(rootid)\n", "            ext = os.path.splitext(path)[-1]\n", "            out_path = os.path.join(args.data_train_dir, f'img{rootfilled}{ext}')\n", "            print(f\"|---> {i} {rootfilled} {path} {out_path}\")\n", "            img = ondata.path_to_formed_pair(path)\n", "            img.save(os.path.join(out_path))\n", "        for i,path in enumerate(test_paths):\n", "            rootid = int(onutil.get_rootid(path))\n", "            rootfilled = onutil.nameint(rootid)\n", "            ext = os.path.splitext(path)[-1]\n", "            out_path = os.path.join(args.data_test_dir, f'img{rootfilled}{ext}')\n", "            print(f\"{i} {rootfilled} {path} {out_path}\")\n", "            img = ondata.path_to_formed_pair(path)\n", "            img.save(os.path.join(out_path))\n", "        assert len(onfile.qfiles(args.data_train_dir)) > 0, f'train data files missing'\n", "        assert len(onfile.qfiles(args.data_test_dir)) > 0, f'test data files missing'\n", "    if 1: # model\n", "        print('|---> gan model')\n", "        gan = GAN(\n", "            models_dir = args.models_dir,\n", "            logs_dir = args.logs_dir,\n", "            ckpt_dir = ckpt_dir,\n", "            #ckpt_prefix = ckpt_prefix,\n", "            input_shape = args.input_shape,\n", "            output_shape = args.input_shape,\n", "        )\n", "    if 1: #  formed => datasets 11\n", "        print(f'|===> to datasets 11')\n", "        #train_dataset = path_to_dataset_11(\n", "        train_dataset = paths_to_dataset(\n", "            args.data_train_dir, \n", "            '*.png', \n", "            batch_size=4)\n", "        #test_dataset = path_to_dataset_11(\n", "        test_dataset = paths_to_dataset(\n", "            args.data_test_dir, \n", "            '*.png', \n", "            batch_size=4)\n", "        print(f'|---> train_dataset {type(train_dataset)}')\n", "        print(f'|---> test_dataset {type(test_dataset)}')\n", "    \n", "    if 1: # train\n", "        print('|===> run the training loop')\n", "        gan.fit(train_dataset, test_dataset, args)     # , summary_writer\n", "    print(f'|===> end nnart')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["  ******************<br>\n", "  nncrys - 22<br>\n", "  "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def nncrys(args, kwargs):\n", "    args = onutil.pargs(vars(args))\n", "    args.PROJECT = 'crystals'\n", "    args.DATASET = 'quimica_tech'\n", "    args.LOCALLAB = 0\n", "    xp = getxp(vars(args))\n", "    args = onutil.pargs(xp)\n", "    onutil.ddict(vars(args), 'args')\n", "    print(f\"|---> nncrys: {args.PROJECT}:  \\n \")\n", "    if 1: # tree\n", "        assert(os.path.exists(args.dataorg_dir))\n", "        args.ckpt_dir = args.models_dir\n", "        args.data_train_dir = os.path.join(args.data_dir, 'train_dir')\n", "        args.data_test_dir = os.path.join(args.data_dir, 'test_dir')\n", "        args.results_dir = os.path.join(args.proj_dir, 'results') # in project dir\n", "        args.dataset_train_B_dir = os.path.join(args.dataset_dir, 'train_B')\n", "        args.dataset_train_A_dir = os.path.join(args.dataset_dir, 'train_A')\n", "        args.dataset_test_B_dir = os.path.join(args.dataset_dir, 'test_B')\n", "        args.dataset_test_A_dir = os.path.join(args.dataset_dir, 'test_A')\n", "        os.makedirs(args.models_dir, exist_ok=True)\n", "        os.makedirs(args.logs_dir, exist_ok=True)\n", "        os.makedirs(args.data_train_dir, exist_ok=True) \n", "        os.makedirs(args.data_test_dir, exist_ok=True) "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        os.makedirs(args.dataset_train_B_dir, exist_ok=True) \n", "        os.makedirs(args.dataset_train_A_dir, exist_ok=True) \n", "        os.makedirs(args.dataset_test_B_dir, exist_ok=True) \n", "        os.makedirs(args.dataset_test_A_dir, exist_ok=True) \n", "        os.makedirs(args.models_dir, exist_ok=True)\n", "        os.makedirs(args.logs_dir, exist_ok=True)\n", "        os.makedirs(args.tmp_dir, exist_ok=True)\n", "        os.makedirs(args.records_dir, exist_ok=True)\n", "        os.makedirs(args.results_dir, exist_ok=True)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    if args.verbose: print(f\"|---> nncrys tree: {args.PROJECT}:  \\n \\\n", "    cwd: {os.getcwd()} \\n \\\n", "    args.PROJECT:        {args.PROJECT} \\n \\\n", "    args.DATASET:        {args.DATASET} \\n \\\n", "    args.proj_dir:       {args.proj_dir} \\n \\\n", "    args.dataorg_dir:    {args.dataorg_dir} :-: {onfile.qfiles(args.dataorg_dir, '*.jpg')}  jpgs \\n \\\n", "    args.data_dir:       {args.data_dir} :-: {onfile.qfiles(args.data_dir, '*')} items \\n \\\n", "    args.data_train_dir: {args.data_train_dir} :-: {onfile.qfiles(args.data_train_dir, '*.jpg')} jpgs \\n \\\n", "    args.data_test_dir:  {args.data_test_dir} :-: {onfile.qfiles(args.data_test_dir, '*.jpg')} jpgs \\n \\\n", "    args.dataset_dir:    {args.dataset_dir} :-: {onfile.qfolders(args.dataset_dir)} folders\\n \\\n", "    args.logs_dir:       {args.logs_dir} {onfile.qfiles(args.models_dir, '*')} logs \\n \\\n", "    args.results_dir:       {args.results_dir} {onfile.qfiles(args.results_dir, '*')} results \\n \\\n", "    args.dataset_train_B_dir: {args.dataset_train_B_dir} :-: {onfile.qfiles(args.dataset_train_B_dir, '*.jpg')}  jpgs \\n \\\n", "    args.dataset_train_A_dir: {args.dataset_train_A_dir} :-: {onfile.qfiles(args.dataset_train_A_dir, '*.jpg')}  jpgs \\n \\\n", "    args.dataset_test_B_dir:  {args.dataset_test_B_dir} :-: {onfile.qfiles(args.dataset_test_B_dir, '*.jpg')}  jpgs \\n \\\n", "    args.dataset_test_A_dir:  {args.dataset_test_A_dir} :-: {onfile.qfiles(args.dataset_test_A_dir, '*.jpg')}  jpgs \\n \\\n", "    args.records_dir:    {args.records_dir} :-: {onfile.qfiles(args.records_dir, '*')} files \\n \\\n", "    args.models_dir:     {args.models_dir} :-: {onfile.qfiles(args.models_dir, '*.index')} snaps \\n \\\n", "    \")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    if 1: # config\n", "        args.ckpt_prefix = 'ckpt-'\n", "        args.img_height = 512\n", "        args.img_width = 512\n", "        args.max_size=512\n", "        args.height=args.img_height\n", "        args.width=args.img_height\n", "        args.batch_size=1\n", "        args.input_shape = [args.height, args.width, args.input_channels]\n", "    if args.verbose: print(f'|--->  {args.PROJECT}: config  \\n \\\n", "        args.height:         {args.height} \\n \\\n", "        args.width:          {args.width} \\n \\\n", "        args.max_size:       {args.max_size} \\n \\\n", "        args.input_channels: {args.input_channels} \\n \\\n", "        args.buffer_size:    {args.buffer_size} \\n \\\n", "        args.batch_size:     {args.batch_size} \\n \\\n", "        args.input_shape:    {args.input_shape} \\n \\\n", "    ')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    if 0: # clear tree\n", "        print(f\"clear tree at {args.proj_dir}\")\n", "        onfile.clearfolder(args.proj_dir, inkey=args.PROJECT)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    if 0: # make gif out of results: all generatd imgs with patterns\n", "        imgpatts = ['0012*.png']\n", "        dstpath = os.path.join(args.results_dir, 'out.gif')\n", "        nresults = args.results_dir\n", "        srcdir = nresults # args.results_dir\n", "        print(f\"|===> tovid \\n \\\n", "            args.results_dir: {args.results_dir} \\n \\\n", "            nresults: {nresults} \\n \\\n", "            srcdir: {srcdir} \\n \\\n", "        \")\n", "        onvid.folder_to_gif(srcdir, dstpath, patts=imgpatts)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    if 1: # \tmodel\n", "        print(f\"|===> get model from {args.models_dir} \\n \")\t\t\n", "        model = GAN( \n", "            models_dir = args.models_dir,\n", "            logs_dir = args.logs_dir,\n", "            results_dir = args.results_dir,\n", "            ckptidx = -1,\n", "            ckpt_dir = args.ckpt_dir,\n", "            ckpt_prefix = args.ckpt_prefix,\n", "            input_shape = args.input_shape,\n", "            output_shape = args.input_shape,\n", "        )"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    if 1: # raw images to data (dataorg_dir => data_train_dir, data_test_dir)\n", "        trainpc = 0.9\n", "        testpc = 0.1\n", "    \n", "        input_paths = onfile.folder_to_paths(args.dataorg_dir)\n", "        q_from_imgs = len(input_paths)\n", "        q_train_imgs = int(q_from_imgs * trainpc)\n", "        q_test_imgs = int(q_from_imgs * testpc)\n", "        train_paths = input_paths[0:q_train_imgs]\n", "        test_paths = input_paths[0:q_test_imgs]\n", "        q_from_train_imgs = len(train_paths)\n", "        q_from_test_imgs = len(test_paths)\n", "        q_to_train_imgs = onfile.qfiles(args.data_train_dir)\n", "        q_to_test_imgs = onfile.qfiles(args.data_test_dir)\n", "        print(f\"|===>  org raw to data \\n \\\n", "            {len(train_paths)} to {args.data_train_dir} with {q_to_train_imgs} \\n \\\n", "            {len(test_paths)} to {args.data_test_dir} with {q_to_test_imgs} \\n \\\n", "        \")\n\n", "        # raw images to train data (args.dataorg_dir => args.data_train_dir)\n", "        if not q_from_train_imgs == q_to_train_imgs:\t\t\n", "            onfile.paths_to_folder_with_cv(train_paths, args.data_train_dir)\n", "        else:\n", "            print(f\"|... !!! train not copied. {args.data_train_dir} got them\")\n\n", "        # raw images to test data (args.dataorg_dir => args.data_test_dir)\n", "        if not q_from_test_imgs == q_to_test_imgs:\t\t\t\n", "            onfile.paths_to_folder_with_cv(test_paths, args.data_test_dir)\n", "        else:\n", "            print(f\"|... !!! test not  copied. {args.data_test_dir} got them\")\n", "        \n", "        if 1:  # show raw images shapes\n", "            nuas = onfile.folder_to_nuas(args.data_train_dir)\n", "            n = np.random.randint(0, len(nuas))\n", "            print(f\"|... data train image {n} shape: {np.shape(nuas[n])}\")\n", "    if 1: # data to dataset B (data_dir => (train, test))\n", "        args.keep_folder=True    \n", "        args.process_type='crop_to_square'\n", "        args.file_extension= 'jpg'\n", "        args.name=1 # alpha name\n", "        print(f\"|===> data to dataset B (real) \\n \\\n", "            {args.data_train_dir} to {args.dataset_train_B_dir}   \\n \\\n", "            {args.data_test_dir}  to {args.dataset_test_B_dir} \\n \\\n", "            args.process_type:  {args.process_type} \\n \\\n", "            args.file_extension:{args.file_extension} \\n \\\n", "            args.max_size:{args.max_size} \\n \\\n", "        \")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        # dataset to train data\n", "        args.input_folder = args.data_train_dir\n", "        args.output_folder = args.dataset_train_B_dir\n", "        q_from_train_imgs = onfile.qfiles(args.input_folder)\n", "        q_to_train_imgs = onfile.qfiles(args.output_folder)\n", "        print(f'|==> data to dataset train: {args.process_type} \\n \\\n", "            {args.input_folder} ==> {args.output_folder} \\n \\\n", "            q_from_train_imgs: {onfile.qfiles(args.input_folder)} \\n \\\n", "            q_to_train_imgs: {onfile.qfiles(args.output_folder)} \\n \\\n", "        ')\n", "        if not q_from_train_imgs == q_to_train_imgs: # dir empty\t\t\t\t\n", "            onset.processFolder(args) # copy reals to train\n", "        else:\n", "            print(f\"|... nothing copied. {args.output_folder} not empty\")\n", "        assert onfile.qfiles(args.output_folder) > 0, f're train files not found {args.output_folder}'\n\n", "        # show train images shapes\n", "        if 1:\n", "            nuas = onfile.folder_to_nuas(args.dataset_train_B_dir)\n", "            n = np.random.randint(0, len(nuas))\n", "            print(f\"|---> train image {n} shape: {np.shape(nuas[n])}\")\t\t\n\n", "        # dataset to test data\n", "        args.input_folder = args.data_test_dir\n", "        args.output_folder = args.dataset_test_B_dir\n", "        q_from_test_imgs = onfile.qfiles(args.input_folder)\n", "        q_to_test_imgs = onfile.qfiles(args.output_folder)\n", "        print(f'|==> data to dataset test: {args.process_type} \\n \\\n", "            {args.input_folder} ==> {args.output_folder} \\n \\\n", "            q_from_test_imgs: {onfile.qfiles(args.input_folder)} \\n \\\n", "            q_to_test_imgs: {onfile.qfiles(args.output_folder)} \\n \\\n", "        ')\n", "        if not q_from_test_imgs == q_to_test_imgs: # dir empty\t\t\t\t\n", "            onset.processFolder(args) # copy reals to test\n", "        else:\n", "            print(f\"|... nothing copied. {args.output_folder} not empty\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    if 1: # canny to dataset A ((train, test)B => (train, test)A)\n", "        args.keep_folder=True    \n", "        args.process_type='canny' # 'square' # 'canny-pix2pix'\n", "        args.direction='B2A'\n", "        args.file_extension='jpg'\n", "        args.blur_type='gaussian'\n", "        args.blur_amount=3\n", "        args.name=1\n", "        args.mirror=None\n", "        args.rotate=None\n", "        if args.verbose: print(f\"|===>  canny B ==> dataset A (sketch):   \\n \\\n", "            args.process_type:   {args.process_type} \\n \\\n", "            args.direction:   \t {args.direction} \\n \\\n", "            args.blur_type:   \t {args.blur_type} \\n \\\n", "            args.blur_amount:    {args.blur_amount} \\n \\\n", "            args.file_extension: {args.file_extension} \\n \\\n", "            from {args.dataset_train_B_dir}  \\n \\\n", "                to {args.dataset_train_A_dir} \\n \\\n", "            from {args.dataset_test_B_dir}  \\n \\\n", "                to {args.dataset_test_A_dir} \\n \\\n", "        \")\n\n", "        # data to dataset train B\n", "        args.input_folder = args.dataset_train_B_dir\n", "        args.output_folder = args.dataset_train_A_dir\n", "        if not os.listdir(args.output_folder): # dir empty\n", "            print(f\"|---> train canny {args.process_type}: {args.input_folder}   \\n \\\n", "                to {args.output_folder},  \\n \\\n", "                from imgs q: {onfile.qfiles(args.input_folder)}\t\\n \\\n", "                to imgs q: {onfile.qfiles(args.output_folder)}\t\\n \\\n", "            \")\n", "            onset.processFolder(args) # canny's to train\n\n", "            #convert grey to rgb\n", "            for filename in os.listdir(args.output_folder):\n", "                file_path = os.path.join(args.output_folder, filename)\n", "                img = cv2.imread(file_path)    \n", "                canny = cv2.cvtColor(Onset.processCanny(img,args),cv2.COLOR_GRAY2RGB)\n", "                if(args.file_extension == \"png\"):\n", "                    new_file = os.path.splitext(filename)[0] + \".png\"\n", "                    cv2.imwrite(os.path.join(args.output_folder, new_file), canny, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n", "                elif(args.file_extension == \"jpg\"):\n", "                    new_file = os.path.splitext(filename)[0] + \".jpg\"\n", "                    cv2.imwrite(os.path.join(args.output_folder, new_file), canny, [cv2.IMWRITE_JPEG_QUALITY, 90])\n", "        else:\n", "            print(f\"|---> nothing copied. {args.output_folder} not empty\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        # data to dataset test B\n", "        args.input_folder = args.dataset_test_B_dir\n", "        args.output_folder = args.dataset_test_A_dir\n", "        if not os.listdir(args.output_folder): # dir  empty\t\t\t\n", "            print(f\"|---> test canny {args.process_type}: {args.input_folder}   \\n \\\n", "                to {args.output_folder},  \\n \\\n", "                from imgs q: {onfile.qfiles(args.input_folder)}\t\\n \\\n", "                to imgs q: {onfile.qfiles(args.output_folder)}\t\\n \\\n", "            \")\n", "            onset.processFolder(args) # canny's to test\n\n", "            #convert grey to rgb\n", "            for filename in os.listdir(args.output_folder):\n", "                file_path = os.path.join(args.output_folder, filename)\n", "                img = cv2.imread(file_path)    \n", "                canny = cv2.cvtColor(Onset.processCanny(img,args),cv2.COLOR_GRAY2RGB)\n", "                if(args.file_extension == \"png\"):\n", "                    new_file = os.path.splitext(filename)[0] + \".png\"\n", "                    cv2.imwrite(os.path.join(args.output_folder, new_file), canny, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n", "                elif(args.file_extension == \"jpg\"):\n", "                    new_file = os.path.splitext(filename)[0] + \".jpg\"\n", "                    cv2.imwrite(os.path.join(args.output_folder, new_file), canny, [cv2.IMWRITE_JPEG_QUALITY, 90])\n", "            \n", "        else:\n", "            print(f\"|---> nothing copied. {args.output_folder} not empty\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    if 1: #  data_train_dir => tf datasets 22\n", "        print(f\"|===> data to datasets 22\")\n", "        pths_train = [args.dataset_train_A_dir, args.dataset_train_B_dir, ]\n", "        pths_test = [args.dataset_test_A_dir,args.dataset_test_B_dir, ]\n", "        args.patts = ['*.jpg', '*.jpg']\n", "        print(f\"|--->  data to dataset A:   \\n \\\n", "            train_dataset from {pths_train} with args.patts {args.patts} \\n \\\n", "            test_dataset from {pths_test} with args.patts {args.patts} \\n \\\n", "            height {args.height} \\n \\\n", "            width {args.width} \\n \\\n", "            buffer_size {args.buffer_size} \\n \\\n", "            batch_size {args.height} \\n \\\n", "        \")\n\n", "        #train_dataset = paths_to_dataset_22(\n", "        train_dataset = paths_to_dataset(\n", "            pths_train, \n", "            args.patts, \n", "            height=args.height, width=args.width, buffer_size=args.buffer_size, batch_size=args.batch_size)\n", "        \n", "        #test_dataset = paths_to_dataset_22(\n", "        test_dataset = paths_to_dataset(\n", "            pths_test, \n", "            args.patts, \n", "            height=args.height, width=args.width, buffer_size=args.buffer_size, batch_size=args.batch_size)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    if 0: # probe train dataset\n", "        print(f\"|===> probe train dataset\")\n", "        iterator = train_dataset.take(1) # <class 'tensorflow.python.data.ops.dataset_ops.TakeDataset'>\n", "        for elem in iterator:\n", "            #itemlist = list(elem)\n", "            example_input, example_target = elem\n", "            if args.verbose:\n", "                print(f'|---> probe train dataset {type(example_input)} {type(example_target)} ')\n", "            img1 = onformat.nnba_to_rgb(example_input)\n", "            img2 = onformat.nnba_to_rgb(example_target)\n", "                      \n", "            display_list = [img1, img2]\n", "            onplot.pil_show_rgbs(display_list, scale=1, rows=1) "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    if 0: #   \tdata => tfrecords\n", "        print(f\"|===> data to tfrecords   \\n \\\n", "        from: {args.dataset_train_A_dir} \\n \\\n", "            to args.records_dir: {args.records_dir} \\n \\\n", "        \")\t\t\n", "        # <class 'numpy.ndarray'> (512, 1024, 3)\n", "        onrecord.folder_to_tfrecords(\n", "            args.dataset_train_A_dir, \n", "            args.records_dir)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    if 1: # walk ckpt models\n", "        maxitems = 40\n", "        patts = ['*.index']\n", "        paths = onfile.path_to_paths(model.ckpt_manager.directory, patts)\n", "        print(f'|===> walk ckpt models \\n \\\n", "            ckpt_manager: {model.ckpt_manager.directory} \\n \\\n", "            ckpt_manager.latest_checkpoint: {model.ckpt_manager.latest_checkpoint} \\n \\\n", "            ckpt_manager.checkpoints: {model.ckpt_manager.checkpoints} \\n \\\n", "            ckpt_manager.directory: {model.ckpt_manager.directory} \\n \\\n", "            patts: {patts} \\n \\\n", "            paths: {len(paths)} \\n \\\n", "        ')\n", "        for path in paths:\n", "            filename = os.path.basename(path)\n", "            ckpt = filename.split('.')[0] # {prefix}-{ckptidx}.index => {prefix}-{ckptidx}\n", "            ckptidx = oncheck.getckptidx(ckpt)\n", "        ckptidxs = []\n", "        for path in paths:\n", "            filename = os.path.basename(path)\n", "            infix = filename.split('.')[0]\n", "            ckptidx = oncheck.getckptidx(infix)\n", "            ckptidxs.append(int(ckptidx)) # if None\n", "        ckptidxs = sorted(ckptidxs)\n", "        qckptidxs = len(ckptidxs)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        mod = int(qckptidxs/maxitems)\n", "        print(f'|===> walk ckpt models with mod {mod}')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        ckptidxs=[]\n", "        for i,idx in enumerate(range(qckptidxs-1)):\n", "            if i % mod == 1:\n", "                ckptidxs.append(idx)\n", "        ckptidxs.append(len(ckptidxs))\n", "        \n", "        for ckptidx in ckptidxs:\n", "            print(f\"|===> walk ckptidxs with ckpt: {ckpt}\")\n", "            model = GAN( \n", "                models_dir = args.models_dir,\n", "                logs_dir = args.logs_dir,\n", "                results_dir = args.results_dir,\n", "                ckptidx = ckptidx,  # 1, None, -1\n", "                ckpt_dir = args.ckpt_dir,\n", "                ckpt_prefix = args.ckpt_prefix, # 'ckpt-'\n", "                input_shape = args.input_shape,\n", "                output_shape = args.input_shape,\n", "            )\n", "            if 0: # img waits\n", "                onplot.plot_iter_grid(model, test_dataset, 1, 3, figsize = (6.4, 6.3), do=['save']) # do=['plot', 'save']"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    if 1: # ckpt models to gif\n", "        fromfolder = args.results_dir\n", "        dstpath = os.path.join(args.results_dir, 'out.gif')\n", "        patts= ['frame*']   \n", "        print(f'|===>  gif of ckpt models \\n \\\n", "            fromfolder: {fromfolder} \\n \\\n", "            dstpath: {dstpath} \\n \\\n", "            patts: {patts}  \\n \\\n", "        ')\n", "        onvid.folder_to_gif(fromfolder, dstpath, patts)\n", "        #_folder_to_gif(fromfolder, dstpath, patts)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    if 0: #  \tcolab\n", "        if onutil.incolab():\n", "            print(\"|---> load tensorboard to monitor logs with colab\")\n", "            os.system(f\"load_ext tensorboard\")\n", "            os.system(f\"tensorboard --logdir {args.logs_dir}\")\n", "        else:\n", "            print(f\"|---> launch a separate tensorboard process to monitor logs with colab\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    if 0: # walk test_dataset\n", "        print(f\"|===> walk the test_dataset\")\n", "        onplot.plot_iter_grid(model, test_dataset, 3, 3, figsize = (6.4, 6.3), do=['plot', 'save'])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    if 0: # show train first\n", "        print(f\"|===> show first in train dataset\")\n", "        for train_input, train_target in train_dataset.take(1):\n", "            prediction = model.generator(train_input, training=True) # _e_\n", "            display_list = [\n", "                onformat.nnba_to_rgb(train_input),\n", "                onformat.nnba_to_rgb(train_target),\n", "                onformat.nnba_to_rgb(prediction)\n", "            ]\n", "            onplot.pil_show_rgbs(display_list, scale=1, rows=1)   \n", "    if 0: # show test first\n", "        print(f\"|===> show first in test dataset\")\n", "        for test_input, test_target in test_dataset.take(1):\n", "            prediction = model.generator(test_input, training=True) # _e_\n", "            display_list = [\n", "                onformat.nnba_to_rgb(test_input),\n", "                onformat.nnba_to_rgb(test_target),\n", "                onformat.nnba_to_rgb(prediction)\n", "            ]\n", "            onplot.pil_show_rgbs(display_list, scale=1, rows=1)        \n", "    if 0: # show all in dataset\n", "        print(f\"|===> show all in test dataset\")\n", "        for inp,tar in test_dataset.as_numpy_iterator():\n", "            prediction = model.generator(inp, training=True) # _e_\n", "            display_list = [\n", "                onformat.nnba_to_rgb(inp),\n", "                onformat.nnba_to_rgb(tar),\n", "                onformat.nnba_to_rgb(prediction)\n", "            ]\n", "            onplot.pil_show_rgbs(display_list, scale=1, rows=1)   "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    if 0: # train\n", "        print(f\"|===> train loop\")\n", "        model.fit(train_dataset, test_dataset, args)\n", "    print(f'|===> end nncrys')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["  ******************<br>\n", "  nnleonardo - 22<br>\n", "  "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def nnleonardo(args, kwargs):\n", "    args = onutil.pargs(vars(args))\n", "    args.PROJECT = 'leonardo'\n", "    args.DATASET = 'leonardo'\n", "    xp = getxp(vars(args))\n", "    args = onutil.pargs(xp)\n", "    onutil.ddict(vars(args), 'args')\n", "    print(f\"|---> nnleonardo: {args.PROJECT}:   \\n \")\n", "    if 1: # tree\n", "        args.dataorg_train_dir = os.path.join(args.dataorg_dir, 'train')\n", "        args.dataorg_test_dir = os.path.join(args.dataorg_dir, 'test')\n", "        assert(os.path.exists(args.dataorg_dir))\n", "        assert(os.path.exists(args.dataorg_train_dir))\n", "        assert(os.path.exists(args.dataorg_test_dir))\n", "        args.ckpt_dir = args.models_dir\n", "        args.ckpt_prefix = os.path.join(args.ckpt_dir, \"ckpt-\")\n", "        ''' train/test images in origin with pattern '''\n", "        args.data_train_B_dir = os.path.join(args.data_dir, 'train_B')\n", "        args.data_train_A_dir = os.path.join(args.data_dir, 'train_A')\n", "        args.data_test_B_dir = os.path.join(args.data_dir, 'test_B')\n", "        args.data_test_A_dir = os.path.join(args.data_dir, 'test_A')\n", "        args.dataset_train_B_dir = os.path.join(args.dataset_dir, 'train_B')\n", "        args.dataset_train_A_dir = os.path.join(args.dataset_dir, 'train_A')\n", "        args.dataset_test_B_dir = os.path.join(args.dataset_dir, 'test_B')\n", "        args.dataset_test_A_dir = os.path.join(args.dataset_dir, 'test_A')\n", "        args.zipfile = os.path.join(args.dataorg_dir, f'{args.DATASET}.zip')\n", "        os.makedirs(args.data_train_B_dir, exist_ok=True) \n", "        os.makedirs(args.data_train_A_dir, exist_ok=True) \n", "        os.makedirs(args.data_test_B_dir, exist_ok=True) \n", "        os.makedirs(args.data_test_A_dir, exist_ok=True) \n", "        os.makedirs(args.dataset_train_B_dir, exist_ok=True) \n", "        os.makedirs(args.dataset_train_A_dir, exist_ok=True) \n", "        os.makedirs(args.dataset_test_B_dir, exist_ok=True) \n", "        os.makedirs(args.dataset_test_A_dir, exist_ok=True) \n", "        os.makedirs(args.models_dir, exist_ok=True)\n", "        os.makedirs(args.logs_dir, exist_ok=True)\n", "        os.makedirs(args.tmp_dir, exist_ok=True)\n", "    if args.verbose: print(f\"|---> tree: {args.PROJECT}:   \\n \\\n", "        args.PROJECT:    \t  {args.PROJECT} \\n \\\n", "        args.DATASET:    \t  {args.DATASET} \\n \\\n", "        args.dataorg_dir:     {args.dataorg_dir} \\n \\\n", "        args.dataorg_train_dir: {args.dataorg_train_dir} \\n \\\n", "        args.dataorg_test_dir: {args.dataorg_test_dir} \\n \\\n", "        args.ckpt_dir:  {args.ckpt_dir} \\n \\\n", "        args.logs_dir:        {args.logs_dir} \\n \\\n", "        args.tmp_dir:        {args.tmp_dir} \\n \\\n", "        args.zipfile:         {args.zipfile} \\n \\\n", "        args.verbose:         {args.verbose}, \\n \\\n", "        args.visual:          {args.visual}, \\n \\\n", "    \")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    if 1: # config\n", "        args.height = args.img_height\n", "        args.width = args.img_width\n", "        args.buffer_size = args.buffer_size\n", "        args.batch_size = args.batch_size\n", "        args.input_channels = args.input_channels\n", "        args.input_shape = [args.height, args.width, args.input_channels]\n", "        if 0:\n", "            ''' copy org to same data folder'''\n", "            args.patts = ['*in.png', '*re.png']\n", "        else:\n", "            ''' will separate images in data'''\n", "            args.patts = ['*.png', '*.png']\n", "    if args.verbose: print(f\"|---> nnleonardo config:   \\n \\\n", "        args.max_epochs:            {args.max_epochs}, \\n \\\n", "        args.output_channels:\t{args.output_channels} \\n \\\n", "        args.height: \t\t\t{args.height} \\n \\\n", "        args.width: \t\t\t{args.width} \\n \\\n", "        args.input_channels: \t{args.input_channels} \\n \\\n", "        args.buffer_size: \t\t{args.buffer_size} \\n \\\n", "        args.batch_size: \t\t{args.batch_size} \\n \\\n", "        args.input_shape: \t\t{args.input_shape} \\n \\\n", "        args.patts:     \t\t{args.patts}, \\n \\\n", "    \")\n", "    if args.visual > 1: # show ref images\n", "        ref_pict_path = os.path.join(args.dataorg_train_dir, 'da02_re.png')\n", "        ref_draw_path = os.path.join(args.dataorg_train_dir, 'da02_in.png')\n", "        re = onfile.path_to_rgb(ref_pict_path)\n", "        inp = onfile.path_to_rgb(ref_draw_path)\n", "        down_model = ondata.downsample(3, 4)\n", "        down_result = down_model(tf.expand_dims(tf.cast(inp, tf.float32), 0)) # _e_\n", "        up_model = ondata.upsample(3, 4)\n", "        up_result = up_model(down_result)\n", "        print(f\"|---> show ref images:   \\n \\\n", "            ref_pict_path: {ref_pict_path} \\n \\\n", "            ref_draw_path: {ref_draw_path} \\n \\\n", "            down_result.shape: {down_result.shape} \\n \\\n", "            up_result.shape: {up_result.shape} \\n \\\n", "            args.input_shape: {args.input_shape} \\n \\\n", "            re shape: {np.shape(re)} \\n \\\n", "            inp shape: {np.shape(inp)} \\n \\\n", "        \")\n", "        print(f\"|---> plot re, inp ...\")\n", "        onplot.pil_show_rgbs([re, inp])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    if 1: #  dataorg raw => data train \n", "        print(f\"|---> raw to data\")\n", "        args.keep_folder=True    \n", "        args.process_type='crop_to_square'\n", "        args.file_extension= 'png'\n", "        args.name=1\n", "        args.zfill=0\n", "        args.input_folder = args.dataorg_train_dir\n", "        args.filepatt = f'.*in.{args.file_extension}'\n", "        #args.filepatt = f'*' => re.error: nothing to repeat at position 0\n", "        args.output_folder = args.data_train_A_dir\n", "        qinfiles = onfile.qfiles(args.input_folder, f'*in.{args.file_extension}')\n", "        qoutfiles = onfile.qfiles(args.output_folder)\n", "        print(f\"|---> nnleonardo train copy: {args.process_type}: \\n \\\n", "            {args.input_folder} ==> {args.output_folder}, \\n \\\n", "            qinfiles : {qinfiles}, \\n \\\n", "            qoutfiles : {qoutfiles}, \\n \\\n", "        \")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        if  qinfiles > qoutfiles:\n", "            onset.processFolder(args) # copy inputs to train\n", "        else:\n", "            print(f'|... no processFolder !!!!. files already there ')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        args.filepatt = f'.*re.{args.file_extension}'\n", "        args.output_folder = args.data_train_B_dir\n", "        qinfiles = onfile.qfiles(args.input_folder, f'*in.{args.file_extension}')\n", "        qoutfiles = onfile.qfiles(args.output_folder)\n", "        print(f\"|---> train copy: {args.process_type}: \\n \\\n", "            {args.input_folder} ==> {args.output_folder}, \\n \\\n", "            qinfiles : {qinfiles}, \\n \\\n", "            qoutfiles : {qoutfiles}, \\n \\\n", "        \")\n", "        if  qinfiles > qoutfiles:\n", "            onset.processFolder(args) # copy reals to train\n", "        else:\n", "            print(f'|... no processFolder !!!!. files already there ')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    if 1: #  dataorg_test_dir raw => data_test_dir (A/B) data\n", "        args.keep_folder=True    \n", "        args.process_type='crop_to_square'\n", "        args.file_extension= 'png'\n", "        args.name=1\n", "        args.zfill=0\n", "        args.input_folder = args.dataorg_test_dir\n", "        args.filepatt = f'.*in.{args.file_extension}'\n", "        args.output_folder = args.data_test_A_dir\n", "        args.filepatt = f'.*re.{args.file_extension}'\n", "        args.output_folder = args.data_train_B_dir\n", "        print(f\"|---> test copy: {args.process_type}: \\n \\\n", "            {args.input_folder} ==> {args.output_folder}, \\n \\\n", "            qinfiles : {qinfiles}, \\n \\\n", "            qoutfiles : {qoutfiles}, \\n \\\n", "        \")\n", "        if not qinfiles == qoutfiles:\n", "            onset.processFolder(args) # copy inputs to test\n", "        else:\n", "            print(f'|... no processFolder !!!!. files there ')\n", "        args.filepatt = f'.*re.{args.file_extension}'\n", "        args.output_folder = args.data_test_B_dir"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        args.filepatt = f'.*re.{args.file_extension}'\n", "        args.output_folder = args.data_train_B_dir\n", "        print(f\"|---> test copy: {args.process_type}:  \\n \\\n", "            {args.input_folder} ==> {args.output_folder},\\n \\\n", "            qinfiles : {qinfiles}, \\n \\\n", "            qoutfiles : {qoutfiles}, \\n \\\n", "        \")\n", "        if not qinfiles == qoutfiles:\n", "            onset.processFolder(args) # copy reals to test\n", "        else:\n", "            print(f'|... no processFolder !!!!. files there ')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    if 1: #  data to dataset (A/B) data\n", "        print(f\"|---> data to dataset\")\n", "        args.keep_folder=True    \n", "        args.process_type='crop_to_square'\n", "        args.file_extension= 'png'\n", "        args.name=1\n", "        args.zfill=0\n\n", "        # data_train_dir raw => dataset_train_dir (A/B) data\n", "        args.input_folder = args.data_train_A_dir\n", "        args.filepatt = f'.*.{args.file_extension}'\n", "        args.output_folder = args.dataset_train_A_dir\n", "        qinfiles = onfile.qfiles(args.input_folder, f'*.{args.file_extension}')\n", "        qoutfiles = onfile.qfiles(args.output_folder)\n", "        print(f\"|---> train copy: {args.process_type}:   \\n \\\n", "            {args.input_folder} ==> {args.output_folder}, \\n \\\n", "            qinfiles : {qinfiles}, \\n \\\n", "            qoutfiles : {qoutfiles}, \\n \\\n", "        \")\n", "        if not qinfiles == qoutfiles:\n", "            onset.processFolder(args) # copy inputs to train\n", "        else:\n", "            print(f'|... no processFolder !!!!. files there ')\n", "        args.input_folder = args.data_train_B_dir\n", "        args.filepatt = f'.*.{args.file_extension}'\n", "        args.output_folder = args.dataset_train_B_dir\n", "        qinfiles = onfile.qfiles(args.input_folder, f'*.{args.file_extension}')\n", "        qoutfiles = onfile.qfiles(args.output_folder)\n", "        print(f\"|---> train copy: {args.process_type}:   \\n \\\n", "            {args.input_folder} ==> {args.output_folder}, \\n \\\n", "            qinfiles : {qinfiles}, \\n \\\n", "            qoutfiles : {qoutfiles}, \\n \\\n", "        \")\n", "        if not qinfiles == qoutfiles:\n", "            onset.processFolder(args) # copy reals to train\n", "        else:\n", "            print(f'|... no processFolder !!!!. files there ')\n\n", "        # data_test_dir raw => dataset\n", "        args.input_folder = args.data_test_A_dir\n", "        args.filepatt = f'.*in.{args.file_extension}'\n", "        args.output_folder = args.dataset_test_A_dir\n", "        qinfiles = onfile.qfiles(args.input_folder, f'*in.{args.file_extension}')\n", "        qoutfiles = onfile.qfiles(args.output_folder)\n", "        print(f\"|---> test copy: {args.process_type}:   \\n \\\n", "            {args.input_folder} ==> {args.output_folder}, \\n \\\n", "            qinfiles : {qinfiles}, \\n \\\n", "            qoutfiles : {qoutfiles}, \\n \\\n", "        \")\n", "        if not qinfiles == qoutfiles:\n", "            onset.processFolder(args) # copy inputs to test\n", "        else:\n", "            print(f'|... no processFolder !!!!. files there ')\n", "        args.input_folder = args.data_test_B_dir\n", "        args.filepatt = f'.*re.{args.file_extension}'\n", "        args.output_folder = args.dataset_test_B_dir"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        qinfiles = onfile.qfiles(args.input_folder, f'*re.{args.file_extension}')\n", "        qoutfiles = onfile.qfiles(args.output_folder)\n", "        print(f\"|---> test copy: {args.process_type}:   \\n \\\n", "            {args.input_folder} ==> {args.output_folder}, \\n \\\n", "            qinfiles : {qinfiles}, \\n \\\n", "            qoutfiles : {qoutfiles}, \\n \\\n", "        \")\n", "        if not qinfiles == qoutfiles:\n", "            onset.processFolder(args) # copy reals to test\n", "        else:\n", "            print(f'|... no processFolder !!!!. files there ')\n", "    if 1: #  data_train_dir => tf datasets\n", "        print(f\"|---> raw to datasets\")\n", "        pths_train = [args.data_train_A_dir, args.data_train_B_dir]\n", "        #train_dataset = paths_to_dataset_22(\n", "        train_dataset = paths_to_dataset(\n", "            pths_train, \n", "            args.patts, \n", "            height=args.height, width=args.width, buffer_size=args.buffer_size, batch_size=args.batch_size)\n", "        pths_test = [args.data_test_A_dir, args.data_test_B_dir]\n", "        #test_dataset = paths_to_dataset_22(\n", "        test_dataset = paths_to_dataset(\n", "            pths_test, \n", "            args.patts, \n", "            height=args.height, width=args.width, buffer_size=args.buffer_size, batch_size=args.batch_size)\n", "        \n", "    if args.visual > 1: # probe train dataset\n", "        print(f\"|---> probe dataset\")\n", "        iter = train_dataset.take(1) # <class 'tensorflow.python.data.ops.dataset_ops.TakeDataset'>\n", "        for i,elem in enumerate(iter):\n", "            example_input, example_target = elem\n", "            img1 = onformat.nba_to_rgb(example_input)\n", "            img2 = onformat.nba_to_rgb(example_target)\n", "            print(f'probe train dataset: {i} \\n \\\n", "                input:{type(example_input)} \\n \\\n", "                target: {type(example_target)}')\n", "            display_list = [\n", "                img1,\n", "                img2,\n", "            ]\n", "            onplot.pil_show_rgbs(display_list, scale=1, rows=1) "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    if 1: # model\n", "        print(\"|===> model\")\n", "        gan = GAN(\n", "            models_dir = args.models_dir,\n", "            logs_dir = args.logs_dir,\n", "            ckpt_dir = args.ckpt_dir,\n", "            ckpt_prefix = args.ckpt_prefix,\n", "            input_shape = args.input_shape,\n", "            output_shape = args.input_shape,\n", "        )\n", "    if 1: # colab\n", "        if onutil.incolab():\n", "            print(\"|---> load tensorboard to monitor logs with colab\")\n", "            os.system(f\"load_ext tensorboard\")\n", "            os.system(f\"tensorboard --logdir {args.logs_dir}\")\n", "        else:\n", "            print(\"|---> launch a separate tensorboard process to monitor logs with colab\")\n", "    if args.visual: # try generator\n", "        print(\"|===> probe generator with train image pair\")\n", "        path1 = os.path.join(args.data_dir, 'train_A/da09_in.png')\n", "        path2 = os.path.join(args.data_dir, 'train_B/da09_re.png')\n", "        imgs = paths_to_pair([path1, path2], args.img_height, args.img_width)\n", "        print(\"|... path1\", type(path1), np.shape(path1))\n", "        print(\"|... path2\", type(path2), np.shape(path2))\n", "        img1 = tf.cast(imgs[0], tf.float32)[tf.newaxis,...]\n", "        img2 = tf.cast(imgs[1], tf.float32)[tf.newaxis,...]\n", "        prediction = gan.generator(img1, training=True) # _e_\n", "        print(\"|... prediction\", type(prediction), np.shape(prediction))\n", "        img1 = onformat.nnba_to_rgb(img1)\n", "        img2 = onformat.nnba_to_rgb(img2)\n", "        img3 = onformat.nnba_to_rgb(prediction)\n", "        display_list = [ img1, img2, img3 ]\n", "        print(\"|... pil show rgbs\")\n", "        onplot.pil_show_rgbs(display_list, scale=1, rows=1)     "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    if args.visual:  # demo dataset\n", "        print(\"|===> probe train dataset prediction\")\n", "        for train_input, train_target in train_dataset.take(1):\n", "                \n", "            print(\"|--->.. train_input\", type(train_input), np.shape(train_input))\n", "            prediction = gan.generator(train_input, training=True) # _e_\n", "            print(\"|--->.. prediction\", type(prediction), np.shape(prediction))\n", "            img1 = onformat.nnba_to_rgb(train_input)\n", "            img2 = onformat.nnba_to_rgb(train_target) \n", "            img3 = onformat.nnba_to_rgb(prediction)\n", "            display_list = [ img1, img2,  img3 ]\n", "            onplot.pil_show_rgbs(display_list, scale=1, rows=1) \n", "                    \n", "        if test_dataset:\n", "            print(\"|---> probe test dataset prediction\")\n", "            for test_input, test_target in test_dataset.take(1):\n", "                prediction = gan.generator(test_input, training=True) # _e_\n", "                img1 = onformat.nnba_to_rgb(test_input)\n", "                img2 = onformat.nnba_to_rgb(test_target) \n", "                img3 = onformat.nnba_to_rgb(prediction)\n", "            display_list = [ img1, img2,  img3 ]\n", "            onplot.pil_show_rgbs(display_list, scale=1, rows=1)        \n", "    "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    if 1: # train\n", "        print(\"|===> training loop\")\n", "        gan.fit(train_dataset, test_dataset, args)     # , summary_writer\n", "    print(f'|===> end nnleonardo')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["  ******************<br>\n", "  nnfacades - 11<br>\n", "  "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def nnfacades(args, kwargs):\n", "    args = onutil.pargs(vars(args))\n", "    args.PROJECT = 'facades'\n", "    args.DATASET = 'facades'\n", "    xp = getxp(vars(args))\n", "    args = onutil.pargs(xp)\n", "    onutil.ddict(vars(args), 'args')\n", "    print(f\"|---> nnfacades: {args.PROJECT}:  \\n \")\n", "    if 1: # tree\n", "        args.ckpt_dir = args.models_dir\n", "        args.ckpt_prefix = os.path.join(args.ckpt_dir, \"ckpt-\")\n", "        os.makedirs(args.models_dir, exist_ok=True)\n", "        os.makedirs(args.logs_dir, exist_ok=True)\n", "        assert(os.path.exists(args.dataorg_dir))\n", "    if args.verbose: print(f\"|---> {args.PROJECT} tree:   \\n \\\n", "        args.ckpt_dir: {args.ckpt_dir} \\n \\\n", "        args.logs_dir: {args.logs_dir} \\n \\\n", "        args.output_channels: {args.output_channels} \\n \\\n", "        args.batch_size: {args.batch_size}, \\n \\\n", "        args.img_width: {args.img_width} \\n \\\n", "        args.img_height: {args.img_height} \\n \\\n", "        args.input_channels: {args.input_channels} \\n \\\n", "        args.max_epochs: {args.max_epochs} \\n \\\n", "    \")\n", "    if 1: # config\n", "        args.height = args.img_height\n", "        args.width = args.img_width\n", "        args.buffer_size = args.buffer_size\n", "        args.batch_size = 1 # args.batch_size\n", "        args.input_channels = args.input_channels\n", "        args.input_shape = [args.height, args.width, args.input_channels]\n", "        args.src_pattern = '*.jpg'  # superseed pat\n", "    if args.verbose: print(f\"|---> {args.PROJECT} config:   \\n \\\n", "        cwd: {os.getcwd()} \\n \\\n", "        args.PROJECT: {args.PROJECT} \\n \\\n", "        args.height: {args.height} \\n \\\n", "        args.width: {args.width} \\n \\\n", "        args.input_channels: {args.input_channels} \\n \\\n", "        args.buffer_size: {args.buffer_size} \\n \\\n", "        args.batch_size: {args.batch_size} \\n \\\n", "        args.input_shape: {args.input_shape}, \\n \\\n", "        args.src_pattern: {args.src_pattern}, \\n \\\n", "        args.verbose: {args.verbose}, \\n \\\n", "        args.visual: {args.visual}, \\n \\\n", "    \")\n", "    if 1: # git\n", "        onutil.get_git(args.AUTHOR, args.GITPOD, args.proj_dir)\n", "    if args.visual: # ref images\n", "        ref_img_path = os.path.join(args.dataorg_dir, 'train/100.jpg')        \n", "        inp, re = path_to_decoded(ref_img_path)\n", "        if args.visual : \n", "            onplot.pil_show_rgbs([re, inp])\n", "        down_model = ondata.downsample(3, 4)\n", "        down_result = down_model(tf.expand_dims(tf.cast(inp, tf.float32), 0)) # _e_\n", "        up_model = ondata.upsample(3, 4)\n", "        up_result = up_model(down_result)\n", "        if args.verbose: print(f\"|---> {args.PROJECT}: ref images:  \\n \\\n", "            args.input_shape: {args.input_shape} \\n \\\n", "            ref_img_path: {ref_img_path} \\n \\\n", "            down_result.shape: {down_result.shape} \\n \\\n", "            up_result.shape: {up_result.shape} \\n \\\n", "        \")\n", "    if 1: # get DATASETS from src\n", "        path_train = os.path.join(args.dataorg_dir, 'train')\n", "        path_test = os.path.join(args.dataorg_dir, 'val')\n\n", "        #train_dataset = path_to_dataset_11(path_train, '*.jpg',\n", "        train_dataset = paths_to_dataset(path_train, '*.jpg',\n", "            height=args.height,width=args.width,buffer_size=args.buffer_size,batch_size=args.batch_size)\n\n", "        #test_dataset = path_to_dataset_11(path_test, '*.jpg',\n", "        test_dataset = paths_to_dataset(path_test, '*.jpg',\n", "            height=args.height,width=args.width,buffer_size=args.buffer_size,batch_size=args.batch_size)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    if 1: # model\n", "        print(f\"|===> model\")\n", "        gan = GAN(\n", "            models_dir = args.models_dir,\n", "            logs_dir = args.logs_dir,\n", "            ckpt_dir = args.ckpt_dir,\n", "            ckpt_prefix = args.ckpt_prefix,\n", "            input_shape = args.input_shape,\n", "            output_shape = args.input_shape,\n", "        )\n", "    if 0: # # tensorboard\n", "        if onutil.incolab():\n", "            print(\"|---> load tensorboard to monitor logs with colab\")\n", "            os.system(f\"load_ext tensorboard\")\n", "            os.system(f\"tensorboard -- logdir {args.logs_dir}\")\n", "        else:\n", "            print(\"launch a separate tensorboard process to monitor logs with colab\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    if args.visual: # \n", "        print(f\"|---> show dataset train\")\n", "        for train_input, train_target in train_dataset.take(1):\n", "            prediction = gan.generator(train_input, training=True) # _e_\n", "            print(\"|... train_input\", type(train_input), np.shape(train_input))\n", "            print(\"|... train_target\", type(train_target), np.shape(train_target))\n", "            print(\"|... prediction\", type(prediction), np.shape(prediction))\n", "            \n", "            img1 = onformat.nnba_to_rgb(train_input)\n", "            img2 = onformat.nnba_to_rgb(train_target) \n", "            img3 = onformat.nnba_to_rgb(prediction)\n", "            display_list = [img1, img2, img3]\n", "            onplot.pil_show_rgbs(display_list, scale=1, rows=1)        \n", "    if args.visual: \n", "        print(f\"|---> show dataset test\")\n", "        for test_input, test_target in test_dataset.take(1):\n", "            prediction = gan.generator(test_input, training=True) # _e_\n", "            \n", "            img1 = onformat.nnba_to_rgb(test_input)\n", "            img2 = onformat.nnba_to_rgb(test_target) \n", "            img3 = onformat.nnba_to_rgb(prediction)\n", "            display_list = [img1, img2, img3]\n", "            onplot.pil_show_rgbs(display_list, scale=1, rows=1)        "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    if 1: # train\n", "        print(f\"|===> training loop\")\n", "        gan.fit(train_dataset, test_dataset, args)     # , summary_writer\n", "    print(f'|===> end nnfacades')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["  ******************<br>\n", "  nngoya<br>\n", "  "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def nngoya(args, kwargs):\n", "    args = onutil.pargs(vars(args))\n", "    args.PROJECT = 'goya'\n", "    args.DATASET = 'goya'\n", "    xp = getxp(vars(args))\n", "    args = onutil.pargs(xp)\n", "    onutil.ddict(vars(args), 'args')\n", "    print(f\"|---> nngoya: {args.PROJECT}:  \\n \")\n", "    if 1: # data params\n", "        args.src_pattern = '*.jpg'  # superseed pat\n", "        height = args.img_height\n", "        width = args.img_width\n", "        buffer_size = args.buffer_size\n", "        batch_size = args.batch_size\n", "        input_channels = args.input_channels\n", "        input_shape = [height, width, input_channels]\n", "    if 1: # tree\n", "        ckpt_dir = os.path.join(args.proto_dir, 'leonardo', 'Models')\n", "        ckpt_prefix = os.path.join(ckpt_dir, \"ckpt-\")\n", "        os.makedirs(args.data_dir, exist_ok=True)\n", "        os.makedirs(args.models_dir, exist_ok=True)\n", "        os.makedirs(args.logs_dir, exist_ok=True)\n", "    if args.verbose: print(f\"|---> nngoya tree:   \\n \\\n", "        args.data_dir: {args.data_dir} \\n \\\n", "        ckpt_dir: {ckpt_dir} \\n \\\n", "        ckpt_prefix: {ckpt_prefix} \\n \\\n", "        logs_dir: {args.logs_dir} \\n \\\n", "    \")\n", "    if args.verbose: print(f\"|---> nngoya config:   \\n \\\n", "        cwd: {os.getcwd()} \\n \\\n", "        PROJECT: {args.PROJECT} \\n \\\n", "        height: {height} \\n \\\n", "        width: {width} \\n \\\n", "        input_channels: {input_channels} \\n \\\n", "        buffer_size: {buffer_size} \\n \\\n", "        batch_size: {batch_size} \\n \\\n", "        input_shape: {input_shape} \\n \\\n", "    \")\n", "    if 1: # model\n", "        gan = GAN(\n", "            models_dir = args.models_dir,\n", "            logs_dir = args.logs_dir,\n", "            ckpt_dir = ckpt_dir,\n", "            ckpt_prefix = ckpt_prefix,\n", "            input_shape = input_shape,\n", "            output_shape = input_shape,\n", "        )\n", "    if 1: # try generator\n", "        img1 = os.path.join(args.gdata, 'leonardo', 'train', 'da02_in.png')\n", "        img1 = os.path.join(args.gdata, 'leonardo', 'test', 'da13_in.png')\t\t\t\n", "        img1 = os.path.join(args.gdata, 'Goya__Guerra', 'img0006.jpg')\n", "        img1 = onfile.path_to_rgb(img1)\n", "        img1 = img_jitter_random(img1, height, width)        \n", "        img1 = onformat.rgb_to_nba(img1)\n", "        img1 = tf.cast(img1, tf.float32)[tf.newaxis,...]\n", "        prediction = gan.generator(img1, training=True) # _e_\n", "        print(f\"|---> prediction\", type(prediction), np.shape(prediction))\n", "        display_list = [\n", "            onformat.nnba_to_rgb(img1),\n", "            onformat.nnba_to_rgb(prediction)\n", "        ]\n", "        onplot.pil_show_rgbs(display_list, scale=1, rows=1)  \n", "    print(f'|---> end nngoya')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def nninfo(args, kwargs):\n", "    args = onutil.pargs(vars(args))\n", "    onutil.ddict(vars(args), 'args')\n", "    print(f\"|---> pix2pix:  \\n \\\n", "    nndanboo: implement https://github.com/lllyasviel/DanbooRegion \\n \\\n", "    nncrys: train quimica_tech dataset\\n \\\n", "    nnfacades: train facades dataset {args.dataorg_dir} \\n \\\n", "    nnleonardo: train leonardo dataset {args.dataorg_dir} \\n \\\n", "    nninfo: show commands \\n \\\n", "    tree, data,  \\n \\\n", "    ref: https://github.com/NVIDIA/pix2pixHD \\n \\\n", "    ref: https://www.tensorflow.org/tutorials/generative/pix2pix \\n \\\n", "    \\n \\\n", "    citations:\\n \\\n", "        InProceedings=DanbooRegion2020,\\n \\\n", "        author=Lvmin Zhang, Yi JI, and Chunping Liu, \\n \\\n", "        booktitle=European Conference on Computer Vision (ECCV), \\n \\\n", "        title=DanbooRegion: An Illustration Region Dataset, \\n \\\n", "        year=2020, \\n \\\n", "    \")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["  ******************<br>\n", "<br>\n", "  MAIN<br>\n", "<br>\n", "  ******************"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def main():\n", "    parser = argparse.ArgumentParser(description='''Run 'python %(prog)s <subcommand> --help' for subcommand help.''')\n", "    onutil.dodrive()\n", "    ap = getap()\n", "    for p in ap:\n", "        cls = type(ap[p])\n", "        parser.add_argument('--'+p, type=cls, default=ap[p])\n", "    cmds = [key for key in globals() if key.startswith(\"nn\")]\n", "    primecmd = ap[\"primecmd\"]\n", "        \n", "    # ---------------------------------------------------------------\n", "    #   add subparsers\n", "    #\n", "    subparsers = parser.add_subparsers(help='subcommands', dest='command') # command - subparser\n", "    for cmd in cmds:\n", "        subparser = subparsers.add_parser(cmd, help='cmd')  # add subcommands\n", "    \n", "    subparsers_actions = [action for action in parser._actions\n", "        if isinstance(action, argparse._SubParsersAction)] # retrieve subparsers from parser\n", "  \n", "    for subparsers_action in subparsers_actions:  # add common       \n", "        for choice, subparser in subparsers_action.choices.items(): # get all subparsers and print help\n", "            for p in {}:  # subcommand args dict\n", "                cls = type(ap[p])\n", "                subparser.add_argument('--'+p, type=cls, default=ap[p])\n\n", "    # get args to pass to nn cmds\n", "    if onutil.incolab():\n", "        args = parser.parse_args('') #  defaults as args\n", "    else:\n", "        args = parser.parse_args() #  parse_arguments()\n", "    kwargs = vars(args)\n", "    subcmd = kwargs.pop('command')      \n", "    if subcmd is None:\n", "        print (f\"Missing subcommand. set to default {primecmd}\")\n", "        subcmd = primecmd\n", "    \n", "    for name in cmds:\n", "        if (subcmd == name):\n", "            print(\"|---> call %s\" %name)\n", "            globals()[name](args, kwargs) # pass args to nn cmd"]}, {"cell_type": "markdown", "metadata": {}, "source": ["---------------------------------------------------------------<br>\n", "python base/base.py nninfo"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if __name__ == \"__main__\":\n", "    print(\"|--->\", __name__)\n", "    main()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["--------------------------------------------------------------"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}