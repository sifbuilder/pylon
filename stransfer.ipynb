{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# -*- coding: utf-8 -*-\n", "# \n", "# # Copyright (c) 2019, NVIDIA Corporation. All rights reserved.\n", "#\n", "import os\n", "import io\n", "from io import StringIO\n", "import time\n", "import argparse\n", "import functools\n", "import errno\n", "import scipy\n", "import scipy.io\n", "import requests\n", "import zipfile\n", "import random\n", "import datetime\n", "import re\n", "import uuid\n", "import hashlib\n", "import tempfile\n", "from typing import Any, List, Tuple, Union\n", "import types"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from functools import partial\n", "import importlib\n", "from importlib import import_module"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import logging\n", "logging.getLogger('tensorflow').setLevel(logging.ERROR)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import math\n", "from math import floor, log2\n", "from random import random"]}, {"cell_type": "markdown", "metadata": {}, "source": ["import IPython.display as display"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from IPython.core.display import display"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import PIL\n", "from PIL import Image\n", "PIL.Image.MAX_IMAGE_PIXELS = 933120000"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from mpl_toolkits.axes_grid1 import ImageGrid"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import shutil"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import scipy.ndimage as pyimg"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import cv2\n", "import imageio\n", "import glob"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import matplotlib as mpl\n", "import matplotlib.pyplot as plt \n", "import matplotlib.image as mgimg\n", "import matplotlib.animation as anim\n", "mpl.rcParams['figure.figsize'] = (12,12)\n", "mpl.rcParams['axes.grid'] = False"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import gdown"]}, {"cell_type": "markdown", "metadata": {}, "source": [" https://github.com/lllyasviel/DanbooRegion"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from numba import njit\n", "from scipy.ndimage import label"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import sys\n", "sys.path.append('../')  # if called from eon, modules are in parallel folder\n", "sys.path.append('./')  #  if called from dnns, modules are in folder"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["try:\n", "    TF1\n", "    print(\"set tf 1.x env\")\n", "    # %tensorflow_version 1.x\n", "except:\n", "    pass"]}, {"cell_type": "markdown", "metadata": {}, "source": ["pip install -q -U tensorboard"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import tensorflow as tf \n", "from tensorflow.keras import initializers, regularizers, constraints\n", "from tensorflow.keras import backend as K\n", "from tensorflow.keras import layers\n", "from tensorflow.keras.layers import Layer, InputSpec\n", "from tensorflow.keras.layers import BatchNormalization, Activation, ZeroPadding2D, UpSampling2D, Conv2D\n", "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout, LeakyReLU\n", "from tensorflow.keras.models import Sequential, Model\n", "from tensorflow.keras.optimizers import Adam\n", "from tensorflow.python.keras.utils import conv_utils"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from tensorflow.keras.layers import Lambda\n", "from tensorflow.keras.layers import add\n", "from tensorflow.keras.layers import AveragePooling2D\n", "from tensorflow.keras.initializers import VarianceScaling\n", "from tensorflow.keras.models import clone_model\n", "from tensorflow.keras.models import model_from_json\n", "from tensorflow.python.client import device_lib # pylint: disable=no-name-in-module"]}, {"cell_type": "markdown", "metadata": {}, "source": ["python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\""]}, {"cell_type": "markdown", "metadata": {}, "source": ["GLOBALS "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["local_prefix = os.path.abspath('')\n", "try:\n", "    local_prefix = os.path.dirname(os.path.realpath(__file__)) # script dir\n", "except:\n", "    pass"]}, {"cell_type": "markdown", "metadata": {}, "source": ["cuda_cache_path = os.path.join(os.path.dirname(__file__), '_cudacache')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["cuda_cache_path = os.path.join(os.path.dirname(local_prefix), '_cudacache')\n", "cuda_cache_version_tag = 'v1' # _e_\n", "do_not_hash_included_headers = True # _e_ # Speed up compilation by assuming that headers included by the CUDA code never change. Unsafe!"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["compiler_bindir_search_path = [\n", "    'C:/Program Files (x86)/Microsoft Visual Studio/2017/Community/VC/Tools/MSVC/14.14.26428/bin/Hostx64/x64',\n", "    'C:/Program Files (x86)/Microsoft Visual Studio/2019/Community/VC/Tools/MSVC/14.25.28610/bin/Hostx64/x64',\n", "    'C:/Program Files (x86)/Microsoft Visual Studio 14.0/vc/bin',\n", "    'C:/Program Files (x86)/Microsoft Visual Studio/2019/Community/VC/Tools/MSVC/14.26.28801/bin/Hostx64/x64'\n", "]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["_plugin_cache = dict()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class Onpyon:\n", "    @staticmethod\n", "    def ver():\n", "        return '0.0.0'"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class Ontree:\n", "    @staticmethod\n", "    def tree(cp):\n\n", "        # dataprefix\n", "        if os.path.exists('/content/drive/My Drive'):  # collab with drive\n", "            dataprefix = '/content/drive/My Drive'\n", "        elif os.path.exists('/content'): # if /content exists, is collab\n", "            dataprefix = '/content' \n", "        elif not cp[\"LOCALDATA\"] and os.path.exists(cp['net_prefix']): # network\n", "            dataprefix = cp['net_prefix'] \n", "        else:                               # local\n", "            dataprefix = os.path.join(cp[\"local_prefix\"], cp[\"grel_infix\"], 'content') # dnns/../content/gdata/\n\n", "        # modelsprefix\n", "        if os.path.exists('/content/drive/My Drive'):  # collab with drive\n", "            modelsprefix = '/content/drive/My Drive'\n", "        elif os.path.exists('/content'): # if /content exists, is collab\n", "            modelsprefix = '/content' \n", "        elif cp[\"LOCALMODELS\"]:                               # local\n", "            modelsprefix = os.path.join(cp[\"local_prefix\"], cp[\"grel_infix\"], 'content') # dnns/../content/gmodel/\n", "        elif os.path.exists(cp['net_prefix']): # try net drive\n", "                modelsprefix = cp['net_prefix'] \n", "        else:                               # local\n", "            print(f'drive could not be found !!!!!!!!!!!!!! ')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        # labprefix\n", "        if os.path.exists('/content/drive/My Drive'):  # collab with drive\n", "            labprefix = '/content/drive/My Drive'\n", "        elif os.path.exists('/content'): # if /content exists, is collab\n", "            labprefix = '/content' \n", "        elif cp[\"LOCALLAB\"]:                               # local\n", "            labprefix = os.path.join(cp[\"local_prefix\"], cp[\"grel_infix\"], 'content') # dnns/../content/glab/\n", "        elif os.path.exists(cp['net_prefix']): # try net drive\n", "                labprefix = cp['net_prefix'] \n", "        else:                               # local\n", "            print(f'drive could not be found !!!!!!!!!!!!!! ')\n", "        gdata = dataprefix + '/gdata/'\n", "        gmodel = modelsprefix + '/gmodel/'\n", "        glab = labprefix + '/glab/'\n", "        gadir = os.getcwd()\n", "        gedir = os.path.join(cp[\"local_prefix\"])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        Onutil.ddict(cp, 'cp')\n", "        print(labprefix, glab)\n", "        assert os.path.exists(gdata), f\"gdata {gdata} does not exist\"\n", "        assert os.path.exists(gmodel), f\"gmodel {gmodel} does not exist\"\n", "        assert os.path.exists(glab), f\"glab {glab} does not exist\"\n", "        assert os.path.exists(gadir), f\"gadir {gadir} does not exist\"\n", "        assert os.path.exists(gedir), f\"gedir {gedir} does not exist\"\n", "        lab=os.path.normpath(os.path.join(glab, cp[\"MNAME\"]))\n", "        os.makedirs(lab, exist_ok=True)\n", "        proto_dir=os.path.normpath(os.path.join(glab,cp[\"MNAME\"]))\n", "        os.makedirs(proto_dir, exist_ok=True)\n", "        proj_dir = os.path.join(proto_dir, cp[\"PROJECT\"])\n", "        if cp[\"RESETCODE\"] and os.path.exists(proj_dir):\n", "            print(\"will remove tree %s\" %proj_dir)\n", "            try:\n", "                shutil.rmtree(proj_dir)\n", "            except:\n", "                print(\"could not remove git tree\")\n", "                pass\n", "        os.makedirs(proj_dir, exist_ok=True)\n", "        os.chdir(proj_dir) # %cd $proj_dir\n", "        cwd = os.getcwd()\n", "        proj_dir = cwd"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        tp = {\n", "            \"LOCAL\": cp[\"local_prefix\"], # ''\n", "            \"FROMPATH\": cp[\"local_prefix\"],\n", "                    \n", "            \"gdata\": gdata,\n", "            \"gmodel\": gmodel,\n", "            \"glab\": glab,\n", "            \"gadir\": gadir,\n", "            \"gedir\": gedir,\n", "            \"lab\": lab,\n", "            \"proto_dir\": proto_dir,\n", "            \"proj_dir\": proj_dir,\n", "            \"cwd\": cwd,\n", "            \"ani_dir\": os.path.join(proj_dir, 'ani'),           # ani results gifs dir (.gif, .mp4) \n", "            \"results_dir\": os.path.join(proj_dir, \"Results\"),   # Results\n", "            \"tmp_dir\": os.path.join(proj_dir, \"tmp\"),           # tmp\n", "            \"logs_dir\": os.path.join(proj_dir, 'logs'),         # logs\n", "            \"trace_dir\": os.path.join(proj_dir, 'trace'),       # trace\n", "            \"data_dir\": os.path.join(proj_dir, \"data\"),         # data\n", "            \"train_dir\": os.path.join(proj_dir, \"data\", \"train\"),  # train\n", "            \"test_dir\": os.path.join(proj_dir, \"data\", \"test\"), # test\n", "            \n", "            \"dataset_dir\": os.path.join(proj_dir, \"dataset\"),   # dataset\n", "            \"records_dir\": os.path.join(proj_dir, \"records\"),   # records\n", "            \"ckpt_dir\": os.path.join(proj_dir, 'ckpt'),  # ckpt checkpoints place\n", "            \"weights_dir\": os.path.join(proj_dir, 'weights'),   # weights dir (h5) \n", "            \"models_dir\": os.path.join(proj_dir, \"Models\"),     # Models\n", "            \"dataorg_dir\": gdata + '/' + cp[\"DATASET\"],   # dataorg\n", "        }\n", "        return tp"]}, {"cell_type": "markdown", "metadata": {}, "source": ["  ******************<br>\n", "  FUNS UTILS<br>\n", "<br>\n", "  ******************"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class Onutil:\n", "    @staticmethod\n", "    def info():\n", "        print(\"Onutil\")\n", "    @staticmethod\n", "    def error(msg):\n", "        print('Error: ' + msg)\n", "        exit(1)\n", "    @staticmethod\n", "    def incolab():\n", "        res = False\n", "        if os.path.exists('/content'):\n", "            res = True\n", "        return res\n", "    @staticmethod\n", "    def conda():\n\n", "        ## StyleGAN:\n", "        cmd = f'pip install pillow numpy moviepy scipy opencv-python lmdb matplotlib'\n", "        os.system(cmd)\n", "        cmd = f'pip install cmake'\n", "        os.system(cmd)\n", "        cmd = f'pip install dlib'\n", "        os.system(cmd)\n", "        cmd = f'pip install ipython gdown'\n", "        os.system(cmd)\n\n", "        # ## lllyasviel\n", "        cmd = f'pip install numba scikit-image scikit-learn'\n", "        os.system(cmd)\n\n", "        # ## \n", "        cmd = f'pip install cython h5py Pillow'\n", "        os.system(cmd)\n", "        cmd = f'pip install -U gradient'\n", "        os.system(cmd)\n", "        cmd = f'pip install windows-curses'\n", "        os.system(cmd)\n\n", "        # ## confignet https://github.com/microsoft/ConfigNet/blob/main/setup/requirements.txt\n", "        #scipy==1.4.1\n", "        #scikit-learn==0.20.0\n", "        #tensorflow-gpu==2.1.0\n", "        cmd = f'pip install azureml-sdk matplotlib numpy opencv-python pytest transformations'\n", "        os.system(cmd)\n", "    @staticmethod\n", "    def pargs(cp):\n", "        xp={}        \n", "        for key in cp.keys():\n", "            xp[key] = cp[key]\n\n", "        ## ------------ _e_tbc ref stransfer.py\n", "        tree = Ontree.tree(cp)\n", "        for key in tree.keys():\n", "            xp[key] = tree[key]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        parser = argparse.ArgumentParser(description='Run \"python %(prog)s <subcommand> --help\" for subcommand help.')\n", "        for p in xp:\n", "            cls = type(xp[p])\n", "            parser.add_argument('--'+p, type=cls, default=xp[p])\n", "        args = parser.parse_args('')\n", "        return args\n", "    @staticmethod\n", "    def dodrive(domount=True):\n", "        if domount:\n", "            if os.path.exists('/content/'):\n", "                if not os.path.exists('/content/drive'):\n", "                    try:\n", "                        from google.colab import drive # drive from colab\n", "                        drive.mount('/content/drive', force_remount=True)\n", "                    except:\n", "                        print(\"|===> unable to mount drive\")\n", "    @staticmethod\n", "    def check_file(file, path):\n", "        if file is None:\n", "            raise OSError(errno.ENOENT, \"No such file\", path)\n", "    @staticmethod\n", "    def get_git(AUTHOR, PROJECT, proj_dir='./'):\n", "        try:\n", "            # os.system(\"git clone https://github.com/rolux/stylegan2encoder %s\" %proj_dir)\n", "            cmd = f'git clone https://github.com/{AUTHOR}/{PROJECT}.git \"{proj_dir}\"'\n", "            print(\"|... cmd %s\" %cmd)\n", "            os.system(cmd)\n", "        except:\n", "            cmd = f'git pull https://github.com/{AUTHOR}/{PROJECT}.git \"{proj_dir}\"'\n", "            print(\"|... cmd %s\" %cmd)\n", "            os.system(cmd)\n", "    @staticmethod\n", "    def ddict(item, txt=\":\"):\n", "        print(f\"|===> {txt}\")\n", "        for i in item:\n", "            print (f\"  {i} => {item[i]}\")\n", "    @staticmethod\n", "    def ditem(item, txt=\":\", val=True):\n", "        print(txt)\n", "        print(type(item))\n", "        # print(np.shape(item))\n", "        if val:\n", "            print(item)\n", "    @staticmethod\n", "    def isempty(folder):\n", "        empty = True\n", "        if [f for f in os.listdir(folder) if not f.startswith('.')] == []:\n", "            empty = False\n", "        return empty\n", "    @staticmethod\n", "    def walkfolder(folder):\n", "        if os.path.exists(folder):        \n", "            for root, dirs, files in os.walk(folder, topdown=False):\n", "                for name in files:\n", "                    print(os.path.join(root, name))\n", "                for name in dirs:\n", "                    print(os.path.join(root, name))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    @staticmethod\n", "    def nameint(i,zfill=4):\n", "        return str(i).zfill(4)\n", "    @staticmethod\n", "    def pathsort(paths):\n", "        roots = [Onutil.get_rootid(path) for path in paths]\n", "        if all(root.isdigit() for root in roots):\n", "            paths = sorted(paths, key=lambda path: int(Onutil.get_rootid(path)))\n", "            print(f'|---> pathsort numeric q: {len(paths)}')\n", "        else:\n", "            paths = sorted(paths)\n", "            print(f'|---> pathsort alphabetic q: {len(paths)}')\n", "        return paths"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    @staticmethod\n", "    def printProgressBar (iteration, total, prefix = '', suffix = '', decimals = 1, length = 50, fill = '\u00e2\u2013\u02c6'):\n", "        \"\"\"\n", "        Call in a loop to create terminal progress bar\n", "        @params:\n", "            iteration   - Required  : current iteration (Int)\n", "            total       - Required  : total iterations (Int)\n", "            prefix      - Optional  : prefix string (Str)\n", "            suffix      - Optional  : suffix string (Str)\n", "            decimals    - Optional  : positive number of decimals in percent complete (Int)\n", "            length      - Optional  : character length of bar (Int)\n", "            fill        - Optional  : bar fill character (Str)\n", "        \"\"\"\n", "        percent = (\"{0:.\" + str(decimals) + \"f}\").format(100 * (iteration / float(total)))\n", "        filledLength = int(length * iteration // total)\n", "        bar = fill * filledLength + '.' * (length - filledLength)\n", "        print('\\r %s |%s| %s%% %s' % (prefix, bar, percent, suffix), end = '\\r')\n", "        # Print New Line on Complete\n", "        if iteration == total:\n", "            print()\n", "            print()\n", "    @staticmethod\n", "    def gunzip(file_basename, file_id, dst, results_dir):\n", "        if not os.path.exists(dst):\n", "            print(f'|... download {file_basename} from google drive to {dst}')\n", "            gdown.download(file_id, dst)\n", "        else:\n", "            print(f'|... {file_basename} already in content {dst}')\n", "        path_to_zip_file = dst\n", "        directory_to_extract_to = results_dir\n", "        print(\"will unzip %s to %s\" %(path_to_zip_file, directory_to_extract_to))\n", "        with zipfile.ZipFile(path_to_zip_file, 'r') as zip_ref:\n", "            zip_ref.extractall(directory_to_extract_to)\n", "    @staticmethod\n", "    def gdownid(urlfolder, gfolderid, dst):\n", "        import gdown\n", "        print(f'|... gdownid {urlfolder} / {gfolderid} to {dst}')\n", "        #urlfolder = 'https://drive.google.com/drive/folders/'\n", "        #gfolderid = '1ihLt6P7UQRlaFtZUEclXkWC9grmEXEUK'\n", "        #dst = 'DanbooRegion2020.zip.xxx' # 001 - 077\n", "        url = f'{urlfolder}{gfolderid}'\n", "        gdown.download(url, dst)\t\t\n", "    @staticmethod\n", "    def gdownfile(link_name, dest):\n", "        from google_drive_downloader import GoogleDriveDownloader as gdd\n", "        print(f'|... gdownfile {link_name} to {dest}')\t\t\n", "        gdd.download_file_from_google_drive(file_id=link_name,dest_path=dest,unzip=True)\n", "    @staticmethod\n", "    def tenzip(output_filename, source_dir, arcname=None):\n", "        import tarfile\n", "        with tarfile.open(output_filename, \"w:gz\") as tar:\n", "            tar.add(source_dir, arcname=arcname)\n", "    @staticmethod\n", "    def tunzip(url, tarpath, results_dir, tree_root=None):\n", "        # tar xvzf car_devkit.tgz\n", "        import tarfile\n", "        #print(f'|---> tunzip {tarpath} to {results_dir}')\n", "        #if not os.path.exists(tarpath): \n", "        #\tcmd = f'wget -O \"{tarpath}\" \"{url}\"'\n", "        #\tprint(f\"cmd: {cmd}\")\n", "        #\tos.system(cmd)\n", "        #else:\n", "        #\tprint(f\"{tarpath} already exists\")\n", "        target_dir = None\n", "        if tree_root:\n", "            target_dir = os.path.join(results_dir, tree_root)\n", "        if target_dir and os.path.exists(target_dir): \n", "            print(f'do nothing. target dir {target_dir} already exists')\n", "        else:\n", "            if tarpath.endswith(\"tar.gz\"):\n", "                print(f'|... tar.gz {tarpath} is tarfile {tarfile.is_tarfile(tarpath)}')\n", "                tar = tarfile.open(tarpath, \"r:\")\n", "                tar.extractall(results_dir)\n", "                tar.close()\n", "            elif tarpath.endswith(\"tar\"):\n", "                print(f'|... tar {tarpath} is tarfile {tarfile.is_tarfile(tarpath)}')\n", "                tar = tarfile.open(tarpath, \"r:\")\n", "                tar.extractall()\n", "                tar.close()\n", "            elif tarpath.endswith(\"tgz\"):\n", "                print(f'|... tgz {tarpath} is tarfile {tarfile.is_tarfile(tarpath)}')                \n", "                tar = tarfile.open(tarpath, \"r:gz\")\n", "                tar.extractall()\n", "                tar.close()\n", "            elif tarpath.endswith(\"zip\"):\n", "                print(f'|... tar {tarpath} is zip {tarfile.is_tarfile(tarpath)}')\n", "                tar = tarfile.open(tarpath, \"r:\")\n", "                tar.extractall()\n", "                tar.close()                \n", "            else:\n", "                print(f'|... unsupported tarfile {tarpath}')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    @staticmethod\n", "    def zipdir(folder, dstzip='Python.zip'):\n", "        import zipfile\n", "        zipf = zipfile.ZipFile(dstzip, 'w', zipfile.ZIP_DEFLATED)\t\t\n", "        # zipf is zipfile handle\n", "        for root, dirs, files in os.walk(folder):\n", "            for file in files:\n", "                zipf.write(os.path.join(root, file))\n", "        zipf.close()\n", "    def mnormal(mu=0.0, sigma=1.0, size=None):\n", "        return np.random.normal(loc = mu, scale = sigma, size = size).astype('float32')\n", "    @staticmethod\n", "    def muniform(low=0.0, high=1.0, size=None):\n", "        return np.random.uniform(low = low, high = high, size = size).astype('float32')\n", "    @staticmethod\n", "    def mrandom(size=None):\n", "        return np.random.random(size = size).astype('float32')\n", "    @staticmethod\n", "    def get_filename(path):\n", "        name, _ = os.path.splitext(os.path.basename(path))\n", "        return name\n", "    @staticmethod\n", "    def get_rootname(name):\n", "        root, _ = os.path.splitext(name)\n", "        return root\n", "    @staticmethod\n", "    def get_rootid(path):\n", "        return Onutil.get_rootname(Onutil.get_filename(path))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["https://github.com/rolux/stylegan2encoder/dnnlib/util.py"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class EasyDict(dict):\n", "    \"\"\"Convenience class that behaves like a dict but allows access with the attribute syntax.\"\"\"\n", "    def __getattr__(self, name: str) -> Any:\n", "        try:\n", "            return self[name]\n", "        except KeyError:\n", "            raise AttributeError(name)\n", "    def __setattr__(self, name: str, value: Any) -> None:\n", "        self[name] = value\n", "    def __delattr__(self, name: str) -> None:\n", "        del self[name]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["https://github.com/rolux/stylegan2encoder/dnnlib/util.py"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class Logger(object):\n", "    \"\"\"Redirect stderr to stdout, optionally print stdout to a file, and optionally force flushing on both stdout and the file.\"\"\"\n", "    def __init__(self, file_name: str = None, file_mode: str = \"w\", should_flush: bool = True):\n", "        self.file = None\n", "        if file_name is not None:\n", "            self.file = open(file_name, file_mode)\n", "        self.should_flush = should_flush\n", "        self.stdout = sys.stdout\n", "        self.stderr = sys.stderr\n", "        sys.stdout = self\n", "        sys.stderr = self\n", "    def __enter__(self) -> \"Logger\":\n", "        return self\n", "    def __exit__(self, exc_type: Any, exc_value: Any, traceback: Any) -> None:\n", "        self.close()\n", "    def write(self, text: str) -> None:\n", "        \"\"\"Write text to stdout (and a file) and optionally flush.\"\"\"\n", "        if len(text) == 0: # workaround for a bug in VSCode debugger: sys.stdout.write(''); sys.stdout.flush() => crash\n", "            return\n", "        if self.file is not None:\n", "            self.file.write(text)\n", "        self.stdout.write(text)\n", "        if self.should_flush:\n", "            self.flush()\n", "    def flush(self) -> None:\n", "        \"\"\"Flush written text to both stdout and a file, if open.\"\"\"\n", "        if self.file is not None:\n", "            self.file.flush()\n", "        self.stdout.flush()\n", "    def close(self) -> None:\n", "        \"\"\"Flush, close possible files, and remove stdout/stderr mirroring.\"\"\"\n", "        self.flush()\n\n", "        # if using multiple loggers, prevent closing in wrong order\n", "        if sys.stdout is self:\n", "            sys.stdout = self.stdout\n", "        if sys.stderr is self:\n", "            sys.stderr = self.stderr\n", "        if self.file is not None:\n", "            self.file.close()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["  ******************<br>\n", "  FUNS PLOT<br>\n", "<br>\n", "  ******************"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class Onplot:\n", "    @staticmethod\n", "    def info():\n", "        print(\"Plot\")\n", "    @staticmethod   \n", "    def display_pil(img):\n", "        display.display(PIL.Image.fromarray(np.array(img)))\n", "    @staticmethod\n", "    def pil_show_pil(img, title=\"\"):\n", "        display(img) if Onutil.incolab() else img.show(title=title)\n", "        return img\n", "    \n", "    @staticmethod    \n", "    def pil_show_nua(img, title=\"\"):\n", "        img = np.asarray(img)\n", "        if np.ndim(img)>3:\n", "            assert img.shape[0] == 1\n", "            rgb = img[0]        \n", "        #img = np.clip(img, 0, 1).astype('float32')        \n", "        img = Onformat.nua_to_pil(img)\n", "        Onplot.pil_show_pil(img, title)\n", "    @staticmethod\n", "    def pil_show_nuas(nuas, scale=1, rows=1):\n", "        rgbs=Onformat.nuas_to_rgbs(nuas)\n", "        Onplot.pil_show_rgbs(rgbs, scale=1, rows=1)\n", "    @staticmethod   \n", "    def pil_show_nba(img, title=\"\"):\n", "        img = np.asarray(img)        \n", "        img = Onformat.nba_to_nua(img)\n", "        img = Onformat.nua_to_rgb(img)\n", "        img = PIL.Image.fromarray(img)\n", "        Onplot.pil_show_pil(img, title)\n", "     \n", "    @staticmethod   \n", "    def pil_show_nbas(nbas, title=[]):\n", "        for nba in nbas:\n", "            Onplot.pil_show_nba(nba)\n", "    @staticmethod    \n", "    def pil_show_rgb(img, title=\"\"):\n", "        img = np.asarray(img)  \n", "        if len(img.shape) > 3: img = tf.squeeze(img, axis=0)  # img = img[0,...]            \n", "        img = Onformat.rgb_to_pil(img)\n", "        Onplot.pil_show_pil(img, title)\n", "    @staticmethod\n", "    def pil_show_rgbs(rgbs, scale=1, rows=1):\n", "        pils = []\n", "        for img in rgbs:\n", "            if len(img.shape) > 3: img = tf.squeeze(img, axis=0)  # img = img[0,...]\n", "            pils.append(PIL.Image.fromarray(np.array(img, dtype=np.uint8)))\n", "        w,h = pils[0].size\n", "        w = int(w*scale)\n", "        h = int(h*scale)\n", "        height = rows*h\n", "        cols = int(math.ceil(len(pils) / rows))\n", "        width = cols*w\n", "        pil = PIL.Image.new('RGBA', (width,height), 'white')\n", "        for i,img in enumerate(pils):\n", "            img = img.resize((w,h), PIL.Image.ANTIALIAS)\n", "            pil.paste(img, (w*(i % cols), h*(i // cols))) \n", "        Onplot.pil_show_pil(pil)\n", "    @staticmethod\n", "    def pil_show_nba(img, title=\"img\"):\n", "        if len(img.shape) > 3:\n", "            assert img.shape[0] == 1\n", "            img = tf.squeeze(img, axis=0)  # img = img[0,...] # bnbt => nba    \n", "        img = (img + 1.0)/2.0\n", "        img = np.array(255 * img, dtype=np.uint8)\n", "        img = PIL.Image.fromarray(img)\n", "        img if Onutil.incolab() else img.show(title=title)\n", "        return img\n", "    @staticmethod\n", "    def plot_pils_grid(imgs, rows=2, cols=2, figsize=(4, 4)):\n", "        qtiles = cols * rows\n", "        plt.figure(figsize=figsize)\n", "        for i in range(qtiles):\n", "            plt.subplot(rows, cols, i+1)\n", "            plt.imshow(np.array(imgs[i])/255.0)\n", "            plt.axis('off')\n", "        plt.show()\n", " \n\n", "    #https://stackoverflow.com/questions/53255432/saving-a-grid-of-heterogenous-images-in-python\n", "    @staticmethod\n", "    def plot_save_grid(ims, path=None, rows=None, cols=None, \n", "            figsize = (6,5.9),\n", "            fill=1, showax=0,\n", "            do =  ['plot']):\n", "        if rows is None != cols is None:\n", "            raise ValueError(\"Set either both rows and cols or neither.\")\n", "        print(f'|---> plot_save_grid {len(ims)} to {path}')\n", "        plt.close() \n", "        if rows is None:\n", "            rows = len(ims)\n", "            cols = 1\n", "        gridspec_kw = {'wspace': 0, 'hspace': 0} if fill else {}\n", "        fig,axarr = plt.subplots(rows, cols, gridspec_kw=gridspec_kw, figsize=figsize)\n", "        if fill:\n", "            bleed = 0\n", "            fig.subplots_adjust(left=bleed, bottom=bleed, right=(1 - bleed), top=(1 - bleed))\n", "        for ax,im in zip(axarr.ravel(), ims):\n", "            ax.imshow(im)\n", "            if not showax:\n", "                ax.set_axis_off()\n", "        kwargs = {'pad_inches': .01} if fill else {}\n", "        if 'save' in do:\n", "            if path:\n", "                fig.savefig(path, **kwargs)\n", "            else:\n", "                print(f'path must be defined')\n", "        if 'plot' in do:\n", "            plt.show()\n", "    @staticmethod\n", "    def plot_iter_grid(model, dataset, rows, cols, figsize = (10,9), do=['plot'], ext='jpg', prefix = 'frame'):\n", "        rndvects = {}\n", "        print(f'|--->  plot_iter_grid {do}')\n", "        size = (model.input_shape[0], model.input_shape[1], model.input_shape[2])\n", "        vary = np.random.normal(0.0, 1.0, size=size).astype('float32') # vary shape: (512, 512, 3)\n", "        iterator = iter(dataset)\n", "        \n", "        ppi = 80\n", "        ppt = 3 * ppi\n", "        fy = int(cols * ppt / ppi)\n", "        fx = int(rows * ppt / ppi)\n\n", "        #fig = plt.figure(figsize=figsize)\n", "        fig = plt.figure(figsize=(fy, fx))\n", "        #plt.tight_layout(pad=0.2, w_pad=0.2, h_pad=1.0)\n", "        if 1: # fill:\n", "            bleed = 0\n", "            fig.subplots_adjust(left=bleed, bottom=bleed, right=(1 - bleed), top=(1 - bleed))\n", "        qtiles = cols * rows\n", "        \n", "        ckptidx = model.ckptidx\n", "        ckptidx = Onutil.nameint(ckptidx)\n", "        frame = f'{prefix}{ckptidx}.{ext}'\n", "        path = os.path.join(model.results_dir, frame)\n", "        images = []\n", "        for i in range(rows):\n", "            for j in range(cols):\n", "                inp, rea = iterator.get_next()\n", "                img = model.generator(inp, training=True)\n", "                img = Onformat.nnba_to_rgb(img)\n", "                images.append(img)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        Onplot.plot_save_grid(images, path, rows, cols,do=['plot', 'save'])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    @staticmethod   \n", "    def plot_nuas(imgs=[], r=1, c=1, titles=[]):\n", "        assert(not c == 0)\n", "        qtiles = r * c\n", "        qimgs = len(imgs)\n", "        for i,img in enumerate(imgs):\n", "            col = 1 + (i % c)   # subplot rows: 1 ..\n", "            row = 1 + int(i/c)  # subplot cols: 1 ..\n", "            print(\"plot_nuas x\", i, r, c)\n", "            plt.subplot(r, c, i + 1)\n", "            idx =  i if i < qimgs else qimgs -1\n", "            plt.imshow(imgs[idx]) \n", "            if (len(titles) > i):\n", "                plt.title(titles[i])\n", "            plt.axis('off')\n", "        plt.show()\n", "        plt.close()\n", "    @staticmethod\n", "    def plot_paths(img_paths=[], rows=1, cols=1):\n", "        qtiles = rows * cols\n", "        qimgs = len(img_paths)\n", "        imgs = []\n", "        for i in range(qtiles):\n", "            idx =  i if i < qimgs else qimgs -1\n", "            imgs.append(Image.open(img_paths[idx]))\n", "        Onplot.plot_pils_grid(imgs, rows, cols)\n", "    @staticmethod\n", "    def plot_names(names=[], dir=\"./\", rows=1, cols=1):\n", "        imgpaths = []\n", "        for name in names:\n", "            imgpaths.append(os.path.join(dir, name))\n", "        Onplot.plot_paths(imgpaths, rows, cols)     \n", "    @staticmethod    \n", "    def plot_pil(img, title=None):\n", "        plt.imshow(img)\n", "        if title:\n", "            plt.title(title)\n", "        plt.show()\n", "    @staticmethod   \n", "    def plot_nua(nua, title=None):\n", "        plt.imshow(nua)\n", "        if title:\n", "            plt.title(title)\n", "        plt.show()\n", "    @staticmethod   \n", "    def plot_dnua(tnua, title=None):\n", "        nua = Onformat.dnua_to_nua(tnua)\n", "        Onplot.plot_nua(nua, title)\n", "    @staticmethod   \n", "    def plot_rgb(img, title=None):\n", "        rgb = np.array(img, dtype=np.uint8)\n", "        plt.imshow(rgb)\n", "        if title:\n", "            plt.title(title)\n", "        plt.show() \n", "    @staticmethod        \n", "    def plot_grid_pils(imgs, rows=2, cols=2, figsize=(4, 4)):\n", "        from mpl_toolkits.axes_grid1 import ImageGrid\n", "        fig = plt.figure(figsize=figsize) # width, height in inches\n", "        grid = ImageGrid(fig, 111,\n", "                        nrows_ncols=(rows, cols),  # creates 2x2 grid of axes\n", "                        axes_pad=0.1,  # pad between axes in inch.\n", "                        )\n", "        for ax, im in zip(grid, imgs): # Iterating over the grid returns the Axes.\n", "            ax.imshow(im)\n", "        plt.show()\n", "    @staticmethod\n", "    def plot_grid(im_list, grid_shape, scale=0.1, axes_pad=0.07):\n", "    # https://gist.github.com/lebedov/7018889ba47668c64bcf96aee82caec0\n", "        \"\"\"\n", "        Display the specified PIL images in a grid.\n", "        Parameters\n", "        ----------\n", "        im_list : list of numpy.ndarray instances\n", "            Bitmaps to display.\n", "        grid_shape : tuple\n", "            Grid shape.\n", "        scale : float\n", "            Scaling factor; 1 is 100%.\n", "        axes_pad : float or (float, float)\n", "            Padding between axes, in inches.\n", "        \"\"\"\n\n", "        # Grid must be 2D:\n", "        assert len(grid_shape) == 2\n\n", "        # Make sure all images can fit in grid:\n", "        assert np.prod(grid_shape) >= len(im_list)\n", "        grid = ImageGrid(plt.gcf(), 111, grid_shape, axes_pad=axes_pad)\n", "        for i, data in enumerate(im_list):\n\n", "            # Scale image:\n", "            im = PIL.Image.fromarray(data)\n", "            thumb_shape = [int(scale*j) for j in im.size]\n", "            im.thumbnail(thumb_shape, PIL.Image.ANTIALIAS)\n", "            data_thumb = np.array(im)\n", "            grid[i].plot_dnua(data_thumb)\n\n", "            # Turn off axes:\n", "            grid[i].axes.get_xaxis().set_visible(False)\n", "            grid[i].axes.get_yaxis().set_visible(False)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    @staticmethod   \n", "    def generate_and_plot_images(gen, seed, w_avg, truncation_psi=1):\n", "        # https://github.com/rosasalberto/StyleGAN2-TensorFlow-2.x\n", "        \"\"\" plot images from generator output \"\"\"\n", "        \n", "        fig, ax = plt.subplots(1,3,figsize=(15,15))\n", "        for i in range(3):\n", "            \n", "            # creating random latent vector\n", "            rnd = np.random.RandomState(seed)\n", "            z = rnd.randn(1, 512).astype('float32')\n\n", "            # running mapping network\n", "            dlatents = gen.mapping_network(z)\n", "            # adjusting dlatents depending on truncation psi, if truncatio_psi = 1, no adjust\n", "            dlatents = w_avg + (dlatents - w_avg) * truncation_psi \n", "            # running synthesis network\n", "            out = gen.synthesis_network(dlatents)\n\n", "            #converting image/s to uint8\n", "            img = Onrosa.convert_images_to_uint8(out, nchw_to_nhwc=True, uint8_cast=True)\n\n", "            #plotting images\n", "            # ax[i].axis('off')\n", "            # img_plot = ax[i].imshow(img.numpy()[0])\n", "            print(f\"plot img {i}: {type(img)} : {np.shape(img)}\")\n", "            Onplot.pil_show_rgb(img)\n", "            seed += 1\n", "    @staticmethod   \n", "    def cv_tfr(src_dir,tfr_file):\n", "        images = []\n", "        tfr_files = sorted(glob.glob(os.path.join(src_dir, '*.tfrecords')))\n", "        dataset = tf.data.TFRecordDataset(src_dir, compression_type=None, buffer_size=None, num_parallel_reads=None)\n", "        tfrpath = os.path.join(src_dir, tfr_file)\n", "        raw_image_dataset = tf.data.TFRecordDataset(tfrpath) # <TFRecordDatasetV2 shapes: (), types: tf.string>\n", "        image_feature_description = {\n", "            'shape': tf.io.FixedLenFeature([3], tf.int64),\n", "            'data': tf.io.FixedLenFeature([], tf.string),\n", "        }\n", "        def _parse_image_function(example_proto):\n", "            return tf.io.parse_single_example(example_proto, image_feature_description)        \n", "        parsed_dataset = raw_image_dataset.map(_parse_image_function)\n", "        for idx, dataitem in enumerate(parsed_dataset):\n", "            tfshape = dataitem['shape']\n", "            shape = tfshape.numpy()\n", "            tfdata = dataitem['data']\n", "            data = tfdata.numpy()\n", "            size = (shape[1], shape[2])\n", "            mode = 'RGB' if shape[0] == 3 else 'RGBA'\n", "            img = np.array(data)\n", "            channels = shape[0]\n", "            width = shape[1]\n", "            height = shape[2]\n", "            bytes_needed = int(width * height * channels)  # tfr 9: 512x512x3\n", "            bytesq = len(data) # tfr 9: 512x512x3\n", "            b = np.frombuffer(data, dtype=np.uint8)\n", "            img_arr =  b.reshape(shape[0], shape[1], shape[2]) # 3x3 b/w\n", "            img_arr = img_arr.transpose([1, 2, 0])\n", "            Onplot.cv_rgb(img_arr)\n", "    @staticmethod   \n", "    def cv_path(path, size = 512, title='img', wait=2000):\n", "        img = cv2.imread(path, cv2.IMREAD_COLOR)\n", "        img = cv2.resize(img, (size, int((np.shape(img)[0]/np.shape(img)[1]) * size)))\n", "        img = Onvgg.vgg_preprocess(img)\n", "        img = Onvgg.vgg_deprocess(img)\n", "        cv2.imshow(title, img) # keep open per wait\n", "        cv2.waitKey(wait)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    @staticmethod  \n", "    def cv_resize(img, max_size= None, dim=None):\n", "        if max_size:\n", "            img = cv2.resize(img, (max_size, int((np.shape(img)[0]/np.shape(img)[1]) * max_size)))\n", "        \n", "        if dim:\n", "            img = cv2.resize(img, (\n", "                dim[0] if dim[0] > 0 else img.size[0],\n", "                dim[1] if dim[1] > 0 else img.size[1]\n", "                ), Image.ANTIALIAS)            \n", "        return img"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    def cv_rgb(rgb, wait=2000):\n", "        rgb = cv2.cvtColor(rgb, cv2.COLOR_RGB2BGR)\n", "        cv2.imshow('img', rgb)\n", "        if wait:\n", "            cv2.waitKey(wait) "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    @staticmethod   \n", "    def cv_nba(img, title=\"img\", wait=0):\n", "        img = Onformat.nnba_to_rgb(img)\n", "        cv2.imshow(title, img)\n", "        cv2.waitKey(0)\n", "    @staticmethod   \n", "    def cv_img(img, title=\"img\", wait=0):\n", "        if Onutil.incolab():\n", "            from google.colab.patches import cv2_imshow\n", "            cv2_imshow(img)\n", "            cv2.waitKey(wait)\n", "            cv2.destroyAllWindows()\n", "        else:\n", "            cv2.imshow(title, img)\n", "            cv2.waitKey(wait)\n", "            cv2.destroyAllWindows()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["  ******************<br>\n", "  FUNS FORMAT<br>\n", "<br>\n", "  ******************"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class Onformat:\n", "    @staticmethod\n", "    def cvt_to_rgb(cvt):\n", "        img=np.array(cvt, dtype=np.float32)\n", "        img = img[0]\n", "        img = (img / 255 + 1.0)/2.0\n", "        return img\n", "    @staticmethod\n", "    def pil_to_cvi(img):\n", "        img = np.array(img) # [[[155  91  69]\n", "        img = img[:, :, ::-1] # val: [[[ 69  91 155]\n", "        return img\n", "    @staticmethod\n", "    def pil_to_nua(img):\n", "        img = img.convert(\"RGB\")\n", "        img = np.asarray(img, dtype=np.float32) / 255    \n", "        return img\n", "    @staticmethod\n", "    def nua_to_pil(nua):\n", "        nua = nua*255\n", "        nua = np.array(nua, dtype=np.uint8)\n", "        if np.ndim(nua)>3:\n", "            assert nua.shape[0] == 1\n", "            nua = nua[0]\n", "        return PIL.Image.fromarray(nua)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    @staticmethod\n", "    def pil_to_rgb(img):\n", "        img = img.convert(\"RGB\")\n", "        img = np.asarray(img)\n", "        return img\n", "    @staticmethod\n", "    def nba_to_nnba(img):\n", "        return img[np.newaxis,:,:,:]\n", "    \n", "    @staticmethod\n", "    def tnua_to_nua(img):\n", "        # np.array (by default) will make a copy of the object, \n", "        # while np.asarray will not unless necessary\n", "        img = np.asarray(img) # img = np.array(img)\n", "        return img\n", "    @staticmethod\n", "    def rgb_to_pil(img):\n", "        img = PIL.Image.fromarray(np.array(img, dtype=np.uint8))\n", "        return img\n", "    @staticmethod\n", "    def rgb_to_nba(img):\n", "        # normalizing the images to [-1, 1]\n", "        img = tf.cast(img, tf.float32) # _e_\n", "        img = (img / 127.5) - 1\n", "        return img\n", "        \n", "    @staticmethod\n", "    def _rgbs_to_nbas(input_image, real_image):\n", "        # normalizing the images to [-1, 1]\n", "        input_image = tf.cast(input_image, tf.float32) # _e_\n", "        real_image = tf.cast(real_image, tf.float32)   # _e_\n", "        input_image = (input_image / 127.5) - 1\n", "        real_image = (real_image / 127.5) - 1\n", "        return input_image, real_image\n", "    @staticmethod\n", "    def rgbs_to_nbas(imgs):\n", "        res = []\n", "        for img in imgs:\n", "            img = Onformat.rgb_to_nba(img)\n", "            res.append(img)\n", "        return res\n", "    @staticmethod\n", "    def rgbs_to_nuas_batch(imgs, num, flip = True):\n", "        idx = np.random.randint(0, imgs.shape[0] - 1, num)\n", "        out = []\n", "        for i in idx:\n", "            out.append(imgs[i])\n", "            if flip and np.random.uniform(()) < 0.5:  # flip as arg\n", "                out[-1] = np.flip(out[-1], 1)\n", "        return np.array(out).astype('float32') / 255.0   \n", "    @staticmethod\n", "    def nua_to_rgb(img):\n", "        img = img*255\n", "        rgb = np.array(img, dtype=np.uint8)\n", "        if np.ndim(img)>3:\n", "            assert img.shape[0] == 1\n", "            rgb = img[0]\n", "        return rgb\n", "    @staticmethod\n", "    def nua_to_pil(img):\n", "        img = Onformat.nua_to_rgb(img)\n", "        img = PIL.Image.fromarray(img)\n", "        return img\n", "    @staticmethod\n", "    def nua_to_rgb(nua):\n", "        res = nua*255\n", "        res = np.array(res, dtype=np.uint8)\n", "        if np.ndim(res)>3:\n", "            assert res.shape[0] == 1\n", "            res = res[0]\n", "        return res\n", "    @staticmethod\n", "    def nuas_to_rgbs(nuas):\n", "        imgs=[]\n", "        for nua in nuas:\n", "            imgs.append(Onformat.nua_to_rgb(nua))\n", "        return imgs\n", "    @staticmethod\n", "    def names_to_nnuas(img_names=[], img_dir = \"./\", max_size = None, img_nrows = None, img_ncols = None):\n", "        _imgs = []\n", "        for img_name in img_names:\n", "            fil = os.path.join(img_dir, img_name)\n", "            img = Onfile.path_to_nnua(fil, max_size, img_nrows, img_ncols)\n", "            _imgs.append(img)\n", "        return _imgs\n", "    @staticmethod\n", "    def nnba_to_rgb(img):\n", "        img = img[0,...]\n", "        img = (img + 1.0)/2.0\n", "        img = np.array(255 * img, dtype=np.uint8)\n", "        return img\n", "    @staticmethod\n", "    def nba_to_rgb(img):\n", "        img = 255*(img + 1.0)/2.0\n", "        return tf.cast(img, tf.uint8)\n", "    @staticmethod\n", "    def bgr_to_nua(img):\n", "        img = (img / 255 + 1.0)/2.0\n", "        return img\n", "    @staticmethod\n", "    def nba_to_nua(img): # [-1,1] => [0,255]\n", "        img = (img + 1.0)/2.0\n", "        return img\n", "    @staticmethod\n", "    def tnua_resize(image, width, height):\n", "        image = tf.cast(image, tf.float32)\n", "        image = tf.image.resize(image, (width, height))\n", "        # image = image[None, ...]\n", "        return image\n", "    @staticmethod\n", "    def cvt_to_nua(cvt):\n", "        img=np.array(cvt, dtype=np.float32)\n", "        img = img[0] # squeeze dim\n", "        img = (img / 255 + 1.0)/2.0\n", "        return img\n", "    @staticmethod\n", "    def imgs_to_tiling(imgs, imgpath, qsegs=1, save=True):\n", "        qtiles = qsegs * qsegs  # will predict images\n", "        r = []\n", "        for i in range(0, qtiles, qsegs): # for each row\n", "            r.append(np.concatenate(imgs[i:i+qsegs], axis = 0)) # concat cols\n", "        c1 = np.concatenate(r, axis = 1)\n", "        c1 = np.clip(c1, 0.0, 1.0)\n", "        x = Image.fromarray(np.uint8(c1*255))\n", "        if save:\n", "            x.save(imgpath)\n", "        return x\n", "    @staticmethod\n", "    def dnua_to_nua(tnua):\n", "        nua = tnua\n", "        if len(tnua.shape) > 3:\n", "            assert tnua.shape[0] == 1\n", "            nua = tf.squeeze(tnua, axis=0)\n", "        nua = np.asarray(nua)        \n", "        return nua\n", "    @staticmethod\n", "    def dnuas_to_nuas(tnuas):\n", "        nuas=[]\n", "        for item in tnuas:\n", "            nuas.append(Onformat.dnua_to_nua(item))\n", "        return nuas\n", "    @staticmethod\n", "    def dnuas_to_pils(nuas):\n", "        imgs=[]\n", "        for nua in nuas:\n", "            imgs.append(Onformat.nua_to_pil(nua))\n", "        return imgs\n", "    \n", "    @staticmethod\n", "    def rgb_to_bgr(img):\n", "        img = np.array(img) # [[[155  91  69]\n", "        img = img[:, :, ::-1] # val: [[[ 69  91 155]\n", "        return img\n", "    @staticmethod\n", "    def rgb_to_dnua(img):\n", "        img = img/255.0\n", "        img = img[np.newaxis,:,:,:]\n", "        return img\n", "    @staticmethod\n", "    def pil_to_dnua(img):\n", "        img=np.array(img, dtype=np.float32)\n", "        img = img/255.0\n", "        img = img[np.newaxis,:,:,:]\n", "        return img\n", "    @staticmethod\n", "    def pils_to_dnuas(pils):\n", "        dnuas=[]\n", "        for img in pils:\n", "            nua = Onformat.pil_to_dnua(img)\n", "            dnuas.append(nua)\n", "        return dnuas\n", "    @staticmethod\n", "    def cvi_to_pil(img):\n", "        img = img[...,::-1] # bgr => rgb\n", "        img = Image.fromarray((img).astype(np.uint8))\n", "        img = np.array(img)\n", "        img = PIL.Image.fromarray(img)\n", "        return img"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    @staticmethod\n", "    def cvis_to_pils(imgs):\n", "        pils=[]\n", "        for img in imgs:\n", "            pil = Onformat.cvi_to_pil(img)\n", "            pils.append(pil)\n", "        return pils\n", "    @staticmethod\n", "    def bgr_cv2_rgb(img):\n", "        return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n", "    @staticmethod\n", "    def path_to_nbt_with_tf(img, height=256, width=256):\n", "        img = Onfile.path_to_rgb(img)\n", "        img = tf.image.resize(img, [height, width], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)        \n", "        img = Onformat.rgb_to_nba(img)\n", "        return img"]}, {"cell_type": "markdown", "metadata": {}, "source": ["  ******************<br>\n", "  FUNS FILE<br>\n", "<br>\n", "  ******************"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class Onfile:\n", "    @staticmethod\n", "    def rgbs_to_file(rgbs, scale=1, rows=1, save_path='./img.png',):\n", "        pils = []\n", "        for img in rgbs:\n", "            pils.append(PIL.Image.fromarray(np.array(img, dtype=np.uint8)))\n", "        w,h = pils[0].size\n", "        w = int(w*scale)\n", "        h = int(h*scale)\n", "        height = rows*h\n", "        cols = int(math.ceil(len(pils) / rows))\n", "        width = cols*w\n", "        canvas = PIL.Image.new('RGBA', (width,height), 'white')\n", "        for i,img in enumerate(pils):\n", "            img = img.resize((w,h), PIL.Image.ANTIALIAS)\n", "            canvas.paste(img, (w*(i % cols), h*(i // cols))) \n", "        canvas.save(save_path)\n", "    @staticmethod\n", "    def path_to_nba(img, height=256, width=256):\n", "        img = Onfile.path_to_rgb(img)\n", "        img = tf.image.resize(img, [height, width], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n", "        img = Onformat.rgb_to_nba(img)\n", "        return img\n", "    @staticmethod\n", "    def path_to_tnua_with_cv(path):\n", "        img = cv2.imread(path, cv2.IMREAD_COLOR)\n", "        img = img.astype(np.float32)\n", "        img = img[...,::-1]\n", "        # shape (h, w, d) to (1, h, w, d)\n", "        img = img[np.newaxis,:,:,:]\n", "        img -= np.array([123.68, 116.779, 103.939]).reshape((1,1,1,3))\n", "        return img\n", "    @staticmethod\n", "    def path_to_cvi(path,  max_size=None):\n", "        # bgr image\n", "        img = cv2.imread(path, cv2.IMREAD_COLOR)\n", "        if max_size:\n", "            h, w, d = img.shape\n", "            mx = max_size\n", "            # resize if > max size\n", "            if h > w and h > mx:\n", "                w = (float(mx) / float(h)) * w\n", "                img = cv2.resize(img, dsize=(int(w), mx), interpolation=cv2.INTER_AREA)\n", "            if w > mx:\n", "                h = (float(mx) / float(w)) * h\n", "                img = cv2.resize(img, dsize=(mx, int(h)), interpolation=cv2.INTER_AREA)\n", "        return img"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    @staticmethod\n", "    def path_cv_pil(path):\n", "        img = cv2.imread(path, cv2.IMREAD_COLOR)\n", "        img = img[...,::-1] # bgr => rgb\n", "        img = np.array(Image.fromarray((img).astype(np.uint8)))\n", "        img = PIL.Image.fromarray(img)\n", "        return img\n", "    @staticmethod\n", "    def path_to_tvgg(img_path, tileimg=None, scale=None, max_size=None ):\n", "        print(\"get init with cv2\")\n", "        img = Onfile.path_to_cvi(img_path,max_size=max_size)\n", "        img = Onvgg.vgg_preprocess(img)    \n", "        return img\n", "    @staticmethod\n", "    def path_to_nua(img_path, max_size = None, img_nrows = None, img_ncols = None):\n", "        assert os.path.isfile(img_path), f\"path_to_nnua {img_path} not found\"\n\n", "        # <class 'tensorflow.python.framework.ops.EagerTensor'> ()\n", "        # tf.Tensor(b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\n", "        img = tf.io.read_file(img_path)\n", "        img = tf.image.decode_image(img, channels=3) # _e_\n", "        img = tf.image.convert_image_dtype(img, tf.float32)\n", "        shape = tf.cast(tf.shape(img)[:-1], tf.float32) # \n", "        long_dim = max(shape)\n", "        scale = max_size / long_dim if max_size else 1\n", "        new_shape = tf.cast(shape * scale, tf.int32)\n", "        if (img_nrows and img_ncols): new_shape = tf.cast((img_nrows, img_ncols), tf.int32)\n", "        img = tf.image.resize(img, new_shape)\n", "        return img\n", "    @staticmethod\n", "    def path_to_nnua(img_path, max_size = None, img_nrows = None, img_ncols = None):\n", "        img = Onfile.path_to_nua(img_path, max_size, img_nrows, img_ncols)\n", "        img = img[tf.newaxis, :] # b, h, w, c\n", "        return img\n", "    @staticmethod\n", "    def names_to_nuas_with_tf(imgs_names, img_dir, args=None):\n", "        imgs = []\n", "        for item in imgs_names:\n", "            path = os.path.join(img_dir, item)\n", "            img = Onfile.path_to_tnua_with_tf(path, args)\n", "            imgs.append(img)\n", "        return imgs\n", "    @staticmethod\n", "    def names_to_paths(imgs_names, img_dir):\n", "        paths = []\n", "        for item in imgs_names:\n", "            path = os.path.join(img_dir, item)\n", "            paths.append(path)\n", "        return paths\n", "    @staticmethod\n", "    def folder_to_tnuas(folder, patt='*.jpg', max_size = None, img_nrows = None, img_ncols = None):\n", "        paths = glob.glob(os.path.join(folder, patt))\n", "        tnuas = []\n", "        for path in paths:\n", "            nua = Onfile.path_to_nnua(path, max_size, img_nrows, img_ncols)\n", "            tnuas.append(nua)\n", "        return tnuas\n", "    @staticmethod\n", "    def path_to_tnua_with_tf(path, args=None):\n", "            \n", "        max_size = args.max_size \n", "        assert os.path.isfile(path), f\"path_to_tnua_with_tf img {path} not found\"\n", "        parts = tf.strings.split(path, os.sep)\n", "        label = parts[-2]    \n\n", "        # <class 'tensorflow.python.framework.ops.EagerTensor'>  () tf.Tensor(b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\n", "        img = tf.io.read_file(path)\n", "        img = tf.image.decode_image(img, channels=3)\n", "        img = tf.image.convert_image_dtype(img, tf.float32)\n", "        shape = tf.cast(tf.shape(img)[:-1], tf.float32) #  \n", "        long_dim = max(shape)\n", "        scale = max_size / long_dim if max_size else 1\n", "        new_shape = tf.cast(shape * scale, tf.int32)\n\n", "        # <class 'tensorflow.python.framework.ops.EagerTensor'>  (336, 512, 3) tf.Tensor([[[0.60938966 0.36011618 0.27445853]    \n", "        img = tf.image.resize(img, new_shape)\n", "        img = img[tf.newaxis, :]\n", "        return img\n", "    @staticmethod\n", "    def pil_to_file_with_cv(path, img):\n", "        cv2.imwrite(path, Onformat.pil_to_cvi(img))\n", "    @staticmethod\n", "    def pil_to_file(path, img):\n", "        img.save(path)\n", "    @staticmethod\n", "    def path_to_bgr(path): # _e_\n", "        # bgr image \n", "        img = cv2.imread(path, cv2.IMREAD_COLOR)\n", "        img = img.astype(np.float32)\n", "        # img = Onformat.vgg_preprocess(img)\n", "        return img\n", "    @staticmethod\n", "    def names_to_pils(imgs,dst_dir= './',img_name_frmt='img{}.jpg',zfill = 4,):\n", "        for i,img in enumerate(imgs):\n", "            img_name = img_name_frmt.format(str(i).zfill(zfill))\n", "            path = os.path.join(dst_dir, img_name)\n", "            tft = img # <class 'tensorflow.python.framework.ops.EagerTensor'> (256, 256, 3)\n", "            arr = img.numpy().astype(np.uint8) # <class 'numpy.ndarray'> (256, 256, 3)\n", "            img = Image.fromarray(arr)\n", "            img = img.convert(\"RGB\")\n", "            img.save(path)\n", "    @staticmethod\n", "    def path_cv2_dnua(path):  #  _e_\n", "        img = cv2.imread(path, cv2.IMREAD_COLOR)\n", "        img = Onformat.vgg_preprocess(img)\n", "        img = Onformat.vgg_deprocess(img)\n", "        img = Onformat.pil_to_dnua(img)\n", "        return img\n", "    \n", "    @staticmethod\n", "    def cvs_to_folder(imgs, path, img_format='img{}.jpg', zfill=4):\n", "        for i,img in enumerate(imgs):\n", "            Onfile.cv_to_path(img, os.path.join(path, img_format.format(str(i).zfill(zfill))))\n", "    @staticmethod\n", "    def cv_to_path(img, path):\n", "        saved = cv2.imwrite(path, img)\n", "        return saved\n", "    @staticmethod\n", "    def cv_to_file(path, img):\n", "        cv2.imwrite(path, Onformat.rgb_to_bgr(img))\n", "    @staticmethod\n", "    def path_to_cv(path, max_size=512):\n\n", "        # bgr image\n", "        img = cv2.imread(path, cv2.IMREAD_COLOR)\n", "        h, w, d = img.shape\n", "        mx = max_size\n", "        # resize if > max size\n", "        if h > w and h > mx:\n", "            w = (float(mx) / float(h)) * w\n", "            img = cv2.resize(img, dsize=(int(w), mx), interpolation=cv2.INTER_AREA)\n", "        if w > mx:\n", "            h = (float(mx) / float(w)) * h\n", "            img = cv2.resize(img, dsize=(mx, int(h)), interpolation=cv2.INTER_AREA)\n", "        return img"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    @staticmethod\n", "    def paths_to_cvs(paths):\n", "        imgs = []\n", "        for path in paths:\n", "            imgs.append(Onfile.path_to_cv(path))\n", "        return imgs\n", "    @staticmethod\n", "    def paths_to_folder_with_cv(paths, folder, img_format='img{}.jpg', zfill=4):\n", "        imgs = []\n", "        for i,path in enumerate(paths):\n", "            img = Onfile.path_to_cv(path)\n", "            img_path = os.path.join(folder, img_format.format(str(i).zfill(zfill)))\n", "            if 1:\n", "                print(f'save {i} to {img_path}')\n", "            Onfile.cv_to_file(img_path, img)\n", "        return imgs\n", "    @staticmethod\n", "    def folder_to_cvs(path):\n", "        paths = Onfile.folder_to_paths(path)\n", "        imgs = Onfile.paths_to_cvs(paths)\n", "        return imgs\n", "    @staticmethod\n", "    def folder_to_cv_name_pairs(path, args=None):\n", "        pairs = []\n", "        for root, subdirs, files in os.walk(path):\n", "            if(args.verbose): print('folder_to_cv_name_pairs --\\nroot = ' + root)\n", "            for subdir in subdirs:\n", "                if(args.verbose): print('\\t- subdirectory ' + subdir)\n", "            for filename in files:\n", "                if not filename.startswith('.'):\n", "                    file_path = os.path.join(root, filename)\n", "                    if(args.verbose): print('\\t- file %s (full path: %s)' % (filename, file_path))\n", "                    \n", "                    pairs.append([cv2.imread(file_path),filename])\n", "        return pairs\n", "    @staticmethod\n", "    def cv_name_pairs_to_folder(pairs, args=None):\n", "        folder = args.output_folder\n", "        for pair in pairs:\n", "            img = pair[0]\n", "            filename = pair[1]\n", "            if(args.file_extension == \"png\"):\n", "                new_file = os.path.splitext(filename)[0] + \".png\"\n", "                cv2.imwrite(os.path.join(folder, new_file), img, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n", "            else:\n", "                new_file = os.path.splitext(filename)[0] + \".jpg\"\n", "                cv2.imwrite(os.path.join(folder, new_file), img, [cv2.IMWRITE_JPEG_QUALITY, 90])\n", "    @staticmethod\n", "    def path_to_pil(path):\n", "        img = Image.open(path)\n", "        return img\n", "    @staticmethod\n", "    def folder_to_paths(path, \n", "            exts=['jpg', 'jpeg', 'png'], \n", "            n=-1\n", "        ):\n", "        import glob\n", "        paths = [] # <class 'list'>\n", "        for ext in exts:\n", "            paths += glob.glob(os.path.join(path, f\"*.{ext}\"))\n", "            if 0 < n and n < len(paths):\n", "                break            \n", "        return paths\n", "    @staticmethod\n", "    def folder_to_paths(path, \n", "            exts=['jpg', 'jpeg', 'png'], \n", "            n=-1\n", "        ):\n", "        paths=[]\n", "        for root, dirs, files in os.walk(path):\n", "            for name in files:\n", "                if name.endswith(tuple(exts)):\n", "                    target_path = os.path.join(path, name)\n", "                    paths.append(target_path)\n", "                    if 0 < n and n < len(paths):\n", "                        break\n", "                else:\n", "                    pass # print('Only image')          \n", "        return paths"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    @staticmethod\n", "    def copyfolder(input_folder, output_folder, deep=True):\n", "        for filename in os.listdir(input_folder):\n", "            input_path = os.path.join(input_folder, filename)\n", "            try:\n", "                if os.path.isfile(input_path) or os.path.islink(input_path):\n", "                    output_path = os.path.join(output_folder, filename)\n", "                    shutil.copyfile(input_path, output_path)\n", "                elif os.path.isdir(input_path):\n", "                    if deep:\n", "                        Onfile.copyfolder(input_path, output_folder)\n", "            except Exception as e:\n", "                print(f'Failed to copy {input_path}. Reason: {e}')\n", "                \n", "    @staticmethod\n", "    def clearfolder(folder, inkey=''):\n", "        if inkey and inkey in folder:\n", "            print(f\"|===> clearfolder: {folder} has key {inkey}. will clear\")\n", "            for filename in os.listdir(folder):\n", "                file_path = os.path.join(folder, filename)\n", "                try:\n", "                    if os.path.isfile(file_path) or os.path.islink(file_path):\n", "                        os.unlink(file_path)\n", "                    elif os.path.isdir(file_path):\n", "                        shutil.rmtree(file_path)\n", "                except Exception as e:\n", "                    print('Failed to delete %s. Reason: %s' % (file_path, e))\n", "        else:\n", "            print(f\"|===> clearfolder: {folder} has no key {inkey}\")\n", "    @staticmethod\n", "    def qfolders(folder, topdown=False):\n", "        q = 0\n", "        if os.path.exists(folder):        \n", "            for root, dirs, files in os.walk(folder, topdown=topdown):\n", "                for name in dirs:\n", "                    q += 1\n", "        return q\n", "    @staticmethod\n", "    def qfiles(folder, patts=None):\n", "        howmany = 0\n", "        if not patts:\n", "            howmany = len(os.listdir(folder))\n", "        elif type(patts) is list: \n", "            paths = []\n", "            howmany = len(paths)\n", "            for patt in patts:\n", "                infolder = os.path.join(folder, patt)\n", "                pathsinfolder = glob.glob(infolder)\n", "                paths = paths + pathsinfolder\n", "                howmany = len(paths)\t\t\n", "        else:\n", "            files = glob.glob(os.path.join(folder, patts))\n", "            howmany = len(files)\n", "        return howmany"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    @staticmethod\n", "    def path_to_paths(path, patts=None): # ['*.jpg', '*.jpeg', '*.png']\n", "        paths = []\n", "        if patts:\n", "            for patt in patts:\n", "                inpath = os.path.join(path, patt)\n", "                new = glob.glob(inpath)\n", "                paths = paths + new\n", "        else:\n", "            for entry in os.listdir(path):\n", "                full_path = os.path.join(path, entry)\n", "                if os.path.isfile(full_path):\n", "                    paths.append(full_path)\n", "        return paths\n", "    @staticmethod\n", "    def folder_to_pils(src_dir, n=-1):\n", "        if 0: print(f\"folder_to_pils: was asked to get {n} imgs from: {src_dir}\")\n", "        imgs = []\n", "        import glob\n", "        jpgs = glob.glob(os.path.join(src_dir, \"*.jpg\"))\n", "        pngs = glob.glob(os.path.join(src_dir, \"*.png\"))\n", "        fs = jpgs + pngs  # <class 'list'>\n", "        for i,f in enumerate(fs):\n", "            if (n<0 or i<n):\n", "                img = Image.open(f)\n", "                imgs.append(img)\n", "        if 0: print(f\"folder_to_pils: got {len(imgs)} imgs from: {src_dir}\")            \n", "        return imgs\n", "    @staticmethod\n", "    def pils_to_folder(imgs, dest_dir, img_format = 'img{}.jpg', zfill=4, verbose=False):\n", "        for i, pil in enumerate(imgs):        \n", "            img_name = img_format.format(str(i).zfill(zfill))                \n", "            outpath = os.path.join(dest_dir, img_name)\n", "            if 0: \n", "                print(f\"save image {i} to {outpath}\")\n", "            pil.save(outpath, 'JPEG', quality=90) "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    @staticmethod\n", "    def folder_to_named_files(src_dir, dst_dir, img_format= 'img{}.jpg', zfill= 4, n=-1, verbose=False):\n", "        paths=[]\n", "        imgs=[]\n", "        idx = 0\n", "        for root, dirs, files in os.walk(src_dir):\n", "            for name in files:\n", "                if name.endswith((\".png\", \".jpg\")):\n", "                    src_path = os.path.join(src_dir, name)\n", "                    newname = img_format.format(str(idx).zfill(zfill))       \n", "                    target_path = os.path.join(dst_dir, newname)\n", "                    img = Image.open(src_path)\n", "                    paths.append(target_path)\n", "                    if verbose: \n", "                        print(f\"save image {idx} to {target_path}\")\n", "                    img.save(target_path, 'JPEG', quality=90) \n", "                    if -1 < n and n < len(paths):\n", "                        break\n", "                    idx += 1\n", "                else:\n", "                    print('get only image files')          \n", "        return paths\n", "    @staticmethod\n", "    def folder_to_rgbs(src_dir, qimgs=-1):\n", "        if 0: print(f\"folder_to_rgbs q:{qimgs} from: {src_dir}\")\n", "        imgs = Onfile.folder_to_pils(src_dir, qimgs)\n", "        res=[]\n", "        for img in imgs:\n", "            img = np.asarray(img)\n", "            res.append(img)\n", "        return res\n", "    @staticmethod\n", "    def folder_to_nuas(src_dir, qimgs=-1):\n", "        if 0: print(f\"folder_to_nuas q:{qimgs} from: {src_dir}\")\n", "        imgs = Onfile.folder_to_rgbs(src_dir, qimgs)\n", "        res=[]\n", "        for img in imgs:\n", "            img = img.astype(np.float32)\n", "            img = img / 255\n", "            res.append(img)\n", "        return np.asarray(res)\n", "    @staticmethod\n", "    def tfts_to_files(imgs,dst_dir= './',img_name_frmt='img{}.jpg',zfill = 4,):\n", "        for i,img in enumerate(imgs):\n", "            img_name = img_name_frmt.format(str(i).zfill(zfill))\n", "            path = os.path.join(dst_dir, img_name)\n", "            tft = img # <class 'tensorflow.python.framework.ops.EagerTensor'> (256, 256, 3)\n", "            arr = img.numpy().astype(np.uint8) # <class 'numpy.ndarray'> (256, 256, 3)\n", "            img = Image.fromarray(arr)\n", "            img = img.convert(\"RGB\")\n", "            img.save(path)\n", "    @staticmethod\n", "    def path_of_paired_to_rgbs(path):\n", "        image = tf.io.read_file(path) # => dtype=string\n", "        image = tf.image.decode_jpeg(image) # => shape=(256, 512, 3), dtype=uint8)\n", "        w = tf.shape(image)[1]\n", "        w = w // 2\n", "        real_image = image[:, :w, :] # real comes left \n", "        input_image = image[:, w:, :] \n", "        return input_image, real_image\n", "    @staticmethod\n", "    def path_to_rgb(path):\n", "        img = tf.io.read_file(path) # => dtype=string\n", "        img = tf.image.decode_jpeg(img) # => shape=(256, 512, 3), dtype=uint8)\n", "        return img\n", "    @staticmethod\n", "    def path_to_rgbt(path):\n", "        return Onfile.path_to_rgb(path)\n", "    @staticmethod\n", "    def path_to_tnua_with_tf(path, args=None):\n", "        max_size = args.max_size \n", "        assert os.path.isfile(path), f\"path_to_tnua_with_tf img {path} not found\"\n", "        parts = tf.strings.split(path, os.sep)\n", "        label = parts[-2]    \n\n", "        # <class 'tensorflow.python.framework.ops.EagerTensor'>  () tf.Tensor(b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\n", "        img = tf.io.read_file(path)\n", "        img = tf.image.decode_image(img, channels=3)\n", "        img = tf.image.convert_image_dtype(img, tf.float32)\n", "        shape = tf.cast(tf.shape(img)[:-1], tf.float32) #  \n", "        long_dim = max(shape)\n", "        scale = max_size / long_dim if max_size else 1\n", "        new_shape = tf.cast(shape * scale, tf.int32)\n\n", "        # <class 'tensorflow.python.framework.ops.EagerTensor'>  (336, 512, 3) tf.Tensor([[[0.60938966 0.36011618 0.27445853]    \n", "        img = tf.image.resize(img, new_shape)\n", "        img = img[tf.newaxis, :]\n", "        return img\n", "    @staticmethod\n", "    def names_tf_tnuas(imgs_names, img_dir, args=None):\n", "        imgs = []\n", "        for item in imgs_names:\n", "            path = os.path.join(img_dir, item)\n", "            img = Onfile.path_to_tnua_with_tf(path, args)\n", "            imgs.append(img)\n", "        return imgs\n\n", "    # https://github.com/rosasalberto/StyleGAN2-TensorFlow-2.x\n", "    @staticmethod\n", "    def generate_and_save_images(images, it, plot_fig=True, outdir='./'):\n", "        plt.close() \n", "        fig = plt.figure(figsize=(9,9))\n", "        for i in range(images.shape[0]):\n", "            plt.subplot(2, 2, i+1)\n", "            plt.imshow(images[i])\n", "            plt.axis('off')\n\n", "        # tight_layout minimizes the overlap between 2 sub-plots\n", "        fig.tight_layout()\n", "        imgoutname = 'image_at_iter_{:04d}.png'.format(it)\n", "        imgoutpath = os.path.join(outdir, imgoutname)\n", "        plt.savefig(imgoutpath)\n", "        if plot_fig: plt.show()\n", "    @staticmethod\n", "    def rgb_cv2_file(rgb, path): # to jpg\n", "        im_bgr = cv2.cvtColor(rgb, cv2.COLOR_RGB2BGR)\n", "        cv2.imwrite(path, im_bgr)   "]}, {"cell_type": "markdown", "metadata": {}, "source": ["  ******************<br>\n", "  FUNS Onimg<br>\n", "<br>\n", "  ******************"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class Onimg:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    @staticmethod\n", "    def img_to_mask(img, outpath=None, \n", "                    height=None, width=None, \n", "                    threshold=76, maxVal=255, \n", "                    thresmode=cv2.THRESH_BINARY,\n", "                    visual=0, verbose=0,\n", "                ):\n", "        #https://answers.opencv.org/question/228538/how-to-create-a-binary-mask-for-medical-images/\n", "        if verbose > -1:\n", "            print(f'|---> img_to_mask {np.shape(img)}')\n\n", "        #cv2.resize(src, dsize[, dst[, fx[, fy[, interpolation]]]])\n", "        if height and width:\n", "            (h1, w1) = (height, width)\n", "            img = cv2.resize(img, (w1, h1))\n", "        elif height:\n", "            h0 = np.shape(img)[0] # 384\n", "            w0 = np.shape(img)[1] # 512\n", "            h1 = height\n", "            w1 = int(w0  * (h1/h0))\n", "            img = cv2.resize(img, (w1, h1))\n", "        elif width:\n", "            h0 = np.shape(img)[0] # 384\n", "            w0 = np.shape(img)[1] # 512\n", "            w1 = width\n", "            h1 = int(h0  * (w1/w0))\n", "            dim = (w1, h1)\n", "            img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n", "        else:\n", "            pass\n", "        image_contours = np.zeros((img.shape[0], img.shape[1], 1), np.uint8)\n", "        image_binary = np.zeros((img.shape[0], img.shape[1], 1), np.uint8)\n", "        for channel in range(img.shape[2]):\n", "            ret, image_thresh = cv2.threshold(img[:, :, channel],\n", "                                            threshold, maxVal,\n", "                                            thresmode)\n", "            contours = cv2.findContours(image_thresh, 1, 1)[0]   \n", "            cv2.drawContours(image_contours,\n", "                            contours, -1,\n", "                            (255,255,255), 3)\n", "        contours = cv2.findContours(image_contours, cv2.RETR_LIST,\n", "                                cv2.CHAIN_APPROX_SIMPLE)[0]\n", "        cv2.drawContours(image_binary, [max(contours, key = cv2.contourArea)],\n", "                        -1, (255, 255, 255), -1)\n", "        if outpath:\n", "            outbasename = os.path.basename(outpath)\n", "            outdirname = os.path.dirname(outpath)\n", "            assert os.path.exists(outdirname), f\"outdirname {outdirname} does not exist\"\n", "            cv2.imwrite(outpath, image_binary)\n", "        if visual > 0:\n", "            cv2.imshow('inimg', img)            \n", "            cv2.imshow('outimg', image_binary)\n", "            cv2.waitKey(0) & 0xFF is 27\n", "            cv2.destroyAllWindows()\n", "        return image_binary"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    @staticmethod\n", "    def name_to_maskname(name):\n", "        name_base = os.path.splitext(name)[0]\n", "        name_ext = os.path.splitext(name)[1]\n", "        print(\"|...> name_base\", name_base, name_ext)\n", "        name_mask = f'{name_base}_mask{name_ext}'\n", "        return name_mask\n", "        \n", "    @staticmethod\n", "    def name_to_unmaskname(name):\n", "        name_base = os.path.splitext(name)[0]\n", "        name_ext = os.path.splitext(name)[1]\n", "        print(\"|...> name_base\", name_base, name_ext)\n", "        basename_unmask = name_base.replace('_mask', '')\n", "        name_unmask = f'{basename_unmask}{name_ext}'\n", "        return name_unmask\n", "        \n", "    @staticmethod\n", "    def path_to_maskpath(path):\n", "        dirname = os.path.dirname(path)\n", "        basename  =os.path.basename(path)\n", "        maskname = Onimg.name_to_maskname(basename)\n", "        maskpath = os.path.join(dirname, maskname)\n", "        return maskpath\n", "    @staticmethod\n", "    def path_to_mask(inpath, outpath, height = None, width = None, ml=2*38, mh=255, visual=0):\n", "        #https://answers.opencv.org/question/228538/how-to-create-a-binary-mask-for-medical-images/\n", "        inbasename = os.path.basename(inpath)\n", "        assert os.path.exists(inpath), f\"inpath {inpath} does not exist\"\n", "        img = cv2.imread(inpath)\n", "        image_binary = img_to_mask(img, outpath, height, width, ml, mh, visual)\n", "        return image_binary"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    @staticmethod\n", "    def tf_resize_nua(nua, args=None):\n", "            \n", "        max_size = args.max_size \n", "        shape = np.shape(nua)\n", "        (d,w,h,c) = shape\n", "        dim = (w,h)\n", "        long_dim = max(w,h)\n", "        scale = max_size / long_dim if max_size else 1\n", "        new_dim = (int(w * scale), int(h * scale))\n", "        print(f\"|===> tf_resize_nua \\n \\\n", "            nua type: {type(nua)} \\n \\\n", "            shape: {shape} \\n \\\n", "            max_size: {max_size} \\n \\\n", "            long_dim: {long_dim} \\n \\\n", "            scale: {scale} \\n \\\n", "            dim: {dim} \\n \\\n", "            new_dim: {new_dim} \\n \\\n", "        \")\n", "        nua = tf.image.resize(nua, new_dim)\n", "        #nua = nua[tf.newaxis, :]\n", "        print(f\"|... tf_resize_nua \\n \\\n", "            nua type: {type(nua)} \\n \\\n", "            shape: {np.shape(nua)} \\n \\\n", "        \")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        return nua"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    @staticmethod\n", "    def cvi_mask_to_cvi(img, mask, op=2):\n", "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n", "        \n", "        if op < 0: # reverse mask\n", "            mask = cv2.bitwise_not(mask)\n", "            op = abs(op)\n", "        if op == 1: # bitwise_and\n", "            mask = cv2.cvtColor(mask, cv2.COLOR_GRAY2RGB)\n", "            img = cv2.bitwise_and(img, mask)\n", "        elif op == 2: # bitwise_or\n", "            mask = cv2.cvtColor(mask, cv2.COLOR_GRAY2RGB)\n", "            img = cv2.bitwise_or(img, mask)\n", "        elif op == 3: # bitwise_xor\n", "            mask = cv2.cvtColor(mask, cv2.COLOR_GRAY2RGB)\n", "            img = cv2.bitwise_xor(img, mask)\n", "        elif op == 4: # bitwise_not\n", "            mask = cv2.cvtColor(mask, cv2.COLOR_GRAY2RGB)\n", "            img = cv2.bitwise_not(img, mask)\n", "        elif op == 5: # addWeighted\n", "            mask = cv2.cvtColor(mask, cv2.COLOR_GRAY2RGB)\n", "            img = cv2.addWeighted(img, 0.5, mask, 0.5, 0)\n", "        elif op == 6: # thresh\n", "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n", "            blur = cv2.GaussianBlur(gray, (13,13), 0)\n", "            thresh = cv2.adaptiveThreshold(blur,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV,51,7)\n\n", "            # Morph close\n", "            kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n", "            close = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel, iterations=1)\n\n", "            # Find contours, sort for largest contour, draw contour\n", "            cnts = cv2.findContours(close, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n", "            cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n", "            cnts = sorted(cnts, key=cv2.contourArea, reverse=True)\n", "            for c in cnts:\n", "                cv2.drawContours(thresh, [c], -1, (36,255,12), 2)\n", "                break\n", "            img = thresh"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n", "        return img"]}, {"cell_type": "markdown", "metadata": {}, "source": ["  ******************<br>\n", "  FUNS ONVID<br>\n", "<br>\n", "  ******************"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class Onvid:\n", "    @staticmethod\n", "    def vid_to_frames(video_path, frames_dir='./', frame_format= 'frame{}.jpg', zfill= 4, target = 1):\n", "        video = cv2.VideoCapture(video_path)      \n", "        success, frame = video.read() # Capture frame-by-frame\n", "        currentFrame = 0\n", "        counter = 0\n", "        addframe = 0\n", "        start = time.time()\n", "        while(success):\n", "            if currentFrame % target ==0:\n", "                name = frames_dir + '/frame' + \"{:04d}\".format(currentFrame) + '.jpg'\n", "                if 0: print (f'Creating... {currentFrame} {name}')\n", "                cv2.imwrite(name, frame)\n", "                success,frame = video.read()\n", "                if 0: print (f'will create... {currentFrame}')\n", "                currentFrame += 1\n", "                counter = 0\n", "                addframe += 1\n", "            else:\n", "                ret = video.grab()\n", "                currentFrame += 1\n", "                counter += 1\n", "        end = time.time()\n", "        seconds = end - start\n", "        num_frames = currentFrame\n", "        fps  = addframe / (seconds * target)\n", "        print (f\"|... Estimated frames per second : {int(round(fps))}\")\n", "        video.release() # When everything done, release the capture\n", "        cv2.destroyAllWindows()\n", "    @staticmethod\n", "    def frames_to_video(inputpath, outputpath, fps):\n", "        DWITH_FFMPEG=\"ON\"    \n", "        image_array = []\n", "        files = [f for f in os.listdir(inputpath) if os.path.isfile(os.path.join(inputpath, f))]\n", "        \n", "        # files.sort(key = lambda x: int(x[5:-4]))\n", "        if 1:\n", "            for i in range(len(files)):\n", "                img_path = os.path.join(inputpath,files[i] )\n", "                print(f'|---> frames_to_video img_path: {img_path}')\n", "                img = cv2.imread(img_path)\n", "                size =  (img.shape[1],img.shape[0])\n", "                img = cv2.resize(img,size)\n", "                image_array.append(img)\n", "            fourcc = cv2.VideoWriter_fourcc('D', 'I', 'V', 'X')\n", "            print(f'|---> frames_to_video outputpath: {outputpath}')            \n", "            out = cv2.VideoWriter(outputpath, fourcc, fps, size) # VideoWriter(filename, cv2.CAP_OPENCV_MJPEG, ...)\n", "            for i in range(len(image_array)):\n", "                out.write(image_array[i])     \n", "            out.release()\n", "        else:\n", "            with imageio.get_writer(outputpath, mode='I') as writer:\n", "                for filename in files:\n", "                    img_path = os.path.join(inputpath,filename)\n", "                    image = imageio.imread(img_path)\n", "                    writer.append_data(image)   \n", "    @staticmethod\n", "    def folder_to_movie(images, out_dir, out_name):\n", "        temp_dir = 'frames%06d'%int(1000000*random.random())\n", "        os.system('mkdir %s'%temp_dir)\n", "        for idx in tqdm(range(len(images))):\n", "            Image.fromarray(images[idx], 'RGB').save('%s/frame%05d.png' % (temp_dir, idx))\n", "        cmd = 'ffmpeg -i %s/frame%05d.png -c:v libx264 -pix_fmt yuv420p %s/%s.mp4' % (temp_dir, out_dir, out_name)\n", "        print(cmd)\n", "        os.system(cmd)\n", "        os.system('rm -rf %s'%temp_dir)\n", "    @staticmethod\n", "    def folder_to_vid(fromfolder, dstfile, ext='png', save=True, args=None):\n", "        srcpath = fromfolder\n", "        anifile = dstfile\n", "        size=(640, 480)\n", "        fps=20\n", "        if 1: # args.verbose: \n", "            print(f'|--->  folder_to_vid  \\n \\\n", "                srcpath:         {srcpath} \\n \\\n", "                anifile:         {anifile} \\n \\\n", "            ')            \n\n", "        # anime.anigif(srcpath, anifile)\n", "        fig = plt.figure()\n", "        fig.set_size_inches(size[0] / 100, size[1] / 100)\n", "        ax = fig.add_axes([0, 0, 1, 1], frameon=False, aspect=1)\n", "        ax.set_xticks([])\n", "        ax.set_yticks([])\n", "        images = []\n", "        imgnames = [img for img in os.listdir(srcpath) if img.endswith(ext)]\n", "        for i,imgname in enumerate(imgnames):\n", "            imgpath = os.path.join(srcpath, imgname)\n", "            img = imageio.imread(imgpath)\n", "            label=' '\n", "            plt_im = plt.imshow(img, animated=True)\n", "            plt_txt = plt.text(10, 310, label, color='black')\n", "            images.append([plt_im, plt_txt])\n\n", "        # animated_gif.save(anipath + \"/ani.gif\")\n", "        # MovieWriter imagemagick unavailable; \n", "        # trying to use <class 'matplotlib.animation.PillowWriter'> instead\n", "        if 1: #  args.verbose:\n", "            print(f'|...>  folder_to_vid: call anim.ArtistAnimation  \\n \\\n", "                images len:      {len(images)} \\n \\\n", "            ')\n", "        import matplotlib.animation as anim\n", "        ani = anim.ArtistAnimation(fig, images, \n", "            interval=20, blit=True, repeat_delay=1000)\n", "        if save:\n", "            ani.save(dstfile, writer='imagemagick')  \n", "        return ani\n", "    @staticmethod\n", "    def folder_to_gif(fromfolder, dstpath='./out.gif', patts=None):\n", "        paths = Onfile.path_to_paths(fromfolder, patts)\n", "        paths = sorted(paths)\n", "        print(f'---> folder_to_gif \\n \\\n", "            fromfolder: {fromfolder} \\n \\\n", "            dstpath: {dstpath} \\n \\\n", "            patts: {patts} \\n \\\n", "            paths: {len(paths)} \\n \\\n", "        ')\n", "        with imageio.get_writer(dstpath, mode='I') as writer:\n", "            for i,filename in enumerate(paths):\n", "                # if i % 8 != 0: continue\n", "                img = imageio.imread(filename)\n", "                writer.append_data(img)\n", "            #image = imageio.imread(filename)\n", "            #writer.append_data(image)\n", "    @staticmethod\n", "    def vid_show(path):\n", "        print(\"show anigif\")\n", "        anim_file = path\n", "        cap = cv2.VideoCapture(anim_file)\n", "        ret, frame = cap.read()\n", "        while(1):\n", "            ret, frame = cap.read()\n", "            if (not frame is None):\n", "                cv2.imshow('frame',frame)\n", "                if cv2.waitKey(1) & 0xFF == ord('q') or ret==False :\n", "                    cap.release()\n", "                    cv2.destroyAllWindows()\n", "                    break\n", "                cv2.imshow('frame',frame)\n", "    @staticmethod\n", "    def imgs_to_tiling(imgs, imgpath, qsegs=1, save=True):\n", "        qcells = qsegs * qsegs  # will predict images\n", "        r = []\n", "        for i in range(0, qcells, qsegs): # for each row\n", "            r.append(np.concatenate(imgs[i:i+qsegs], axis = 0)) # concat cols\n", "        c1 = np.concatenate(r, axis = 1)\n", "        c1 = np.clip(c1, 0.0, 1.0)\n", "        x = Image.fromarray(np.uint8(c1*255))\n", "        if save:\n", "            x.save(imgpath)\n", "        return x    \n\n", "    # rolux\n", "    @staticmethod\n", "    def render_video(src_file, dst_dir, tmp_dir, num_frames, mode, size, fps, codec, bitrate):\n", "        import PIL.Image\n", "        import moviepy.editor\n", "        def render_frame(t):\n", "            frame = np.clip(np.ceil(t * fps), 1, num_frames)\n", "            image = PIL.Image.open('%s/video/%08d.png' % (tmp_dir, frame))\n", "            if mode == 1:\n", "                canvas = image\n", "            else:\n", "                canvas = PIL.Image.new('RGB', (2 * src_size, src_size))\n", "                canvas.paste(src_image, (0, 0))\n", "                canvas.paste(image, (src_size, 0))\n", "            if size != src_size:\n", "                canvas = canvas.resize((mode * size, size), PIL.Image.LANCZOS)\n", "            return np.array(canvas)\n", "        src_image = PIL.Image.open(src_file)\n", "        src_size = src_image.size[1]\n", "        duration = num_frames / fps\n", "        filename = os.path.join(dst_dir, os.path.basename(src_file)[:-4] + '.mp4')\n", "        video_clip = moviepy.editor.VideoClip(render_frame, duration=duration)\n", "        video_clip.write_videofile(filename, fps=fps, codec=codec, bitrate=bitrate)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    # dvschultz\n", "    @staticmethod\n", "    def create_mp4(\n", "            src_dir, \n", "            dest_dir, \n", "            steppattern=\"*step*.png\",\n", "            tgtpattern=\"*target*.png\",\n", "            moviename = \"movie.mp4\",\n", "        ):\n\n", "        # Create video \n", "        import glob\n", "        imgspattern = os.path.join(src_dir, steppattern)\n", "        imgs = sorted(glob.glob(imgspattern))\n", "        targetpattern = os.path.join(src_dir, tgtpattern)\n", "        target_imgs = sorted(glob.glob(targetpattern))\n", "        assert len(target_imgs) == 1, \"More than one target found?\"\n", "        target_img = imageio.imread(target_imgs[0])\n", "        \n", "        moviepath = os.path.join(dest_dir, moviename)\n", "        with imageio.get_writer(moviepath, mode='I') as writer:\n", "            for filename in imgs:\n", "                image = imageio.imread(filename)\n", "                # Concatenate images with original target image\n", "                w,h = image.shape[0:2]\n", "                canvas = PIL.Image.new('RGBA', (w*2,h), 'white')\n", "                canvas.paste(Image.fromarray(target_img), (0, 0))\n", "                canvas.paste(Image.fromarray(image), (w, 0))\n", "                writer.append_data(np.array(canvas))\n", "    @staticmethod\n", "    def vid_to_file(\n", "            frame, \n", "            output_img, \n", "            video_output_dir= './',\n", "            frame_content_frmt='frame{}.jpg',\n", "            zfill = 4,\n", "        ):\n", "        print(f\"|---> vid_to_file frame {frame}\")\n", "        fn = frame_content_frmt.format(str(frame).zfill(zfill))\n", "        path = os.path.join(video_output_dir, fn)\n", "        save_cv2(path, output_img)\n", "    @staticmethod\n", "    def frame_cv2_rgb_vgg(frame, frames_dir, args):\n", "        frame_content_frmt = args.frame_content_frmt\n", "        max_size = args.max_size\n", "        zfill = args.zfill\n", "        frame_name = args.frame_content_frmt.format(str(frame).zfill(zfill))\n", "        frame_img_path = os.path.join(frames_dir, frame_name)\n", "        print(\"frame_img_path\", frame_img_path)\n", "        img = cv2.imread(frame_img_path, cv2.IMREAD_COLOR)\n", "        img = onvgg.vgg_preprocess(img)\n", "        # img = onvgg.vgg_deprocess(img)\n", "        # cv2.imshow('img', img)\n", "        # cv2.waitKey(2000)    \n", "        return img\n", "    @staticmethod\n", "    def get_Lucas_Kanade_Optical_Flow(path):\n", "        cap = cv2.VideoCapture(path)\n\n", "        # params for ShiTomasi corner detection\n", "        feature_params = dict( maxCorners = 100,\n", "                            qualityLevel = 0.3,\n", "                            minDistance = 7,\n", "                            blockSize = 7 )\n\n", "        # Parameters for lucas kanade optical flow\n", "        lk_params = dict( winSize  = (15,15),\n", "                        maxLevel = 2,\n", "                        criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n\n", "        # Create some random colors\n", "        color = np.random.randint(0,255,(100,3))\n\n", "        # Take first frame and find corners in it\n", "        ret, old_frame = cap.read()\n", "        old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n", "        p0 = cv2.goodFeaturesToTrack(old_gray, mask = None, **feature_params)\n\n", "        # Create a mask image for drawing purposes\n", "        mask = np.zeros_like(old_frame)\n", "        while(1):\n", "            ret,frame = cap.read()\n", "            frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n\n", "            # calculate optical flow\n", "            p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)\n\n", "            # Select good points\n", "            good_new = p1[st==1]\n", "            good_old = p0[st==1]\n\n", "            # draw the tracks\n", "            for i,(new,old) in enumerate(zip(good_new,good_old)):\n", "                a,b = new.ravel()\n", "                c,d = old.ravel()\n", "                mask = cv2.line(mask, (a,b),(c,d), color[i].tolist(), 2)\n", "                frame = cv2.circle(frame,(a,b),5,color[i].tolist(),-1)\n", "            img = cv2.add(frame,mask)\n", "            cv2.imshow('frame',img)\n", "            k = cv2.waitKey(30) & 0xff\n", "            if k == 27:\n", "                break\n\n", "            # Now update the previous frame and previous points\n", "            old_gray = frame_gray.copy()\n", "            p0 = good_new.reshape(-1,1,2)\n", "        cv2.destroyAllWindows()\n", "        cap.release()\n", "    \n", "    @staticmethod\n", "    def get_dense_Optical_Flow(path):\n", "        cap = cv2.VideoCapture(path)\n", "        ret, frame1 = cap.read()\n", "        prvs = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n", "        hsv = np.zeros_like(frame1)\n", "        hsv[...,1] = 255\n", "        while(1):\n", "            ret, frame2 = cap.read()\n", "            next = cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY)\n", "            flow = cv2.calcOpticalFlowFarneback(prvs,next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n", "            mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])\n", "            hsv[...,0] = ang*180/np.pi/2\n", "            hsv[...,2] = cv2.normalize(mag,None,0,255,cv2.NORM_MINMAX)\n", "            rgb = cv2.cvtColor(hsv,cv2.COLOR_HSV2BGR)\n", "            cv2.imshow('frame2',rgb)\n", "            k = cv2.waitKey(30) & 0xff\n", "            if k == 27:\n", "                break\n", "            elif k == ord('s'):\n", "                cv2.imwrite('opticalfb.png',frame2)\n", "                cv2.imwrite('opticalhsv.png',rgb)\n", "            prvs = next\n", "        cap.release()\n", "        cv2.destroyAllWindows()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["  ******************<br>\n", "   Ondata<br>\n", "  ******************"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class Ondata:\n", "    @staticmethod\n", "    def pil_scale(img, scale=1):\n", "        img.thumbnail((img.size[0]*scale, img.size[1]*scale), Image.LANCZOS) \n", "        return img\n", "    @staticmethod\n", "    def pil_resize(img, ps=(-1, -1)):\n", "        img = img.resize((\n", "            ps[0] if ps[0] > 0 else img.size[0],\n", "            ps[1] if ps[1] > 0 else img.size[1]\n", "            ), Image.ANTIALIAS)\n", "        return img\n", "    @staticmethod\n", "    def resize_tf_hwc(image, width, height):\n", "        # Resized images will be distorted if their original aspect ratio is not the same as size. \n", "        # To avoid distortions see tf.image.resize_with_pad\n", "        image = tf.cast(image, tf.float32)\n", "        image = tf.image.resize(image, (width, height))\n", "        return image\n", "    @staticmethod\n", "    def resize_tf_bhwc(image, width, height):\n", "        Ondata.resize_tf_hwc(image, width, height)\n", "    \n", "    @staticmethod\n", "    def crop_image(img,tol=0):\n", "        # https://www.youtube.com/watch?v=weRmcRzMfUQ\n", "        # https://codereview.stackexchange.com/questions/132914/crop-black-border-of-image-using-numpy\n", "        # https://www.youtube.com/user/bustbright/videos\n", "        # img is 2D or 3D image data\n", "        # tol  is tolerance\n", "        mask = img>tol\n", "        if img.ndim==3:\n", "            mask = mask.all(2)\n", "        mask0,mask1 = mask.any(0),mask.any(1)\n", "        return img[np.ix_(mask0,mask1)]\n", "    @staticmethod\n", "    def crop_img_only_outside(img,tol=0):\n", "        # img is 2D or 3D image data\n", "        # tol  is tolerance\n", "        mask = img>tol\n", "        if img.ndim==3:\n", "            mask = mask.all(2)\n", "        m,n = mask.shape\n", "        mask0,mask1 = mask.any(0),mask.any(1)\n", "        col_start,col_end = mask0.argmax(),n-mask0[::-1].argmax()\n", "        row_start,row_end = mask1.argmax(),m-mask1[::-1].argmax()\n", "        return img[row_start:row_end,col_start:col_end]\n", "    @staticmethod\n", "    def random_crop_with_tf(img, h, w):\n", "        stacked_image = tf.stack([img], axis=0)\n", "        cropped_image = tf.image.random_crop(stacked_image, size=[1, h, w, 3])\n", "        return cropped_image[0]\n", "    @staticmethod\n", "    def resize_with_tf(img, height, width):\n", "        img = tf.image.resize(img, [height, width],\n", "            method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n", "        return img\n", "    @staticmethod\n", "    def img_to_sqr_pils(img, qslices=1, eps = 0.5, clip = (512, 512)):\n", "        newimgs = []\n", "        img_data = np.array(list(img.getdata())).reshape( (img.size[1],img.size[0],-1) ) # y,x\n", "        for n in range(qslices):\n", "            rx = int(( ( img.size[0]-clip[0] ) / 2 ) + eps * np.random.randint( ( img.size[0]-clip[0] ) / 2 )) if img.size[0]> clip[0] + 2 else 0\n", "            ry = int(( ( img.size[1]-clip[1] ) / 2 ) + eps * np.random.randint( ( img.size[1]-clip[0] ) / 2 )) if img.size[1]> clip[1] + 2 else 0\n", "            print(f\"|... img_to_sqr_pils tile {n}: {ry}, {ry+clip[1]}, {rx}, {rx+clip[0]}\")\n", "            sub = np.copy(img_data[ry:ry+clip[1], rx:rx+clip[0]]).astype(np.uint8) # y,x\n", "            sub = sub[:,:,:3]\n\n", "            # append\n", "            newimg = Image.fromarray(sub)\n", "            newimgs.append(newimg)\n", "        return newimgs\n", "    @staticmethod\n", "    def img_to_tiled_pils(img, tile = (512, 512)):\n", "        img_data = np.asarray(img.convert(\"RGB\")).reshape( (img.size[1],img.size[0],-1) )\n", "        shape = np.shape(img_data)\n", "        hb,wb  = shape[0], shape[1]\n", "        hb2,wb2 = int(hb/2), int(wb/2)\n", "        hs, ws = tile[0], tile[1]\n", "        hs2, ws2 = int(hs/2), int(ws/2)\n", "        hr, wr = ((hb2-hs2))/hs, ((wb2-ws2))/ws\n", "        hn, wn = math.floor(hr), math.floor(wr)\n", "        newimgs=[]\n", "        if wn >= 0 and hn >= 0:\n", "            rx = wb2 + (0 - 1) * ws2\n", "            ry = hb2 + (0 - 1) * hs2\n", "            sub = np.copy(img_data[ry:ry+hs, rx:rx+ws]).astype(np.uint8) # y,x\n", "            newimg = Image.fromarray(sub[:,:,:3])\n", "            if 0:\n", "                print(f\"|... img_to_tiled_pils r0 ==> {0}, {0}: {[ry, rx]}: {np.shape(newimg)}\")\n", "            newimgs.append(newimg)\n", "        for i in range(wn+1):\n", "            for j in range(hn+1):\n", "                wi = i\n", "                hi = j\n", "                if wi > 0:\n", "                    # -x-|---\n", "                    rx = wb2 + (-wi - 0) * ws2\n", "                    ry = hb2 + (+hi - 0) * hs2\n", "                    sub = np.copy(img_data[\n", "                                ry:ry+hs, \n", "                                rx:rx+ws\n", "                                ]).astype(np.uint8) # y,x\n", "                    newimg = Image.fromarray(sub[:,:,:3])\n", "                    # pil_show_rgb(newimg)\n", "                    newimgs.append(newimg)\n", "                    if 0:\n", "                        print(f\"|... img_to_tiled_pils r2 ==> {wi}, {hi}: {[ry, rx]}: {np.shape(newimg)}\")\n", "                    # ---|-x-\n", "                    rx = wb2 + (+wi - 0) * ws2\n", "                    ry = hb2 + (+hi - 0) * hs2\n", "                    sub = np.copy(img_data[\n", "                                ry:ry+hs, \n", "                                rx:rx+ws\n", "                                ]).astype(np.uint8) # y,x\n", "                    newimg = Image.fromarray(sub[:,:,:3])\n", "                    # pil_show_rgb(newimg)\n", "                    newimgs.append(newimg)\n", "                    if 0:\n", "                        print(f\"|... img_to_tiled_pils r2 ==> {wi}, {hi}: {[ry, rx]}: {np.shape(newimg)}\")\n", "                if hi > 0:\n", "                    #  ---^\n", "                    rx = wb2 + (+wi - 0) * ws2\n", "                    ry = hb2 + (-hi - 0) * hs2 \n", "                    sub = np.copy(img_data[\n", "                                ry:ry+hs, \n", "                                rx:rx+ws\n", "                                ]).astype(np.uint8) # y,x\n", "                    newimg = Image.fromarray(sub[:,:,:3])\n", "                    # pil_show_rgb(newimg)\n", "                    if 0:\n", "                        print(f\" r3 ==> {wi}, {hi}: {[ry, rx]}: {np.shape(newimg)}\")\n", "                    newimgs.append(newimg)\n", "                    #  ---_\n", "                    rx = wb2 + (+wi - 0) * ws2\n", "                    ry = hb2 + (+hi - 0) * hs2 \n", "                    sub = np.copy(img_data[\n", "                                ry:ry+hs, \n", "                                rx:rx+ws\n", "                                ]).astype(np.uint8) # y,x\n", "                    newimg = Image.fromarray(sub[:,:,:3])\n", "                    # pil_show_rgb(newimg)\n", "                    if 0:\n", "                        print(f\"|... img_to_tiled_pils r3 ==> {wi}, {hi}: {[ry, rx]}: {np.shape(newimg)}\")\n", "                    newimgs.append(newimg)\n", "                if wi > 0 and hi > 0:\n", "                    rx = wb2 + (-wi - 0) * ws2\n", "                    ry = hb2 + (-hi - 0) * hs2 \n", "                    sub = np.copy(img_data[\n", "                                ry:ry+hs, \n", "                                rx:rx+ws\n", "                                ]).astype(np.uint8) # y,x\n", "                    newimg = Image.fromarray(sub[:,:,:3])\n", "                    if 0:\n", "                        print(f\"|... img_to_tiled_pils r4 ==> {wi}, {hi}: {[ry, rx]}: {np.shape(newimg)}\")\n", "                    # pil_show_rgb(newimg)\n", "                    newimgs.append(newimg)\n", "        print(f\"|... img_to_tiled_pils new imgs q: {len(newimgs)}\")\n", "        return newimgs\n", "    @staticmethod\n", "    def random_jitter(img, throughsize=(286, 286), tosize=(256, 256)):\n", "        # resizing to 286 x 286 x 3\n", "        img = Ondata.resize_with_tf(img, throughsize[0], throughsize[1])\n\n", "        # randomly cropping to 256 x 256 x 3\n", "        img = Ondata.random_crop_with_tf(img, tosize[0], tosize[1])\n", "        if np.random.uniform(()) > 0.5: # tf _e_\n", "            # random mirroring\n", "            img = tf.image.flip_left_right(img)\n", "            real_image = tf.image.flip_left_right(real_image)\n", "        \n", "        return img\n", "    @staticmethod\n", "    def folder_to_formed_rgbs(\n", "        src_dir,\n", "        qimgs = -1,          # number of images to get from src\n", "        scale = 1,          # will scale by scale\n", "        ps = (-1, -1),      # will resize images if sizes in N\n", "        qslices = 1,         # will generte slices per images\n", "        eps = 0.0,          # will deviate from the center of th image\n", "        clip = (512, 512),  # will generate slices of clip size   \n", "    ):\n", "        imgs = Ondata.folder_to_formed_pils(src_dir,qimgs,scale,ps,qslices,eps,clip)\n", "        arrs = [np.array(img) for img in imgs]\n", "        return arrs\n", "    @staticmethod\n", "    def folder_to_formed_nuas(\n", "        src_dir,\n", "        qimgs = -1,          # number of images to get from src\n", "        scale = 1,          # will scale by scale\n", "        ps = (-1, -1),      # will resize images if sizes in N\n", "        qslices = 1,         # will generte slices per images\n", "        eps = 0.0,          # will deviate from the center of th image\n", "        clip = (512, 512),  # will generate slices of clip size   \n", "    ):\n", "        rgbs = Ondata.folder_to_formed_rgbs(src_dir,qimgs,scale,ps,qslices,eps,clip)\n", "        narrs = [rgb / 255 for rgb in rgbs]\n", "        return narrs\n", "    @staticmethod\n", "    def folder_to_formed_pils(\n", "        src_dir,\n", "        qimgs = -1,         # number of images to get from src\n", "        scale = 1,          # will scale by scale\n", "        ps = (-1, -1),      # will resize images if sizes in N\n", "        qslices = 1,        # will generte slices per images\n", "        eps = 0.0,          # will deviate from the center of th image\n", "        clip = (512, 512),  # will generate slices of clip size   \n", "    ):\n", "        assert os.path.exists(src_dir), \"src_dir does not exist\"\n", "        newimgs = []\n", "        items = Onfile.folder_to_pils(src_dir, qimgs)\n", "        for i,img in enumerate(items):\n", "            img = Ondata.pil_scale(img, scale)\n", "            print(f\"|... folder_to_formed_pils after-scale img shape: {np.shape(img)}\")\n", "            img = Ondata.pil_resize(img, ps)\n", "            print(f\"|... folder_to_formed_pils alter-resize img shape: {np.shape(img)}\")\n", "            tiledimgs = Ondata.img_to_sqr_pils(img,qslices,eps,clip)\n", "            newimgs += tiledimgs\n", "        return newimgs\n", "    @staticmethod\n", "    def path_to_formed_pair(path, dim=512, do_crop=False, canny_thresh1=100, canny_thresh2=200):\n", "        # https://github.com/memo/webcam-pix2pix-tensorflow/blob/master/preprocess.py\n", "        print(f'|... path_to_formed_pair {path}')\n", "        out_shape = (dim, dim)\n", "        im = PIL.Image.open(path)\n", "        im = im.convert('RGB')\n", "        if do_crop:\n", "            resize_shape = list(out_shape)\n", "            if im.width < im.height:\n", "                resize_shape[1] = int(round(float(im.height) / im.width * dim))\n", "            else:\n", "                resize_shape[0] = int(round(float(im.width) / im.height * dim))\n", "            im = im.resize(resize_shape, PIL.Image.BICUBIC)\n", "            hw = int(im.width / 2)\n", "            hh = int(im.height / 2)\n", "            hd = int(dim/2)\n", "            area = (hw-hd, hh-hd, hw+hd, hh+hd)\n", "            im = im.crop(area)            \n", "                \n", "        else:\n", "            im = im.resize(out_shape, PIL.Image.BICUBIC)\n", "            \n", "        a1 = np.array(im) \n", "        a2 = cv2.Canny(a1, canny_thresh1, canny_thresh2)\n", "        a2 = cv2.cvtColor(a2, cv2.COLOR_GRAY2RGB)                 \n", "        a3 = np.concatenate((a1,a2), axis=1)\n", "        im = PIL.Image.fromarray(a3)                     \n", "                        \n", "        # im.save(os.path.join(out_path, out_fname))\n", "        # print(f\"save {os.path.join(out_path, out_fname)})\n", "        return im"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    @staticmethod\n", "    def path_to_formed_pil(path, dim=None, do_crop=False):\n", "        # https://github.com/memo/webcam-pix2pix-tensorflow/blob/master/preprocess.py\n", "        if 0: print(f'|... path_to_formed_pil {path}')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        im = PIL.Image.open(path)\n", "        im = im.convert('RGB')\n", "        if do_crop:\n", "            assert dim, \"dim must be defined\"\n", "            resize_shape = list((dim, dim))\n", "            if im.width < im.height:\n", "                resize_shape[1] = int(round(float(im.height) / im.width * dim))\n", "            else:\n", "                resize_shape[0] = int(round(float(im.width) / im.height * dim))\n", "            im = im.resize(resize_shape, PIL.Image.BICUBIC)\n", "            hw = int(im.width / 2)\n", "            hh = int(im.height / 2)\n", "            hd = int(dim/2)\n", "            area = (hw-hd, hh-hd, hw+hd, hh+hd)\n", "            im = im.crop(area)            \n", "                \n", "        elif dim:\n", "            out_shape = (dim, dim)\n", "            im = im.resize(out_shape, PIL.Image.BICUBIC)\n", "            \n", "        return im\n", "    @staticmethod\n", "    def folder_to_formed_data(\n", "        src_dir,\n", "        dest_dir,\n", "        qimgs = -1,         # number of images to get from src\n", "        scale = 1,          # will scale by scale\n", "        ps = (-1, -1),      # will resize images if sizes in N\n", "        qslices = 2,        # will generte slices per images\n", "        eps = 0.5,          # will deviate from the center of th image\n", "        clip = (512, 512),  # will generate slices of clip size   \n", "        img_format = 'img{}.jpg', zfill=4,\n", "        verbose=False\n", "    ):\n", "        assert os.path.exists(src_dir), \"src_dir does not exist\"\n", "        newimgs = []\n", "        imgs = []\n", "        jpgs = glob.glob(os.path.join(src_dir, \"*.jpg\"))\n", "        pngs = glob.glob(os.path.join(src_dir, \"*.png\"))\n", "        fs = jpgs + pngs  # <class 'list'>\n", "        newimgidx = 0\n", "        for i,f in enumerate(fs):\n", "            if (qimgs<0 or i<qimgs):\n", "                img = Image.open(f)\n", "                img = Ondata.pil_scale(img, scale)\n", "                img = Ondata.pil_resize(img, ps)\n", "                if verbose:\n", "                    print(f\"folder_to_formed_pils alter-resize img shape: {np.shape(img)}\")\n", "                tiledimgs = Ondata.img_to_sqr_pils(img,qslices,eps,clip)\n", "                for newimg in tiledimgs:\n", "                    img_name = img_format.format(str(newimgidx).zfill(zfill))                \n", "                    outpath = os.path.join(dest_dir, img_name)\n", "                    if verbose:\n", "                        print(f\"save image {newimgidx} to {outpath}\")\n", "                    newimg.save(outpath, 'JPEG', quality=90) \n", "                    newimgidx = newimgidx + 1\n", "    @staticmethod\n", "    def downsample(filters, size, apply_batchnorm=True):\n", "        initializer = tf.random_normal_initializer(0., 0.02)\n", "        result = tf.keras.Sequential()\n", "        result.add(\n", "            tf.keras.layers.Conv2D(filters, size, strides=2, padding='same',\n", "                kernel_initializer=initializer, use_bias=False))\n", "        if apply_batchnorm:\n", "            result.add(tf.keras.layers.BatchNormalization())\n", "        result.add(tf.keras.layers.LeakyReLU())\n", "        return result\n", "    @staticmethod\n", "    def upsample(filters, size, apply_dropout=False):\n", "        initializer = tf.random_normal_initializer(0., 0.02)\n", "        result = tf.keras.Sequential()\n", "        result.add(\n", "            tf.keras.layers.Conv2DTranspose(filters, \n", "                size, \n", "                strides=2,\n", "                padding='same',\n", "                kernel_initializer=initializer,\n", "                use_bias=False))\n", "        result.add(tf.keras.layers.BatchNormalization())\n", "        if apply_dropout:\n", "            result.add(tf.keras.layers.Dropout(0.5))\n", "        result.add(tf.keras.layers.ReLU())\n", "        return result\n", "    @staticmethod\n", "    def rgbs_to_nuas_batch(imgs, num, flip = True):\n", "        idx = np.random.randint(0, imgs.shape[0] - 1, num)\n", "        out = []\n", "        for i in idx:\n", "            out.append(imgs[i])\n", "            if flip and np.random.uniform(()) < 0.5:  # flip as arg\n", "                out[-1] = np.flip(out[-1], 1)\n", "        return np.array(out).astype('float32') / 255.0"]}, {"cell_type": "markdown", "metadata": {}, "source": ["  *******************<br>\n", "  ONSET<br>\n", "<br>\n", "  *******************"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class Onset:\n", "# https://github.com/dvschultz/dataset-tools\n", "# dataset-tools/dataset-tools.py\n", "    @staticmethod\n", "    def image_resize(image, width = None, height = None, max = None):\n", "        inter = cv2.INTER_CUBIC\n\n", "        # initialize the dimensions of the image to be resized and\n", "        # grab the image size\n", "        dim = None\n", "        (h, w) = image.shape[:2]\n", "        if max is not None:\n", "            if w > h:\n", "                # produce\n", "                r = max / float(w)\n", "                dim = (max, int(h * r))\n", "            elif h > w:\n", "                r = max / float(h)\n", "                dim = (int(w * r), max)\n", "            else :\n", "                dim = (max, max)\n", "        else: \n", "            # if both the width and height are None, then return the\n", "            # original image\n", "            if width is None and height is None:\n", "                return image\n\n", "            # check to see if the width is None\n", "            if width is None:\n", "                # calculate the ratio of the height and construct the\n", "                # dimensions\n", "                r = height / float(h)\n", "                dim = (int(w * r), height)\n\n", "            # otherwise, the height is None\n", "            else:\n", "                # calculate the ratio of the width and construct the\n", "                # dimensions\n", "                r = width / float(w)\n", "                dim = (width, int(h * r))\n\n", "        # resize the image\n", "        resized = cv2.resize(image, dim, interpolation = inter)\n\n", "        # return the resized image\n", "        return resized\n", "    @staticmethod\n", "    def image_scale(image, scalar = 1.0):\n", "        (h, w) = image.shape[:2]\n", "        dim = (int(w*scalar),int(h*scalar))\n", "        # resize the image\n", "        resized = cv2.resize(image, dim, interpolation = inter)\n", "        \n", "        # return the resized image\n", "        return resized\n", "    @staticmethod\n", "    def arbitrary_crop(img, h_crop,w_crop, args=None):\n", "        error = False\n", "        bType = cv2.BORDER_REPLICATE\n", "        if(args.border_type == 'solid'):\n", "            bType = cv2.BORDER_CONSTANT\n", "        elif (args.border_type == 'reflect'):\n", "            bType = cv2.BORDER_REFLECT\n", "        (h, w) = img.shape[:2]\n", "        if(h>h_crop):\n", "            hdiff = int((h-h_crop)/2) + args.shift_y\n", "            if( ((hdiff+h_crop) > h) or (hdiff < 0)):\n", "                print(\"error! crop settings are too much for this image\")\n", "                error = True\n", "            else:\n", "                img = img[hdiff:hdiff+h_crop,0:w]\n", "        if(w>w_crop):\n", "            wdiff = int((w-w_crop)/2) + args.shift_x\n", "            \n", "            if( ((wdiff+w_crop) > w) or (wdiff < 0) ):\n", "                print(\"error! crop settings are too much for this image\")\n", "                error = True\n", "            else:\n", "                img = img[0:h_crop,wdiff:wdiff+w_crop]\n", "        return img, error\n", "    @staticmethod\n", "    def crop_to_square(img, args=None):\n", "        (h, w) = img.shape[:2]\n", "        \n", "        cropped = img.copy()\n", "        if w > h:\t\n", "            if (args.h_align=='left'):\n", "                print('here first')\n", "                cropped = img[:h,:h]\n", "            elif (args.h_align=='right'):\n", "                cropped = img[0:h, w-h:w]\n", "            else:\n", "                diff = int((w-h)/2)\n", "                cropped = img[0:h, diff:diff+h]\n", "        elif h > w:\n", "            if (args.v_align=='top'):\n", "                cropped = img[:w, :w]\n", "            elif (args.v_align=='bottom'):\n", "                cropped = img[h-w:h, 0:w]\n", "            else:\n", "                diff = int((h-w)/2)\n", "                cropped = img[diff:diff+w, 0:w]\n", "            \n", "        return cropped\n", "    @staticmethod\n", "    def crop_square_patch(img, imgSize):\n", "        (h, w) = img.shape[:2]\n", "        rH = random.randint(0,h-imgSize)\n", "        rW = random.randint(0,w-imgSize)\n", "        cropped = img[rH:rH+imgSize,rW:rW+imgSize]\n", "        return cropped\n", "    @staticmethod\n", "    def processCanny(img, args=None):\n", "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n", "        \n", "        if(args.blur_type=='gaussian'):\n", "            gray = cv2.GaussianBlur(gray, (args.blur_amount, args.blur_amount), 0)\n", "        elif(args.blur_type=='median'):\n", "            gray = cv2.medianBlur(gray,args.blur_amount)\n", "        gray = cv2.Canny(gray,100,300)\n", "        return gray\n", "    @staticmethod\n", "    def makeResize(img,filename,scale, args=None):\n", "        remakePath = args.output_folder + str(scale)+\"/\"\n", "        if(args.keep_folder==True): remakePath = args.output_folder\n", "        if not os.path.exists(remakePath):\n", "            os.makedirs(remakePath)\n", "        img_copy = img.copy()\n", "        img_copy = Onset.image_resize(img_copy, max = scale)\n", "        if(args.file_extension == \"png\"):\n", "            new_file = os.path.splitext(filename)[0] + \".png\"\n", "            cv2.imwrite(os.path.join(remakePath, new_file), img_copy, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n", "        elif(args.file_extension == \"jpg\"):\n", "            new_file = os.path.splitext(filename)[0] + \".jpg\"\n", "            cv2.imwrite(os.path.join(remakePath, new_file), img_copy, [cv2.IMWRITE_JPEG_QUALITY, 90])\n", "        if (args.mirror): Onset.flipImage(img_copy,new_file,remakePath, args)\n", "        if (args.rotate): Onset.rotateImage(img_copy,new_file,remakePath, args)\n", "    @staticmethod\n", "    def makeDistance(img,filename,scale, args=None):\n", "        makePath = args.output_folder + \"distance-\"+ str(args.max_size)+\"/\"\n", "        if(args.keep_folder==True): makePath = args.output_folder\n", "        if not os.path.exists(makePath):\n", "            os.makedirs(makePath)\n", "        img_copy = img.copy()\n", "        img_copy = Onset.image_resize(img_copy, max = scale)\n", "        BW = img_copy[:,:,0] > 127\n", "        G_channel = pyimg.distance_transform_edt(BW)\n", "        G_channel[G_channel>32]=32\n", "        B_channel = pyimg.distance_transform_edt(1-BW)\n", "        B_channel[B_channel>200]=200\n", "        img_copy[:,:,1] = G_channel.astype('uint8')\n", "        img_copy[:,:,0] = B_channel.astype('uint8')\n", "        if(args.file_extension == \"png\"):\n", "            new_file = os.path.splitext(filename)[0] + \".png\"\n", "            cv2.imwrite(os.path.join(makePath, new_file), img_copy, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n", "        elif(args.file_extension == \"jpg\"):\n", "            new_file = os.path.splitext(filename)[0] + \".jpg\"\n", "            cv2.imwrite(os.path.join(makePath, new_file), img_copy, [cv2.IMWRITE_JPEG_QUALITY, 90])\n", "        if (args.mirror): Onset.flipImage(img_copy,new_file,makePath)\n", "        if (args.rotate): Onset.rotateImage(img_copy,new_file,makePath)\n", "    @staticmethod\n", "    def makeScale(img,filename,scale, args=None):\n", "        remakePath = args.output_folder + \"scale_\"+str(scale)+\"/\"\n", "        if(args.keep_folder==True): remakePath = args.output_folder\n", "        if not os.path.exists(remakePath):\n", "            os.makedirs(remakePath)\n", "        img_copy = img.copy()\n", "        \n", "        img_copy = image_scale(img_copy, scale)\n", "        new_file = os.path.splitext(filename)[0] + \".png\"\n", "        cv2.imwrite(os.path.join(remakePath, new_file), img_copy, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n", "        if (args.mirror): Onset.flipImage(img_copy,new_file,remakePath)\n", "        if (args.rotate): Onset.rotateImage(img_copy,new_file,remakePath)\n", "    @staticmethod\n", "    def makeSquare(img,filename,scale, args=None):\n", "        sqPath = args.output_folder + \"sq-\"+str(scale)+\"/\"\n", "        if(args.keep_folder==True): sqPath = args.output_folder\n", "        if not os.path.exists(sqPath):\n", "            os.makedirs(sqPath)\n", "        bType = cv2.BORDER_REPLICATE\n", "        if(args.border_type == 'solid'):\n", "            bType = cv2.BORDER_CONSTANT\n", "        elif (args.border_type == 'reflect'):\n", "            bType = cv2.BORDER_REFLECT\n", "        img_sq = img.copy()\n", "        (h, w) = img_sq.shape[:2]\n", "        if((h < scale) and (w < scale)):\n", "            if args.verbose > 1: print('skip resize')\n", "        else:\n", "            img_sq = Onset.image_resize(img_sq, max = scale)\n", "        bColor = [int(item) for item in args.border_color.split(',')]\n", "        (h, w) = img_sq.shape[:2]\n", "        if(h > w):\n", "            # pad left/right\n", "            diff = h-w\n", "            if(diff%2 == 0):\n", "                img_sq = cv2.copyMakeBorder(img_sq, 0, 0, int(diff/2), int(diff/2), bType,value=bColor)\n", "            else:\n", "                img_sq = cv2.copyMakeBorder(img_sq, 0, 0, int(diff/2)+1, int(diff/2), bType,value=bColor)\n", "        elif(w > h):\n", "            # pad top/bottom\n", "            diff = w-h\n", "            if(diff%2 == 0):\n", "                img_sq = cv2.copyMakeBorder(img_sq, int(diff/2), int(diff/2), 0, 0, bType,value=bColor)\n", "            else:\n", "                img_sq = cv2.copyMakeBorder(img_sq, int(diff/2), int(diff/2)+1, 0, 0, bType,value=bColor)\n", "        else:\n", "            diff = scale-h\n", "            if(diff%2 == 0):\n", "                img_sq = cv2.copyMakeBorder(img_sq, int(diff/2), int(diff/2), int(diff/2), int(diff/2), bType,value=bColor)\n", "            else:\n", "                img_sq = cv2.copyMakeBorder(img_sq, int(diff/2), int(diff/2)+1, int(diff/2), int(diff/2)+1, bType,value=bColor)\n", "        if(args.file_extension == \"png\"):\n", "            new_file = os.path.splitext(filename)[0] + \".png\"\n", "            cv2.imwrite(os.path.join(sqPath, new_file), img_sq, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n", "        elif(args.file_extension == \"jpg\"):\n", "            new_file = os.path.splitext(filename)[0] + \".jpg\"\n", "            cv2.imwrite(os.path.join(sqPath, new_file), img_sq, [cv2.IMWRITE_JPEG_QUALITY, 90])\n", "        if (args.mirror): Onset.flipImage(img_sq,new_file,sqPath,args)\n", "        if (args.rotate): Onset.rotateImage(img_sq,new_file,sqPath,args)\n", "    @staticmethod        \n", "    def makeCanny(img,filename,scale, args=None):\n", "        make_path = args.output_folder + \"canny-\"+str(scale)+\"/\"\n", "        if(args.keep_folder==True): make_path = args.output_folder\n", "        if not os.path.exists(make_path):\n", "            os.makedirs(make_path)\n", "        img_copy = img.copy()\n", "        img_copy = Onset.image_resize(img_copy, max = scale)\n", "        gray = Onset.processCanny(img_copy, args)\n\n", "        # save out\n", "        if(args.file_extension == \"png\"):\n", "            new_file = os.path.splitext(filename)[0] + \".png\"\n", "            cv2.imwrite(os.path.join(make_path, new_file), gray, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n", "        elif(args.file_extension == \"jpg\"):\n", "            new_file = os.path.splitext(filename)[0] + \".jpg\"\n", "            cv2.imwrite(os.path.join(make_path, new_file), gray, [cv2.IMWRITE_JPEG_QUALITY, 90])\n", "        if (args.mirror): Onset.flipImage(img_copy,new_file,make_path,args)\n", "        if (args.rotate): Onset.rotateImage(img_copy,new_file,make_path,args)\n", "    @staticmethod\n", "    def makeCrop(img,filename, args=None):\n", "        make_path = args.output_folder + \"crop-\"+str(args.height)+\"x\"+str(args.width)+\"/\"\n", "        if(args.keep_folder==True): make_path = args.output_folder\n", "            \n", "        if not os.path.exists(make_path):\n", "            os.makedirs(make_path)\n", "        img_copy = img.copy()\n", "        img_copy,error = arbitrary_crop(img_copy,args.height,args.width)\n", "        if (error==False):\n", "            if(args.file_extension == \"png\"):\n", "                new_file = os.path.splitext(filename)[0] + \".png\"\n", "                cv2.imwrite(os.path.join(make_path, new_file), img_copy, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n", "            elif(args.file_extension == \"jpg\"):\n", "                new_file = os.path.splitext(filename)[0] + \".jpg\"\n", "                cv2.imwrite(os.path.join(make_path, new_file), img_copy, [cv2.IMWRITE_JPEG_QUALITY, 90])\n", "            if (args.mirror): Onset.flipImage(img_copy,new_file,make_path,args)\n", "            if (args.rotate): Onset.rotateImage(img_copy,new_file,make_path,args)\n", "        else:\n", "            if(args.verbose): print(filename+\" returned an error\")\n", "    @staticmethod\n", "    def makeSquareCrop(img,filename,scale, args=None):\n", "        make_path = args.output_folder + \"sq-\"+str(scale)+\"/\"\n", "        if(args.keep_folder==True): make_path = args.output_folder    \n", "        if not os.path.exists(make_path):\n", "            os.makedirs(make_path)\n", "        img_copy = img.copy()\n", "        img_copy = Onset.crop_to_square(img_copy, args)\n", "        img_copy = Onset.image_resize(img_copy, max = scale)\n", "        if(args.file_extension == \"png\"):\n", "            new_file = os.path.splitext(filename)[0] + \".png\"\n", "            cv2.imwrite(os.path.join(make_path, new_file), img_copy, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n", "        elif(args.file_extension == \"jpg\"):\n", "            new_file = os.path.splitext(filename)[0] + \".jpg\"\n", "            cv2.imwrite(os.path.join(make_path, new_file), img_copy, [cv2.IMWRITE_JPEG_QUALITY, 90])\n", "        if (args.mirror): Onset.flipImage(img_copy,new_file,make_path,args)\n", "        if (args.rotate): Onset.rotateImage(img_copy,new_file,make_path,args)\n", "    @staticmethod\n", "    def makeManySquares(img,filename,scale,args=None):\n", "        make_path = args.output_folder + \"many_squares-\"+str(scale)+\"/\"\n", "        if(args.keep_folder==True): make_path = args.output_folder    \n", "        if not os.path.exists(make_path):\n", "            os.makedirs(make_path)\n", "        img_copy = img.copy()\n", "        (h, w) = img_copy.shape[:2]\n", "        img_ratio = h/w\n", "        if(img_ratio >= 1.25):\n\n", "            #crop images from top and bottom\n", "            crop = img_copy[0:w,0:w]\n", "            crop = Onset.image_resize(crop, max = scale)\n", "            new_file = os.path.splitext(filename)[0] + \"-1.png\"\n", "            cv2.imwrite(os.path.join(make_path, new_file), crop, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n", "            if (args.mirror): Onset.flipImage(crop,new_file,make_path,args)\n", "            if (args.rotate): Onset.rotateImage(crop,filename,make_path,args)\n", "            crop = img_copy[h-w:h,0:w]\n", "            crop = Onset.image_resize(crop, max = scale)\n", "            new_file = os.path.splitext(filename)[0] + \"-2.png\"\n", "            cv2.imwrite(os.path.join(make_path, new_file), crop, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n", "            if (args.mirror): Onset.flipImage(crop,new_file,make_path,args)\n", "            if (args.rotate): Onset.rotateImage(crop,filename,make_path,args)\n", "        elif(img_ratio <= .8):\n", "            #crop images from left and right\n", "            print(os.path.splitext(filename)[0] + ': wide image')\n", "            crop = img_copy[0:h,0:h]\n", "            crop = Onset.image_resize(crop, max = scale)\n", "            new_file = os.path.splitext(filename)[0] + \"-wide1.png\"\n", "            cv2.imwrite(os.path.join(make_path, new_file), crop, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n", "            if (args.mirror): Onset.flipImage(crop,new_file,make_path)\n", "            if (args.rotate): Onset.rotateImage(crop,filename,make_path)\n", "            crop = img_copy[0:h,w-h:w]\n", "            crop = Onset.image_resize(crop, max = scale)\n", "            new_file = os.path.splitext(filename)[0] + \"-wide2.png\"\n", "            cv2.imwrite(os.path.join(make_path, new_file), crop, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n", "            if (args.mirror): Onset.flipImage(crop,new_file,make_path)\n", "            if (args.rotate): Onset.rotateImage(crop,filename,make_path)\n", "        else:\n", "            img_copy = Onset.crop_to_square(img_copy, args)\n", "            img_copy = Onset.image_resize(img_copy, max = scale)\n", "            new_file = os.path.splitext(filename)[0] + \".png\"\n", "            cv2.imwrite(os.path.join(make_path, new_file), img_copy, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n", "            if (args.mirror): Onset.flipImage(img_copy,new_file,make_path)\n", "            if(args.rotate): Onset.rotateImage(img_copy,filename,make_path)\n", "            \n", "    @staticmethod\n", "    def makeSquareCropPatch(img,filename,scale,args=None):\n", "        make_path = args.output_folder + \"sq-\"+str(scale)+\"/\"\n", "        if(args.keep_folder==True): make_path = args.output_folder    \n", "        if not os.path.exists(make_path):\n", "            os.makedirs(make_path)\n", "        img_copy = img.copy()\n", "        img_copy = crop_square_patch(img_copy,args.max_size)\n", "        new_file = os.path.splitext(filename)[0] + \".png\"\n", "        cv2.imwrite(os.path.join(make_path, new_file), img_copy, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n", "        if (args.mirror): Onset.flipImage(img_copy,new_file,make_path,args)\n", "        if (args.rotate): Onset.rotateImage(img_copy,new_file,make_path,args)\n", "    @staticmethod\n", "    def makePix2Pix(img,filename,scale,direction=\"BtoA\",value=[0,0,0],args=None):\n", "        img_p2p = img.copy()\n", "        img_p2p = Onset.image_resize(img_p2p, max = scale)\n", "        (h, w) = img_p2p.shape[:2]\n", "        bType = cv2.BORDER_CONSTANT\n", "        \n", "        make_path = args.output_folder + \"pix2pix-\"+str(h)+\"/\"\n", "        if(args.keep_folder==True): make_path = args.output_folder    \n", "        if not os.path.exists(make_path):\n", "            os.makedirs(make_path)\n", "        canny = cv2.cvtColor(Onset.processCanny(img_p2p,args),cv2.COLOR_GRAY2RGB)\n", "        \n", "        if(direction==\"BtoA\"):\n", "            img_p2p = cv2.copyMakeBorder(img_p2p, 0, 0, w, 0, bType, None, value)\n", "            img_p2p[0:h,0:w] = canny\n", "        \n", "        if(args.file_extension == \"png\"):\n", "            new_file = os.path.splitext(filename)[0] + \".png\"\n", "            cv2.imwrite(os.path.join(make_path, new_file), img_p2p, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n", "        elif(args.file_extension == \"jpg\"):\n", "            new_file = os.path.splitext(filename)[0] + \".jpg\"\n", "            cv2.imwrite(os.path.join(make_path, new_file), img_p2p, [cv2.IMWRITE_JPEG_QUALITY, 90])\n", "    @staticmethod\n", "    def flipImage(img,filename,path,args=None):\n", "        flip_img = cv2.flip(img, 1)\n", "        flip_file = os.path.splitext(filename)[0] + \"-flipped.png\"\n", "        cv2.imwrite(os.path.join(path, flip_file), flip_img, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n", "    @staticmethod\n", "    def rotateImage(img,filename,path, args=None):\n", "        r = img.copy() \n", "        r = imutils.rotate_bound(r, 90)\n", "        if(args.file_extension == \"png\"):\n", "            r_file = os.path.splitext(filename)[0] + \"-rot90.png\"\n", "            cv2.imwrite(os.path.join(path, r_file), r, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n", "        elif(args.file_extension == \"jpg\"):\n", "            r_file = os.path.splitext(filename)[0] + \"-rot90.jpg\"\n", "            cv2.imwrite(os.path.join(path, r_file), r, [cv2.IMWRITE_JPEG_QUALITY, 90])\n", "        r = imutils.rotate_bound(r, 90)\n", "        if(args.file_extension == \"png\"):\n", "            r_file = os.path.splitext(filename)[0] + \"-rot180.png\"\n", "            cv2.imwrite(os.path.join(path, r_file), r, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n", "        elif(args.file_extension == \"jpg\"):\n", "            r_file = os.path.splitext(filename)[0] + \"-rot180.jpg\"\n", "            cv2.imwrite(os.path.join(path, r_file), r, [cv2.IMWRITE_JPEG_QUALITY, 90])\n", "        r = imutils.rotate_bound(r, 90)\n", "        if(args.file_extension == \"png\"):\n", "            r_file = os.path.splitext(filename)[0] + \"-rot270.png\"\n", "            cv2.imwrite(os.path.join(path, r_file), r, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n", "        elif(args.file_extension == \"jpg\"):\n", "            r_file = os.path.splitext(filename)[0] + \"-rot270.jpg\"\n", "            cv2.imwrite(os.path.join(path, r_file), r, [cv2.IMWRITE_JPEG_QUALITY, 90])\n", "    @staticmethod\n", "    def processImage(img,filename, args=None):\n", "        if args.process_type == \"resize\":\t\n", "            Onset.makeResize(img,filename,args.max_size, args)\n", "        if args.process_type == \"resize_pad\":\t\n", "            Onset.makeResizePad(img,filename,args.max_size, args)\n", "        if args.process_type == \"square\":\n", "            Onset.makeSquare(img,filename,args.max_size, args)\n", "        if args.process_type == \"crop_to_square\":\n", "            Onset.makeSquareCrop(img,filename,args.max_size, args)\n", "        if args.process_type == \"canny\":\n", "            Onset.makeCanny(img,filename,args.max_size, args)\n", "        if args.process_type == \"canny-pix2pix\":\n", "            Onset.makePix2Pix(img,filename,args.max_size, args=args)\n", "        if args.process_type == \"crop_square_patch\":\n", "            Onset.makeSquareCropPatch(img,filename,args.max_size, args)\n", "        if args.process_type == \"scale\":\n", "            Onset.makeScale(img,filename,args.scale, args)\n", "        if args.process_type == \"many_squares\":\n", "            Onset.makeManySquares(img,filename,args.max_size, args)\n", "        if args.process_type == \"crop\":\n", "            Onset.makeCrop(img,filename, args)\n", "        if args.process_type == \"distance\":\n", "            Onset.makeDistance(img,filename,args.max_size, args)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    @staticmethod\n", "    def processFolder(args=None):\n", "        count = int(0)\n", "        inter = cv2.INTER_CUBIC\n", "        ''' filter files '''\n", "        patt = re.compile(\".*\")\n", "        try:\n", "            if args.filepatt:\n", "                patt = re.compile(args.filepatt)\t# file name pattern\n", "        except:\n", "            pass"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        for root, subdirs, files in os.walk(args.input_folder):\n", "            if args.verbose > 0: print(f'processFolder {root}')\n", "            for subdir in subdirs:\n", "                if(args.verbose): print('\\t- subdirectory ' + subdir)\n", "            exclude = []\n", "            try:\n", "                exclude = args.exclude\n", "            except:\n", "                pass\n", "            if 0: print(f\"|.... exclude {exclude}\")\n", "            for filename in files:\n", "                if patt.match(filename) and not filename in exclude: # file name pattern mach\n", "                    if 0: print(f\"|.... filename {filename} not in exclude\")\n", "                    file_path = os.path.join(root, filename)\n", "                    if args.verbose > 0: print('\\t- file %s (full path: %s)' % (filename, file_path))\n", "                    \n", "                    img = cv2.imread(file_path)\n", "                    if hasattr(img, 'copy'):\n", "                        if args.name:\n", "                            if args.verbose > 1: \n", "                                print(f'|... processing image name: {filename}')\n", "                            Onset.processImage(img,filename, args)\n", "                        else:\n", "                            if args.verbose > 1: \n", "                                print(f'|... processing image idx: {str(count)}')\n", "                            zfill=0\n", "                            try:\n", "                                zfill = args.zfill\n", "                            except:\n", "                                pass\n", "                            Onset.processImage(img,str(count).zfill(zfill), args)\n", "                        count = count + int(1)\n", "                else:\n", "                    if 0: print(f\"|.... filename {filename} EXCLUDED\")\n\n", "    # https://github.com/dvschultz/dataset-tools/dedupe.py\n\n", "        # input_folder = './input/'\n", "        # output_folder = './output/'\n", "        # process_type = 'exclude'\n", "        # file_extension = 'png'\n", "        # avg_match = 1.0\n\n", "        # absolute = True\n", "        # relative = True\n", "    @staticmethod\n", "    def compare(img1,img2, args=None):\n", "        test = False\n", "        difference = cv2.absdiff(img1, img2)\n", "        if(args.absolute):\t\n", "            return not np.any(difference)\n", "        else:\n", "            return np.divide(np.sum(difference),img1.shape[0]*img1.shape[1]) <= args.avg_match\n\n", "            #way too greedy\n", "            #return np.allclose(img1,img2,2,2)\n", "    @staticmethod\n", "    def exclude(imgs,args=None):\n", "        expath = args.output_folder + \"exclude/\"\n", "        if not os.path.exists(expath):\n", "            os.makedirs(expath)\n", "        i = 0\n", "        print(\"avg_match\" + str(args.avg_match))\n", "        print(\"processing...\")\n", "        print(\"total images: \" + str(len(imgs)))\n", "        while i < len(imgs):\n", "            img = imgs[i][0]\n", "            filename = imgs[i][1]\n", "            if 0:\n", "                print( f\"{str(i)}/{str(len(imgs))} matching to: {filename}\")\n", "            i2 = i+1\n", "            while i2 < len(imgs):\n", "                popped = False\n", "                img2 = imgs[i2][0]\n", "                filename2 = imgs[i2][1]\n", "                # print ('comparing '+filename + \" to \" + filename2)\n", "                if Onset.compare(img,img2, args):\n", "                    print (f\">>> {filename} matches {filename2}, pop <<<\")\n", "                    popped = True \n", "                    imgs.pop(i2)\n", "                else:\n", "                    pass\n", "                    # print (f\"imgs do not match\")\n", "                if not popped:\n", "                    i2 += 1\n", "                else:\n", "                    # copy dup to exclude\n", "                    if(args.file_extension == \"png\"):\n", "                        new_file = os.path.splitext(filename2)[0] + \".png\"\n", "                        cv2.imwrite(os.path.join(expath, new_file), img2, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n", "                    else:\n", "                        new_file = os.path.splitext(filename2)[0] + \".jpg\"\n", "                        cv2.imwrite(os.path.join(expath, new_file), img2, [cv2.IMWRITE_JPEG_QUALITY, 90])\n", "            i += 1\n", "        \n", "        return imgs\n", "    @staticmethod\n", "    def sort(imgs):\n", "        #TODO\n", "        print(\"skip\")\n", "        make_path1 = args.output_folder + \"yes/\"\n", "        make_path2 = args.output_folder + \"no/\"\n", "        if not os.path.exists(make_path1):\n", "            os.makedirs(make_path1)\n", "        if not os.path.exists(make_path2):\n", "            os.makedirs(make_path2)\n", "        (h, w) = img.shape[:2]\n", "        ratio = h/w\n", "        if(args.exact == True):\n", "            if((ratio >= 1.0) and (h == args.max_size) and (w == args.min_size)):\n", "                path = make_path1\n", "            elif((ratio < 1.0) and (w == args.max_size) and (h == args.min_size)):\n", "                path = make_path1\n", "            else:\n", "                path = make_path2\n", "        else:\n", "            #only works with ratio right now\n", "            if(ratio>=args.min_ratio):\n", "                path = make_path1\n", "            else:\n", "                path = make_path2\n", "        if(args.file_extension == \"png\"):\n", "            new_file = os.path.splitext(filename)[0] + \".png\"\n", "            cv2.imwrite(os.path.join(path, new_file), img, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n", "        else:\n", "            new_file = os.path.splitext(filename)[0] + \".jpg\"\n", "            cv2.imwrite(os.path.join(path, new_file), img, [cv2.IMWRITE_JPEG_QUALITY, 90])\n", "    @staticmethod\n", "    def dedupe(imgs,filenames, args=None):\n", "        if args.process_type == \"exclude\":\t\n", "            exclude(imgs,filenames)\n", "        if args.process_type == \"sort\":\t\n", "            sort(imgs,filenames)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["  ******************<br>\n", "  ONRECORD<br>\n", "<br>\n", "  ******************"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class Onrecord:\n", "    @staticmethod   \n", "    def folder_to_tfrecord_paths(path):\n", "        trf_paths = sorted(glob.glob(os.path.join(path, '*.tfrecords')))\n", "        return trf_paths\n", "    @staticmethod   \n", "    def tfrecord_show(tfrpath):\n", "        dataset = tf.data.TFRecordDataset(tfrpath) # <TFRecordDatasetV2 shapes: (), types: tf.string>\n", "        print(\"dataset type\", type(dataset)) #  <class 'tensorflow.python.\n", "        image_feature_description = {\n", "            'shape': tf.io.FixedLenFeature([3], tf.int64),\n", "            'data': tf.io.FixedLenFeature([], tf.string),\n", "        }\n\n", "        # Parse the input tf.Example proto using the dictionary above\n", "        # https://www.tensorflow.org/api_docs/python/tf/io/parse_single_example\n", "        def _parse_image_function(example_proto):\n", "            return tf.io.parse_single_example(example_proto, image_feature_description)\n\n", "        # parse raw dataset\n", "        parsed_dataset = dataset.map(_parse_image_function)\n", "        print(\"parsed_dataset: \", parsed_dataset)\n", "        for idx, dataitem in enumerate(parsed_dataset):\n", "            print(\"image record id:\", idx)\n", "            tfshape = dataitem['shape']\n", "            print(\"tfshape type: \", type(tfshape))\n", "            print(\"tfshape shape: \", tfshape.shape)\n", "            print(\"shape: \", tfshape) # tf.Tensor([  3 256 256], shape=(3,), dtype=int64)\n", "            shape = tfshape.numpy() # [  3 256 256]\n", "            tfdata = dataitem['data'] # () EagerTensor\n", "            data = tfdata.numpy()\n", "            # print(\"data type: \", type(data)) # <class 'bytes'>\n", "            # display.display(display.Image(data=data))\n", "            # image = Image.fromarray(data, 'RGB')\n", "            # image = Image.open(StringIO.StringIO(data))\n\n", "            # https://www.programcreek.com/python/example/89944/PIL.Image.frombytes\n", "            # https://pillow.readthedocs.io/en/3.3.x/handbook/concepts.html#concept-modes\n", "            size = (shape[1], shape[2])\n", "            mode = 'RGB' if shape[0] == 3 else 'RGBA'\n", "            img = np.array(data)\n", "            channels = shape[0]\n", "            width = shape[1]\n", "            height = shape[2]\n", "            bytes_needed = int(width * height * channels)  # tfr 9: 512x512x3\n", "            bytesq = len(data) # tfr 9: 512x512x3\n", "            # read from string buffer into int8 array\n", "            b = np.frombuffer(data, dtype=np.uint8)\n", "            # group int8 array to CHW format\n", "            img_arr =  b.reshape(shape[0], shape[1], shape[2]) # 3x3 b/w\n", "            # transpose int array to HWC, CHW => HWC\n", "            img_arr = img_arr.transpose([1, 2, 0])\n", "            cv_rgb(img_arr)\n", "    @staticmethod\n", "    def rgbs_to_npy(imgs,npyfolder,\n", "            im_size=256,\n", "            mss=(1024 ** 3),\n", "            verbose=False,\n", "            npy_file_frmt='data{}.npy',\n", "            zfill=4\n", "        ):\n", "        segment_length = mss // (im_size * im_size * 3)\n", "        np.random.shuffle(imgs)\n", "        if verbose:\n", "            print(f\"{str(len(imgs))} imgs to npy\")\n", "        kn = 0  # image in segment\n", "        sn = 0  # segment - segment_length = mss // (im_size * im_size * 3)\n", "        segment = []\n", "        for item in imgs:        \n", "            if verbose:\n", "                print('\\r' + str(sn) + \" // \" + str(kn) + \"\\t\", end = '\\r')\n", "            segment.append(item)\n", "            kn = kn + 1\n", "            if kn >= segment_length:\n", "                npyfile = npy_file_frmt.format(str(sn).zfill(zfill))\n", "                # npyfile = \"data-\"+str(sn)+\".npy\"\n", "                npydst = os.path.join(npyfolder, npyfile)\n", "                np.save(npydst, np.array(segment))\n", "                segment = []\n", "                kn = 0\n", "                sn = sn + 1\n", "        npyfile = npy_file_frmt.format(str(sn).zfill(zfill))\n", "        npydst = os.path.join(npyfolder, npyfile)\n", "        print(\"sn.kn %d %d\" %(sn,kn))\n", "        print(f\"array_to_npy save to {npydst}\")\n", "        np.save(npydst, np.array(segment))\n", "    @staticmethod\n", "    def folder_to_npy(data_org, data_npy, im_size = 256, mss = (1024 ** 3), verbose = True):\n", "    # https://github.com/manicman1999/StyleGAN2-Tensorflow-2.0/blob/master/datagen.py\n", "        imgs = Onfile.folder_to_pils(data_org)\n", "        Onrecord.pils_to_npy(imgs, data_npy, im_size, mss, verbose)\n", "    @staticmethod\n", "    def _folder_to_npy(data_dir, npy_folder, im_size, mss=(1024 ** 3), verbose=True):\n", "        def snname(sn):\n", "            return \"data-\"+str(sn)+\".npy\"\n", "        os.makedirs(npy_folder, exist_ok=True)\n", "        if verbose:\n", "            print(f\"Converting from images in {data_dir} to numpy files... onto {npy_folder}\")\n", "        names = []\n", "        for dirpath, dirnames, filenames in os.walk(data_dir):\n", "            for filename in [f for f in filenames if (f.endswith(\".jpg\") or f.endswith(\".png\") or f.endswith(\".JPEG\"))]:\n", "                fname = os.path.join(dirpath, filename)\n", "                names.append(fname)\n", "        np.random.shuffle(names)\n", "        if verbose:\n", "            print(str(len(names)) + \" images.\")\n", "        kn = 0\n", "        sn = 0\n", "        segment = []\n", "        for fname in names:\n", "            if verbose:\n", "                print('\\r' + str(sn) + \" // \" + str(kn) + \"\\t\", end = '\\r')\n", "            try:\n", "                temp = Image.open(fname).convert('RGB').resize((im_size, im_size), Image.BILINEAR)\n", "            except:\n", "                print(\"Importing image failed on\", fname)\n", "            temp = np.array(temp, dtype='uint8')\n", "            segment.append(temp)\n", "            kn = kn + 1\n", "            segment_length = mss // (im_size * im_size * 3)\n", "            if kn >= segment_length:\n", "                \n", "                target = os.path.join(npy_folder,snname(sn))\n", "                np.save(target, np.array(segment))\n", "                segment = []\n", "                kn = 0\n", "                sn = sn + 1\n", "        target = os.path.join(npy_folder,snname(sn))\n", "        np.save(target, np.array(segment))\n", "    @staticmethod\n", "    def pils_to_npy(pils, data_npy, im_size = 256, mss = (1024 ** 3), verbose = True):\n", "        npyfolder = data_npy\n", "        if verbose:\n", "            print(\"datagene.folder_to_npy:images.q: %s\" %(str(len(pils))))\n", "        \n", "        segment_length = mss // (im_size * im_size * 3)\n", "        print(f\"pils_to_npy segment_length: {segment_length}\")\n", "        np.random.shuffle(pils)\n", "        kn = 0  # image in segment\n", "        sn = 0  # segment where segment_length: mss // (im_size * im_size * 3)\n", "        segment = []\n", "        # for img in pils:\n", "        for img in pils:        \n", "            if 0:\n", "                print(f\"img type: {type(img)} {np.shape(img)}\")\n", "                print('\\r' + str(sn) + \" // \" + str(kn) + \"\\t\", end = '\\r')\n", "            img = img.convert('RGB').resize((im_size, im_size), Image.BILINEAR)\n", "            rgb = np.array(img, dtype='uint8')\n", "            \n", "            # print(\"folder_to_npy img type\", type(img)) # <class 'numpy.ndarray'>\n", "            # print(\"folder_to_npy img shape\", img.shape) # (256, 256, 3)\n", "            segment.append(rgb)\n", "            kn = kn + 1\n", "            if kn >= segment_length:\n", "                npyfile = \"data-\"+str(sn)+\".npy\"\n", "                npydst = os.path.join(npyfolder, npyfile)\n", "                np.save(npydst, np.array(segment))\n", "                segment = []\n", "                kn = 0\n", "                sn = sn + 1\n", "        npyfile = \"data-\"+str(sn)+\".npy\"\n", "        npydst = os.path.join(npyfolder, npyfile)\n", "        np.save(npydst, np.array(segment))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    @staticmethod\n", "    def npys_folder_to_pils(folder):\n", "    #  https://github.com/manicman1999/StyleGAN2-Tensorflow-2.0/blob/master/datagen.py\n", "        pils=[]\n", "        segments = []\n", "        for dirpath, dirnames, filenames in os.walk(folder):\n", "            for filename in [f for f in filenames if f.endswith(\".npy\")]:\n", "                segments.append(os.path.join(dirpath, filename))\n", "        for i in range(len(segments)):\n", "            tmp = np.load(segments[i])\n", "            for j in range(len(tmp)):\n", "                rgb = tmp[j]\n", "                pil = Image.fromarray(rgb)\n", "                pils.append(pil)\n", "        \n", "        return pils\n", "    @staticmethod\n", "    def npys_folder_to_rgbs(folder):\n", "        segments = []\n", "        for dirpath, dirnames, filenames in os.walk(folder):\n", "            for filename in [f for f in filenames if f.endswith(\".npy\")]:\n", "                segments.append(os.path.join(dirpath, filename))\n", "        import random\n", "        segment_num = random.randint(0, len(segments) - 1)\n", "        imgs = np.load(segments[segment_num])\n", "        return imgs\n", "    @staticmethod\n", "    def load_from_npy(folder, segments):\n", "        # for dirpath, dirnames, filenames in os.walk(\"data/\" + folder + \"-npy-\" + str(self.im_size)):\n", "        for dirpath, dirnames, filenames in os.walk(folder):\n", "            for filename in [f for f in filenames if f.endswith(\".npy\")]:\n", "                segments.append(os.path.join(dirpath, filename))\n", "        return Onrecord.load_segment(segments)\n", "    @staticmethod\n", "    def load_segment(segments):\n", "        segment_num =np.random.randint(0, len(segments))\n", "        images = np.load(segments[segment_num])\n", "        return images\n", "    @staticmethod\n", "    def folder_to_labels(data_dir='./', xSize=128, ySize=128, qslices=100, resize=0.75, eps = 1):\n", "        \n", "        arrs = folder_to_formed_nuas(data_dir, xSize, ySize, qslices, resize, eps)\n", "        labels = [[arr[0], arr[1]] for arr in arrs]\n", "        return labels\n", "    @staticmethod\n", "    def folder_to_tfrecords(src_dir, target_dir):\n", "        assert os.path.exists(src_dir), f\"src dir {src_dir} does not exist\"\n", "        assert os.path.exists(target_dir), f\"src dir {target_dir} does not exist\"\n", "        imgs = Onfile.folder_to_rgbs(src_dir)\n", "        Onrecord.imgs_to_tfrecords(imgs, target_dir)\n", "    @staticmethod\n", "    # relux\n", "    def create_from_images(tfrecord_dir, image_dir, shuffle):\n", "        print('Loading images from \"%s\"' % image_dir)\n", "        image_filenames = sorted(glob.glob(os.path.join(image_dir, '*')))\n", "        if len(image_filenames) == 0:\n", "            Onutil.error('No input images found')\n", "        img = np.asarray(PIL.Image.open(image_filenames[0]))\n", "        resolution = img.shape[0]\n", "        print(\"create_from_images resolution\", resolution)\n", "        channels = img.shape[2] if img.ndim == 3 else 1\n", "        if img.shape[1] != resolution:\n", "             Onutil.error('Input images must have the same width and height')\n", "        if resolution != 2 ** int(np.floor(np.log2(resolution))):\n", "             Onutil.error('Input image resolution must be a power-of-two')\n", "        if channels not in [1, 3]:\n", "             Onutil.error('Input images must be stored as RGB or grayscale')\n", "        with TFRecordExporter(tfrecord_dir, len(image_filenames)) as tfr:\n", "            order = tfr.choose_shuffled_order() if shuffle else np.arange(len(image_filenames))\n", "            for idx in range(order.size):\n", "                img = np.asarray(PIL.Image.open(image_filenames[order[idx]]))\n", "                if channels == 1:\n", "                    img = img[np.newaxis, :, :] # HW => CHW\n", "                else:\n", "                    img = img.transpose([2, 0, 1]) # HWC => CHW\n", "                tfr.add_image(img)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    @staticmethod\n", "    def imgs_to_tfrecords(imgs, target_dir, shuffle=False):\n", "        assert os.path.exists(target_dir), f\"src dir {target_dir} does not exist\"\n\n", "        # write imgs to tfrecord\n", "        with TFRecordExporter(target_dir, len(imgs)) as tfr:\n", "            order = tfr.choose_shuffled_order() if shuffle else np.arange(len(imgs))\n", "            for idx in range(order.size):\n", "                img = imgs[idx]\n", "                channels = img.shape[2] if img.ndim == 3 else 1\n", "                if channels == 1:\n", "                    img = img[np.newaxis, :, :] # HW => CHW\n", "                else:\n", "                    img = img.transpose([2, 0, 1]) # HWC => CHW\n", "                img = img / 255 # normalize\n", "                tfr.add_image(img)\n", "    @staticmethod\n", "    def show_tfrecord_from_file(src_dir,tfr_file):\n", "        images = []\n", "        tfr_files = sorted(glob.glob(os.path.join(src_dir, '*.tfrecords')))\n", "        dataset = tf.data.TFRecordDataset(src_dir, compression_type=None, buffer_size=None, num_parallel_reads=None)\n", "        # tfrpath = os.path.join(src_dir, tfr_file)\n", "        # dataset = tf.data.TFRecordDataset(tfrpath) # <TFRecordDatasetV2 shapes: (), types: tf.string>\n", "        Onrecord.show_tfrecord(dataset)\n", "    @staticmethod\n", "    def show_tfrecord(dataset):\n", "        image_feature_description = {\n", "            'shape': tf.io.FixedLenFeature([3], tf.int64),\n", "            'data': tf.io.FixedLenFeature([], tf.string),\n", "        }\n", "        def _parse_image_function(example_proto):\n", "            return tf.io.parse_single_example(example_proto, image_feature_description)        \n", "        parsed_dataset = dataset.map(_parse_image_function)\n", "        for idx, dataitem in enumerate(parsed_dataset):\n", "            tfshape = dataitem['shape']\n", "            shape = tfshape.numpy()\n", "            tfdata = dataitem['data']\n", "            data = tfdata.numpy()\n", "            size = (shape[1], shape[2])\n", "            mode = 'RGB' if shape[0] == 3 else 'RGBA'\n", "            img = np.array(data)\n", "            channels = shape[0]\n", "            width = shape[1]\n", "            height = shape[2]\n", "            bytes_needed = int(width * height * channels)  # tfr 9: 512x512x3\n", "            bytesq = len(data) # tfr 9: 512x512x3\n", "            b = np.frombuffer(data, dtype=np.uint8)\n", "            img_arr =  b.reshape(shape[0], shape[1], shape[2]) # 3x3 b/w\n", "            img_arr = img_arr.transpose([1, 2, 0])\n", "            cv_rgb(img_arr)\n", "    @staticmethod\n", "    def get_dataset(tfrecord_base_dir, res, buffer_size, batch_size, epochs=None, name=None):\n", "        # _p_ https://github.com/moono/stylegan2-tf-2.x/blob/master/dataset_ffhq.py\n", "        fn_index = int(np.log2(res))\n", "        if name:\n", "            prefix=name\n", "        else:\n", "            prefix='*'\n", "        # tfrecord_fn = os.path.join(tfrecord_base_dir, 'ffhq-r{:02d}.tfrecords'.format(fn_index))\n", "        files = glob.glob(os.path.join(tfrecord_base_dir, prefix + '-r{:02d}.tfrecords'.format(fn_index)))\n", "        tfrecord_fn = files[0]\n", "        with tf.device('/cpu:0'):\n", "            dataset = tf.data.TFRecordDataset(tfrecord_fn)\n", "            dataset = dataset.map(map_func=Onrecord.parse_tfrecord_tf, num_parallel_calls=8)\n", "            dataset = dataset.shuffle(buffer_size=buffer_size)\n", "            dataset = dataset.repeat(epochs)\n", "            dataset = dataset.batch(batch_size)\n", "            dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n", "        return dataset\n", "    @staticmethod\n", "    def parse_tfrecord_tf(record):\n", "        # n_samples = 70000    \n", "        features = tf.io.parse_single_example(record, features={\n", "            'shape': tf.io.FixedLenFeature([3], tf.dtypes.int64),\n", "            'data': tf.io.FixedLenFeature([], tf.dtypes.string)\n", "        })\n\n", "        # [0 ~ 255] uint8\n", "        images = tf.io.decode_raw(features['data'], tf.dtypes.uint8)\n", "        images = tf.reshape(images, features['shape'])\n\n", "        # [0.0 ~ 255.0] float32\n", "        images = tf.cast(images, tf.dtypes.float32)\n", "        return images\n", "    @staticmethod\n", "    def tfts_to_files(imgs,dst_dir= './',img_name_frmt='img{}.jpg',zfill = 4,):\n", "        for i,img in enumerate(imgs):\n", "            img_name = img_name_frmt.format(str(i).zfill(zfill))\n", "            path = os.path.join(dst_dir, img_name)\n", "            tft = img # <class 'tensorflow.python.framework.ops.EagerTensor'> (256, 256, 3)\n", "            arr = img.numpy().astype(np.uint8) # <class 'numpy.ndarray'> (256, 256, 3)\n", "            img = Image.fromarray(arr)\n", "            img = img.convert(\"RGB\")\n", "            img.save(path)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["  ******************<br>\n", "  ONCHECK<br>\n", "  ******************"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class Oncheck(tf.keras.models.Model):\n", "    def __init__(self,\n", "                 model,\n", "                 ckpt_dir = 'ckpt',\n", "                 clear = True):\n", "        \n", "        super(Oncheck, self).__init__()\n", "        \n", "        self.clear = clear\n", "        self.model = model\n", "        self.ckpt_dir = ckpt_dir\n", "        self.step = 1"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    def getckptidx(self, ckptname): # ckpt-98, None, ckpt--1\n", "        idx = None\n", "        if ckptname:\n", "            m = re.search(r'([a-zA-Z_]*)-(.*)', ckptname)\n", "            if m and m.group(2):\n", "                idx = m.group(2)\n", "        return idx"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    def ckpt_sample(self):\n", "        ckpt = tf.train.Checkpoint(v=tf.Variable(0.))\n", "        mgr = tf.train.CheckpointManager(ckpt, '/tmp/tfckpts', max_to_keep=5)\n", "        @tf.function\n", "        def train_fn():\n", "            data = tf.data.Dataset.range(10)\n", "            for item in data:\n", "                ckpt.v.assign_add(tf.cast(item, tf.float32))\n", "                tf.py_function(mgr.save, [], [tf.string])\n", "        train_fn()\n", "    def get_ckpt_prefix(self):\n", "        ckpt_dir = self.ckpt_dir\n", "        return ckpt_dir\n", "    def get_checkpoint(self):\n", "        model = self.model\n", "        p = model.chkpt\n", "        ckpt = tf.train.Checkpoint(**p)\n", "        return ckpt\n", "    def get_weights(self):\n", "        model = self.model\n", "        ws = model.ws\n", "        wspath = model.wspath\n", "        for w in ws:\n", "            wfile = wspath + \"/\" + w\n", "            if os.path.exists(wfile):\n", "                print(\"load weights %s\" %wfile)\n", "                ws[w] = model[w]\n", "                model[w].load_weights(wfile)\n", "                model[w] = ws[w]\n", "            else:\n", "                print(\"weights not found: %s\" %wfile)            \n", "    def get_manager(self, ckpt):\n", "        model = self.model\n", "        ckpt_dir = model.ckpt_dir\n", "        max_to_keep = 3\n", "        if self.clear:\n", "            if os.path.exists(ckpt_dir):\n", "                for root, dirs, files in os.walk(ckpt_dir, topdown=False):\n", "                    print(\"clear ckpt dir: %s\" %root)\n", "                    for name in files:\n", "                        os.remove(os.path.join(root, name))\n", "                    for name in dirs:\n", "                        os.rmdir(os.path.join(root, name))\n", "                \n", "        manager = tf.train.CheckpointManager(ckpt, \n", "                                             ckpt_dir, \n", "                                             max_to_keep)\n", "        return manager"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    #   ******************\n", "    #   restore\n", "    #\n", "    #   if a checkpoint exists, restore the latest checkpoint\n", "    #   eg:\n", "    #       ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n", "    #       if ckpt_manager.latest_checkpoint:\n", "    #           ckpt.restore(ckpt_manager.latest_checkpoint)\n", "    #           print ('Latest checkpoint restored!!')\n", "    #\n", "    def restore(self, ckpt):\n", "        model = self.model\n", "        ckpt_dir = self.ckpt_dir\n", "         \n", "        print(\"checkpoint restore %s\" %ckpt)\n", "        res = ckpt.restore(tf.train.latest_checkpoint(ckpt_dir))\n", "        print(\"res: in % s checkpoint: %s\" %(ckpt_dir, res))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["  ******************<br>\n", "  ONCUDA<br>\n", "<br>\n", "  ******************"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class Oncuda:\n\n", "    # Internal helper funcs.\n", "    @staticmethod\n", "    def _find_compiler_bindir():\n", "        for compiler_path in compiler_bindir_search_path:\n", "            if os.path.isdir(compiler_path):\n", "                return compiler_path\n", "        return None\n", "    @staticmethod\n", "    def _get_compute_cap(device):\n", "        caps_str = device.physical_device_desc\n", "        m = re.search('compute capability: (\\\\d+).(\\\\d+)', caps_str)\n", "        major = m.group(1)\n", "        minor = m.group(2)\n", "        return (major, minor)\n", "    @staticmethod\n", "    def _get_cuda_gpu_arch_string():\n", "        gpus = [x for x in device_lib.list_local_devices() if x.device_type == 'GPU']\n", "        if len(gpus) == 0:\n", "            raise RuntimeError('No GPU devices found')\n", "        (major, minor) = Oncuda._get_compute_cap(gpus[0])\n", "        return 'sm_%s%s' % (major, minor)\n", "    @staticmethod\n", "    def _run_cmd(cmd):\n", "        with os.popen(cmd) as pipe:\n", "            output = pipe.read()\n", "            status = pipe.close()\n", "        if status is not None:\n", "            raise RuntimeError('NVCC returned an error. See below for full command line and output log:\\n\\n%s\\n\\n%s' % (cmd, output))\n", "    @staticmethod\n", "    def _prepare_nvcc_cli(opts):\n", "        # cmd = 'nvcc --std=c++11 -DNDEBUG ' + opts.strip()\n", "        cmd = 'nvcc -DNDEBUG ' + opts.strip()\n", "        cmd += ' --disable-warnings'\n", "        cmd += ' --include-path \"%s\"' % tf.sysconfig.get_include()\n", "        cmd += ' --include-path \"%s\"' % os.path.join(tf.sysconfig.get_include(), 'external', 'protobuf_archive', 'src')\n", "        cmd += ' --include-path \"%s\"' % os.path.join(tf.sysconfig.get_include(), 'external', 'com_google_absl')\n", "        cmd += ' --include-path \"%s\"' % os.path.join(tf.sysconfig.get_include(), 'external', 'eigen_archive')\n", "        compiler_bindir = Oncuda._find_compiler_bindir()\n", "        if compiler_bindir is None:\n", "            # Require that _find_compiler_bindir succeeds on Windows.  Allow\n", "            # nvcc to use whatever is the default on Linux.\n", "            if os.name == 'nt':\n", "                raise RuntimeError('Could not find MSVC/GCC/CLANG installation on this computer. Check compiler_bindir_search_path list in \"%s\".' % __file__)\n", "        else:\n", "            cmd += ' --compiler-bindir \"%s\"' % compiler_bindir\n", "        cmd += ' 2>&1'\n", "        return cmd\n", "    @staticmethod\n", "    def get_plugin(cuda_file, verbose=False):\n", "        # print(\"=========================> custom_ops.py get_plugin \", cuda_file)\n", "        cuda_file_base = os.path.basename(cuda_file)\n", "        cuda_file_name, cuda_file_ext = os.path.splitext(cuda_file_base)\n\n", "        # Already in cache?\n", "        if cuda_file in _plugin_cache:\n", "            return _plugin_cache[cuda_file]\n\n", "        # Setup plugin.\n", "        if verbose:\n", "            print('Setting up TensorFlow plugin \"%s\": ' % cuda_file_base, end='', flush=True)\n", "        try:\n", "            # -----------------------------------------------------\n", "            # Hash CUDA source.\n", "            with open(cuda_file, 'wb') as f:\n", "                f.write(Oncuda.get_kernel_upfirdn().encode('utf-8'))\n", "            md5 = hashlib.md5()\n", "            with open(cuda_file, 'rb') as f:\n", "                md5.update(f.read())\n", "            md5.update(b'\\n')\n", "            # -----------------------------------------------------\n\n", "            # Hash headers included by the CUDA code by running it through the preprocessor.\n", "            if not do_not_hash_included_headers:\n", "                if verbose:\n", "                    print('Preprocessing... ', end='', flush=True)\n", "                with tempfile.TemporaryDirectory() as tmp_dir:\n", "                    os.makedirs(tmp_dir, exist_ok=True)\n", "                    tmp_file = os.path.join(tmp_dir, cuda_file_name + '_tmp' + cuda_file_ext)\n", "                    _run_cmd(Oncuda._prepare_nvcc_cli('\"%s\" --preprocess -o \"%s\" --keep --keep-dir \"%s\"' % (cuda_file, tmp_file, tmp_dir)))\n", "                    with open(tmp_file, 'rb') as f:\n", "                        bad_file_str = ('\"' + cuda_file.replace('\\\\', '/') + '\"').encode('utf-8') # __FILE__ in error check macros\n", "                        good_file_str = ('\"' + cuda_file_base + '\"').encode('utf-8')\n", "                        for ln in f:\n", "                            if not ln.startswith(b'# ') and not ln.startswith(b'#line '): # ignore line number pragmas\n", "                                ln = ln.replace(bad_file_str, good_file_str)\n", "                                md5.update(ln)\n", "                        md5.update(b'\\n')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["            # Select compiler options.\n", "            compile_opts = ''\n", "            if os.name == 'nt':\n", "                compile_opts += '\"%s\"' % os.path.join(tf.sysconfig.get_lib(), 'python', '_pywrap_tensorflow_internal.lib')\n", "            elif os.name == 'posix':\n", "                compile_opts += '\"%s\"' % os.path.join(tf.sysconfig.get_lib(), 'python', '_pywrap_tensorflow_internal.so')\n", "                compile_opts += ' --compiler-options \\'-fPIC -D_GLIBCXX_USE_CXX11_ABI=0\\''\n", "            else:\n", "                assert False # not Windows or Linux, w00t?\n", "            compile_opts += ' --gpu-architecture=%s' % Oncuda._get_cuda_gpu_arch_string()\n", "            compile_opts += ' --use_fast_math'\n", "            nvcc_cmd = Oncuda._prepare_nvcc_cli(compile_opts)\n\n", "            # Hash build configuration.\n", "            md5.update(('nvcc_cmd: ' + nvcc_cmd).encode('utf-8') + b'\\n')\n", "            md5.update(('tf.VERSION: ' + tf.__version__).encode('utf-8') + b'\\n')\n", "            md5.update(('cuda_cache_version_tag: ' + cuda_cache_version_tag).encode('utf-8') + b'\\n')\n\n", "            # Compile if not already compiled.\n", "            bin_file_ext = '.dll' if os.name == 'nt' else '.so'\n", "            bin_file = os.path.join(cuda_cache_path, cuda_file_name + '_' + md5.hexdigest() + bin_file_ext)\n", "            if not os.path.isfile(bin_file):\n", "                if verbose:\n", "                    print('Compiling... ', end='', flush=True)\n", "                with tempfile.TemporaryDirectory() as tmp_dir:\n", "                    tmp_file = os.path.join(tmp_dir, cuda_file_name + '_tmp' + bin_file_ext)\n", "                    Oncuda._run_cmd(nvcc_cmd + ' \"%s\" --shared -o \"%s\" --keep --keep-dir \"%s\"' % (cuda_file, tmp_file, tmp_dir))\n", "                    os.makedirs(cuda_cache_path, exist_ok=True)\n", "                    intermediate_file = os.path.join(cuda_cache_path, cuda_file_name + '_' + uuid.uuid4().hex + '_tmp' + bin_file_ext)\n", "                    shutil.copyfile(tmp_file, intermediate_file)\n", "                    os.rename(intermediate_file, bin_file) # atomic\n\n", "            # Load.\n", "            if verbose:\n", "                print('Loading... ', end='', flush=True)\n", "            plugin = tf.load_op_library(bin_file)\n", "            keys = plugin.__dict__.keys()        \n\n", "            # Add to cache.\n", "            _plugin_cache[cuda_file] = plugin\n", "            if verbose:\n", "                print('Done.', flush=True)\n", "            return plugin\n", "        except:\n", "            if verbose:\n", "                print('Failed!', flush=True)\n", "            raise\n", "    @staticmethod\n", "    def _get_plugin(plg=None):\n", "        # return custom_ops.get_plugin(os.path.splitext(__file__)[0] + '.cu')\n", "        # upfirdn_2d.cu\n", "        # cufile = os.path.splitext(__file__)[0] + '.cu'   # _e_\n", "        cufile = plg + '.cu'   # _e_\n", "        return Oncuda.get_plugin(cufile)\n", "    @staticmethod\n", "    def upfirdn_2d(x, k, upx=1, upy=1, downx=1, downy=1, padx0=0, padx1=0, pady0=0, pady1=0, impl='cuda', gpu=True):\n", "        r\"\"\"Pad, upsample, FIR filter, and downsample a batch of 2D images.\n", "        Accepts a batch of 2D images of the shape `[majorDim, inH, inW, minorDim]`\n", "        and performs the following operations for each image, batched across\n", "        `majorDim` and `minorDim`:\n", "        1. Pad the image with zeros by the specified number of pixels on each side\n", "        (`padx0`, `padx1`, `pady0`, `pady1`). Specifying a negative value\n", "        corresponds to cropping the image.\n", "        2. Upsample the image by inserting the zeros after each pixel (`upx`, `upy`).\n", "        3. Convolve the image with the specified 2D FIR filter (`k`), shrinking the\n", "        image so that the footprint of all output pixels lies within the input image.\n", "        4. Downsample the image by throwing away pixels (`downx`, `downy`).\n", "        This sequence of operations bears close resemblance to scipy.signal.upfirdn().\n", "        The fused op is considerably more efficient than performing the same calculation\n", "        using standard TensorFlow ops. It supports gradients of arbitrary order.\n", "        Args:\n", "            x:      Input tensor of the shape `[majorDim, inH, inW, minorDim]`.\n", "            k:      2D FIR filter of the shape `[firH, firW]`.\n", "            upx:    Integer upsampling factor along the X-axis (default: 1).\n", "            upy:    Integer upsampling factor along the Y-axis (default: 1).\n", "            downx:  Integer downsampling factor along the X-axis (default: 1).\n", "            downy:  Integer downsampling factor along the Y-axis (default: 1).\n", "            padx0:  Number of pixels to pad on the left side (default: 0).\n", "            padx1:  Number of pixels to pad on the right side (default: 0).\n", "            pady0:  Number of pixels to pad on the top side (default: 0).\n", "            pady1:  Number of pixels to pad on the bottom side (default: 0).\n", "            impl:   Name of the implementation to use. Can be `\"ref\"` or `\"cuda\"` (default).\n", "        Returns:\n", "            Tensor of the shape `[majorDim, outH, outW, minorDim]`, and same datatype as `x`.\n", "        \"\"\"\n", "        impl_dict = {\n", "            'ref':  Oncuda._upfirdn_2d_ref,\n", "            'cuda': Oncuda._upfirdn_2d_cuda,\n", "        }\n", "        return impl_dict[impl](x=x, k=k, upx=upx, upy=upy, downx=downx, downy=downy, padx0=padx0, padx1=padx1, pady0=pady0, pady1=pady1, gpu=gpu)\n\n", "    #----------------------------------------------------------------------------\n", "    @staticmethod\n", "    def _upfirdn_2d_ref(x, k, upx, upy, downx, downy, padx0, padx1, pady0, pady1, gpu=True):\n", "        \"\"\"Slow reference implementation of `upfirdn_2d()` using standard TensorFlow ops.\"\"\"\n", "        x = tf.convert_to_tensor(x)\n", "        k = np.asarray(k, dtype=np.float32)\n", "        assert x.shape.rank == 4\n", "        inH = x.shape[1]\n", "        inW = x.shape[2]\n", "        minorDim = Oncuda._shape(x, 3)\n", "        kernelH, kernelW = k.shape\n", "        assert inW >= 1 and inH >= 1\n", "        assert kernelW >= 1 and kernelH >= 1\n", "        assert isinstance(upx, int) and isinstance(upy, int)\n", "        assert isinstance(downx, int) and isinstance(downy, int)\n", "        assert isinstance(padx0, int) and isinstance(padx1, int)\n", "        assert isinstance(pady0, int) and isinstance(pady1, int)\n\n", "        # Upsample (insert zeros).\n", "        x = tf.reshape(x, [-1, inH, 1, inW, 1, minorDim])\n", "        x = tf.pad(x, [[0, 0], [0, 0], [0, upy - 1], [0, 0], [0, upx - 1], [0, 0]])\n", "        x = tf.reshape(x, [-1, inH * upy, inW * upx, minorDim])\n\n", "        # Pad (crop if negative).\n", "        x = tf.pad(x, [[0, 0], [max(pady0, 0), max(pady1, 0)], [max(padx0, 0), max(padx1, 0)], [0, 0]])\n", "        x = x[:, max(-pady0, 0) : x.shape[1] - max(-pady1, 0), max(-padx0, 0) : x.shape[2] - max(-padx1, 0), :]\n\n", "        # Convolve with filter.\n", "        x = tf.transpose(x, [0, 3, 1, 2])\n", "        x = tf.reshape(x, [-1, 1, inH * upy + pady0 + pady1, inW * upx + padx0 + padx1])\n", "        w = tf.constant(k[::-1, ::-1, np.newaxis, np.newaxis], dtype=x.dtype)\n", "        if gpu:\n", "            x = tf.nn.conv2d(x, w, strides=[1,1,1,1], padding='VALID', data_format='NCHW')\n", "        else:\n", "            x = tf.transpose(x, [0, 2, 3, 1])\n", "            x = tf.nn.conv2d(x, w, strides=[1,1,1,1], padding='VALID', data_format='NHWC')\n", "            x = tf.transpose(x, [0, 3, 1, 2])     \n", "        x = tf.reshape(x, [-1, minorDim, inH * upy + pady0 + pady1 - kernelH + 1, inW * upx + padx0 + padx1 - kernelW + 1])\n", "        x = tf.transpose(x, [0, 2, 3, 1])\n\n", "        # Downsample (throw away pixels).\n", "        return x[:, ::downy, ::downx, :]\n\n", "    #----------------------------------------------------------------------------\n", "    @staticmethod\n", "    def _upfirdn_2d_cuda(x, k, upx, upy, downx, downy, padx0, padx1, pady0, pady1, gpu=True):\n", "        \"\"\"Fast CUDA implementation of `upfirdn_2d()` using custom ops.\"\"\"\n", "        x = tf.convert_to_tensor(x)\n", "        k = np.asarray(k, dtype=np.float32)\n", "        majorDim, inH, inW, minorDim = x.shape.as_list()\n", "        kernelH, kernelW = k.shape\n", "        assert inW >= 1 and inH >= 1\n", "        assert kernelW >= 1 and kernelH >= 1\n", "        assert isinstance(upx, int) and isinstance(upy, int)\n", "        assert isinstance(downx, int) and isinstance(downy, int)\n", "        assert isinstance(padx0, int) and isinstance(padx1, int)\n", "        assert isinstance(pady0, int) and isinstance(pady1, int)\n", "        outW = (inW * upx + padx0 + padx1 - kernelW) // downx + 1\n", "        outH = (inH * upy + pady0 + pady1 - kernelH) // downy + 1\n", "        assert outW >= 1 and outH >= 1\n", "        kc = tf.constant(k, dtype=x.dtype)\n", "        gkc = tf.constant(k[::-1, ::-1], dtype=x.dtype)\n", "        gpadx0 = kernelW - padx0 - 1\n", "        gpady0 = kernelH - pady0 - 1\n", "        gpadx1 = inW * upx - outW * downx + padx0 - upx + 1\n", "        gpady1 = inH * upy - outH * downy + pady0 - upy + 1\n\n", "        # add plugin _e_\n", "        @tf.custom_gradient\n", "        def func(x):\n", "            y = Oncuda._get_plugin('upfirdn_2d').up_fir_dn2d(x=x, k=kc, upx=upx, upy=upy, downx=downx, downy=downy, padx0=padx0, padx1=padx1, pady0=pady0, pady1=pady1)\n", "            y.set_shape([majorDim, outH, outW, minorDim])\n", "            @tf.custom_gradient\n", "            def grad(dy):\n", "                dx = Oncuda._get_plugin('upfirdn_2d').up_fir_dn2d(x=dy, k=gkc, upx=downx, upy=downy, downx=upx, downy=upy, padx0=gpadx0, padx1=gpadx1, pady0=gpady0, pady1=gpady1)\n", "                dx.set_shape([majorDim, inH, inW, minorDim])\n", "                return dx, func\n", "            return y, grad\n", "        return func(x)\n\n", "    #----------------------------------------------------------------------------\n", "    @staticmethod\n", "    def filter_2d(x, k, gain=1, data_format='NCHW', impl='cuda'):\n", "        r\"\"\"Filter a batch of 2D images with the given FIR filter.\n", "        Accepts a batch of 2D images of the shape `[N, C, H, W]` or `[N, H, W, C]`\n", "        and filters each image with the given filter. The filter is normalized so that\n", "        if the input pixels are constant, they will be scaled by the specified `gain`.\n", "        Pixels outside the image are assumed to be zero.\n", "        Args:\n", "            x:            Input tensor of the shape `[N, C, H, W]` or `[N, H, W, C]`.\n", "            k:            FIR filter of the shape `[firH, firW]` or `[firN]` (separable).\n", "            gain:         Scaling factor for signal magnitude (default: 1.0).\n", "            data_format:  `'NCHW'` or `'NHWC'` (default: `'NCHW'`).\n", "            impl:         Name of the implementation to use. Can be `\"ref\"` or `\"cuda\"` (default).\n", "        Returns:\n", "            Tensor of the same shape and datatype as `x`.\n", "        \"\"\"\n", "        k = Oncuda._setup_kernel(k) * gain\n", "        p = k.shape[0] - 1\n", "        return Oncuda._simple_upfirdn_2d(x, k, pad0=(p+1)//2, pad1=p//2, data_format=data_format, impl=impl)\n\n", "    #----------------------------------------------------------------------------\n", "    @staticmethod\n", "    def upsample_2d(x, k=None, factor=2, gain=1, data_format='NCHW', impl='cuda', gpu=True):\n", "        r\"\"\"Upsample a batch of 2D images with the given filter.\n", "        Accepts a batch of 2D images of the shape `[N, C, H, W]` or `[N, H, W, C]`\n", "        and upsamples each image with the given filter. The filter is normalized so that\n", "        if the input pixels are constant, they will be scaled by the specified `gain`.\n", "        Pixels outside the image are assumed to be zero, and the filter is padded with\n", "        zeros so that its shape is a multiple of the upsampling factor.\n", "        Args:\n", "            x:            Input tensor of the shape `[N, C, H, W]` or `[N, H, W, C]`.\n", "            k:            FIR filter of the shape `[firH, firW]` or `[firN]` (separable).\n", "                        The default is `[1] * factor`, which corresponds to nearest-neighbor\n", "                        upsampling.\n", "            factor:       Integer upsampling factor (default: 2).\n", "            gain:         Scaling factor for signal magnitude (default: 1.0).\n", "            data_format:  `'NCHW'` or `'NHWC'` (default: `'NCHW'`).\n", "            impl:         Name of the implementation to use. Can be `\"ref\"` or `\"cuda\"` (default).\n", "        Returns:\n", "            Tensor of the shape `[N, C, H * factor, W * factor]` or\n", "            `[N, H * factor, W * factor, C]`, and same datatype as `x`.\n", "        \"\"\"\n", "        assert isinstance(factor, int) and factor >= 1\n", "        if k is None:\n", "            k = [1] * factor\n", "        k = Oncuda._setup_kernel(k) * (gain * (factor ** 2))\n", "        p = k.shape[0] - factor\n", "        return Oncuda._simple_upfirdn_2d(x, k, up=factor, pad0=(p+1)//2+factor-1, pad1=p//2, data_format=data_format, impl=impl, gpu=gpu)\n\n", "    #----------------------------------------------------------------------------\n", "    @staticmethod\n", "    def downsample_2d(x, k=None, factor=2, gain=1, data_format='NCHW', impl='cuda'):\n", "        r\"\"\"Downsample a batch of 2D images with the given filter.\n", "        Accepts a batch of 2D images of the shape `[N, C, H, W]` or `[N, H, W, C]`\n", "        and downsamples each image with the given filter. The filter is normalized so that\n", "        if the input pixels are constant, they will be scaled by the specified `gain`.\n", "        Pixels outside the image are assumed to be zero, and the filter is padded with\n", "        zeros so that its shape is a multiple of the downsampling factor.\n", "        Args:\n", "            x:            Input tensor of the shape `[N, C, H, W]` or `[N, H, W, C]`.\n", "            k:            FIR filter of the shape `[firH, firW]` or `[firN]` (separable).\n", "                        The default is `[1] * factor`, which corresponds to average pooling.\n", "            factor:       Integer downsampling factor (default: 2).\n", "            gain:         Scaling factor for signal magnitude (default: 1.0).\n", "            data_format:  `'NCHW'` or `'NHWC'` (default: `'NCHW'`).\n", "            impl:         Name of the implementation to use. Can be `\"ref\"` or `\"cuda\"` (default).\n", "        Returns:\n", "            Tensor of the shape `[N, C, H // factor, W // factor]` or\n", "            `[N, H // factor, W // factor, C]`, and same datatype as `x`.\n", "        \"\"\"\n", "        assert isinstance(factor, int) and factor >= 1\n", "        if k is None:\n", "            k = [1] * factor\n", "        k = Oncuda._setup_kernel(k) * gain\n", "        p = k.shape[0] - factor\n", "        return Oncuda._simple_upfirdn_2d(x, k, down=factor, pad0=(p+1)//2, pad1=p//2, data_format=data_format, impl=impl)\n\n", "    #----------------------------------------------------------------------------\n", "    @staticmethod\n", "    def upsample_conv_2d(x, w, k=None, factor=2, gain=1, data_format='NCHW', impl='cuda', gpu=True):\n", "        r\"\"\"Fused `upsample_2d()` followed by `tf.nn.conv2d()`.\n", "        Padding is performed only once at the beginning, not between the operations.\n", "        The fused op is considerably more efficient than performing the same calculation\n", "        using standard TensorFlow ops. It supports gradients of arbitrary order.\n", "        Args:\n", "            x:            Input tensor of the shape `[N, C, H, W]` or `[N, H, W, C]`.\n", "            w:            Weight tensor of the shape `[filterH, filterW, inChannels, outChannels]`.\n", "                        Grouped convolution can be performed by `inChannels = x.shape[0] // numGroups`.\n", "            k:            FIR filter of the shape `[firH, firW]` or `[firN]` (separable).\n", "                        The default is `[1] * factor`, which corresponds to nearest-neighbor\n", "                        upsampling.\n", "            factor:       Integer upsampling factor (default: 2).\n", "            gain:         Scaling factor for signal magnitude (default: 1.0).\n", "            data_format:  `'NCHW'` or `'NHWC'` (default: `'NCHW'`).\n", "            impl:         Name of the implementation to use. Can be `\"ref\"` or `\"cuda\"` (default).\n", "        Returns:\n", "            Tensor of the shape `[N, C, H * factor, W * factor]` or\n", "            `[N, H * factor, W * factor, C]`, and same datatype as `x`.\n", "        \"\"\"\n", "        assert isinstance(factor, int) and factor >= 1\n\n", "        # Check weight shape.\n", "        w = tf.convert_to_tensor(w)\n", "        assert w.shape.rank == 4\n", "        convH = w.shape[0]\n", "        convW = w.shape[1]\n", "        inC = Oncuda._shape(w, 2)\n", "        outC = Oncuda._shape(w, 3)\n", "        assert convW == convH\n\n", "        # Setup filter kernel.\n", "        if k is None:\n", "            k = [1] * factor\n", "        k = Oncuda._setup_kernel(k) * (gain * (factor ** 2))\n", "        p = (k.shape[0] - factor) - (convW - 1)\n\n", "        # Determine data dimensions.\n", "        if data_format == 'NCHW':\n", "            stride = [1, 1, factor, factor]\n", "            output_shape = [Oncuda._shape(x, 0), outC, (Oncuda._shape(x, 2) - 1) * factor + convH, (Oncuda._shape(x, 3) - 1) * factor + convW]\n", "            num_groups = Oncuda._shape(x, 1) // inC\n", "        else:\n", "            stride = [1, factor, factor, 1]\n", "            output_shape = [Oncuda._shape(x, 0), (Oncuda._shape(x, 1) - 1) * factor + convH, (Oncuda._shape(x, 2) - 1) * factor + convW, outC]\n", "            num_groups = Oncuda._shape(x, 3) // inC\n\n", "        # Transpose weights.\n", "        w = tf.reshape(w, [convH, convW, inC, num_groups, -1])\n", "        w = tf.transpose(w[::-1, ::-1], [0, 1, 4, 3, 2])\n", "        w = tf.reshape(w, [convH, convW, -1, num_groups * inC])\n\n", "        # Execute.\n", "        x = tf.nn.conv2d_transpose(x, w, output_shape=output_shape, strides=stride, padding='VALID', data_format=data_format)\n", "        return Oncuda._simple_upfirdn_2d(x, k, pad0=(p+1)//2+factor-1, pad1=p//2+1, data_format=data_format, impl=impl, gpu=gpu)\n\n", "    #----------------------------------------------------------------------------\n", "    @staticmethod\n", "    def conv_downsample_2d(x, w, k=None, factor=2, gain=1, data_format='NCHW', impl='cuda', gpu=True):\n", "        r\"\"\"Fused `tf.nn.conv2d()` followed by `downsample_2d()`.\n", "        Padding is performed only once at the beginning, not between the operations.\n", "        The fused op is considerably more efficient than performing the same calculation\n", "        using standard TensorFlow ops. It supports gradients of arbitrary order.\n", "        Args:\n", "            x:            Input tensor of the shape `[N, C, H, W]` or `[N, H, W, C]`.\n", "            w:            Weight tensor of the shape `[filterH, filterW, inChannels, outChannels]`.\n", "                        Grouped convolution can be performed by `inChannels = x.shape[0] // numGroups`.\n", "            k:            FIR filter of the shape `[firH, firW]` or `[firN]` (separable).\n", "                        The default is `[1] * factor`, which corresponds to average pooling.\n", "            factor:       Integer downsampling factor (default: 2).\n", "            gain:         Scaling factor for signal magnitude (default: 1.0).\n", "            data_format:  `'NCHW'` or `'NHWC'` (default: `'NCHW'`).\n", "            impl:         Name of the implementation to use. Can be `\"ref\"` or `\"cuda\"` (default).\n", "        Returns:\n", "            Tensor of the shape `[N, C, H // factor, W // factor]` or\n", "            `[N, H // factor, W // factor, C]`, and same datatype as `x`.\n", "        \"\"\"\n", "        assert isinstance(factor, int) and factor >= 1\n", "        w = tf.convert_to_tensor(w)\n", "        convH, convW, _inC, _outC = w.shape.as_list()\n", "        assert convW == convH\n", "        if k is None:\n", "            k = [1] * factor\n", "        k = Oncuda._setup_kernel(k) * gain\n", "        p = (k.shape[0] - factor) + (convW - 1)\n", "        if data_format == 'NCHW':\n", "            s = [1, 1, factor, factor]\n", "        else:\n", "            s = [1, factor, factor, 1]\n", "        x = Oncuda._simple_upfirdn_2d(x, k, pad0=(p+1)//2, pad1=p//2, data_format=data_format, impl=impl, gpu=gpu)\n", "        return tf.nn.conv2d(x, w, strides=s, padding='VALID', data_format=data_format)\n\n", "    #----------------------------------------------------------------------------\n", "    # Internal helper funcs.\n", "    @staticmethod\n", "    def _shape(tf_expr, dim_idx):\n", "        if tf_expr.shape.rank is not None:\n", "            dim = tf_expr.shape[dim_idx]\n", "            if dim is not None:\n", "                return dim\n", "        return tf.shape(tf_expr)[dim_idx]\n", "    @staticmethod\n", "    def _setup_kernel(k):\n", "        k = np.asarray(k, dtype=np.float32)\n", "        if k.ndim == 1:\n", "            k = np.outer(k, k)\n", "        k /= np.sum(k)\n", "        assert k.ndim == 2\n", "        assert k.shape[0] == k.shape[1]\n", "        return k\n", "    @staticmethod\n", "    def _simple_upfirdn_2d(x, k, up=1, down=1, pad0=0, pad1=0, data_format='NCHW', impl='cuda', gpu=True):\n", "        assert data_format in ['NCHW', 'NHWC']\n", "        assert x.shape.rank == 4\n", "        y = x\n", "        if data_format == 'NCHW':\n", "            y = tf.reshape(y, [-1, Oncuda._shape(y, 2), Oncuda._shape(y, 3), 1])\n", "        y = Oncuda.upfirdn_2d(y, k, upx=up, upy=up, downx=down, downy=down, padx0=pad0, padx1=pad1, pady0=pad0, pady1=pad1, impl=impl, gpu=gpu)\n", "        if data_format == 'NCHW':\n", "            y = tf.reshape(y, [-1, Oncuda._shape(x, 1), Oncuda._shape(y, 1), Oncuda._shape(y, 2)])\n", "        return y"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    #   ******************\n", "    #   dnnlib/ops/upfirdn_2d.cu - get raw\n", "    #\n\n", "    # _e_\n", "    # ERROR in Eigen C++ file named Tensor\n", "    # ref: https://github.com/tensorflow/tensorflow/issues/40148\n", "    # ref: https://github.com/tensorflow/tensorflow/issues/39829\n", "    # C:/Users/xxx/AppData/Local/Programs/Python/Python36/lib/site-packages/tensorflow/include/unsupported/Eigen/CXX11/Tensor    \n", "    #     {port}/Anaconda3/envs/{env}/lib/site-packages/tensorflow/include/unsupported/Eigen/CXX11/Tensor(74): fatal error C1083: Cannot open include file: 'unistd.h': No such file or directory\n", "    #     _pywrap_tensorflow_internal.lib\n", "    #     upfirdn_2d.cu\n", "    # python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\" \n", "    @staticmethod    \n", "    def get_kernel_upfirdn():\n", "        res=\"\"\"// Copyright (c) 2019, NVIDIA Corporation. All rights reserved.\n", "//\n", "// This work is made available under the Nvidia Source Code License-NC.\n", "// To view a copy of this license, visit\n", "// https://nvlabs.github.io/stylegan2/license.html"]}, {"cell_type": "markdown", "metadata": {}, "source": ["efine EIGEN_USE_GPU<br>\n", "efine __CUDA_INCLUDE_COMPILER_INTERNAL_HEADERS__<br>\n", "nclude \"tensorflow/core/framework/op.h\"<br>\n", "nclude \"tensorflow/core/framework/op_kernel.h\"<br>\n", "nclude \"tensorflow/core/framework/shape_inference.h\"<br>\n", "nclude <stdio.h>"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["using namespace tensorflow;\n", "using namespace tensorflow::shape_inference;"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["//------------------------------------------------------------------------\n", "// Helpers."]}, {"cell_type": "markdown", "metadata": {}, "source": ["efine OP_CHECK_CUDA_ERROR(CTX, CUDA_CALL) do { cudaError_t err = CUDA_CALL; OP_REQUIRES(CTX, err == cudaSuccess, errors::Internal(cudaGetErrorName(err))); } while (false)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["static __host__ __device__ __forceinline__ int floorDiv(int a, int b)\n", "{\n", "    int c = a / b;\n", "    if (c * b > a)\n", "        c--;\n", "    return c;\n", "}"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["//------------------------------------------------------------------------\n", "// CUDA kernel params."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["template <class T>\n", "struct UpFirDn2DKernelParams\n", "{\n", "    const T*    x;          // [majorDim, inH, inW, minorDim]\n", "    const T*    k;          // [kernelH, kernelW]\n", "    T*          y;          // [majorDim, outH, outW, minorDim]\n", "    int         upx;\n", "    int         upy;\n", "    int         downx;\n", "    int         downy;\n", "    int         padx0;\n", "    int         padx1;\n", "    int         pady0;\n", "    int         pady1;\n", "    int         majorDim;\n", "    int         inH;\n", "    int         inW;\n", "    int         minorDim;\n", "    int         kernelH;\n", "    int         kernelW;\n", "    int         outH;\n", "    int         outW;\n", "    int         loopMajor;\n", "    int         loopX;\n", "};"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["//------------------------------------------------------------------------\n", "// General CUDA implementation for large filter kernels."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["template <class T>\n", "static __global__ void UpFirDn2DKernel_large(const UpFirDn2DKernelParams<T> p)\n", "{\n", "    // Calculate thread index.\n", "    int minorIdx = blockIdx.x * blockDim.x + threadIdx.x;\n", "    int outY = minorIdx / p.minorDim;\n", "    minorIdx -= outY * p.minorDim;\n", "    int outXBase = blockIdx.y * p.loopX * blockDim.y + threadIdx.y;\n", "    int majorIdxBase = blockIdx.z * p.loopMajor;\n", "    if (outXBase >= p.outW || outY >= p.outH || majorIdxBase >= p.majorDim)\n", "        return;\n", "    // Setup Y receptive field.\n", "    int midY = outY * p.downy + p.upy - 1 - p.pady0;\n", "    int inY = min(max(floorDiv(midY, p.upy), 0), p.inH);\n", "    int h = min(max(floorDiv(midY + p.kernelH, p.upy), 0), p.inH) - inY;\n", "    int kernelY = midY + p.kernelH - (inY + 1) * p.upy;\n", "    // Loop over majorDim and outX.\n", "    for (int loopMajor = 0, majorIdx = majorIdxBase; loopMajor < p.loopMajor && majorIdx < p.majorDim; loopMajor++, majorIdx++)\n", "    for (int loopX = 0, outX = outXBase; loopX < p.loopX && outX < p.outW; loopX++, outX += blockDim.y)\n", "    {\n", "        // Setup X receptive field.\n", "        int midX = outX * p.downx + p.upx - 1 - p.padx0;\n", "        int inX = min(max(floorDiv(midX, p.upx), 0), p.inW);\n", "        int w = min(max(floorDiv(midX + p.kernelW, p.upx), 0), p.inW) - inX;\n", "        int kernelX = midX + p.kernelW - (inX + 1) * p.upx;\n", "        // Initialize pointers.\n", "        const T* xp = &p.x[((majorIdx * p.inH + inY) * p.inW + inX) * p.minorDim + minorIdx];\n", "        const T* kp = &p.k[kernelY * p.kernelW + kernelX];\n", "        int xpx = p.minorDim;\n", "        int kpx = -p.upx;\n", "        int xpy = p.inW * p.minorDim;\n", "        int kpy = -p.upy * p.kernelW;\n", "        // Inner loop.\n", "        float v = 0.0f;\n", "        for (int y = 0; y < h; y++)\n", "        {\n", "            for (int x = 0; x < w; x++)\n", "            {\n", "                v += (float)(*xp) * (float)(*kp);\n", "                xp += xpx;\n", "                kp += kpx;\n", "            }\n", "            xp += xpy - w * xpx;\n", "            kp += kpy - w * kpx;\n", "        }\n", "        // Store result.\n", "        p.y[((majorIdx * p.outH + outY) * p.outW + outX) * p.minorDim + minorIdx] = (T)v;\n", "    }\n", "}"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["//------------------------------------------------------------------------\n", "// Specialized CUDA implementation for small filter kernels."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["template <class T, int upx, int upy, int downx, int downy, int kernelW, int kernelH, int tileOutW, int tileOutH>\n", "static __global__ void UpFirDn2DKernel_small(const UpFirDn2DKernelParams<T> p)\n", "{\n", "    //assert(kernelW % upx == 0);\n", "    //assert(kernelH % upy == 0);\n", "    const int tileInW = ((tileOutW - 1) * downx + kernelW - 1) / upx + 1;\n", "    const int tileInH = ((tileOutH - 1) * downy + kernelH - 1) / upy + 1;\n", "    __shared__ volatile float sk[kernelH][kernelW];\n", "    __shared__ volatile float sx[tileInH][tileInW];\n", "    // Calculate tile index.\n", "    int minorIdx = blockIdx.x;\n", "    int tileOutY = minorIdx / p.minorDim;\n", "    minorIdx -= tileOutY * p.minorDim;\n", "    tileOutY *= tileOutH;\n", "    int tileOutXBase = blockIdx.y * p.loopX * tileOutW;\n", "    int majorIdxBase = blockIdx.z * p.loopMajor;\n", "    if (tileOutXBase >= p.outW | tileOutY >= p.outH | majorIdxBase >= p.majorDim)\n", "        return;\n", "    // Load filter kernel (flipped).\n", "    for (int tapIdx = threadIdx.x; tapIdx < kernelH * kernelW; tapIdx += blockDim.x)\n", "    {\n", "        int ky = tapIdx / kernelW;\n", "        int kx = tapIdx - ky * kernelW;\n", "        float v = 0.0f;\n", "        if (kx < p.kernelW & ky < p.kernelH)\n", "            v = (float)p.k[(p.kernelH - 1 - ky) * p.kernelW + (p.kernelW - 1 - kx)];\n", "        sk[ky][kx] = v;\n", "    }\n", "    // Loop over majorDim and outX.\n", "    for (int loopMajor = 0, majorIdx = majorIdxBase; loopMajor < p.loopMajor & majorIdx < p.majorDim; loopMajor++, majorIdx++)\n", "    for (int loopX = 0, tileOutX = tileOutXBase; loopX < p.loopX & tileOutX < p.outW; loopX++, tileOutX += tileOutW)\n", "    {\n", "        // Load input pixels.\n", "        int tileMidX = tileOutX * downx + upx - 1 - p.padx0;\n", "        int tileMidY = tileOutY * downy + upy - 1 - p.pady0;\n", "        int tileInX = floorDiv(tileMidX, upx);\n", "        int tileInY = floorDiv(tileMidY, upy);\n", "        __syncthreads();\n", "        for (int inIdx = threadIdx.x; inIdx < tileInH * tileInW; inIdx += blockDim.x)\n", "        {\n", "            int relInY = inIdx / tileInW;\n", "            int relInX = inIdx - relInY * tileInW;\n", "            int inX = relInX + tileInX;\n", "            int inY = relInY + tileInY;\n", "            float v = 0.0f;\n", "            if (inX >= 0 & inY >= 0 & inX < p.inW & inY < p.inH)\n", "                v = (float)p.x[((majorIdx * p.inH + inY) * p.inW + inX) * p.minorDim + minorIdx];\n", "            sx[relInY][relInX] = v;\n", "        }\n", "        // Loop over output pixels.\n", "        __syncthreads();\n", "        for (int outIdx = threadIdx.x; outIdx < tileOutH * tileOutW; outIdx += blockDim.x)\n", "        {\n", "            int relOutY = outIdx / tileOutW;\n", "            int relOutX = outIdx - relOutY * tileOutW;\n", "            int outX = relOutX + tileOutX;\n", "            int outY = relOutY + tileOutY;\n", "            // Setup receptive field.\n", "            int midX = tileMidX + relOutX * downx;\n", "            int midY = tileMidY + relOutY * downy;\n", "            int inX = floorDiv(midX, upx);\n", "            int inY = floorDiv(midY, upy);\n", "            int relInX = inX - tileInX;\n", "            int relInY = inY - tileInY;\n", "            int kernelX = (inX + 1) * upx - midX - 1; // flipped\n", "            int kernelY = (inY + 1) * upy - midY - 1; // flipped\n", "            // Inner loop.\n", "            float v = 0.0f;\n", "            #pragma unroll\n", "            for (int y = 0; y < kernelH / upy; y++)\n", "                #pragma unroll\n", "                for (int x = 0; x < kernelW / upx; x++)\n", "                    v += sx[relInY + y][relInX + x] * sk[kernelY + y * upy][kernelX + x * upx];\n", "            // Store result.\n", "            if (outX < p.outW & outY < p.outH)\n", "                p.y[((majorIdx * p.outH + outY) * p.outW + outX) * p.minorDim + minorIdx] = (T)v;\n", "        }\n", "    }\n", "}"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["//------------------------------------------------------------------------\n", "// TensorFlow op."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["template <class T>\n", "struct UpFirDn2DOp : public OpKernel\n", "{\n", "    UpFirDn2DKernelParams<T> m_attribs;\n", "    UpFirDn2DOp(OpKernelConstruction* ctx) : OpKernel(ctx)\n", "    {\n", "        memset(&m_attribs, 0, sizeof(m_attribs));\n", "        OP_REQUIRES_OK(ctx, ctx->GetAttr(\"upx\", &m_attribs.upx));\n", "        OP_REQUIRES_OK(ctx, ctx->GetAttr(\"upy\", &m_attribs.upy));\n", "        OP_REQUIRES_OK(ctx, ctx->GetAttr(\"downx\", &m_attribs.downx));\n", "        OP_REQUIRES_OK(ctx, ctx->GetAttr(\"downy\", &m_attribs.downy));\n", "        OP_REQUIRES_OK(ctx, ctx->GetAttr(\"padx0\", &m_attribs.padx0));\n", "        OP_REQUIRES_OK(ctx, ctx->GetAttr(\"padx1\", &m_attribs.padx1));\n", "        OP_REQUIRES_OK(ctx, ctx->GetAttr(\"pady0\", &m_attribs.pady0));\n", "        OP_REQUIRES_OK(ctx, ctx->GetAttr(\"pady1\", &m_attribs.pady1));\n", "        OP_REQUIRES(ctx, m_attribs.upx >= 1 && m_attribs.upy >= 1, errors::InvalidArgument(\"upx and upy must be at least 1x1\"));\n", "        OP_REQUIRES(ctx, m_attribs.downx >= 1 && m_attribs.downy >= 1, errors::InvalidArgument(\"downx and downy must be at least 1x1\"));\n", "    }\n", "    void Compute(OpKernelContext* ctx)\n", "    {\n", "        UpFirDn2DKernelParams<T> p = m_attribs;\n", "        cudaStream_t stream = ctx->eigen_device<Eigen::GpuDevice>().stream();\n", "        const Tensor& x = ctx->input(0); // [majorDim, inH, inW, minorDim]\n", "        const Tensor& k = ctx->input(1); // [kernelH, kernelW]\n", "        p.x = x.flat<T>().data();\n", "        p.k = k.flat<T>().data();\n", "        OP_REQUIRES(ctx, x.dims() == 4, errors::InvalidArgument(\"input must have rank 4\"));\n", "        OP_REQUIRES(ctx, k.dims() == 2, errors::InvalidArgument(\"kernel must have rank 2\"));\n", "        OP_REQUIRES(ctx, x.NumElements() <= kint32max, errors::InvalidArgument(\"input too large\"));\n", "        OP_REQUIRES(ctx, k.NumElements() <= kint32max, errors::InvalidArgument(\"kernel too large\"));\n", "        p.majorDim  = (int)x.dim_size(0);\n", "        p.inH       = (int)x.dim_size(1);\n", "        p.inW       = (int)x.dim_size(2);\n", "        p.minorDim  = (int)x.dim_size(3);\n", "        p.kernelH   = (int)k.dim_size(0);\n", "        p.kernelW   = (int)k.dim_size(1);\n", "        OP_REQUIRES(ctx, p.kernelW >= 1 && p.kernelH >= 1, errors::InvalidArgument(\"kernel must be at least 1x1\"));\n", "        p.outW = (p.inW * p.upx + p.padx0 + p.padx1 - p.kernelW + p.downx) / p.downx;\n", "        p.outH = (p.inH * p.upy + p.pady0 + p.pady1 - p.kernelH + p.downy) / p.downy;\n", "        OP_REQUIRES(ctx, p.outW >= 1 && p.outH >= 1, errors::InvalidArgument(\"output must be at least 1x1\"));\n", "        Tensor* y = NULL; // [majorDim, outH, outW, minorDim]\n", "        TensorShape ys;\n", "        ys.AddDim(p.majorDim);\n", "        ys.AddDim(p.outH);\n", "        ys.AddDim(p.outW);\n", "        ys.AddDim(p.minorDim);\n", "        OP_REQUIRES_OK(ctx, ctx->allocate_output(0, ys, &y));\n", "        p.y = y->flat<T>().data();\n", "        OP_REQUIRES(ctx, y->NumElements() <= kint32max, errors::InvalidArgument(\"output too large\"));\n", "        // Choose CUDA kernel to use.\n", "        void* cudaKernel = (void*)UpFirDn2DKernel_large<T>;\n", "        int tileOutW = -1;\n", "        int tileOutH = -1;\n", "        if (p.upx == 1 && p.upy == 1 && p.downx == 1 && p.downy == 1 && p.kernelW <= 7 && p.kernelH <= 7) { cudaKernel = (void*)UpFirDn2DKernel_small<T, 1,1, 1,1, 7,7, 64,16>; tileOutW = 64; tileOutH = 16; }\n", "        if (p.upx == 1 && p.upy == 1 && p.downx == 1 && p.downy == 1 && p.kernelW <= 6 && p.kernelH <= 6) { cudaKernel = (void*)UpFirDn2DKernel_small<T, 1,1, 1,1, 6,6, 64,16>; tileOutW = 64; tileOutH = 16; }\n", "        if (p.upx == 1 && p.upy == 1 && p.downx == 1 && p.downy == 1 && p.kernelW <= 5 && p.kernelH <= 5) { cudaKernel = (void*)UpFirDn2DKernel_small<T, 1,1, 1,1, 5,5, 64,16>; tileOutW = 64; tileOutH = 16; }\n", "        if (p.upx == 1 && p.upy == 1 && p.downx == 1 && p.downy == 1 && p.kernelW <= 4 && p.kernelH <= 4) { cudaKernel = (void*)UpFirDn2DKernel_small<T, 1,1, 1,1, 4,4, 64,16>; tileOutW = 64; tileOutH = 16; }\n", "        if (p.upx == 1 && p.upy == 1 && p.downx == 1 && p.downy == 1 && p.kernelW <= 3 && p.kernelH <= 3) { cudaKernel = (void*)UpFirDn2DKernel_small<T, 1,1, 1,1, 3,3, 64,16>; tileOutW = 64; tileOutH = 16; }\n", "        if (p.upx == 2 && p.upy == 2 && p.downx == 1 && p.downy == 1 && p.kernelW <= 8 && p.kernelH <= 8) { cudaKernel = (void*)UpFirDn2DKernel_small<T, 2,2, 1,1, 8,8, 64,16>; tileOutW = 64; tileOutH = 16; }\n", "        if (p.upx == 2 && p.upy == 2 && p.downx == 1 && p.downy == 1 && p.kernelW <= 6 && p.kernelH <= 6) { cudaKernel = (void*)UpFirDn2DKernel_small<T, 2,2, 1,1, 6,6, 64,16>; tileOutW = 64; tileOutH = 16; }\n", "        if (p.upx == 2 && p.upy == 2 && p.downx == 1 && p.downy == 1 && p.kernelW <= 4 && p.kernelH <= 4) { cudaKernel = (void*)UpFirDn2DKernel_small<T, 2,2, 1,1, 4,4, 64,16>; tileOutW = 64; tileOutH = 16; }\n", "        if (p.upx == 2 && p.upy == 2 && p.downx == 1 && p.downy == 1 && p.kernelW <= 2 && p.kernelH <= 2) { cudaKernel = (void*)UpFirDn2DKernel_small<T, 2,2, 1,1, 2,2, 64,16>; tileOutW = 64; tileOutH = 16; }\n", "        if (p.upx == 1 && p.upy == 1 && p.downx == 2 && p.downy == 2 && p.kernelW <= 8 && p.kernelH <= 8) { cudaKernel = (void*)UpFirDn2DKernel_small<T, 1,1, 2,2, 8,8, 32,8>;  tileOutW = 32; tileOutH = 8;  }\n", "        if (p.upx == 1 && p.upy == 1 && p.downx == 2 && p.downy == 2 && p.kernelW <= 6 && p.kernelH <= 6) { cudaKernel = (void*)UpFirDn2DKernel_small<T, 1,1, 2,2, 6,6, 32,8>;  tileOutW = 32; tileOutH = 8;  }\n", "        if (p.upx == 1 && p.upy == 1 && p.downx == 2 && p.downy == 2 && p.kernelW <= 4 && p.kernelH <= 4) { cudaKernel = (void*)UpFirDn2DKernel_small<T, 1,1, 2,2, 4,4, 32,8>;  tileOutW = 32; tileOutH = 8;  }\n", "        if (p.upx == 1 && p.upy == 1 && p.downx == 2 && p.downy == 2 && p.kernelW <= 2 && p.kernelH <= 2) { cudaKernel = (void*)UpFirDn2DKernel_small<T, 1,1, 2,2, 2,2, 32,8>;  tileOutW = 32; tileOutH = 8;  }\n", "        // Choose launch params.\n", "        dim3 blockSize;\n", "        dim3 gridSize;\n", "        if (tileOutW > 0 && tileOutH > 0) // small\n", "        {\n", "            p.loopMajor = (p.majorDim - 1) / 16384 + 1;\n", "            p.loopX = 1;\n", "            blockSize = dim3(32 * 8, 1, 1);\n", "            gridSize = dim3(((p.outH - 1) / tileOutH + 1) * p.minorDim, (p.outW - 1) / (p.loopX * tileOutW) + 1, (p.majorDim - 1) / p.loopMajor + 1);\n", "        }\n", "        else // large\n", "        {\n", "            p.loopMajor = (p.majorDim - 1) / 16384 + 1;\n", "            p.loopX = 4;\n", "            blockSize = dim3(4, 32, 1);\n", "            gridSize = dim3((p.outH * p.minorDim - 1) / blockSize.x + 1, (p.outW - 1) / (p.loopX * blockSize.y) + 1, (p.majorDim - 1) / p.loopMajor + 1);\n", "        }\n", "        // Launch CUDA kernel.\n", "        void* args[] = {&p};\n", "        OP_CHECK_CUDA_ERROR(ctx, cudaLaunchKernel(cudaKernel, gridSize, blockSize, args, 0, stream));\n", "    }\n", "};"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["REGISTER_OP(\"UpFirDn2D\")\n", "    .Input      (\"x: T\")\n", "    .Input      (\"k: T\")\n", "    .Output     (\"y: T\")\n", "    .Attr       (\"T: {float, half}\")\n", "    .Attr       (\"upx: int = 1\")\n", "    .Attr       (\"upy: int = 1\")\n", "    .Attr       (\"downx: int = 1\")\n", "    .Attr       (\"downy: int = 1\")\n", "    .Attr       (\"padx0: int = 0\")\n", "    .Attr       (\"padx1: int = 0\")\n", "    .Attr       (\"pady0: int = 0\")\n", "    .Attr       (\"pady1: int = 0\");\n", "REGISTER_KERNEL_BUILDER(Name(\"UpFirDn2D\").Device(DEVICE_GPU).TypeConstraint<float>(\"T\"), UpFirDn2DOp<float>);\n", "REGISTER_KERNEL_BUILDER(Name(\"UpFirDn2D\").Device(DEVICE_GPU).TypeConstraint<Eigen::half>(\"T\"), UpFirDn2DOp<Eigen::half>);"]}, {"cell_type": "markdown", "metadata": {}, "source": ["//------------------------------------------------------------------------\n<br>\n", "        return res<br>\n", "#   ******************<br>\n", "#   FUNS ONROSA<br>\n", "#   ******************<br>\n", "class Onrosa:<br>\n", "    # _p_ https://github.com/moono/stylegan2-tf-2.x/blob/master/stylegan2/utils.py<br>\n", "    @staticmethod<br>\n", "    def get_weight_initializer_runtime_coef(shape, gain=1, use_wscale=True, lrmul=1):<br>\n", "      \n get initializer and lr coef for different weights shapes\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        fan_in = np.prod(shape[:-1]) # [kernel, kernel, fmaps_in, fmaps_out] or [in, out]\n", "        he_std = gain / np.sqrt(fan_in) # He init\n\n", "        # Equalized learning rate and custom learning rate multiplier.\n", "        if use_wscale:\n", "            init_std = 1.0 / lrmul\n", "            runtime_coef = he_std * lrmul\n", "        else:\n", "            init_std = he_std / lrmul\n", "            runtime_coef = lrmul\n", "        \n", "        return init_std, runtime_coef\n", "    @staticmethod\n", "    def convert_images_to_uint8(images, drange=[-1, 1], nchw_to_nhwc=False, shrink=1, uint8_cast=True):\n", "        \"\"\"Convert a minibatch of images from float32 to uint8 with configurable dynamic range.\n", "        Can be used as an output transformation for Network.run().\n", "        \"\"\"\n", "        images = tf.cast(images, tf.float32)\n", "        if shrink > 1:\n", "            ksize = [1, 1, shrink, shrink]\n", "            images = tf.nn.avg_pool(images, ksize=ksize, strides=ksize, \n", "                                    padding=\"VALID\", data_format=\"NCHW\")\n", "        if nchw_to_nhwc:\n", "            images = tf.transpose(images, [0, 2, 3, 1])\n", "        scale = 255 / (drange[1] - drange[0])\n", "        images = images * scale + (0.5 - drange[0] * scale)\n", "        if uint8_cast:\n", "            images = tf.saturate_cast(images, tf.uint8)\n", "        return images\n", "    @staticmethod\n", "    def nf(stage, fmap_base=16 << 10, fmap_decay=1.0, fmap_min=1, fmap_max=512): \n", "        return np.clip(int(fmap_base / (2.0 ** (stage * fmap_decay))), fmap_min, fmap_max)\n", "    # utils_stylegan2.py <=    "]}, {"cell_type": "markdown", "metadata": {}, "source": ["  ******************<br>\n", "  FUNS ONROLUX<br>\n", "  /rolux/stylegan2encoder/dnnlib/util.py<br>\n", "  ******************"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class Onrolux:\n\n", "    # Functionality to import modules/objects by name, and call functions by name\n", "    # ------------------------------------------------------------------------------------------\n", "    @staticmethod\n", "    def get_module_from_obj_name(obj_name: str) -> Tuple[types.ModuleType, str]:\n", "        \"\"\"Searches for the underlying module behind the name to some python object.\n", "        Returns the module and the object name (original name with module part removed).\"\"\"\n\n", "        # allow convenience shorthands, substitute them by full names\n", "        obj_name = re.sub(\"^np.\", \"numpy.\", obj_name)\n", "        obj_name = re.sub(\"^tf.\", \"tensorflow.\", obj_name)\n\n", "        # list alternatives for (module_name, local_obj_name)\n", "        parts = obj_name.split(\".\")\n", "        name_pairs = [(\".\".join(parts[:i]), \".\".join(parts[i:])) for i in range(len(parts), 0, -1)]\n\n", "        # try each alternative in turn\n", "        for module_name, local_obj_name in name_pairs:\n", "            try:\n", "                module = importlib.import_module(module_name) # may raise ImportError\n", "                get_obj_from_module(module, local_obj_name) # may raise AttributeError\n", "                return module, local_obj_name\n", "            except:\n", "                pass\n\n", "        # maybe some of the modules themselves contain errors?\n", "        for module_name, _local_obj_name in name_pairs:\n", "            try:\n", "                importlib.import_module(module_name) # may raise ImportError\n", "            except ImportError:\n", "                if not str(sys.exc_info()[1]).startswith(\"No module named '\" + module_name + \"'\"):\n", "                    raise\n\n", "        # maybe the requested attribute is missing?\n", "        for module_name, local_obj_name in name_pairs:\n", "            try:\n", "                module = importlib.import_module(module_name) # may raise ImportError\n", "                get_obj_from_module(module, local_obj_name) # may raise AttributeError\n", "            except ImportError:\n", "                pass\n\n", "        # we are out of luck, but we have no idea why\n", "        raise ImportError(obj_name)\n", "    @staticmethod\n", "    def get_obj_from_module(module: types.ModuleType, obj_name: str) -> Any:\n", "        \"\"\"Traverses the object name and returns the last (rightmost) python object.\"\"\"\n", "        if obj_name == '':\n", "            return module\n", "        obj = module\n", "        for part in obj_name.split(\".\"):\n", "            obj = getattr(obj, part)\n", "        return obj\n", "    @staticmethod\n", "    def get_obj_by_name(name: str) -> Any:\n", "        \"\"\"Finds the python object with the given name.\"\"\"\n", "        module, obj_name = Onrolux.get_module_from_obj_name(name)\n", "        return get_obj_from_module(module, obj_name)\n", "    @staticmethod\n", "    def call_func_by_name(*args, func_name: str = None, **kwargs) -> Any:\n", "        \"\"\"Finds the python object with the given name and calls it as a function.\"\"\"\n", "        assert func_name is not None\n", "        func_obj = get_obj_by_name(func_name)\n", "        assert callable(func_obj)\n", "        return func_obj(*args, **kwargs)\n", "    @staticmethod\n", "    def get_module_dir_by_obj_name(obj_name: str) -> str:\n", "        \"\"\"Get the directory path of the module containing the given object name.\"\"\"\n", "        module, _ = Onrolux.get_module_from_obj_name(obj_name)\n", "        return os.path.dirname(inspect.getfile(module))\n", "    @staticmethod\n", "    def is_top_level_function(obj: Any) -> bool:\n", "        \"\"\"Determine whether the given object is a top-level function, i.e., defined at module scope using 'def'.\"\"\"\n", "        return callable(obj) and obj.__name__ in sys.modules[obj.__module__].__dict__\n", "    @staticmethod\n", "    def get_top_level_function_name(obj: Any) -> str:\n", "        \"\"\"Return the fully-qualified name of a top-level function.\"\"\"\n", "        assert is_top_level_function(obj)\n", "        return obj.__module__ + \".\" + obj.__name__\n\n", "    # rolux/stylegan2encoder/dnnlib/tflib/tfutil.py\n", "    def set_vars(var_to_value_dict: dict) -> None:\n", "        [tf.assign(var, value) for var, value in var_to_value_dict.items()]\n", "    def create_var_with_large_initial_value(initial_value: np.ndarray, *args, **kwargs):\n", "        \"\"\"Create tf.Variable with large initial value without bloating the tf graph.\"\"\"\n", "        assert isinstance(initial_value, np.ndarray)\n", "        zeros = tf.zeros(initial_value.shape, initial_value.dtype)\n", "        var = tf.Variable(zeros, *args, **kwargs)\n", "        # Onrolux.set_vars({var: initial_value})\n", "        return var"]}, {"cell_type": "markdown", "metadata": {}, "source": ["  ******************<br>\n", "  ONMOONO<br>\n", "<br>\n", "  ******************"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class Onmoono:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["  ******************<br>\n", "<br>\n", "   -> https://github.com/moono/stylegan2-tf-2.x/tree/master/stylegan2/upfirdn_2d.py <-<br>\n", "<br>\n", "  ******************"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    @staticmethod\n", "    def setup_resample_kernel(k):\n", "        k = np.asarray(k, dtype=np.float32)\n", "        if k.ndim == 1:\n", "            k = np.outer(k, k)\n", "        k /= np.sum(k)\n", "        return k\n", "    @staticmethod\n", "    def upfirdn_ref(x, k, up_x, up_y, down_x, down_y, pad_x0, pad_x1, pad_y0, pad_y1):\n", "        in_height, in_width = tf.shape(x)[1], tf.shape(x)[2]\n", "        minor_dim = tf.shape(x)[3]\n", "        kernel_h, kernel_w = k.shape\n\n", "        # Upsample (insert zeros).\n", "        x = tf.reshape(x, [-1, in_height, 1, in_width, 1, minor_dim])\n", "        x = tf.pad(x, [[0, 0], [0, 0], [0, up_y - 1], [0, 0], [0, up_x - 1], [0, 0]])\n", "        x = tf.reshape(x, [-1, in_height * up_y, in_width * up_x, minor_dim])\n\n", "        # Pad (crop if negative).\n", "        x = tf.pad(x, [\n", "            [0, 0], \n", "            [tf.math.maximum(pad_y0, 0), tf.math.maximum(pad_y1, 0)], \n", "            [tf.math.maximum(pad_x0, 0), tf.math.maximum(pad_x1, 0)], \n", "            [0, 0]\n", "        ])\n", "        x = x[:, tf.math.maximum(-pad_y0, 0): tf.shape(x)[1] - tf.math.maximum(-pad_y1, 0),\n", "            tf.math.maximum(-pad_x0, 0): tf.shape(x)[2] - tf.math.maximum(-pad_x1, 0), :]\n\n", "        # Convolve with filter.\n", "        x = tf.transpose(x, [0, 3, 1, 2])\n", "        x = tf.reshape(x, [-1, 1, in_height * up_y + pad_y0 + pad_y1, in_width * up_x + pad_x0 + pad_x1])\n", "        w = tf.constant(k[::-1, ::-1, np.newaxis, np.newaxis], dtype=x.dtype)\n", "        x = tf.nn.conv2d(x, w, strides=[1, 1, 1, 1], padding='VALID', data_format='NCHW')\n", "        x = tf.reshape(x, [-1,\n", "                        minor_dim,\n", "                        in_height * up_y + pad_y0 + pad_y1 - kernel_h + 1,\n", "                        in_width * up_x + pad_x0 + pad_x1 - kernel_w + 1])\n", "        x = tf.transpose(x, [0, 2, 3, 1])\n\n", "        # Downsample (throw away pixels).\n", "        return x[:, ::down_y, ::down_x, :]\n", "    @staticmethod\n", "    def simple_upfirdn_2d(x, k, up=1, down=1, pad0=0, pad1=0):\n", "        output_channel = tf.shape(x)[1]\n", "        x = tf.reshape(x, [-1, tf.shape(x)[2], tf.shape(x)[3], 1])\n", "        x = Onmoono.upfirdn_ref(x, k,\n", "                        up_x=up, up_y=up, down_x=down, down_y=down, pad_x0=pad0, pad_x1=pad1, pad_y0=pad0, pad_y1=pad1)\n", "        x = tf.reshape(x, [-1, output_channel, tf.shape(x)[1], tf.shape(x)[2]])\n", "        return x\n", "    @staticmethod\n", "    def upsample_conv_2d(x, k, weight, factor, gain):\n", "        x_height, x_width = tf.shape(x)[2], tf.shape(x)[3]\n", "        w_height, w_width = tf.shape(weight)[0], tf.shape(weight)[1]\n", "        w_ic, w_oc = tf.shape(weight)[2], tf.shape(weight)[3]\n\n", "        # Setup filter kernel.\n", "        k = k * (gain * (factor ** 2))\n", "        p = (k.shape[0] - factor) - (w_width - 1)\n", "        pad0 = (p + 1) // 2 + factor - 1\n", "        pad1 = p // 2 + 1\n\n", "        # Determine data dimensions.\n", "        strides = [1, 1, factor, factor]\n", "        output_shape = [1, w_oc, (x_height - 1) * factor + w_height, (x_width - 1) * factor + w_width]\n", "        num_groups = tf.shape(x)[1] // w_ic\n\n", "        # Transpose weights.\n", "        weight = tf.reshape(weight, [w_height, w_width, w_ic, num_groups, -1])\n", "        weight = tf.transpose(weight[::-1, ::-1], [0, 1, 4, 3, 2])\n", "        weight = tf.reshape(weight, [w_height, w_width, -1, num_groups * w_ic])\n\n", "        # Execute.\n", "        x = tf.nn.conv2d_transpose(x, weight, output_shape, strides, padding='VALID', data_format='NCHW')\n", "        x = Onmoono.simple_upfirdn_2d(x, k, pad0=pad0, pad1=pad1)\n", "        return x\n", "    @staticmethod\n", "    def conv_downsample_2d(x, k, weight, factor, gain):\n", "        w_height, w_width = tf.shape(weight)[0], tf.shape(weight)[1]\n\n", "        # Setup filter kernel.\n", "        k = k * gain\n", "        p = (k.shape[0] - factor) + (w_width - 1)\n", "        pad0 = (p + 1) // 2\n", "        pad1 = p // 2\n", "        strides = [1, 1, factor, factor]\n", "        x = Onmoono.simple_upfirdn_2d(x, k, pad0=pad0, pad1=pad1)\n", "        x = tf.nn.conv2d(x, weight, strides, padding='VALID', data_format='NCHW')\n", "        return x\n", "    @staticmethod\n", "    def upsample_2d(x, k, factor, gain):\n", "        # Setup filter kernel.\n", "        k = k * (gain * (factor ** 2))\n", "        p = k.shape[0] - factor\n", "        pad0 = (p + 1) // 2 + factor - 1\n", "        pad1 = p // 2\n", "        x = Onmoono.simple_upfirdn_2d(x, k, up=factor, pad0=pad0, pad1=pad1)\n", "        return x\n", "    @staticmethod\n", "    def downsample_2d(x, k, factor, gain):\n", "        # Setup filter kernel.\n", "        k = k * gain\n", "        p = k.shape[0] - factor\n", "        pad0 = (p + 1) // 2\n", "        pad1 = p // 2\n", "        x = Onmoono.simple_upfirdn_2d(x, k, down=factor, pad0=pad0, pad1=pad1)\n", "        return x"]}, {"cell_type": "markdown", "metadata": {}, "source": ["  ******************<br>\n", "<br>\n", "   -> https://github.com/moono/stylegan2-tf-2.x/tree/master/stylegan2/custom_layers.py <-<br>\n", "<br>\n", "  ******************"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    @staticmethod\n", "    def compute_runtime_coef(weight_shape, gain, lrmul):\n", "        fan_in = np.prod(weight_shape[:-1])  # [kernel, kernel, fmaps_in, fmaps_out] or [in, out]\n", "        he_std = gain / np.sqrt(fan_in)\n", "        init_std = 1.0 / lrmul\n", "        runtime_coef = he_std * lrmul\n", "        return init_std, runtime_coef"]}, {"cell_type": "markdown", "metadata": {}, "source": ["  ******************<br>\n", "<br>\n", "   -> https://github.com/moono/stylegan2-tf-2.x/blob/master/stylegan2/utils.py <-<br>\n", "<br>\n", "  ******************"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    @staticmethod\n", "    def lerp(a, b, t):\n", "        out = a + (b - a) * t\n", "        return out\n", "    @staticmethod\n", "    def lerp_clip(a, b, t):\n", "        out = a + (b - a) * tf.clip_by_value(t, 0.0, 1.0)\n", "        return out\n", "    @staticmethod\n", "    def adjust_dynamic_range(images, range_in, range_out, out_dtype):\n", "        scale = (range_out[1] - range_out[0]) / (range_in[1] - range_in[0])\n", "        bias = range_out[0] - range_in[0] * scale\n", "        images = images * scale + bias\n", "        images = tf.clip_by_value(images, range_out[0], range_out[1])\n", "        images = tf.cast(images, dtype=out_dtype)\n", "        return images\n", "    @staticmethod\n", "    def random_flip_left_right_nchw(images):\n", "        s = tf.shape(images)\n", "        mask = tf.random.uniform([s[0], 1, 1, 1], 0.0, 1.0)\n", "        mask = tf.tile(mask, [1, s[1], s[2], s[3]])\n", "        images = tf.where(mask < 0.5, images, tf.reverse(images, axis=[3]))\n", "        return images\n", "    @staticmethod\n", "    def preprocess_fit_train_image(images, res):\n", "        images = Onmoono.adjust_dynamic_range(images, range_in=(0.0, 255.0), range_out=(-1.0, 1.0), out_dtype=tf.dtypes.float32)\n", "        images = Onmoono.random_flip_left_right_nchw(images)\n", "        images.set_shape([None, 3, res, res])\n", "        return images\n", "    @staticmethod\n", "    def postprocess_images(images):\n", "        images = Onmoono.adjust_dynamic_range(images, range_in=(-1.0, 1.0), range_out=(0.0, 255.0), out_dtype=tf.dtypes.float32)\n", "        images = tf.transpose(images, [0, 2, 3, 1])\n", "        images = tf.cast(images, dtype=tf.dtypes.uint8)\n", "        return images\n", "    @staticmethod\n", "    def merge_batch_images(images, res, rows, cols):\n", "        batch_size = images.shape[0]\n", "        assert rows * cols == batch_size\n", "        canvas = np.zeros(shape=[res * rows, res * cols, 3], dtype=np.uint8)\n", "        for row in range(rows):\n", "            y_start = row * res\n", "            for col in range(cols):\n", "                x_start = col * res\n", "                index = col + row * cols\n", "                canvas[y_start:y_start + res, x_start:x_start + res, :] = images[index, :, :, :]\n", "        return canvas"]}, {"cell_type": "markdown", "metadata": {}, "source": ["  ******************<br>\n", "<br>\n", "   -> https://github.com/moono/stylegan2-tf-2.x/blob/master/train.py <-<br>\n", "<br>\n", "  ******************"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    @staticmethod\n", "    def filter_resolutions_featuremaps(resolutions, featuremaps, res):\n", "        index = resolutions.index(res)\n", "        filtered_resolutions = resolutions[:index + 1]\n", "        filtered_featuremaps = featuremaps[:index + 1]\n", "        return filtered_resolutions, filtered_featuremaps"]}, {"cell_type": "markdown", "metadata": {}, "source": ["  ******************<br>\n", "  Moono<br>\n", "  https://github.com/moono/stylegan2-encoder/blob/master/utils.py<br>\n", "  https://github.com/moono/stylegan2-tf-2.x/tree/master/stylegan2/tf_utils/utils.py<br>\n", "<br>\n", "  ******************"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    @staticmethod\n", "    def allow_memory_growth():\n", "        gpus = tf.config.experimental.list_physical_devices('GPU')\n", "        if gpus:\n", "            try:\n", "                # Currently, memory growth needs to be the same across GPUs\n", "                for gpu in gpus:\n", "                    tf.config.experimental.set_memory_growth(gpu, True)\n", "                logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n", "                print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n", "            except RuntimeError as e:\n", "                # Memory growth must be set before GPUs have been initialized\n", "                print(e)\n", "        return\n", "    @staticmethod\n", "    def adjust_dynamic_range(images, range_in, range_out, out_dtype):\n", "        scale = (range_out[1] - range_out[0]) / (range_in[1] - range_in[0])\n", "        bias = range_out[0] - range_in[0] * scale\n", "        images = images * scale + bias\n", "        images = tf.clip_by_value(images, range_out[0], range_out[1])\n", "        images = tf.cast(images, dtype=out_dtype)\n", "        return images"]}, {"cell_type": "markdown", "metadata": {}, "source": ["  ******************<br>\n", "  Moono<br>\n", "  https://github.com/lllyasviel/DanbooRegion/<br>\n", "  see licensing terms in https://github.com/lllyasviel/DanbooRegion<br>\n", "<br>\n", "  ******************<br>\n", "<br>\n", "  ******************"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class Onlllyas:\n", "    #   https://github.com/lllyasviel/DanbooRegion/blob/master/code/tricks.py\n", "    @staticmethod\n", "    def thinning(fillmap, max_iter=100):\n", "        \"\"\"Fill area of line with surrounding fill color.\n", "        # Arguments\n", "            fillmap: an image.\n", "            max_iter: max iteration number.\n", "        # Returns\n", "            an image.\n", "        \"\"\"\n", "        line_id = 0\n", "        h, w = fillmap.shape[:2]\n", "        result = fillmap.copy()\n", "        for iterNum in range(max_iter):\n", "            # Get points of line. if there is not point, stop.\n", "            line_points = np.where(result == line_id)\n", "            if not len(line_points[0]) > 0:\n", "                break\n\n", "            # Get points between lines and fills.\n", "            line_mask = np.full((h, w), 255, np.uint8)\n", "            line_mask[line_points] = 0\n", "            line_border_mask = cv2.morphologyEx(line_mask, cv2.MORPH_DILATE,\n", "                                                cv2.getStructuringElement(cv2.MORPH_CROSS, (3, 3)), anchor=(-1, -1),\n", "                                                iterations=1) - line_mask\n", "            line_border_points = np.where(line_border_mask == 255)\n", "            result_tmp = result.copy()\n", "            # Iterate over points, fill each point with nearest fill's id.\n", "            for i, _ in enumerate(line_border_points[0]):\n", "                x, y = line_border_points[1][i], line_border_points[0][i]\n", "                if x - 1 > 0 and result[y][x - 1] != line_id:\n", "                    result_tmp[y][x] = result[y][x - 1]\n", "                    continue\n", "                if x - 1 > 0 and y - 1 > 0 and result[y - 1][x - 1] != line_id:\n", "                    result_tmp[y][x] = result[y - 1][x - 1]\n", "                    continue\n", "                if y - 1 > 0 and result[y - 1][x] != line_id:\n", "                    result_tmp[y][x] = result[y - 1][x]\n", "                    continue\n", "                if y - 1 > 0 and x + 1 < w and result[y - 1][x + 1] != line_id:\n", "                    result_tmp[y][x] = result[y - 1][x + 1]\n", "                    continue\n", "                if x + 1 < w and result[y][x + 1] != line_id:\n", "                    result_tmp[y][x] = result[y][x + 1]\n", "                    continue\n", "                if x + 1 < w and y + 1 < h and result[y + 1][x + 1] != line_id:\n", "                    result_tmp[y][x] = result[y + 1][x + 1]\n", "                    continue\n", "                if y + 1 < h and result[y + 1][x] != line_id:\n", "                    result_tmp[y][x] = result[y + 1][x]\n", "                    continue\n", "                if y + 1 < h and x - 1 > 0 and result[y + 1][x - 1] != line_id:\n", "                    result_tmp[y][x] = result[y + 1][x - 1]\n", "                    continue\n", "            result = result_tmp.copy()\n", "        return result\n", "    @staticmethod\n", "    def topo_compute_normal(dist):\n", "        c = cv2.filter2D(dist, cv2.CV_32F, np.array([[-1, +1]]))\n", "        r = cv2.filter2D(dist, cv2.CV_32F, np.array([[-1], [+1]]))\n", "        h = np.zeros_like(c + r, dtype=np.float32) + 0.75\n", "        normal_map = np.stack([h, r, c], axis=2)\n", "        normal_map /= np.sum(normal_map ** 2.0, axis=2, keepdims=True) ** 0.5\n", "        return normal_map"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    @staticmethod    \n", "    #@njit\n", "    def count_all(labeled_array, all_counts):\n", "        #labeled_array:  [[[0 0 1]\n", "        #                  [0 0 1]\n", "        #                  [0 0 1]\n", "        #                  ...\n", "        M = labeled_array.shape[0] # 2048\n", "        N = labeled_array.shape[1] # 2048\n", "        print(\"count_all MN \", M, N)\n", "        for x in range(M):\n", "            for y in range(N):\n", "                i = labeled_array[x, y] - 1 # [-1 -1  0]\n", "                if i > -1:\n", "                    all_counts[i] = all_counts[i] + 1\n", "        return"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    @staticmethod    \n", "    @njit\n", "    def trace_all(labeled_array, xs, ys, cs):\n", "        M = labeled_array.shape[0]\n", "        N = labeled_array.shape[1]\n", "        for x in range(M):\n", "            for y in range(N):\n", "                current_label = labeled_array[x, y] - 1\n", "                if current_label > -1:\n", "                    current_label_count = cs[current_label]\n", "                    xs[current_label][current_label_count] = x\n", "                    ys[current_label][current_label_count] = y\n", "                    cs[current_label] = current_label_count + 1\n", "        return\n", "    @staticmethod\n", "    def find_all(labeled_array):\n", "        hist_size = int(np.max(labeled_array))\n", "        if hist_size == 0:\n", "            return []\n", "        all_counts = [0 for _ in range(hist_size)]\n", "        Onlllyas.count_all(labeled_array, all_counts)\n", "        xs = [np.zeros(shape=(item, ), dtype=np.uint32) for item in all_counts]\n", "        ys = [np.zeros(shape=(item, ), dtype=np.uint32) for item in all_counts]\n", "        cs = [0 for item in all_counts]\n", "        Onlllyas.trace_all(labeled_array, xs, ys, cs)\n", "        filled_area = []\n", "        for _ in range(hist_size):\n", "            filled_area.append((xs[_], ys[_]))\n", "        return filled_area\n", "    @staticmethod\n", "    def mk_resize(x, k):\n", "        if x.shape[0] < x.shape[1]:\n", "            s0 = k\n", "            s1 = int(x.shape[1] * (k / x.shape[0]))\n", "            s1 = s1 - s1 % 128\n", "            _s0 = 32 * s0\n", "            _s1 = int(x.shape[1] * (_s0 / x.shape[0]))\n", "            _s1 = (_s1 + 64) - (_s1 + 64) % 128\n", "        else:\n", "            s1 = k\n", "            s0 = int(x.shape[0] * (k / x.shape[1]))\n", "            s0 = s0 - s0 % 128\n", "            _s1 = 32 * s1\n", "            _s0 = int(x.shape[0] * (_s1 / x.shape[1]))\n", "            _s0 = (_s0 + 64) - (_s0 + 64) % 128\n", "        new_min = min(_s1, _s0)\n", "        raw_min = min(x.shape[0], x.shape[1])\n", "        if new_min < raw_min:\n", "            interpolation = cv2.INTER_AREA\n", "        else:\n", "            interpolation = cv2.INTER_LANCZOS4\n", "        y = cv2.resize(x, (_s1, _s0), interpolation=interpolation)\n", "        return y\n", "    @staticmethod\n", "    def k_resize(x, k):\n", "        if x.shape[0] < x.shape[1]:\n", "            s0 = k\n", "            s1 = int(x.shape[1] * (k / x.shape[0]))\n", "            s1 = s1 - s1 % 64\n", "            _s0 = 16 * s0\n", "            _s1 = int(x.shape[1] * (_s0 / x.shape[0]))\n", "            _s1 = (_s1 + 32) - (_s1 + 32) % 64\n", "        else:\n", "            s1 = k\n", "            s0 = int(x.shape[0] * (k / x.shape[1]))\n", "            s0 = s0 - s0 % 64\n", "            _s1 = 16 * s1\n", "            _s0 = int(x.shape[0] * (_s1 / x.shape[1]))\n", "            _s0 = (_s0 + 32) - (_s0 + 32) % 64\n", "        new_min = min(_s1, _s0)\n", "        raw_min = min(x.shape[0], x.shape[1])\n", "        if new_min < raw_min:\n", "            interpolation = cv2.INTER_AREA\n", "        else:\n", "            interpolation = cv2.INTER_LANCZOS4\n", "        y = cv2.resize(x, (_s1, _s0), interpolation=interpolation)\n", "        return y\n", "    @staticmethod\n", "    def sk_resize(x, k):\n", "        if x.shape[0] < x.shape[1]:\n", "            s0 = k\n", "            s1 = int(x.shape[1] * (k / x.shape[0]))\n", "            s1 = s1 - s1 % 16\n", "            _s0 = 4 * s0\n", "            _s1 = int(x.shape[1] * (_s0 / x.shape[0]))\n", "            _s1 = (_s1 + 8) - (_s1 + 8) % 16\n", "        else:\n", "            s1 = k\n", "            s0 = int(x.shape[0] * (k / x.shape[1]))\n", "            s0 = s0 - s0 % 16\n", "            _s1 = 4 * s1\n", "            _s0 = int(x.shape[0] * (_s1 / x.shape[1]))\n", "            _s0 = (_s0 + 8) - (_s0 + 8) % 16\n", "        new_min = min(_s1, _s0)\n", "        raw_min = min(x.shape[0], x.shape[1])\n", "        if new_min < raw_min:\n", "            interpolation = cv2.INTER_AREA\n", "        else:\n", "            interpolation = cv2.INTER_LANCZOS4\n", "        y = cv2.resize(x, (_s1, _s0), interpolation=interpolation)\n", "        return y\n", "    @staticmethod\n", "    def d_resize(x, d, fac=1.0):\n", "        new_min = min(int(d[1] * fac), int(d[0] * fac))\n", "        raw_min = min(x.shape[0], x.shape[1])\n", "        if new_min < raw_min:\n", "            interpolation = cv2.INTER_AREA\n", "        else:\n", "            interpolation = cv2.INTER_LANCZOS4\n", "        y = cv2.resize(x, (int(d[1] * fac), int(d[0] * fac)), interpolation=interpolation)\n", "        return y\n", "    @staticmethod\n", "    def n_resize(x, d):\n", "        y = cv2.resize(x, (d[1], d[0]), interpolation=cv2.INTER_NEAREST)\n", "        return y\n", "    @staticmethod\n", "    def s_resize(x, s):\n", "        if x.shape[0] < x.shape[1]:\n", "            s0 = x.shape[0]\n", "            s1 = int(float(s0) / float(s[0]) * float(s[1]))\n", "        else:\n", "            s1 = x.shape[1]\n", "            s0 = int(float(s1) / float(s[1]) * float(s[0]))\n", "        new_max = max(s1, s0)\n", "        raw_max = max(x.shape[0], x.shape[1])\n", "        if new_max < raw_max:\n", "            interpolation = cv2.INTER_AREA\n", "        else:\n", "            interpolation = cv2.INTER_LANCZOS4\n", "        y = cv2.resize(x, (s1, s0), interpolation=interpolation)\n", "        return y\n", "    @staticmethod\n", "    def min_resize(x, m):\n", "        if x.shape[0] < x.shape[1]:\n", "            s0 = m\n", "            s1 = int(float(m) / float(x.shape[0]) * float(x.shape[1]))\n", "        else:\n", "            s0 = int(float(m) / float(x.shape[1]) * float(x.shape[0]))\n", "            s1 = m\n", "        new_max = max(s1, s0)\n", "        raw_max = max(x.shape[0], x.shape[1])\n", "        if new_max < raw_max:\n", "            interpolation = cv2.INTER_AREA\n", "        else:\n", "            interpolation = cv2.INTER_LANCZOS4\n", "        y = cv2.resize(x, (s1, s0), interpolation=interpolation)\n", "        return y\n", "    @staticmethod\n", "    def n_min_resize(x, m):\n", "        if x.shape[0] < x.shape[1]:\n", "            s0 = m\n", "            s1 = int(float(m) / float(x.shape[0]) * float(x.shape[1]))\n", "        else:\n", "            s0 = int(float(m) / float(x.shape[1]) * float(x.shape[0]))\n", "            s1 = m\n", "        new_max = max(s1, s0)\n", "        raw_max = max(x.shape[0], x.shape[1])\n", "        y = cv2.resize(x, (s1, s0), interpolation=cv2.INTER_NEAREST)\n", "        return y\n", "    @staticmethod\n", "    def h_resize(x, m):\n", "        s0 = m\n", "        s1 = int(float(m) / float(x.shape[0]) * float(x.shape[1]))\n", "        new_max = max(s1, s0)\n", "        raw_max = max(x.shape[0], x.shape[1])\n", "        if new_max < raw_max:\n", "            interpolation = cv2.INTER_AREA\n", "        else:\n", "            interpolation = cv2.INTER_LANCZOS4\n", "        y = cv2.resize(x, (s1, s0), interpolation=interpolation)\n", "        return y\n", "    @staticmethod\n", "    def w_resize(x, m):\n", "        s0 = int(float(m) / float(x.shape[1]) * float(x.shape[0]))\n", "        s1 = m\n", "        new_max = max(s1, s0)\n", "        raw_max = max(x.shape[0], x.shape[1])\n", "        if new_max < raw_max:\n", "            interpolation = cv2.INTER_AREA\n", "        else:\n", "            interpolation = cv2.INTER_LANCZOS4\n", "        y = cv2.resize(x, (s1, s0), interpolation=interpolation)\n", "        return y\n", "    @staticmethod\n", "    def max_resize(x, m):\n", "        if x.shape[0] > x.shape[1]:\n", "            s0 = m\n", "            s1 = int(float(m) / float(x.shape[0]) * float(x.shape[1]))\n", "        else:\n", "            s0 = int(float(m) / float(x.shape[1]) * float(x.shape[0]))\n", "            s1 = m\n", "        new_max = max(s1, s0)\n", "        raw_max = max(x.shape[0], x.shape[1])\n", "        if new_max < raw_max:\n", "            interpolation = cv2.INTER_AREA\n", "        else:\n", "            interpolation = cv2.INTER_LANCZOS4\n", "        y = cv2.resize(x, (s1, s0), interpolation=interpolation)\n", "        return y\n", "    @staticmethod\n", "    def vis(region_map, color_map):\n", "        color = Onlllyas.d_resize(color_map, region_map.shape)\n", "        indexs = (region_map.astype(np.float32)[:, :, 0] * 255 + region_map.astype(np.float32)[:, :, 1]) * 255 + region_map.astype(np.float32)[:, :, 2]\n", "        result = np.zeros_like(color, dtype=np.uint8)\n", "        for ids in [np.where(indexs == idsn) for idsn in np.unique(indexs).tolist()]:\n", "            result[ids] = np.median(color[ids], axis=0)\n", "        return result"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    # https://github.com/lllyasviel/DanbooRegion/blob/master/code/skeletonize.py\n", "    @staticmethod   \n", "    def get_skeleton(region_map, filterstrength=5.0):\n", "        from skimage.morphology import skeletonize, dilation    \n", "        Xp = np.pad(region_map, [[0, 1], [0, 0], [0, 0]], 'symmetric').astype(np.float32)\n", "        Yp = np.pad(region_map, [[0, 0], [0, 1], [0, 0]], 'symmetric').astype(np.float32)\n", "        X = np.sum((Xp[1:, :, :] - Xp[:-1, :, :]) ** 2.0, axis=2) ** 0.5\n", "        Y = np.sum((Yp[:, 1:, :] - Yp[:, :-1, :]) ** 2.0, axis=2) ** 0.5\n", "        edge = np.zeros_like(region_map)[:, :, 0]\n", "        edge[X > 0] = 255\n", "        edge[Y > 0] = 255\n", "        edge[0, :] = 255\n", "        edge[-1, :] = 255\n", "        edge[:, 0] = 255\n", "        edge[:, -1] = 255\n", "        skeleton = 1.0 - dilation(edge.astype(np.float32) / 255.0)\n", "        skeleton = skeletonize(skeleton)\n", "        skeleton = (skeleton * 255.0).clip(0, 255).astype(np.uint8)\n", "        field = np.random.uniform(low=0.0, high=255.0, size=edge.shape).clip(0, 255).astype(np.uint8)\n", "        field[skeleton > 0] = 255\n", "        field[edge > 0] = 0\n", "        filter = np.array([\n", "            [0, 1, 0],\n", "            [1, 1, 1],\n", "            [0, 1, 0]],\n", "            dtype=np.float32) / filterstrength\n", "        height = np.random.uniform(low=0.0, high=255.0, size=field.shape).astype(np.float32)\n", "        for _ in range(512):\n", "            height = cv2.filter2D(height, cv2.CV_32F, filter)\n", "            height[skeleton > 0] = 255.0\n", "            height[edge > 0] = 0.0\n", "        return height.clip(0, 255).astype(np.uint8)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    # https://github.com/lllyasviel/DanbooRegion/blob/master/code/skeleton2regions.py\n", "    @staticmethod \n", "    def skeleton_to_regions(skeleton_map): # get_regions\n", "        marker = skeleton_map[:, :, 0]\n", "        normal = Onlllyas.topo_compute_normal(marker) * 127.5 + 127.5\n", "        marker[marker > 100] = 255\n", "        marker[marker < 255] = 0\n", "        labels, nil = label(marker / 255)\n", "        water = cv2.watershed(normal.clip(0, 255).astype(np.uint8), labels.astype(np.int32)) + 1\n", "        water = Onlllyas.thinning(water)\n", "        all_region_indices = Onlllyas.find_all(water)\n", "        regions = np.zeros_like(skeleton_map, dtype=np.uint8)\n", "        for region_indices in all_region_indices:\n", "            regions[region_indices] = np.random.randint(low=0, high=255, size=(3,)).clip(0, 255).astype(np.uint8)\n", "        return regions"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    # https://github.com/lllyasviel/DanbooRegion/blob/master/code/rotate.py\n", "    @staticmethod \n", "    def rotate_image(image, angle):\n", "        \"\"\"\n", "        Rotates an OpenCV 2 / NumPy image about it's centre by the given angle\n", "        (in degrees). The returned image will be large enough to hold the entire\n", "        new image, with a black background\n", "        \"\"\"\n\n", "        # Get the image size\n", "        # No that's not an error - NumPy stores image matricies backwards\n", "        image_size = (image.shape[1], image.shape[0])\n", "        image_center = tuple(np.array(image_size) / 2)\n\n", "        # Convert the OpenCV 3x2 rotation matrix to 3x3\n", "        rot_mat = np.vstack(\n", "            [cv2.getRotationMatrix2D(image_center, angle, 1.0), [0, 0, 1]]\n", "        )\n", "        rot_mat_notranslate = np.matrix(rot_mat[0:2, 0:2])\n\n", "        # Shorthand for below calcs\n", "        image_w2 = image_size[0] * 0.5\n", "        image_h2 = image_size[1] * 0.5\n\n", "        # Obtain the rotated coordinates of the image corners\n", "        rotated_coords = [\n", "            (np.array([-image_w2,  image_h2]) * rot_mat_notranslate).A[0],\n", "            (np.array([ image_w2,  image_h2]) * rot_mat_notranslate).A[0],\n", "            (np.array([-image_w2, -image_h2]) * rot_mat_notranslate).A[0],\n", "            (np.array([ image_w2, -image_h2]) * rot_mat_notranslate).A[0]\n", "        ]\n\n", "        # Find the size of the new image\n", "        x_coords = [pt[0] for pt in rotated_coords]\n", "        x_pos = [x for x in x_coords if x > 0]\n", "        x_neg = [x for x in x_coords if x < 0]\n", "        y_coords = [pt[1] for pt in rotated_coords]\n", "        y_pos = [y for y in y_coords if y > 0]\n", "        y_neg = [y for y in y_coords if y < 0]\n", "        right_bound = max(x_pos)\n", "        left_bound = min(x_neg)\n", "        top_bound = max(y_pos)\n", "        bot_bound = min(y_neg)\n", "        new_w = int(abs(right_bound - left_bound))\n", "        new_h = int(abs(top_bound - bot_bound))\n\n", "        # We require a translation matrix to keep the image centred\n", "        trans_mat = np.matrix([\n", "            [1, 0, int(new_w * 0.5 - image_w2)],\n", "            [0, 1, int(new_h * 0.5 - image_h2)],\n", "            [0, 0, 1]\n", "        ])\n\n", "        # Compute the tranform for the combined rotation and translation\n", "        affine_mat = (np.matrix(trans_mat) * np.matrix(rot_mat))[0:2, :]\n\n", "        # Apply the transform\n", "        result = cv2.warpAffine(\n", "            image,\n", "            affine_mat,\n", "            (new_w, new_h),\n", "            flags=cv2.INTER_LINEAR\n", "        )\n", "        return result\n", "    @staticmethod \n", "    def largest_rotated_rect(w, h, angle):\n", "        \"\"\"\n", "        Given a rectangle of size wxh that has been rotated by 'angle' (in\n", "        radians), computes the width and height of the largest possible\n", "        axis-aligned rectangle within the rotated rectangle.\n", "        Original JS code by 'Andri' and Magnus Hoff from Stack Overflow\n", "        Converted to Python by Aaron Snoswell\n", "        \"\"\"\n", "        quadrant = int(math.floor(angle / (math.pi / 2))) & 3\n", "        sign_alpha = angle if ((quadrant & 1) == 0) else math.pi - angle\n", "        alpha = (sign_alpha % math.pi + math.pi) % math.pi\n", "        bb_w = w * math.cos(alpha) + h * math.sin(alpha)\n", "        bb_h = w * math.sin(alpha) + h * math.cos(alpha)\n", "        gamma = math.atan2(bb_w, bb_w) if (w < h) else math.atan2(bb_w, bb_w)\n", "        delta = math.pi - alpha - gamma\n", "        length = h if (w < h) else w\n", "        d = length * math.cos(alpha)\n", "        a = d * math.sin(alpha) / math.sin(delta)\n", "        y = a * math.cos(gamma)\n", "        x = y * math.tan(gamma)\n", "        return (\n", "            bb_w - 2 * x,\n", "            bb_h - 2 * y\n", "        )\n", "    @staticmethod \n", "    def crop_around_center(image, width, height):\n", "        \"\"\"\n", "        Given a NumPy / OpenCV 2 image, crops it to the given width and height,\n", "        around it's centre point\n", "        \"\"\"\n", "        image_size = (image.shape[1], image.shape[0])\n", "        image_center = (int(image_size[0] * 0.5), int(image_size[1] * 0.5))\n", "        if(width > image_size[0]):\n", "            width = image_size[0]\n", "        if(height > image_size[1]):\n", "            height = image_size[1]\n", "        x1 = int(image_center[0] - width * 0.5)\n", "        x2 = int(image_center[0] + width * 0.5)\n", "        y1 = int(image_center[1] - height * 0.5)\n", "        y2 = int(image_center[1] + height * 0.5)\n", "        return image[y1:y2, x1:x2]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    # https://github.com/lllyasviel/DanbooRegion/blob/master/code/datasets.py\n", "    @staticmethod \n", "    def np_RGB2GRAY(img):\n", "        R = img[:, :, 0].astype(np.float32)\n", "        G = img[:, :, 1].astype(np.float32)\n", "        B = img[:, :, 2].astype(np.float32)\n", "        r = np.random.rand()\n", "        g = np.random.rand()\n", "        b = np.random.rand()\n", "        s = r + g + b\n", "        r /= s\n", "        g /= s\n", "        b /= s\n", "        light = R * r + G * g + B * b\n", "        light -= np.min(light)\n", "        light /= np.max(light)\n", "        a = np.random.rand() * 0.4\n", "        b = 1 - np.random.rand() * 0.4\n", "        light = light.clip(a, b)\n", "        light -= np.min(light)\n", "        light /= np.max(light)\n", "        light = light.clip(0, 1)\n", "        light = (light * 255.0).astype(np.uint8)\n", "        return light\n", "    @staticmethod \n", "    def handle_next():\n", "        indice = np.random.randint(low=0, high=3377)\n", "        paint_r_mat = cv2.imread('./DanbooRegion2020/train/' + str(indice) + '.image.png')\n", "        sketch_r_mat = cv2.imread('./DanbooRegion2020/train/' + str(indice) + '.skeleton.png')\n", "        image_height, image_width = sketch_r_mat.shape[0:2]\n", "        paint_r_mat = Onlllyas.d_resize(paint_r_mat, sketch_r_mat.shape)\n", "        if np.random.rand() < 0.5:\n", "            ri = np.random.rand() * 360.0\n", "            paint_r_mat = crop_around_center(rotate_image(paint_r_mat, ri), *largest_rotated_rect(image_width, image_height, math.radians(ri)))\n", "            sketch_r_mat = crop_around_center(rotate_image(sketch_r_mat, ri), *largest_rotated_rect(image_width, image_height, math.radians(ri)))\n", "            kernel = np.random.randint(520, 650)\n", "        else:\n", "            kernel = np.random.randint(520, 1024)\n", "        raw_s0 = float(paint_r_mat.shape[0])\n", "        raw_s1 = float(paint_r_mat.shape[1])\n", "        if raw_s0 < raw_s1:\n", "            new_s0 = int(kernel)\n", "            new_s1 = int(kernel / raw_s0 * raw_s1)\n", "        else:\n", "            new_s1 = int(kernel)\n", "            new_s0 = int(kernel / raw_s1 * raw_s0)\n", "        c0 = int(np.random.rand() * float(new_s0 - 512))\n", "        c1 = int(np.random.rand() * float(new_s1 - 512))\n", "        paint_mat = Onlllyas.d_resize(paint_r_mat, (new_s0, new_s1))[c0:c0 + 512, c1:c1 + 512, :]\n", "        sketch_mat = Onlllyas.d_resize(sketch_r_mat, (new_s0, new_s1))[c0:c0 + 512, c1:c1 + 512, 0:1]\n", "        if np.random.rand() < 0.5:\n", "            sketch_mat = np.fliplr(sketch_mat)\n", "            paint_mat = np.fliplr(paint_mat)\n", "        if np.random.rand() < 0.5:\n", "            sketch_mat = np.flipud(sketch_mat)\n", "            paint_mat = np.flipud(paint_mat)\n", "        if np.random.rand() < 0.5:\n", "            paint_mat = np.stack([np_RGB2GRAY(paint_mat), np_RGB2GRAY(paint_mat), np_RGB2GRAY(paint_mat)], axis=2)\n", "        if np.random.rand() < 0.5:\n", "            for _ in range(int(np.random.randint(low=0, high=5))):\n", "                paint_mat = cv2.GaussianBlur(paint_mat, (0, 0), 2.0)\n", "        if np.random.rand() < 0.5:\n", "            for _ in range(int(np.random.randint(low=0, high=5))):\n", "                paint_mat = cv2.medianBlur(paint_mat, 3)\n", "        return sketch_mat, paint_mat\n", "    @staticmethod \n", "    def handle_batch(batch_size=4):\n", "        sketch_batch = []\n", "        paint_batch = []\n", "        for _ in range(batch_size):\n", "            sketch_mat, paint_mat = handle_next()\n", "            sketch_batch.append(sketch_mat)\n", "            paint_batch.append(paint_mat)\n", "        sketch_batch = np.stack(sketch_batch, axis=0)\n", "        paint_batch = np.stack(paint_batch, axis=0)\n", "        return sketch_batch, paint_batch"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    # https://github.com/lllyasviel/DanbooRegion/blob/master/code/segment.py\n", "    @staticmethod     \n", "    def go_flipped_vector(x):\n", "        #a = go_vector(x)\n", "        #b = np.fliplr(go_vector(np.fliplr(x)))\n", "        #c = np.flipud(go_vector(np.flipud(x)))\n", "        #d = np.flipud(np.fliplr(go_vector(np.flipud(np.fliplr(x)))))\n", "        print(f'go_flipped_vector: {type(x)} {np.shape(x)}')\n", "        a = x # <class 'numpy.ndarray'> (2944, 2048, 3)\n", "        b = np.fliplr(np.fliplr(x))\n", "        c = np.flipud(np.flipud(x))\n", "        d = np.flipud(np.fliplr(np.flipud(np.fliplr(x))))\n", "        return (a + b + c + d) / 4.0\n", "    @staticmethod \n", "    def go_transposed_vector(x):\n", "        a = Onlllyas.go_flipped_vector(x)\n", "        b = np.transpose(Onlllyas.go_flipped_vector(np.transpose(x, [1, 0, 2])), [1, 0, 2])\n", "        return (a + b) / 2.0"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    #https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.label.html\n", "    from scipy.ndimage import label\n", "    @staticmethod \n", "    def get_fill(image):\n", "        labeled_array, num_features = label(image / 255)\n", "        # num_features: 357\n", "        # labeled_array: <class 'numpy.ndarray'> (2048, 2048, 3)\n", "        # labeled_array: [[[0 0 1] [0 0 1] [0 0 1] ...\n", "        filled_area = Onlllyas.find_all(labeled_array)\n", "        return filled_area\n", "    @staticmethod \n", "    def up_fill(fills, cur_fill_map):\n", "        new_fillmap = cur_fill_map.copy()\n", "        padded_fillmap = np.pad(cur_fill_map, [[1, 1], [1, 1]], 'constant', constant_values=0)\n", "        max_id = np.max(cur_fill_map)\n", "        for item in fills:\n", "            points0 = padded_fillmap[(item[0] + 1, item[1] + 0)]\n", "            points1 = padded_fillmap[(item[0] + 1, item[1] + 2)]\n", "            points2 = padded_fillmap[(item[0] + 0, item[1] + 1)]\n", "            points3 = padded_fillmap[(item[0] + 2, item[1] + 1)]\n", "            all_points = np.concatenate([points0, points1, points2, points3], axis=0)\n", "            pointsets, pointcounts = np.unique(all_points[all_points > 0], return_counts=True)\n", "            if len(pointsets) == 1 and item[0].shape[0] < 128:\n", "                new_fillmap[item] = pointsets[0]\n", "            else:\n", "                max_id += 1\n", "                new_fillmap[item] = max_id\n", "        return new_fillmap\n", "    @staticmethod \n", "    def segment(image):\n", "        #raw_img = go_srcnn(Onlllyas.min_resize(image, 512)).clip(0, 255).astype(np.uint8)\n", "        raw_img = image\n", "        img_2048 = Onlllyas.min_resize(raw_img, 2048)\n", "        height = Onlllyas.d_resize(Onlllyas.go_transposed_vector(Onlllyas.mk_resize(raw_img, 64)), img_2048.shape) * 255.0\n", "        final_height = height.copy()\n", "        height += (height - cv2.GaussianBlur(height, (0, 0), 3.0)) * 10.0\n", "        height = height.clip(0, 255).astype(np.uint8)\n", "        marker = height.copy()\n", "        marker[marker > 135] = 255\n", "        marker[marker < 255] = 0\n", "        fills = Onlllyas.get_fill(marker / 255)\n", "        for fill in fills:\n", "            if fill[0].shape[0] < 64:\n", "                marker[fill] = 0\n", "        filter = np.array([\n", "            [0, 1, 0],\n", "            [1, 1, 1],\n", "            [0, 1, 0]],\n", "            dtype=np.uint8)\n", "        big_marker = cv2.erode(marker, filter, iterations=5)\n", "        fills = Onlllyas.get_fill(big_marker / 255)\n", "        for fill in fills:\n", "            if fill[0].shape[0] < 64:\n", "                big_marker[fill] = 0\n", "        big_marker = cv2.dilate(big_marker, filter, iterations=5)\n", "        small_marker = marker.copy()\n", "        small_marker[big_marker > 127] = 0\n", "        fin_labels, nil = label(big_marker / 255)\n", "        fin_labels = up_fill(Onlllyas.get_fill(small_marker), fin_labels)\n", "        water = cv2.watershed(img_2048.clip(0, 255).astype(np.uint8), fin_labels.astype(np.int32)) + 1\n", "        water = Onlllyas.thinning(water)\n", "        all_region_indices = Onlllyas.find_all(water)\n", "        regions = np.zeros_like(img_2048, dtype=np.uint8)\n", "        for region_indices in all_region_indices:\n", "            regions[region_indices] = np.random.randint(low=0, high=255, size=(3,)).clip(0, 255).astype(np.uint8)\n", "        result = np.zeros_like(img_2048, dtype=np.uint8)\n", "        for region_indices in all_region_indices:\n", "            result[region_indices] = np.median(img_2048[region_indices], axis=0)\n", "        return final_height.clip(0, 255).astype(np.uint8), regions.clip(0, 255).astype(np.uint8), result.clip(0, 255).astype(np.uint8)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["  ******************<br>\n", "  CLS ONVGG<br>\n", "<br>\n", "  ******************"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class Onvgg:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    @staticmethod\n", "    def vgg_deprocess(img):\n", "        VGG_RGB_MEAN = [123.68, 116.78, 103.94]\n", "        vgg_rgb_mean_arr = np.array(VGG_RGB_MEAN)\n", "        imgpost = np.copy(img)\n", "        imgpost += vgg_rgb_mean_arr.reshape((1,1,1,3))\n", "        \n", "        imgpost = imgpost[0] # (1, h, w, d) +> (h, w, d)\n", "        imgpost = np.clip(imgpost, 0, 255).astype('uint8')\n", "        \n", "        imgpost = imgpost[...,::-1] # RGB => BGR\n", "        return imgpost\n", "    @staticmethod\n", "    def vgg_preprocess(img):\n", "        VGG_RGB_MEAN = [123.68, 116.779, 103.939]\n", "        vgg_rgb_mean_arr = np.array(VGG_RGB_MEAN).reshape((1,1,1,3))\n", "        imgpre = np.copy(img)\n", "        imgpre = imgpre[...,::-1] # BGR to RGB\n", "        imgpre = imgpre.astype(np.float32) # _e_\n", "        imgpre = imgpre[np.newaxis,:,:,:] # (h, w, d) => (1, h, w, d)\n", "        imgpre -= vgg_rgb_mean_arr\n", "        return imgpre"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    @staticmethod\n", "    def path_to_tvgg(image_path): # _e_\n", "        # Util function to open, resize and format pictures into appropriate tensors\n", "        img = tf.keras.preprocessing.image.load_img(image_path, target_size=(img_nrows, img_ncols))\n", "        img = tf.keras.preprocessing.image.img_to_array(img)\n", "        img = np.expand_dims(img, axis=0)\n", "        img = vgg19.preprocess_input(img)\n", "        return tf.convert_to_tensor(img)\n", "    @staticmethod   \n", "    def cv2_trgb(img, title=\"img\", wait=3000):\n", "        img = Onformat.vgg_deprocess(img)\n", "        cv_img(img, title, wait)\n", "    @staticmethod\n", "    def cv2_path(path): #  _e_\n", "        img = cv2.imread(path, cv2.IMREAD_COLOR)\n", "        img = Onformat.vgg_preprocess(img)\n", "        img = Onformat.vgg_deprocess(img)\n", "        cv2.imshow('img', img)\n", "        cv2.waitKey(2000)   \n", "    @staticmethod\n", "    def bgr_to_rgb_vgg(img):\n", "        VGG_RGB_MEAN = [123.68, 116.779, 103.939]\n", "        vgg_rgb_mean_arr = np.array(VGG_RGB_MEAN)\n", "        imgpre = np.copy(img)\n", "        # bgr to rgb\n", "        imgpre = imgpre[...,::-1]\n", "        # shape (h, w, d) to (1, h, w, d)\n", "        imgpre = imgpre[np.newaxis,:,:,:]\n", "        imgpre -= vgg_rgb_mean_arr.reshape((1,1,1,3))\n", "        return imgpre\n", "    @staticmethod\n", "    def tbgr_to_trgb_vgg(img):\n", "        # Keras works with batches of images\n", "        # So, the first dimension is used for the number of samples (or images)\n", "        # vgg_mean = np.array([123.68, 116.779, 103.939], dtype=np.float32).reshape((3,1,1))\n", "        VGG_BGR_MEAN = [103.939, 116.779, 123.68]\n", "        vgg_bgr_mean_arr = np.array(VGG_BGR_MEAN)\n\n", "        # img = img[0] # np.squeeze(img, axis = 0) # \n", "        img = img[...,::-1] # bgr to rgb\n", "        # img = img[np.newaxis,:,:,:] # shape (h, w, d) to (1, h, w, d)\n", "        img -= vgg_bgr_mean_arr.reshape((1,1,1,3))\n", "        img = tf.convert_to_tensor(img)\n", "        return img\n", "    @staticmethod\n", "    def bgr_to_tnua_2_vgg(img):\n", "        VGG_RGB_MEAN = [123.68, 116.779, 103.939]\n", "        vgg_rgb_mean_arr = np.array(VGG_RGB_MEAN)\n\n", "        # bgr to rgb\n", "        img = img[...,::-1]\n", "        # shape (h, w, d) to (1, h, w, d)\n", "        img = img[np.newaxis,:,:,:]\n", "        img -= vgg_rgb_mean_arr.reshape((1,1,1,3))\n", "        return img\n", "    @staticmethod\n", "    def tbgr_to_tnua_2_vgg(img):\n", "        VGG_RGB_MEAN = [123.68, 116.779, 103.939]\n", "        vgg_rgb_mean_arr = np.array(VGG_RGB_MEAN)    \n", "        img += vgg_rgb_mean_arr.reshape((1,1,1,3))\n", "        # shape (1, h, w, d) to (h, w, d)\n", "        img = img[0]\n", "        img = np.clip(img, 0, 255).astype('uint8')\n", "        # rgb to bgr\n", "        img = img[...,::-1]\n", "        return img\n", "    @staticmethod\n", "    def bgrs_to_tnuas(inputs):\n", "        pretensors = []\n", "        for item in inputs:\n", "            preitem = Onformat.tbgr_to_trgb_vgg(item)\n", "            pretensors.append(preitem)\n", "        return pretensors\n", "    @staticmethod\n", "    def bgrs_to_tnuas(inputs):\n", "        pretensors = []\n", "        for item in inputs:\n", "            preitem = Onformat.tbgr_to_trgb_vgg(item)\n", "            pretensors.append(preitem)\n", "        return pretensors\n", "    @staticmethod\n", "    def tnua_to_vgg(tnua, width=512, height=512):\n", "        tnua = tf.image.resize(tnua, (width, height))\n", "        bgr = tnua*255.0 \n", "        vgg = Onvgg.tbgr_to_trgb_vgg(bgr)\n", "        return vgg"]}, {"cell_type": "markdown", "metadata": {}, "source": ["  ******************<br>\n", "   TFRecordExporter: export images to tf records<br>\n", "      relux<br>\n", "      https://github.com/rolux/stylegan2encoder/dataset_tool.py<br>\n", "<br>\n", "  ******************"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class TFRecordExporter:\n", "    def __init__(self, \n", "        tfrecord_dir, \n", "        expected_images, \n", "        tfr_prefix='tfrecord', \n", "        progress_interval=10,\n", "        verbose = True):\n", "        self.tfrecord_dir       = tfrecord_dir\n", "        self.tfr_prefix         = tfr_prefix\n", "        self.expected_images    = expected_images\n", "        self.cur_images         = 0\n", "        self.shape              = None\n", "        self.resolution_log2    = None\n", "        self.tfr_writers        = []\n", "        self.verbose     = verbose\n", "        self.progress_interval  = progress_interval\n", "        if self.verbose:\n", "            print(f'Creating dataset in {tfrecord_dir}')\n", "        os.makedirs(tfrecord_dir, exist_ok=True)\n", "    def close(self):\n", "        if self.verbose:\n", "            print('%-40s\\r' % 'Flushing data...', end='', flush=True)\n", "        for tfr_writer in self.tfr_writers:\n", "            tfr_writer.close()\n", "        self.tfr_writers = []\n", "        if self.verbose:\n", "            print('%-40s\\r' % '', end='', flush=True)\n", "            print('Added %d image%s.' % (self.cur_images, 's'[:self.cur_images > 1]))\n", "    def choose_shuffled_order(self): # Note: Images and labels must be added in shuffled order.\n", "        order = np.arange(self.expected_images)\n", "        np.random.RandomState(123).shuffle(order)\n", "        return order\n", "    def add_image(self, img):\n", "        if self.verbose and self.cur_images % self.progress_interval == 0:\n", "            print('%d / %d\\r' % (self.cur_images, self.expected_images), end='', flush=True)\n", "        if self.shape is None:\n", "            self.shape = img.shape\n", "            self.resolution_log2 = int(np.log2(self.shape[1]))\n\n", "            # print(\"add_image shape[1]: %s\" %self.shape[1])\n", "            # print(\"add_image resolution_log2: %s\" %self.resolution_log2)\n", "            assert self.shape[0] in [1, 3], f\"shape[0] assertion failed\"\n", "            assert self.shape[1] == self.shape[2], f\"shape[1]:shape[2] assertion failed\"\n", "            assert self.shape[1] == 2**self.resolution_log2, f\"shape is pow(2) assertion failed\"\n", "            tfr_opt = tf.io.TFRecordOptions(compression_type = None)\n", "            for lod in range(self.resolution_log2 - 1):\n", "                tfr_file = os.path.join(self.tfrecord_dir, self.tfr_prefix + '-r%02d.tfrecords' % (self.resolution_log2 - lod))\n", "                self.tfr_writers.append(tf.io.TFRecordWriter(tfr_file, tfr_opt))\n", "        assert img.shape == self.shape, \"image shapes are not equal\"\n", "        for lod, tfr_writer in enumerate(self.tfr_writers):\n", "            if lod:\n", "                img = img.astype(np.float32)\n", "                img = (img[:, 0::2, 0::2] + img[:, 0::2, 1::2] + img[:, 1::2, 0::2] + img[:, 1::2, 1::2]) * 0.25\n\n", "            # assume normalized input\n", "            quant = np.rint(img * 255).clip(0, 255).astype(np.uint8) # img * 255  # _e_\n", "            ex = tf.train.Example(features=tf.train.Features(feature={\n", "                'shape': tf.train.Feature(int64_list=tf.train.Int64List(value=quant.shape)),\n", "                'data': tf.train.Feature(bytes_list=tf.train.BytesList(value=[quant.tostring()]))}))\n", "                \n", "            # https://www.tensorflow.org/tutorials/load_data/tfrecord \n", "            feature = ex.SerializeToString()\n", "            tfr_writer.write(feature)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": [" \n", "            example_proto = tf.train.Example.FromString(feature)           \n\n", "            # feature_description = {\n", "            #     'shape': tf.io.FixedLenFeature([3], tf.int64),\n", "            #     'data': tf.io.FixedLenFeature([], tf.string),\n", "            # }\n", "            # def _parse_function(example_proto):\n", "            #     # Parse the input `tf.Example` proto using the dictionary above.\n", "            #     return tf.io.parse_single_example(example_proto, feature_description)\n", "            # parsed_dataset = example_proto.map(_parse_function)\n", "            # print(parsed_dataset)\n", "            examples = []\n", "            data = example_proto.features.feature[\"data\"]\n", "            shape = example_proto.features.feature[\"shape\"]\n", "            shape = shape.int64_list.value"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["            ndata = np.frombuffer(data.bytes_list.value[0], dtype=np.uint8)\n", "            im_arr =  ndata.reshape(shape[0], shape[1], shape[2])\n\n", "            # im_arr = im_arr.reshape(shape[2], shape[0], shape[1])\n", "            # im_arr = im_arr / 255\n", "            im_arr = im_arr.transpose([1, 2, 0])\n", "            imgstoplot = []\n", "            imgstoplot.append(Image.fromarray(im_arr))\n\n", "            # plt.imshow(im_arr)\n", "            # image = Image.fromarray(im_arr)\n", "            # image = im_arr\n", "            # plt.show()\n", "        self.cur_images += 1\n", "    def add_labels(self, labels):\n", "        if self.verbose:\n", "            print('%-40s\\r' % 'Saving labels...', end='', flush=True)\n", "        assert labels.shape[0] == self.cur_images\n", "        with open(self.tfr_prefix + '-rxx.labels', 'wb') as f:\n", "            np.save(f, labels.astype(np.float32))\n", "    def __enter__(self):\n", "        return self\n", "    def __exit__(self, *args):\n", "        self.close()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# -*- coding: utf-8 -*-\n", "# \n", "# # Copyright (c) 2019, NVIDIA Corporation. All rights reserved.\n", "#\n", "import os\n", "import io\n", "from io import StringIO\n", "import time\n", "import argparse\n", "import functools\n", "import errno\n", "import scipy\n", "import scipy.io\n", "import requests\n", "import zipfile\n", "import random\n", "import datetime\n", "        \n", "from functools import partial\n", "from importlib import import_module"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import logging\n", "logging.getLogger('tensorflow').setLevel(logging.ERROR)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "from numpy import *"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import math\n", "from math import floor, log2\n", "from random import random\n", "from pylab import *"]}, {"cell_type": "markdown", "metadata": {}, "source": ["import IPython.display as display"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from IPython.core.display import display"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import PIL\n", "from PIL import Image\n", "PIL.Image.MAX_IMAGE_PIXELS = 933120000"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import scipy.ndimage as pyimg"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import cv2\n", "import imageio\n", "import glob"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import matplotlib as mpl\n", "import matplotlib.pyplot as plt \n", "import matplotlib.image as mgimg\n", "import matplotlib.animation as anim\n", "mpl.rcParams['figure.figsize'] = (12,12)\n", "mpl.rcParams['axes.grid'] = False"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import shutil\n", "import gdown"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import sys"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import tensorflow as tf \n", "from tensorflow.keras import initializers, regularizers, constraints\n", "from tensorflow.keras import backend as K\n", "from tensorflow.keras import layers\n", "from tensorflow.keras.layers import Layer, InputSpec\n", "from tensorflow.keras.layers import BatchNormalization, Activation, ZeroPadding2D, UpSampling2D, Conv2D\n", "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout, LeakyReLU\n", "from tensorflow.keras.models import Sequential, Model\n", "from tensorflow.keras.optimizers import Adam\n", "from tensorflow.python.keras.utils import conv_utils"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from tensorflow.keras.layers import Lambda\n", "from tensorflow.keras.layers import add\n", "from tensorflow.keras.layers import AveragePooling2D\n", "from tensorflow.keras.initializers import VarianceScaling\n", "from tensorflow.keras.models import clone_model\n", "from tensorflow.keras.models import model_from_json"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from absl import app\n", "from absl import flags\n", "from absl import logging"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["tf.get_logger().setLevel('ERROR')\n", "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(f'|===> {tf.__version__}')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["  ******************<br>\n", "  FUNS<br>\n", "<br>\n", "  ******************"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["try:\n", "    # check if base.Onpyon is defined\n", "    var = Onpyon()\n", "except NameError:\n", "    # Onpyon not defined\n", "    sys.path.append('../')  # if called from eon, modules are in parallel folder\n", "    sys.path.append('./')  #  if called from dnns, modules are in folder\n", "    from base import *"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["onutil = Onutil()\n", "onplot = Onplot()\n", "onformat = Onformat()\n", "onfile = Onfile()\n", "onvid = Onvid()\n", "onimg = Onimg()\n", "ondata = Ondata()\n", "onset = Onset()\n", "onrecord = Onrecord()\n", "ontree = Ontree()\n", "onvgg = Onvgg()\n", "onlllyas = Onlllyas()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["  *******************<br>\n", "  CONTEXT<br>\n", "<br>\n", "  *******************"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def getap():\n", "    cp = {\n", "        \"primecmd\": 'nnani',        \n", "        \"MNAME\": \"stransfer\",      \n", "        \"AUTHOR\": \"xueyangfu\",      \n", "        \"PROJECT\": \"building\",      \n", "        \"GITPOD\": \"neural-style-tf\",      \n", "        \"DATASET\": \"styler\",        \n", "    \n", "        \"GDRIVE\": 1,            # mount gdrive: gdata, gwork    \n", "        \"TRAINDO\": 1,      \n", "        \"MAKEGIF\": 1,      \n", "        \"RUNGIF\": 0,      \n", "        \"CLEARTMP\": 0,      \n", "        \"REGET\": 0,             # get again data \n", "        \"ING\": 1,               # ckpt in gwork\n", "        \"MODITEM\": \"\",          # will look into module\n", "        \"RESETCODE\": 0,\n", "        \"LOCALDATA\": 0,\n", "        \"LOCALMODELS\": 0,\n", "        \"LOCALLAB\": 1,\n", "        \"grel_infix\": '../..',            # relative path to content \n", "        \"net_prefix\": '//enas/hdrive',     \n", "        \"gdrive_prefix\": '/content/drive/My Drive',     \n", "        \"gcloud_prefix\": '/content',     \n", "    }\n", "    local_prefix = os.path.abspath('')\n", "    try:\n", "            local_prefix = os.path.dirname(os.path.realpath(__file__)) # script dir\n", "    except:\n", "            pass\n", "    cp[\"local_prefix\"] = local_prefix"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    tree = ontree.tree(cp)\n", "    for key in tree.keys():\n", "        cp[key] = tree[key]\n", "    hp = {\n", "        \"verbose\": 0,\n", "        \"visual\": 1,\n", "    }\n", "    ap = {}\n", "    for key in cp.keys():\n", "        ap[key] = cp[key]\n", "    for key in hp.keys():\n", "        ap[key] = hp[key]\n", "    return ap"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def getxp(cp):\n", "    yp = {\n", "        # \"model_weights\": os.path.join(cp[\"gmodel\"], 'vgg', 'vgg19_weights_tf_dim_ordering_tf_kernels.h5'),\n", "        \"model_weights\": os.path.join(cp[\"gmodel\"], 'vgg', 'vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5'), # vgg19\n", "        \"model_include_top\": 0,\n", "        \"model_classes\": 1000,\n", "        \"max_epochs\": 800, # 10,\n", "        \"steps_per_epoch\": 1,\n", "        \"print_iterations\": 10, #  50\n", "        \"max_iterations\": 100, # 1000\n\n", "        # \"optimizer\": \"Adam\", # \"SGD\", # \n", "        \"adam_learning_rate\": 0.01,\n", "        \"adam_beta_1\": 0.99,\n", "        \"adam_epsilon\": 1e-1,\n", "        \"optimizer\": \"SGD\", # \"Adam\", # \"SGD\", # \n", "        \"sgd_learning_rate\": 0.01, \n", "        \"learning_rate\": 1e0,\n", "        \"model_pooling\": 'avg',\n", "        \"exp_decay\": [100., 100, 0.96], # [initial_learning_rate, decay_steps, decay_rate]\n", "        # \"momentum\": 0.0, \n", "        # \"nesterov\": 0"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        \"content_imgs_files\": [],\n", "        \"content_imgs_dir\": cp[\"data_dir\"],\n", "        \"content_imgs_weights\": [1.0],\n", "        \"content_layers\": ['conv4_2'], # ['conv4_2']\n", "        \"content_layer_weights\": [1e4],\n", "        # \"content_layers_weights\": [1e4], \n", "        # \"content_layers_weights\": [1e2], \n", "        \"content_layers_weights\": [2.5 * 1e-8], \n", "        \"content_layer_weights\": [1.0],\n", "        \"content_loss_function\": 1,\n", "        \"content_weight\": 5e0,\n", "        \"frame_content_frmt\": 'frame{}.jpg',\n", "        \"content_imgs_weights\": [1.0],\n", "        \"content_layers_weights\": [2.5e-08],\n", "        \"content_loss_function\": 1,\n", "        \"content_weight\": 5e0,\n", "        \"content_weights_frmt\": 'reliable_{}_{}.txt',\n", "        \"style_imgs_dir\": cp[\"data_dir\"],\n", "        \"style_scale\": 1,\n", "        \"style_imgs_weights\": [1.0],\n", "        # \"style_layers\": ['relu1_1', 'relu2_1', 'relu3_1', 'relu4_1', 'relu5_1'],\n", "        \"style_layers\": ['conv1_1','conv2_1','conv3_1','conv4_1','conv5_1'],\n", "        # \"style_layers_weights\": [1e-2],\n", "        # \"style_layers_weights\": [1e2],  \n", "        # \"style_layers_weights\": [1e-6 / 100],  \n", "        # \"style_layers_weights\": [1e-2, 1e-2, 1e-2, 1e-2, 1e-2],\n", "        \"style_layers_weights\": [0.2, 0.2, 0.2, 0.2, 0.2],\n", "        \"style_weight\": 1e4,\n", "        \"style_imgs_weights\": [1.0],\n", "        \"style_layers_weights\": [0.01, 0.01, 0.01, 0.01, 0.01],\n", "        \"style_layers_weights\": [0.2, 0.2, 0.2, 0.2, 0.2],\n", "        \"style_weight\": 1e4,\n", "        \"style_mask\": 0,\n", "        \"max_size\": 512,\n", "        \"input_shape\": (224, 224, 3), # (512, 512, 3) # \n", "        \"frame_first_iterations\": 2000,\n", "        \"frame_first_type\": 'content', # args.frame_first_type ['random', 'content', 'style'\n", "        \"init_image_type\": \"content\", # 'content','style','init','random','prev','prev_warped'\n", "        \"frame_init_type\": 'prev',\n", "        \"init_img_dir\": cp[\"data_dir\"],\n", "        \"init_image_type\": \"content\",\n", "        \"frame_first_iterations\": 2000,\n", "        \"init_img_type\": 'content',\n", "        \"img_name\": 'result',\n", "        \"original_colors\": None,\n", "        \"color_convert_type\": 'yuv',\n", "        \"color_convert_time\": 'after',\n", "        \"optimizer\": 'adam', # 'lbfgs' # \n", "        \n", "        # \"total_variation_weight\": 1e-6, # 300,\n", "        \"total_variation_weight\": 0.001,\n", "        \"total_variation_weight\": 1e-3,"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        # \"video_input_dir\": os.path.join(cp[\"proj_dir\"], 'intput_vid'),        \n", "        \"video_input_dir\": os.path.join(cp[\"data_dir\"], ''),\n", "        \"video_output_dir\": os.path.join(cp[\"results_dir\"], 'output_vid'),\n", "        \"video_output_dir\": os.path.join(cp[\"data_dir\"], 'output_vid'),\n", "        \"video_dir\": os.path.join(cp[\"lab\"], \"\"),\n", "        \"video_frames_dir\": os.path.join(cp[\"lab\"], \"NewYork\"),\n", "        \"video_frames_dir\": os.path.join(cp[\"results_dir\"], 'frames'),\n", "        \"video_output_dir\": os.path.join(cp[\"data_dir\"], 'output_vid'),\n", "        \"video_file\": 'videoframe.mp4',\n", "        \"video_file\": 'Streets of New York City 4K video-vCdBIRtsL6o.f313.mp4',\n", "        \"video_file\": 'portu.mp4',\n", "        # \"video_input_dir\": os.path.join(cp[\"data_dir\"], 'intput_vid'),\n", "        \"video_output_dir\": os.path.join(cp[\"results_dir\"], 'output_vid'),\n", "        \"video_dir\": os.path.join(cp[\"lab\"], \"\"),\n", "        # \"video_path\": os.path.join(video_dir, video_file),\n", "        \"backward_optical_flow_frmt\": 'backward_{}_{}.flo',\n", "        \"forward_optical_flow_frmt\": 'forward_{}_{}.flo',\n", "        \"video\": 0,\n", "        \"frames_dir\": os.path.join(cp[\"results_dir\"], 'cromes/frames'),\n", "        \"frame_iterations\": 800,\n", "        \"frame_end\": 9,\n", "        \"frame\": None,    \n", "        \"frame_start\": 0,\n", "        \"frame_end\": -1, # num_frames\n", "        \"frame_first_iterations\": 20, # 2000\n", "        \"frame_init_type\": 'prev', # 'prev_warped'\n", "        \"frame_content_frmt\": 'frame{}.jpg',\n", "        \"frame_first_type\": 'content',\n", "        \"temporal_weight\": 2e2,\n", "        \"img_output_dir\": cp[\"results_dir\"],\n", "        \"image_step_format\": 'step{}.jpg',\n", "        \"image_epoch_format\": 'epoch{}.jpg',\n", "        \"show_entry_imgs\": 0,\n", "        \"show_set_imgs\": 1,\n", "        \"show_fit_imgs\": 1,\n", "        \"zfill\": 4,\n", "        \"device\": '/gpu:0',\n", "    }\n", "    xp={}\n", "    for key in cp.keys():\n", "        xp[key] = cp[key]\n", "    tree = ontree.tree(cp)\n", "    for key in tree.keys():\n", "        xp[key] = tree[key]\n", "    for key in yp.keys():\n", "        print(key, yp[key])\n", "        xp[key] = yp[key]\n", "   \n", "    return xp"]}, {"cell_type": "markdown", "metadata": {}, "source": ["  ******************<br>\n", "  FUNS VIDEO<br>\n", "<br>\n", "  ***************"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def get_content_frame(frame, args):\n", "        \n", "    video_input_dir = args.video_input_dir\n", "    frame_content_frmt = args.frame_content_frmt\n\n", "    # frame_content_frmt = 'frame_{}.ppm' # args.frame_content_frmt\n", "    zfill = 4 # args.zfill\n", "    frame_name = frame_content_frmt.format(str(frame).zfill(zfill))\n", "    # path_to_img = os.path.join(video_input_dir, frame_name)\n\n", "    # print(\"get_content_frame path\", path_to_img)    \n", "    # img = read_image(path_to_img)\n", "    path = os.path.join(args.video_input_dir, frame_name)\n", "    img = onfile.path_to_tnua_with_tf(path, args)\n", "    return img"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def _get_style_images(content_img, args=None):\n", "  _, ch, cw, cd = content_img.shape\n", "  style_imgs = []\n", "  for style_fn in args.style_imgs_files:\n", "    path = os.path.join(args.style_imgs_dir, style_fn)\n", "    # bgr image\n", "    img = cv2.imread(path, cv2.IMREAD_COLOR)\n", "    check_image(img, path)\n", "    img = img.astype(np.float32)\n", "    img = cv2.resize(img, dsize=(cw, ch), interpolation=cv2.INTER_AREA)\n", "    img = onvgg.vgg_preprocess(img)\n", "    style_imgs.append(img)\n", "  return style_imgs"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def cv2_frame(cvi, refimg, scale):\n", "    _, ch, cw, cd = refimg.shape #  (1, 256, 256, 3) [[[[-107.68   -90.779  -78.939]\n", "    img = cvi\n", "    img = img.astype(np.float32) # shape: (657, 1000, 3) [[[ 51.  68. 135.]\n", "    sh, sw, sd = img.shape # shape: (657, 1000, 3)\n\n", "    # use scale args to resize and tile image\n", "    scaled_img = cv2.resize(img, dsize=(int(sw*scale), int(sh*scale)), \n", "        interpolation=cv2.INTER_AREA)\n", "    ssh, ssw, ssd = scaled_img.shape # shape: (657, 1000, 3)\n", "    if ssh > ch and ssw > cw:\n", "        starty = int((ssh-ch)/2)\n", "        startx = int((ssw-cw)/2)\n", "        img = scaled_img[starty:starty+ch, startx:startx+cw]\n", "    elif ssh > ch:\n", "        starty = int((ssh-ch)/2)\n", "        img = scaled_img[starty:starty+ch, 0:ssw]\n", "    # if ssw != cw:   # scaled_style_width != content_width 1000 != 256 \n", "    if ssw <= cw:   # scaled_style_width != content_width 1000 != 256 \n", "        # cv2.copyMakeBorder(src, top, bottom, left, right, borderType, value)\n", "        img = cv2.copyMakeBorder(img,0,0,0,(cw-ssw),cv2.BORDER_REFLECT)\n", "    elif ssw > cw:\n", "        startx = int((ssw-cw)/2)\n", "        img = scaled_img[0:ssh, startx:startx+cw]\n", "    # if ssh != ch:\n", "    if ssh <= ch:\n", "        img = cv2.copyMakeBorder(img,0,(ch-ssh),0,0,cv2.BORDER_REFLECT)\n", "    # else:\n", "    if ssh <= ch and ssw <= cw:\n", "        img = cv2.copyMakeBorder(scaled_img,0,(ch-ssh),0,(cw-ssw),cv2.BORDER_REFLECT)\n", "    return img"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def get_style_cvis(content_img, args):\n", "    print(f'|---> get_style_cvis  \\n \\\n", "        content_img: {args.style_imgs_files} \\n \\\n", "        args.style_imgs_dir: {args.style_imgs_dir} \\n \\\n", "    ')\n", "    style_imgs=[]\n", "    style_imgs_dir=args.style_imgs_dir\n", "    max_size=args.max_size\n", "    style_scale =args.style_scale\n", "    _, ch, cw, cd = content_img.shape #  (1, 256, 256, 3) [[[[-107.68   -90.779  -78.939]\n", "    mx = max_size\n", "    cvis = []\n", "    for style_fn in args.style_imgs_files:\n", "        path = os.path.join(style_imgs_dir, style_fn)\n", "        print(f'|...> get_style_cvis path {path}')        \n", "        # bgr image\n", "        cvi = cv2.imread(path, cv2.IMREAD_COLOR)\n", "        img = cv2_frame(cvi, content_img, style_scale)\n\n", "        # img = onvgg.vgg_preprocess(img)\n", "        cvis.append(img)\n", "    return cvis"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def get_input_image(\n", "        init_type= 'content', # {content,style,init,random,prev,prev_warped}\n", "        content_img=None, \n", "        style_imgs=[], \n", "        init_img=None, \n", "        frame=None, \n", "        video_input_dir='./', \n", "        video_output_dir='./', \n", "        frame_content_frmt = 'frame_{}.ppm',\n", "        zill=4,\n", "        noise_ratio = 1.0, \n", "        args=None\n", "    ):\n", "    print(f\"|---> get_input_image of type: {init_type} with frame: {frame}\")\n", "    if init_type == 'content':\n", "        return content_img\n", "    elif init_type == 'style':\n", "        style_img = style_imgs[0]   # _e_\n", "        return style_img\n", "    elif init_type == 'init':\n", "        return init_img\n", "    elif init_type == 'random':\n", "        init_img = get_noise_image(noise_ratio, content_img)\n", "        return init_img\n", "    # only for video frames\n", "    elif init_type == 'prev':\n", "        assert(not frame == None)\n", "        #init_img = get_prev_frame(\n", "        #    frame, \n", "        #    video_output_dir,\n", "        #    frame_content_frmt,\n", "        #    zill,\n", "        #)\n", "        init_img = get_prev_frame(\n", "            frame, \n", "            args\n", "        )        \n", "        return init_img\n", "    elif init_type == 'prev_warped':\n", "        #init_img = get_prev_warped_frame(\n", "        #    frame, \n", "        #    video_input_dir\n", "        #)\n", "        init_img = get_prev_warped_frame(\n", "            frame, \n", "            args\n", "        )        \n", "        return init_img"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def get_optimizer(loss):\n", "    print_iterations = 100 # \n", "    max_iterations = 1000 # args.max_iterations\n", "    verbose = True # args.verbose\n", "    learning_rate = 1e0 # args.learning_rate\n", "    optimizer = 'adam' # args.optimizer\n", "    print_iterations = print_iterations if verbose else 0\n", "    if optimizer == 'lbfgs':\n", "        optimizer = tf.contrib.opt.ScipyOptimizerInterface(\n", "        loss, method='L-BFGS-B',\n", "        options={'maxiter': max_iterations,\n", "                    'disp': print_iterations})\n", "    elif optimizer == 'adam':\n", "        # optimizer = tf.train.AdamOptimizer(learning_rate)\n", "        optimizer = tf.optimizers.Adam(learning_rate)\n", "    return optimizer"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def get_noise_image(noise_ratio, content_img, \n", "        seed = 0\n", "    ):\n", "    np.random.seed(seed)\n", "    noise_img = np.random.uniform(-20., 20., content_img.shape).astype(np.float32)\n", "    img = noise_ratio * noise_img + (1.-noise_ratio) * content_img\n", "    return img"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def get_mask_image(mask_img, width, height, \n", "        content_imgs_dir = './'\n", "    ):\n", "    path = os.path.join(content_imgs_dir, mask_img)\n", "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n", "    #check_file(img, path)\n", "    print(f'|---> get_mask_image {path}')\n", "    img = cv2.resize(img, dsize=(width, height), interpolation=cv2.INTER_AREA)\n", "    img = img.astype(np.float32)\n", "    mx = np.amax(img)\n", "    img /= mx\n", "    return img"]}, {"cell_type": "markdown", "metadata": {}, "source": ["  ****************<br>\n", "  get_prev_frame: previously stylized frame"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def get_prev_frame(frame, args=None):\n", "    video_output_dir = args.video_input_dir # _e_ tbc\n", "    frame_content_frmt = args.frame_content_frmt\n", "    zfill = args.zfill\n", "    \n", "    prev_frame = frame - 1\n", "    fn = frame_content_frmt.format(str(prev_frame).zfill(zfill))\n", "    path = os.path.join(video_output_dir, fn)\n", "    print(f\"|---> get_prev_frame for frame: {frame} from {path}\")\n\n", "    # img = cv2.imread(path, cv2.IMREAD_COLOR)\n", "    # check_file(img, path)\n", "    img = onfile.path_cv_pil(path)\n", "    img = onformat.pil_to_dnua(img)\n", "    return img"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def get_prev_warped_frame(frame, args=None):\n", "    video_input_dir = args.video_input_dir\n", "    backward_optical_flow_frmt = args.backward_optical_flow_frmt\n", "    frame_content_frmt = args.frame_content_frmt\n", "    prev_img = get_prev_frame(frame, args)\n", "    print(f\"|---> get_prev_frame in {video_input_dir} with {frame_content_frmt}\")\n", "    prev_frame = frame - 1\n", "    # backwards flow: current frame -> previous frame\n", "    fn = backward_optical_flow_frmt.format(str(frame), str(prev_frame))\n", "    path = os.path.join(video_input_dir, fn)\n", "    flow = read_flow_file(path)\n", "    warped_img = warp_image(prev_img, flow).astype(np.float32)\n", "    img = onvgg.vgg_preprocess(warped_img)\n", "    return img"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def get_content_weights(frame, prev_frame, args):\n", "    video_input_dir=args.video_input_dir\n", "    content_weights_frmt = args.content_weights_frmt\n", "    forward_fn = content_weights_frmt.format(str(prev_frame), str(frame))\n", "    backward_fn = content_weights_frmt.format(str(frame), str(prev_frame))\n", "    forward_path = os.path.join(video_input_dir, forward_fn)\n", "    backward_path = os.path.join(video_input_dir, backward_fn)\n", "    forward_weights = read_weights_file(forward_path)\n", "    backward_weights = read_weights_file(backward_path)\n", "    return forward_weights #, backward_weights"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def warp_image(src, flow):\n", "    _, h, w = flow.shape\n", "    flow_map = np.zeros(flow.shape, dtype=np.float32)\n", "    for y in range(h):\n", "        flow_map[1,y,:] = float(y) + flow[1,y,:]\n", "    for x in range(w):\n", "        flow_map[0,:,x] = float(x) + flow[0,:,x]\n", "    # remap pixels to optical flow\n", "    dst = cv2.remap(\n", "        src, flow_map[0], flow_map[1], \n", "        interpolation=cv2.INTER_CUBIC, borderMode=cv2.BORDER_TRANSPARENT)\n", "    return dst"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def convert_to_original_colors(content_img, stylized_img, args=None):\n", "    color_convert_type = args.color_convert_type\n", "    content_img  = onvgg.vgg_deprocess(content_img)\n", "    stylized_img = onvgg.vgg_deprocess(stylized_img)\n", "    if color_convert_type == 'yuv':\n", "        cvt_type = cv2.COLOR_BGR2YUV\n", "        inv_cvt_type = cv2.COLOR_YUV2BGR\n", "    elif color_convert_type == 'ycrcb':\n", "        cvt_type = cv2.COLOR_BGR2YCR_CB\n", "        inv_cvt_type = cv2.COLOR_YCR_CB2BGR\n", "    elif color_convert_type == 'luv':\n", "        cvt_type = cv2.COLOR_BGR2LUV\n", "        inv_cvt_type = cv2.COLOR_LUV2BGR\n", "    elif color_convert_type == 'lab':\n", "        cvt_type = cv2.COLOR_BGR2LAB\n", "        inv_cvt_type = cv2.COLOR_LAB2BGR\n", "    content_cvt = cv2.cvtColor(content_img, cvt_type)\n", "    stylized_cvt = cv2.cvtColor(stylized_img, cvt_type)\n", "    c1, _, _ = cv2.split(stylized_cvt)\n", "    _, c2, c3 = cv2.split(content_cvt)\n", "    merged = cv2.merge((c1, c2, c3))\n", "    dst = cv2.cvtColor(merged, inv_cvt_type).astype(np.float32)\n", "    dst = onvgg.vgg_preprocess(dst)\n", "    return dst"]}, {"cell_type": "markdown", "metadata": {}, "source": ["  ******************<br>\n", "  FUNCS LOG<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def write_image_output(output_img, \n", "        content_img, style_imgs, input_img, \n", "        epoch=0,\n", "        args=None,\n", "    ):\n", "    if args.verbose > 1:\n", "        print(f'|---> write_image_output \\n \\\n", "            to img_output_dir: {args.img_output_dir} \\n \\\n", "            epoch: {epoch} \\n \\\n", "        ')\n", "    output_img = onformat.nua_to_pil(output_img)\n", "    content_img = onformat.nua_to_pil(content_img)\n", "    style_imgs = onformat.dnuas_to_pils(style_imgs)\n", "    input_img = onformat.nua_to_pil(input_img)\n\n", "    # save result image\n", "    img_file = f'output_'+str(epoch)+'.png'\n", "    img_path = os.path.join(args.img_output_dir, img_file)\n", "    onfile.pil_to_file_with_cv(img_path, output_img)\n\n", "    # save content image\n", "    content_file = f'content.jpg'\n", "    content_path = os.path.join(args.img_output_dir, content_file)\n", "    onfile.pil_to_file_with_cv(content_path, content_img)\n\n", "    # save input image\n", "    init_file = f'init.jpg'\n", "    init_path = os.path.join(args.img_output_dir, init_file)\n", "    onfile.pil_to_file_with_cv(init_path, input_img)\n", "    style_files = []\n", "    style_paths = []\n\n", "    # save style images\n", "    for i, style_img in enumerate(style_imgs):\n", "        style_files.append(f'style_{str(i)}.png')\n", "        style_paths.append(os.path.join(args.img_output_dir, style_files[i]))\n", "        path = style_paths[i]\n", "        onfile.pil_to_file_with_cv(path, style_img)\n\n", "    # save the configuration settings\n", "    out_file = os.path.join(args.img_output_dir, 'meta_data.txt')\n", "    f = open(out_file, 'w')\n", "    f.write(f'image_name: {img_path}\\n')\n", "    f.write(f'content: {content_path}\\n')\n", "    index = 0\n", "    for i, style_path in enumerate(style_paths):\n", "        f.write(f'styles[{str(i)}]: {style_path}\\n')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    if 'mask_imgs_files' in vars(args).keys():\n", "        for i, style_mask_img in enumerate(args.mask_imgs_files):\n", "            style_mask_img_path = os.path(args.style_imgs_dir, args.mask_imgs_files[i])\n", "            f.write(f'style_masks[{str(i)}]: {style_mask_img_path}\\n')        "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    f.write(f'init_type: {args.init_img_type}\\n')\n", "    f.write(f'content_weight: {args.content_weight}\\n')\n", "    f.write(f'content_layers: {args.content_layers}\\n')\n", "    f.write(f'content_layers_weights: {args.content_layers_weights}\\n')\n", "    f.write(f'style_imgs_weights: {args.style_imgs_weights}\\n')\n", "    f.write(f'style_layers: {args.style_layers}\\n')\n", "    f.write(f'style_layers_weights: {args.style_layers_weights}\\n')\n", "    f.write(f'total_variation_weight: {args.total_variation_weight}\\n')\n", "    f.write(f'content_size: {args.content_size}\\n')\n", "    f.write(f'input_shape: {args.input_shape}\\n')\n", "    f.write(f'optimizer: {args.optimizer}\\n')\n", "    f.write(f'max_size: {args.max_size}\\n')\n", "    f.write(f'frame_iterations: {args.frame_iterations}\\n')\n", "    f.write(f'max_epochs: {args.max_epochs}\\n')\n", "    f.write(f'steps_per_epoch: {args.steps_per_epoch}\\n')\n", "    f.write(f'print_iterations: {args.print_iterations}\\n')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    f.close()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["  *****************<br>\n", "  FUNCS MODEL<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def read_weights_file(path):\n", "    lines = open(path).readlines()\n", "    header = list(map(int, lines[0].split(' ')))\n", "    w = header[0]\n", "    h = header[1]\n", "    vals = np.zeros((h, w), dtype=np.float32)\n", "    for i in range(1, len(lines)):\n", "        line = lines[i].rstrip().split(' ')\n", "        vals[i-1] = np.array(list(map(np.float32, line)))\n", "        vals[i-1] = list(map(lambda x: 0. if x < 255. else 1., vals[i-1]))\n", "    # expand to 3 channels\n", "    weights = np.dstack([vals.astype(np.float32)] * 3)\n", "    return weights"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def get_content_weights(frame, prev_frame):\n", "    content_weights_frmt = 'reliable_{}_{}.txt' # args.content_weights_frmt\n", "    video_input_dir = './video_input' # args.video_input_dir\n", "    forward_fn = content_weights_frmt.format(str(prev_frame), str(frame))\n", "    backward_fn = content_weights_frmt.format(str(frame), str(prev_frame))\n", "    forward_path = os.path.join(video_input_dir, forward_fn)\n", "    backward_path = os.path.join(video_input_dir, backward_fn)\n", "    forward_weights = read_weights_file(forward_path)\n", "    backward_weights = read_weights_file(backward_path)\n", "    return forward_weights #, backward_weights"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def minimize_with_lbfgs(sess, net, optimizer, init_img,\n", "        verbose=True,\n", "    ):\n", "    if verbose: print('\\nMINIMIZING LOSS USING: L-BFGS OPTIMIZER')\n", "    init_op = tf.global_variables_initializer()\n", "    sess.run(init_op)\n", "    sess.run(net['input'].assign(init_img))\n", "    optimizer.minimize(sess)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def minimize_with_adam(sess, net, optimizer, init_img, loss,\n", "        verbose=True,\n", "        max_iterations=1000,\n", "        print_iterations=50,\n", "    ):\n", "    if verbose: print('\\nMINIMIZING LOSS USING: ADAM OPTIMIZER')\n", "    train_op = optimizer.minimize(loss)\n", "    init_op = tf.global_variables_initializer()\n", "    sess.run(init_op)\n", "    sess.run(net['input'].assign(init_img))\n", "    iterations = 0\n", "    while (iterations < max_iterations):\n", "        sess.run(train_op)\n", "        if iterations % print_iterations == 0 and verbose:\n", "            curr_loss = loss.eval()\n", "            print(\"At iterate {}\\tf=  {}\".format(iterations, curr_loss))\n", "        iterations += 1"]}, {"cell_type": "markdown", "metadata": {}, "source": ["  ******************<br>\n", "  NETS<br>\n", ""]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "  'a neural algorithm for artistic style' loss functions<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def content_layer_loss(p, x, args=None):\n", "    _, h, w, d = p.get_shape()\n", "    M = h * w # h.value * w.value\n", "    N = d # d.value\n", "    if args.content_loss_function   == 1:\n", "        K = 1. / (2. * N**0.5 * M**0.5)\n", "    elif args.content_loss_function == 2:\n", "        K = 1. / (N * M)\n", "    elif args.content_loss_function == 3:  \n", "        K = 1. / 2.\n", "    loss = K * tf.reduce_sum(input_tensor=tf.pow((x - p), 2))\n", "    return loss"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def style_layer_loss(a, x):\n", "    if 0:\n", "        print(f'|---> style_layer_loss')      \n", "    _, h, w, d = a.get_shape()\n", "    M = h * w # h.value * w.value\n", "    N = d # d.value\n", "    A = gram_matrix(a, M, N)\n", "    G = gram_matrix(x, M, N)\n", "    loss = (1./(4 * N**2 * M**2)) * tf.reduce_sum(input_tensor=tf.pow((G - A), 2))\n", "    return loss"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def gram_matrix(x, area, depath):\n", "    F = tf.reshape(x, (area, depath))\n", "    G = tf.matmul(tf.transpose(a=F), F)\n", "    return G"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def mask_style_layer(a, x, mask_img, args=None):\n", "    if 1:\n", "        print(f'|---> mask_style_layer {mask_img}')    \n", "    _, h, w, d = a.get_shape()\n", "    #mask = get_mask_image(mask_img, w.value, h.value)\n", "    mask = get_mask_image(mask_img, w, h,\n", "        content_imgs_dir=args.style_imgs_dir) # _e_\n", "    mask = tf.convert_to_tensor(value=mask)\n", "    tensors = []\n", "    # for _ in range(d.value): \n", "    for _ in range(d): \n", "        tensors.append(mask)\n", "    mask = tf.stack(tensors, axis=2)\n", "    mask = tf.stack(mask, axis=0)\n", "    mask = tf.expand_dims(mask, 0)\n", "    a = tf.multiply(a, mask)\n", "    x = tf.multiply(x, mask)\n", "    return a, x"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def sum_masked_style_losses(net, combo, style_imgs, args=None):\n", "    if 0:\n", "        print(f'|---> sum_masked_style_losses')\n", "    total_style_loss = 0.\n", "    weights = args.style_imgs_weights\n", "    masks = args.style_mask_imgs\n", "    for img, img_weight, img_mask in zip(style_imgs, weights, masks):\n", "        #net['input'].assign(img)\n", "        ps = net.extract_features([combo], args.style_layers)[0]   # net[layer]\n", "        xs = net.extract_features([img], args.style_layers)[0]   # net[layer]          \n", "        style_loss = 0.\n", "        for layer, weight in zip(args.style_layers, args.style_layers_weights):\n", "            a = ps[layer] # net[layer]\n", "            x = xs[layer] # net[layer]\n", "            #a = tf.convert_to_tensor(value=a)\n", "            a, x = mask_style_layer(a, x, img_mask, args)\n", "            style_loss += style_layer_loss(a, x) * weight\n", "        style_loss /= float(len(args.style_layers))\n", "        total_style_loss += (style_loss * img_weight)\n", "    total_style_loss /= float(len(style_imgs))\n", "    return total_style_loss"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def sum_style_losses(net, combo, style_imgs, args=None):\n", "    if 0:\n", "        print(f'|---> sum_style_losses')    \n", "    total_style_loss = 0.\n", "    weights = args.style_imgs_weights\n", "    for img, img_weight in zip(style_imgs, weights):\n", "            # net['input'].assign(img)\n", "            ps = net.extract_features([combo], args.style_layers)[0]   # net[layer]\n", "            xs = net.extract_features([img], args.style_layers)[0]   # net[layer]            \n", "            style_loss = 0.\n", "            for layer, weight in zip(args.style_layers, args.style_layers_weights):\n", "                p = ps[layer] # net[layer]\n", "                x = xs[layer] # net[layer]\n", "                # p = tf.convert_to_tensor(value=p)\n", "                style_loss += style_layer_loss(p, x) * weight\n", "            style_loss /= float(len(args.style_layers))\n", "            total_style_loss += (style_loss * img_weight)\n", "    total_style_loss /= float(len(style_imgs))\n", "    return total_style_loss"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def sum_content_losses(net, combo, content_img, args=None):\n", "    if 0:\n", "        print(f'|---> sum_content_losses')     \n", "    # net['input'].assign(content_img)\n", "    content_loss = 0.\n", "    ps = net.extract_features([combo], args.content_layers)[0]   # net[layer]\n", "    xs = net.extract_features([content_img], args.content_layers)[0]   # net[layer]\n", "    for layer, weight in zip(args.content_layers, args.content_layer_weights):\n", "            p = ps[layer]   # net[layer]\n", "            x = xs[layer]   # net[layer]\n", "            # p = tf.convert_to_tensor(value=p)\n", "            content_loss += content_layer_loss(p, x, args) * weight\n", "    content_loss /= float(len(args.content_layers))\n", "    return content_loss"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "  'artistic style transfer for videos' loss functions<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def temporal_loss(x, w, c):\n", "  c = c[np.newaxis,:,:,:]\n", "  D = float(x.size)\n", "  loss = (1. / D) * tf.reduce_sum(input_tensor=c * tf.nn.l2_loss(x - w))\n", "  loss = tf.cast(loss, tf.float32)\n", "  return loss"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def get_longterm_weights(i, j, args=None):\n", "  c_sum = 0.\n", "  for k in range(args.prev_frame_indices):\n", "    if i - k > i - j:\n", "      c_sum += get_content_weights(i, i - k, args)\n", "  c = get_content_weights(i, i - j, args)\n", "  c_max = tf.maximum(c - c_sum, 0.)\n", "  return c_max"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def sum_longterm_temporal_losses(sess, net, frame, input_img, args=None):\n", "  x = sess.run(net['input'].assign(input_img))\n", "  loss = 0.\n", "  for j in range(args.prev_frame_indices):\n", "    prev_frame = frame - j\n", "    print(\"sum_longterm_temporal_losses\", args.frame_init_type)\n", "    w = input_img # _e_\n", "    if args.frame_init_type == 'prev':\n", "        w = get_prev_frame(frame, args) # _e_\n", "    elif args.frame_init_type == 'prev_warped':\n", "        w = get_prev_warped_frame(frame, args)\n\n", "    # w = get_prev_warped_frame(frame, args)\n", "    c = get_longterm_weights(frame, prev_frame)\n", "    loss += temporal_loss(x, w, c)\n", "  return loss"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def sum_shortterm_temporal_losses(sess, net, frame, input_img, args=None):\n", "  x = sess.run(net['input'].assign(input_img))\n", "  prev_frame = frame - 1"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["  print(\"sum_longterm_temporal_losses frame_init_type\", args.frame_init_type)\n", "  w = input_img # _e_\n", "  if args.frame_init_type == 'prev':\n", "      w = get_prev_frame(frame, args) # _e_\n", "  elif args.frame_init_type == 'prev_warped':\n", "      w = get_prev_warped_frame(frame, args)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["  #   w = get_prev_warped_frame(frame, args)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["  c = get_content_weights(frame, prev_frame, args)\n", "  loss = temporal_loss(x, w, c)\n", "  return loss"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "  utilities and i/o<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def read_image(path):\n", "  # bgr image\n", "  img = cv2.imread(path, cv2.IMREAD_COLOR)\n", "  check_image(img, path)\n", "  img = img.astype(np.float32)\n", "  img = onvgg.vgg_preprocess(img)\n", "  return img"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def write_image(path, img):\n", "  img = onvgg.vgg_deprocess(img)\n", "  cv2.imwrite(path, img)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def preprocess_tensor(inputs):\n\n", "    # Keras works with batches of images. \n", "    # So, the first dimension is used for the number of samples (or images) you have.\n", "    # vgg_mean = np.array([123.68, 116.779, 103.939], dtype=np.float32).reshape((3,1,1))\n", "    VGG_BGR_MEAN = [103.939, 116.779, 123.68]\n", "    vgg_bgr_mean_arr = np.array(VGG_BGR_MEAN)\n", "    imgpre = inputs[0] # np.squeeze(inputs, axis = 0) # \n", "    imgpre = imgpre[...,::-1] # BGR => RGB\n", "    imgpre = imgpre[np.newaxis,:,:,:] # shape (h, w, d) to (1, h, w, d)\n", "    imgpre -= vgg_bgr_mean_arr.reshape((1,1,1,3))\n", "    imgpre = tf.convert_to_tensor(imgpre)\n", "    return imgpre"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def preprocess_tensors(inputs):\n", "    pretensors = []\n", "    for item in inputs:\n", "        preitem = preprocess_tensor(item)\n", "        pretensors.append(preitem)\n", "    return pretensors"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def show_effect_a(path):\n", "    from PIL import Image\n", "    image = Image.open(path)\n", "    image.show()\n", "    import cv2\n", "    img = cv2.imread(path, cv2.IMREAD_COLOR)\n", "    if 0:\n", "        cv2.imshow('img', img)\n", "        cv2.waitKey(0)      \n", "    img = onvgg.vgg_preprocess(img) # <class 'numpy.ndarray'> (1, 1654, 1654, 3)\n", "    print(type(img))\n", "    print(np.shape(img))\n", "    rgb = tf.squeeze(img, axis=0)\n", "    rgb = np.array(rgb, dtype=np.uint8)\n", "    rgb = PIL.Image.fromarray(rgb)\n", "    rgb.show()\n", "    img = onvgg.vgg_deprocess(img)\n", "    image = Image.fromarray(img)\n", "    image.show() "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def read_flow_file(path):\n", "  with open(path, 'rb') as f:\n", "    # 4 bytes header\n", "    header = struct.unpack('4s', f.read(4))[0]\n", "    # 4 bytes width, height    \n", "    w = struct.unpack('i', f.read(4))[0]\n", "    h = struct.unpack('i', f.read(4))[0]   \n", "    flow = np.ndarray((2, h, w), dtype=np.float32)\n", "    for y in range(h):\n", "      for x in range(w):\n", "        flow[0,y,x] = struct.unpack('f', f.read(4))[0]\n", "        flow[1,y,x] = struct.unpack('f', f.read(4))[0]\n", "  return flow"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def read_weights_file(path):\n", "  lines = open(path).readlines()\n", "  header = list(map(int, lines[0].split(' ')))\n", "  w = header[0]\n", "  h = header[1]\n", "  vals = np.zeros((h, w), dtype=np.float32)\n", "  for i in range(1, len(lines)):\n", "    line = lines[i].rstrip().split(' ')\n", "    vals[i-1] = np.array(list(map(np.float32, line)))\n", "    vals[i-1] = list(map(lambda x: 0. if x < 255. else 1., vals[i-1]))\n", "  # expand to 3 channels\n", "  weights = np.dstack([vals.astype(np.float32)] * 3)\n", "  return weights"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def normalize(weights):\n", "  denom = sum(weights)\n", "  if denom > 0.:\n", "    return [float(i) / denom for i in weights]\n", "  else: return [0.] * len(weights)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def check_image(img, path):\n", "  if img is None:\n", "    raise OSError(errno.ENOENT, \"No such file\", path)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "  rendering -- where the magic happens<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def compute_loss(combo):\n", "    loss = tf.zeros(shape=())"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def clip_0_1(image):\n", "    return tf.clip_by_value(image, clip_value_min=0.0, clip_value_max=1.0)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def build_vgg(\n", "        input_shape = (224, 224, 3),\n", "        model_classes = 1000,\n", "        model_pooling=None,\n", "        model_include_top = True,\n", "        model_weights = None,\n", "    ):\n", "    inputs = tf.keras.layers.Input(shape = input_shape)\n\n", "    # Block 1\n", "    x = tf.keras.layers.Conv2D(64, (3,3),activation='relu',padding='same',name='conv1_1')(inputs)\n", "    x = tf.keras.layers.Conv2D(64, (3,3),activation='relu',padding='same',name='conv1_2')(x)\n", "    x = tf.keras.layers.MaxPooling2D((2,2), strides=(2,2), name='pool1')(x)\n\n", "    # Block 2\n", "    x = tf.keras.layers.Conv2D(128, (3,3),activation='relu',padding='same',name='conv2_1')(x)\n", "    x = tf.keras.layers.Conv2D(128, (3,3),activation='relu',padding='same',name='conv2_2')(x)\n", "    x = tf.keras.layers.MaxPooling2D((2,2), strides=(2,2), name='pool2')(x)\n\n", "    # Block 3\n", "    x = tf.keras.layers.Conv2D(256, (3,3),activation='relu',padding='same',name='conv3_1')(x)\n", "    x = tf.keras.layers.Conv2D(256, (3,3),activation='relu',padding='same',name='conv3_2')(x)\n", "    x = tf.keras.layers.Conv2D(256, (3,3),activation='relu',padding='same',name='conv3_3')(x)\n", "    x = tf.keras.layers.Conv2D(256, (3,3),activation='relu',padding='same',name='conv3_4')(x)\n", "    x = tf.keras.layers.MaxPooling2D((2,2), strides=(2,2), name='pool3')(x)\n\n", "    # Block 4\n", "    x = tf.keras.layers.Conv2D(512, (3,3),activation='relu',padding='same',name='conv4_1')(x)\n", "    x = tf.keras.layers.Conv2D(512, (3,3),activation='relu',padding='same',name='conv4_2')(x)\n", "    x = tf.keras.layers.Conv2D(512, (3,3),activation='relu',padding='same',name='conv4_3')(x)\n", "    x = tf.keras.layers.Conv2D(512, (3,3),activation='relu',padding='same',name='conv4_4')(x)\n", "    x = tf.keras.layers.MaxPooling2D((2,2), strides=(2,2), name='pool4')(x)\n\n", "    # Block 5\n", "    x = tf.keras.layers.Conv2D(512, (3,3),activation='relu',padding='same',name='conv5_1')(x)\n", "    x = tf.keras.layers.Conv2D(512, (3,3),activation='relu',padding='same',name='conv5_2')(x)\n", "    x = tf.keras.layers.Conv2D(512, (3,3),activation='relu',padding='same',name='cpmv5_3')(x)\n", "    x = tf.keras.layers.Conv2D(512, (3,3),activation='relu',padding='same',name='conv5_4')(x)\n", "    x = tf.keras.layers.MaxPooling2D((2,2), strides=(2,2), name='pool5')(x)\n", "    if model_include_top:\n", "        print(\"include classification block: flatten, fc1, fc2, predictions\")\n", "        # Classification block\n", "        x = tf.keras.layers.Flatten(name='flatten')(x)\n", "        x = tf.keras.layers.Dense(4096, activation='relu', name='fc1')(x)\n", "        x = tf.keras.layers.Dense(4096, activation='relu', name='fc2')(x)\n", "        x = tf.keras.layers.Dense(model_classes, activation='softmax', name='predictions')(x)\n", "    else:\n", "        if model_pooling == 'avg':\n", "            x = tf.keras.layers.GlobalAveragePooling2D()(x)\n", "        elif model_pooling == 'max':\n", "            x = tf.keras.layers.GlobalMaxPooling2D()(x)\n", "    outputs = x\n", "    vgg = tf.keras.Model(inputs, outputs)\n", "    if model_weights:\n", "        print(\"|...> load model_weights\")\n", "        vgg.load_weights(model_weights)\n", "    else:\n", "        print(\"|...> did not load model_weights\")\n", "    return vgg"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class GAN(tf.keras.models.Model):\n", "    def __init__(self, \n", "        input_shape = (224, 224, 3),        \n", "        args=None, \n", "    ):\n", "        super(GAN, self).__init__()\n", "        content_layers = args.content_layers\n", "        style_layers = args.style_layers\n", "        model_weights = args.model_weights\n", "        model_include_top = args.model_include_top\n", "        model_classes = args.model_classes\n", "        model_pooling = args.model_pooling\n", "        \n", "        self.num_content_layers = len(content_layers)\n", "        self.num_style_layers = len(style_layers)\n\n", "        # shap = np.shape(tf.squeeze(content_img, axis=0))\n", "        self.imgshape = input_shape\n", "        vggmodel = build_vgg(\n", "            input_shape = self.imgshape,\n", "            model_classes = model_classes,\n", "            model_pooling = model_pooling,\n", "            model_include_top = model_include_top,\n", "            model_weights = model_weights,\n", "        )\n", "        layer_names = content_layers + style_layers\n", "        print(\"|...> GAN content_layers\", content_layers)\n", "        print(\"|...> GAN style_layers\", style_layers)\n", "        print(\"|...> GAN layers\", layer_names)\n", "        outputs = {name: vggmodel.get_layer(name).output for name in layer_names}        \n", "        # outputs = [vggmodel.get_layer(name).output for name in layer_names]\n", "        self.net = tf.keras.Model([vggmodel.input], outputs) \n", "        self.net.trainable = False        \n", "        if 0:\n", "            self.net.summary()\n", "        self.optimizer = tf.optimizers.Adam(\n", "            learning_rate=0.01,\n", "            beta_1=0.99, \n", "            epsilon=1e-1\n", "        )\n\n", "        #self.optimizer = tf.keras.optimizers.SGD(\n", "        #    learning_rate=0.1, \n", "        #    momentum=0.9, \n", "        #    #nesterov=False, \n", "        #    #name='SGD'\n", "        #)    \n\n", "        # if not hasattr(self, \"image\"):  # Or set self.v to None in __init__ \n", "        #     image = tf.Variable(self.content_img) \n", "        # self.image = image"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    def extract_features(self, imgs, layers=None):\n", "        net = self.net\n", "        imgshape = self.imgshape\n", "        if len(imgshape) == 3:\n", "            imgshape = imgshape[:-1]\n", "        (width,height) = imgshape\n", "        rei = []\n", "        for i,sty_img in enumerate(imgs):\n", "            img = imgs[i] # _e_\n", "            preprocessed_input = onvgg.tnua_to_vgg(img, width=width, height=height)\n", "            if 0:\n", "                print(f'|===> extract_features \\n \\\n", "                    preprocessed_input {type(preprocessed_input)} {np.shape(preprocessed_input)} \\n \\\n", "                ')\n", "            outputs = net(preprocessed_input)\n", "            features = {}\n", "            if layers:\n", "                for layer in layers:\n", "                    features[layer]=outputs[layer]\n", "            else:\n", "                features = outputs\n", "            rei.append(features)\n", "        return rei            \n", "    def call(self, image = None):\n", "        print(f'|===> GAN call {type(image)}')\n", "        img = self.image # <class 'tensorflow.python.ops.resource_variable_ops.ResourceVariable'>\n", "        img = onformat.nua_to_pil(img)\n", "        img.show()\n", " \n\n", "    # @tf.function\n", "    def train_step(self, image, content_img, style_imgs, args = None):\n", "        net = self.net\n", "        total_variation_weight = args.total_variation_weight\n", "        style_weight = args.style_weight\n", "        content_weight = args.content_weight\n", "        video = args.video\n", "        frame = args.frame\n", "        temporal_weight = args.temporal_weight\n", "        content_layer_weight = args.content_layer_weights\n", "        style_imgs_weights = args.style_imgs_weights\n", "        style_layers_weight = args.style_layers_weights\n", "        with tf.GradientTape() as tape:\n", "           \n", "        #     # content loss\n", "            L_content = sum_content_losses(self, image, content_img, args)\n\n", "            # style loss\n", "            if args.style_mask:\n", "                L_style = sum_masked_style_losses(self, image, style_imgs, args)\n", "            else:\n", "                L_style = sum_style_losses(self, image, style_imgs, args)\n", "            L_tv = tf.image.total_variation(image)\n\n", "            # loss weights\n", "            alpha = args.content_weight\n", "            beta  = args.style_weight\n", "            theta = args.total_variation_weight\n", "            \n", "            # total loss\n", "            L_total  = 0.\n", "            L_total += alpha * L_content\n", "            L_total += beta  * L_style\n", "            L_total += theta * L_tv\n", "        grad = tape.gradient(L_total, image)\n", "        self.optimizer.apply_gradients([(grad, image)])\n", "        image.assign(clip_0_1(image))\n", "        self.image = image"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    def fit(self, input_img, content_img, style_imgs, \n", "            frame = None,\n", "            args  = None\n", "        ):\n", "        max_epochs = args.max_epochs\n", "        steps_per_epoch = args.steps_per_epoch\n", "        video = args.video\n", "        visual = args.visual\n", "        verbose = args.verbose\n", "        img_output_dir = args.img_output_dir\n", "        video_styled_dir = args.video_styled_dir\n", "        image_step_format = args.image_step_format\n", "        image_epoch_format = args.image_epoch_format\n", "        frame_content_frmt = args.frame_content_frmt\n", "        zfill = args.zfill\n", "        show_fit_imgs = args.show_fit_imgs\n", "        train_step = self.train_step\n", "        image = tf.Variable(input_img)   \n", "        self.image = image\n", "        print(f'|===> fit \\n \\\n", "            max_epochs: {max_epochs} \\n \\\n", "            steps_per_epoch: {steps_per_epoch} \\n \\\n", "            train_step: {train_step} \\n \\\n", "            input_img shape: {np.shape(input_img)} \\n \\\n", "            content_img shape: {np.shape(content_img)} \\n \\\n", "            style_imgs shape: {[np.shape(img) for img in style_imgs]} \\n \\\n", "            combo_img shape: {type(self.image)} {np.shape(self.image)} \\n \\\n", "            style_mask: {args.style_mask} \\n \\\n", "        ')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        if visual > 1:\n", "            print(f'|---> pil input_img')\n", "            if 1: onplot.pil_show_nua(input_img)        \n", "            print(f'|---> pil content_img')\n", "            if 1: onplot.pil_show_nua(content_img)        \n", "            print(f'|---> pil style_imgs')\n", "            if 1: onplot.pil_show_nuas(style_imgs)   \n", "            print(f'|---> pil combo_img')\n", "            if 1: onplot.pil_show_nua(self.image)\n", "            if args.style_mask_imgs:\n", "                print(f'|---> pil combo_img')\n", "                onplot.pil_show_nua(self.image)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        # # ============\n", "        start = time.time()\n\n", "        #if 0: print(f\"[   .   ] display input image {step} image\")\n", "        #img = onformat.nua_to_pil(image)\n", "        #img = ondata.pil_resize(img, (256,256))\n", "        #img.show()\n", "        for epoch in range(max_epochs):\n", "            step = 0\n", "            for step_in_epoch in range(steps_per_epoch):\n", "                step += 1\n", "                if 1 and step % args.print_iterations == 0:\n", "                    if video:\n", "                        print(f'|---> fit {frame}:{epoch}:{step}')\n", "                    else:\n", "                        print(f'|---> fit {epoch}:{step}')\n", "                # ==========================================\n", "                train_step(image, content_img, style_imgs, args)\n", "                # =========================================\n", "                print(\".\", end='')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["            if 1 and step % args.print_iterations == 0: # show results each n steps\n", "                if 0:\n", "                    try:\n", "                        # display image per epoch _e_\n", "                        display.clear_output(wait=True)\n", "                        print(f\"[   .   ] display in step {step} image\")\n", "                        display.display(onformat.nua_to_pil(self.image))\n", "                    except:\n", "                        print(\"could not display epoch images\")\n", "                else:\n", "                    print(f\"[   .   ] show epoch {epoch} image\")\n", "                    img = onformat.nua_to_pil(self.image)\n", "                    img.show()\n\n", "            # write image per epoch\n", "            img_name = image_epoch_format.format(str(epoch).zfill(zfill))        \n", "            img_path = os.path.join(img_output_dir, img_name)\n", "            #onfile.pil_to_file_with_cv(img_path, self.image)\n", "            if 1: # write image per epoch\n", "                write_image_output(\n", "                    output_img = self.image, \n", "                    content_img = content_img, \n", "                    style_imgs = style_imgs, \n", "                    input_img = input_img,\n", "                    epoch = epoch,\n", "                    args = args,\n", "                )\n", "            if 1 and visual:\n", "                if 0:\n", "                    print(f'|---> pil combo_img epoch: {epoch}')\n", "                onplot.pil_show_nua(self.image)\n", "        if video:\n", "            frame_name = args.frame_content_frmt.format(str(frame).zfill(zfill))\n", "            outpath_path = os.path.join(video_styled_dir, frame_name) # styled\n", "            print(f\"|...> fit save frame to {outpath_path} on epoch {epoch}\")\n", "            output_img = onformat.nua_to_pil(image)\n", "            onfile.pil_to_file_with_cv(outpath_path, output_img)\n", "        end = time.time()\n", "        print(\"Total time: {:.1f}\".format(end-start))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["  ******************<br>\n", "  CMDS<br>\n", "<br>\n", "  ****************"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "   stylize<br>\n", "    sum_style_losses<br>\n", "    sum_masked_style_losses args.style_mask<br>\n", "<br>\n", "  *******************<br>\n", "  nnimg<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def nnimg(args, kwargs):\n", "    if 0:\n", "        args.PROJECT = 'bomze' # https://github.com/tg-bomze/Style-Transfer-Collection\n", "        args.DATASET = 'bomze'\n", "        args.content_img_file = 'bomze-content.png'\n", "        args.content_size = (512, 512)        \n", "        args.init_img_name = 'bomze-content.png'\n", "        args.style_imgs_files = ['bomze-style.png']\n", "    if 0:\n", "        args.PROJECT = 'building'\n", "        args.DATASET = 'building'\n", "        args.content_img_file = 'IMG_4468.JPG'\n", "        args.content_size = (512, 512)        \n", "        args.init_img_name = 'IMG_4468.JPG'\n", "        args.style_imgs_files = ['EZNJVoTXsAgUh6M.jpg', 'EZsQWC1X0AQaxHs.jpg']\n", "    if 0:\n", "        args.PROJECT = 'labrador'\n", "        args.DATASET = 'labrador'        \n", "        args.content_img_file = 'YellowLabradorLooking_new.jpg'\n", "        args.content_size = (512, 512)        \n", "        args.init_img_name = 'YellowLabradorLooking_new.jpg'\n", "        args.style_imgs_files = ['starry-night.jpg']\n", "    if 0:\n", "        args.PROJECT = 'kandinsky'\n", "        args.DATASET = 'Kandinsky'        \n", "        args.content_img_file = 'YellowLabradorLooking_new.jpg'\n", "        args.content_size = (512, 512)        \n", "        args.init_img_name = 'YellowLabradorLooking_new.jpg'\n", "        args.style_imgs_files = ['Vassily_Kandinsky,_1913_-_Composition_7.jpg']\n", "    if 0:\n", "        args.PROJECT = 'lion'\n", "        args.DATASET = 'lion'        \n", "        args.content_img_file = 'lion.jpg'\n", "        args.content_size = (512, 512)        \n", "        args.init_img_name = 'lion.jpg'\n", "        args.style_imgs_files = ['a-hymn-to-the-shulamite-1982.jpg']\n", "    if 1:\n", "        args.PROJECT = 'lion'\n", "        args.DATASET = 'lion'        \n", "        args.content_img_file = 'lion.jpg'\n", "        args.content_size = (512, 512)        \n", "        args.init_img_name = 'lion.jpg'\n", "        args.style_imgs_files = ['starry-night.jpg']\n", "    if 0:\n", "        args.PROJECT = 'madrid'\n", "        args.DATASET = 'madrid'          \n", "        args.content_img_file = 'madrid.JPG'\n", "        args.content_size = (512, 512)\n", "        args.init_img_name = 'madrid.JPG'\n", "        args.style_imgs_files = ['starry-night.jpg']\n\n", "        #args.style_mask_imgs_files = [onimg.name_to_maskname(item) for item in args.style_imgs_files]\n", "        args.style_mask_imgs_files = ['madrid_mask.JPG' for item in args.style_imgs_files]\n", "        #args.style_imgs_thress = [(100,cv2.THRESH_BINARY)]\n", "        #args.style_imgs_thress = [(145,cv2.THRESH_BINARY)]\n", "        #args.style_imgs_thress = [(38,cv2.THRESH_BINARY)]\n", "        args.style_imgs_thress = [(38, cv2.THRESH_BINARY_INV)]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    if 0:\n", "        args.PROJECT = 'portubridge'\n", "        args.DATASET = 'portubridge'        \n", "        args.content_img_file = 'portu_frame0000.jpg'\n", "        args.content_size = (512, 512)        \n", "        args.init_img_name = 'portu_frame0000.jpg'\n", "        args.style_imgs_files = ['kandinsky.jpg']\n", "    args = onutil.pargs(vars(args))\n", "    xp = getxp(vars(args))\n", "    args = onutil.pargs(xp)    \n", "    onutil.ddict(vars(args), 'args')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    if 1: # config\n", "        print(f\"|===> nnimg: config \\n \\\n", "            args.video: {args.video} : content images from frames \\n \\\n", "            args.show_entry_imgs: {args.show_entry_imgs} \\n \\\n", "            args.steps_per_epoch: {args.steps_per_epoch} \\n \\\n", "            args.model_weights: {args.model_weights} \\n \\\n", "            args.max_epochs: {args.max_epochs} \\n \\\n", "        \")\n", "    if 1: # tree\n", "        args.code_dir = os.path.join(args.proto_dir, 'code') # up project dir\n", "        #args.data_dir = os.path.join(args.proto_dir, 'data')\n", "        args.video_input_path = os.path.join(args.dataorg_dir, args.video_file)\n", "        args.video_frames_dir=os.path.join(args.proj_dir, 'frames')\n", "        args.video_styled_dir=os.path.join(args.proj_dir, 'outstyled')\n", "        args.video_output_dir=os.path.join(args.proj_dir, 'outvid')\n", "        args.video_input_dir = args.video_output_dir # frames _e_\n", "        args.style_imgs_weights = normalize(args.style_imgs_weights)\n", "        args.style_imgs_dir = args.data_dir\n", "        style_base = os.path.splitext(args.style_imgs_files[0])[0]\n", "        args.style_layers_weights = normalize(args.style_layers_weights)\n", "        args.content_layer_weights = normalize(args.content_layer_weights)\n", "        args.content_imgs_dir = args.data_dir\n", "        content_base = os.path.splitext(args.content_img_file)[0]\n", "        args.output_folder = content_base + \"_\" + style_base\n", "        args.img_output_dir = os.path.join(args.results_dir, 'cromes', args.output_folder)\n", "        args.init_img_dir = args.data_dir\n", "        print(f\"|===> nnimg: tree \\n \\\n", "            args.output_folder: {args.output_folder} \\n \\\n", "            args.img_output_dir: {args.img_output_dir} \\n \\\n", "            \\n \\\n", "            args.proto_dir: {args.proto_dir} \\n \\\n", "            args.data_dir: {args.data_dir} \\n \\\n", "            args.content_imgs_dir: {args.content_imgs_dir} \\n \\\n", "            args.init_img_dir: {args.init_img_dir} \\n \\\n", "            args.style_imgs_dir: {args.style_imgs_dir} \\n \\\n", "        \")\n", "        os.makedirs(args.data_dir, exist_ok=True)\n", "        os.makedirs(args.video_output_dir, exist_ok=True)\n", "        os.makedirs(args.img_output_dir, exist_ok=True)\n", "        os.makedirs(args.content_imgs_dir, exist_ok=True) # data_dir"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    if 1: # content image: (422, 512, 3) <class 'numpy.ndarray'>  [[[ 99 165 160]\n", "        content_img_path = os.path.join(args.content_imgs_dir, args.content_img_file)\n", "        img_file = os.path.basename(content_img_path)\n", "        if not os.path.exists(content_img_path):\n", "            urlfolder = 'https://github.com/xueyangfu/neural-style-tf/raw/master/image_input/'\n", "            url = f'{urlfolder}{img_file}'\n", "            topath = os.path.join(args.content_imgs_dir, f'{img_file}')\n", "            print(f\"|===> nnimg: content file does not exist\\n \\\n", "                content_img_path: {content_img_path} \\n \\\n", "                urlfolder: {urlfolder} \\n \\\n", "                url: {url} \\n \\\n", "                topath: {topath} \\n \\\n", "                args.content_imgs_dir: {args.content_imgs_dir} \\n \\\n", "            \")\n", "            tofile = tf.keras.utils.get_file(f'{topath}', origin=url, extract=True)\n", "        assert os.path.exists(content_img_path), f\"content image {content_img_path} does not exist\""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        img = onfile.path_cv_pil(content_img_path)\n", "        img = ondata.pil_resize(img, ps=args.content_size)\n", "        img = onformat.pil_to_dnua(img)\n", "        print(f\"|===> nnimg: content \\n \\\n", "            content_img_path: {content_img_path} \\n \\\n", "            args.content_imgs_dir: {args.content_imgs_dir} \\n \\\n", "            img shape: {np.shape(img)} \\n \\\n", "        \")\n", "        content_img = img\n", "    if args.visual > 1: # show content image\n", "        print(f'|---> pil content img')\n", "        onplot.pil_show_nua(content_img) # non interrupt\n", "    if args.visual > 1:# show content image from path\n", "        print(f'|---> cv content img')\n", "        content_img_path = os.path.join(args.content_imgs_dir, args.content_img_file)\n", "        onplot.cv_path(content_img_path, size = 512, title='content img', wait=2000)\n", "    if 1: #   input image: (422, 512, 3) <class 'numpy.ndarray'> [[[ 99 165 160]\n", "        init_path = os.path.join(args.init_img_dir, args.init_img_name)\n", "        init_image = onfile.path_to_tnua_with_tf(init_path, args)\n", "        print(f\"|===> nnimg: init \\n \\\n", "            init_path: {init_path} \\n \\\n", "            args.content_imgs_dir: {args.content_imgs_dir} \\n \\\n", "            init_shape: {np.shape(init_image)} \\n \\\n", "        \")\n", "        if args.visual > 1:\n", "            print(f'|---> vis init')\n", "            onplot.pil_show_nua(init_image, \"[   .   ] init_image\")\n", "    if 1: #   style images\n", "        style_imgs_paths = onfile.names_to_paths(args.style_imgs_files, args.style_imgs_dir)\n", "        for path in style_imgs_paths:\n", "            print(f'path: {path}')\n", "            if not os.path.exists(path):\n", "                print(f'path: {path} DOES NOT EXIST')\n", "                urlfolder = 'https://raw.github.com/xueyangfu/neural-style-tf/master/styles/'\n", "                file_name = os.path.basename(path)\n", "                url = f'{urlfolder}{file_name}'\n", "                topath = os.path.join(args.style_imgs_dir, file_name)\n", "                tofile = tf.keras.utils.get_file(f'{topath}', origin=url, extract=True)\n", "        style_imgs = onfile.names_to_nuas_with_tf(args.style_imgs_files, args.style_imgs_dir, args)\n", "        print(f\"|===> nnimg: styles \\n \\\n", "            args.style_imgs_files: {args.style_imgs_files} \\n \\\n", "            args.style_imgs_dir: {args.style_imgs_dir} \\n \\\n", "            shapes: {[str(np.shape(style_imgs[i])) for i,img in enumerate(style_imgs)]} \\n \\\n", "        \")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        if args.visual > 1:\n", "            print(f'|---> vis styles')\n", "            onplot.pil_show_nuas(style_imgs, [\"[   .   ] style_imgs\"])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    if 1: #   mask style images\n", "        b,h,w,c = np.shape(content_img)\n", "        csize = (w,h)\n", "        print(f'|===> nnimg: mask style images \\n \\\n", "            masks are regions of the content(input) image impacted by style transfer \\n \\\n", "            content image size: {csize} \\n \\\n", "        ')\n", "        args.style_mask = 0\n", "        if 'style_mask_imgs_files' in vars(args).keys():\n", "            if args.style_mask_imgs_files:\n", "                for maskfile, thress in zip(args.style_mask_imgs_files, args.style_imgs_thress):\n", "                    maskpath = os.path.join(args.style_imgs_dir, maskfile)\n", "                    if os.path.exists(maskpath):\n", "                        print(f'|... nnimg: mask file exists - assume ok, delete if not \\n \\\n", "                            maskpath: {maskpath} \\n \\\n", "                            maskfile: {maskfile} \\n \\\n", "                            thress: {thress} \\n \\\n", "                        ')\n", "                        args.style_mask = 1\n", "                    else:\n", "   \n", "                        unmaskfile = onimg.name_to_unmaskname(maskfile)\n", "                        unmaskpath =  os.path.join(args.style_imgs_dir, unmaskfile)\n", "                        print(f'|... nnimg: maskpath {maskpath} does NOT exist \\n \\\n", "                            generate {maskpath} from {unmaskpath} \\n \\\n", "                            with thress {thress} \\n \\\n", "                            the mask has to be created from {unmaskpath} with same size than imput img: {csize} \\n \\\n", "                        ')\n", "    \n", "                        style_img_to_mask = onfile.path_to_cvi(unmaskpath)\n", "                        style_img_to_mask = cv2.resize(style_img_to_mask, dsize=csize, interpolation=cv2.INTER_AREA)\n", "                        if args.visual > 1:\n", "                            cv2.imshow('style_img_to_mask', style_img_to_mask)             \n", "                            cv2.waitKey(0) & 0xFF is 27\n", "                            cv2.destroyAllWindows()\n", "                        style_mask = onimg.img_to_mask(\n", "                                style_img_to_mask, outpath=maskpath,\n", "                                height=None,width=None,\n", "                                threshold=thress[0], # 77,\n", "                                thresmode=thress[1], #cv2.THRESH_BINARY,\n", "                                visual=1, verbose=1)                        \n", "                        args.style_mask = 1\n", "            args.style_mask = 1\n", "            args.style_mask_imgs = args.style_mask_imgs_files\n", "        if args.style_mask: # _e_\n", "            style_mask_imgs = onfile.names_to_nuas_with_tf(args.style_mask_imgs_files, args.style_imgs_dir, args,)\n", "            print(f\"|===> nnimg: masks \\n \\\n", "                args.style_mask_imgs_files: {args.style_mask_imgs_files} \\n \\\n", "                args.style_imgs_dir: {args.style_imgs_dir} \\n \\\n", "                shapes: {[str(np.shape(style_mask_imgs[i])) for i,img in enumerate(style_mask_imgs)]} \\n \\\n", "            \")\n", "            if args.visual > 0:\n", "                print(f'|---> vis masks')\n", "                onplot.pil_show_nuas(style_mask_imgs, [\"[   .   ] style_mask_imgs\"])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    if 0: #   mask content images\n", "        print(\"|===> mask content images\")\n", "        \n", "        name_base = os.path.splitext(args.content_img_file)[0]\n", "        name_ext = os.path.splitext(args.content_img_file)[1]\n", "        print(\"|...> name_base\", name_base, name_ext)\n", "        name_mask = f'{name_base}_mask{name_ext}'\n", "        print(\"|...> name_mask\", name_mask)\n", "        (b,h,w,c) = np.shape(content_img)\n", "        dim = (w, h)\n", "        print(\"|...> content_size\", dim)\n", "        outpath = os.path.join(args.data_dir, name_mask)\n", "        img = onformat.nua_to_pil(content_img)\n", "        cvi = onformat.pil_to_cvi(img)\n", "        content_img_mask = onimg.img_to_mask(\n", "            cvi,outpath=outpath,\n", "            height=h,width=w,\n", "            threshold=38,\n", "            thresmode=cv2.THRESH_BINARY\n", "        )\n", "        cvimasked = onimg.cvi_mask_to_cvi(cvi, content_img_mask, op=4)\n", "        if args.visual > 1:\n", "            cv2.imshow('content img', cvi)                 \n", "            cv2.imshow('content mask', content_img_mask)            \n", "            cv2.imshow('masked img', cvimasked)            \n", "            cv2.waitKey(0) & 0xFF is 27\n", "            cv2.destroyAllWindows()\n", "    if 1: # input image\n", "        print(f'|===> input shape  \\n \\\n", "            cwd: {os.getcwd()} \\n \\\n", "            args.video: {args.video} \\n \\\n", "            args.init_image_type: {args.init_image_type} \\n \\\n", "        ')          \n", "        input_img = get_input_image( # (1, 512, 512, 3)\n", "            args.init_image_type, \n", "            content_img, \n", "            style_imgs,\n", "            init_image,\n", "            args.frame, \n", "            args.video_input_dir, \n", "            args.video_output_dir, \n", "            args.frame_content_frmt,\n", "        )\n", "        input_img = onformat.tnua_resize(input_img, args.max_size, args.max_size)\n", "        if 0 and args.visual:\n", "            onplot.pil_show_nua(input_img, \"[   .   ] input_img\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    if 1: # model\n", "        b,w,h,c = np.shape(input_img)\n", "        input_shape = (w,h,c)\n", "        print(f'|===> model \\n \\\n", "            input_shape: {input_shape} \\n \\\n", "        ')\n", "        model = GAN( input_shape = input_shape, args = args, )"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    if 1: # fit\n", "        print(f'|===> fit input image \\n \\\n", "            cwd: {os.getcwd()} \\n \\\n", "            input_img shape: {np.shape(input_img)} \\n \\\n", "            args.style_mask: {args.style_mask} \\n \\\n", "        ')\n", "        model.fit(\n", "            input_img, content_img, style_imgs, \n", "            frame= None,\n", "            args = args\n", "        )"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    if 0: # mask result\n", "        epoch = 10\n", "        basename = f'output_{int(epoch-1)}.png'\n", "        img_output_path = os.path.join(args.img_output_dir, basename)\n", "        print(f'|---> cv img_output_path img {img_output_path}')\n", "        output = onfile.path_to_cvi(img_output_path)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        content_img_path = os.path.join(args.content_imgs_dir, args.content_img_file)\n", "        content = onfile.path_to_cvi(content_img_path)\n", "        content = onplot.cv_resize(content, dim=args.content_size)\n", "        result1 = onimg.cvi_mask_to_cvi(content, content_img_mask, op=1)\n", "        result2 = onimg.cvi_mask_to_cvi(output, content_img_mask, op=-1)\n", "        #result = cv2.addWeighted(result1,0.0,result2,0.0,0)\n", "        result = cv2.add(result1,result2)\n", "        if args.visual > 1:\n", "            cv2.imshow('result1 img', result1)                 \n", "            cv2.imshow('result2 img', result2)                 \n", "            cv2.imshow('result img', result)                 \n", "            cv2.waitKey(0) & 0xFF is 27\n", "            cv2.destroyAllWindows()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["  *******************<br>\n", "  nnani<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def nnani(args, kwargs):\n", "    if 0:\n", "        args = onutil.pargs(vars(args))\n", "        args.PROJECT = 'newyork'\n", "        args.DATASET = 'stransfer'\n", "        args.content_size = (512, 512)   \n", "        args.style_imgs_files = ['starry-night.jpg']        \n", "        args.video_file = 'Streets of New York City 4K video-vCdBIRtsL6o.f313.mp4'\n", "    if 1:\n", "        args = onutil.pargs(vars(args))\n", "        args.PROJECT = 'portu'\n", "        args.DATASET = 'stransfer'\n", "        args.content_size = (512, 512)   \n", "        args.style_imgs_files = ['kandinsky.jpg']        \n", "        args.video_file = 'portu.mp4'    \n", "    args = onutil.pargs(vars(args))\n", "    xp = getxp(vars(args))\n", "    args = onutil.pargs(xp)    \n", "    onutil.ddict(vars(args), 'args')\n", "    if 1: # config\n", "        args.frame_start = 0\n", "        args.frame_end = -1 # num_frames\n", "        args.video = True \n", "    print(f\"|===> nnani config \\n \\\n", "        args.video: {args.video} \\n \\\n", "        args.visual: {args.visual} \\n \\\n", "        args.frame_first_iterations: {args.frame_first_iterations} \\n \\\n", "        args.frame_start: {args.frame_start} \\n \\\n", "        args.max_iterations: {args.max_iterations} \\n \\\n", "        args.style_imgs_files = {args.style_imgs_files} \\n \\\n", "    \")\n", "    if 1: # tree\n", "        extension=os.path.splitext(os.path.basename(args.video_file))[1]\n", "        args.code_dir = os.path.join(args.proto_dir, 'code') # up project dir\n", "        args.video_input_path = os.path.join(args.dataorg_dir, args.video_file)\n", "        args.video_frames_dir=os.path.join(args.proj_dir, 'frames')\n", "        args.video_styled_dir=os.path.join(args.proj_dir, 'outstyled')\n", "        args.video_output_dir=os.path.join(args.proj_dir, 'outvid')\n", "        args.video_input_dir = args.video_output_dir # frames _e_\n", "        content_filename=os.path.splitext(os.path.basename(args.video_file))[0]\n", "        content_filename=f\"{content_filename}\" # eg portu"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        args.img_output_dir=os.path.join(args.proj_dir, 'outimgs')\n", "        args.data_dir = os.path.join(args.proto_dir, 'data')\n", "        args.content_imgs_dir = args.data_dir\n", "        args.init_img_dir = args.data_dir\n", "        args.style_imgs_dir = args.data_dir\n", "        print(f'|===> nnani tree \\n \\\n", "            cwd: {os.getcwd()} \\n \\\n", "            args.video_file: {args.video_file} \\n \\\n", "            content_filename: {content_filename} \\n \\\n", "            args.video_input_path: {args.video_input_path} \\n \\\n", "            args.proto_dir: {args.proto_dir} \\n \\\n", "            args.code_dir: {args.code_dir} \\n \\\n", "            args.video_frames_dir: {args.video_frames_dir} \\n \\\n", "            args.video_styled_dir: {args.video_styled_dir} \\n \\\n", "            args.video_output_dir: {args.video_output_dir} \\n \\\n", "            args.video_input_dir: {args.video_input_dir} \\n \\\n", "        ')\n", "        os.makedirs(args.results_dir, exist_ok=True)\n", "        os.makedirs(args.video_frames_dir, exist_ok=True)\n", "        os.makedirs(args.video_styled_dir, exist_ok=True)\n", "        os.makedirs(args.video_output_dir, exist_ok=True)\n", "        os.makedirs(args.img_output_dir, exist_ok=True)\n", "        assert os.path.exists(args.video_input_path), f'input vide {args.video_input_path} does not exist'"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    if 1: # git\n", "        onutil.get_git(args.AUTHOR, args.GITPOD, args.code_dir)\n", "    assert os.path.exists(args.code_dir), \"code_dir not found\"        \n", "    os.chdir(args.code_dir) # _e_ not std\n", "    if 1: # vid => frames\n", "        if 1:\n", "            print(f'|===> nnani vid to frames \\n \\\n", "                args.video_input_path: {args.video_input_path} \\n \\\n", "                args.video_frames_dir: {args.video_frames_dir} \\n \\\n", "            ')\n", "            onvid.vid_to_frames(args.video_input_path, args.video_frames_dir, target = 1)\n", "        else:\n", "            frame_pattern = 'frame%04d.ppm'\n", "            cmd = f'ffmpeg -v quiet -i \"{args.video_input_path}\" \"{args.video_frames_dir}/{frame_pattern}\"'\n", "            print(f\"cmd: {cmd}\")\n", "            os.system(cmd)            "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    if 0: # frames size\n", "        ppm = os.path.join(args.video_frames_dir, 'frame0000.jpg')\n", "        im = Image.open(ppm)\n", "        width, height = im.size   \n", "        max_size = max(width, height)\n", "        print(f\"|===> nnani frame size \\n \\\n", "            max_size: {max_size} \\n \\\n", "        \")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    if 1: # video\n", "        num_frames = len([name for name in os.listdir(args.video_frames_dir) if os.path.isfile(os.path.join(args.video_frames_dir, name))])\n", "        args.frame_end = num_frames\n", "        found_q_frames = len([name for name in os.listdir(args.video_styled_dir) if os.path.isfile(os.path.join(args.video_styled_dir, name))])\n", "        frame_start = found_q_frames + 1\n", "    \n", "        frame = args.frame_start\n", "        args.frame_name = args.frame_content_frmt.format(str(frame).zfill(args.zfill))\n", "        args.frame_img_path = os.path.join(args.video_frames_dir, args.frame_name) \n", "    print(f\"|===> nnani video \\n \\\n", "        cwd: {os.getcwd()} \\n \\\n", "        num_frames: {num_frames} \\n \\\n", "        args.video_input_path: {args.video_input_path} \\n \\\n", "        args.img_output_dir: {args.img_output_dir} \\n \\\n", "        content_filename: {content_filename} \\n \\\n", "        extension: {extension} \\n \\\n", "        args.style_imgs_dir: {args.style_imgs_dir} \\n \\\n", "        args.style_imgs: {args.style_imgs_files} \\n \\\n", "        args.video_file: {args.video_file} \\n \\\n", "        args.video: {args.video} \\n \\\n", "        args.frame_end: {args.frame_end} \\n \\\n", "        args.input_shape: {args.input_shape} \\n \\\n", "        args.frame_content_frmt: {args.frame_content_frmt} \\n \\\n", "        frame: {frame} \\n \\\n", "        args.frame_name: {args.frame_name} \\n \\\n", "        args.frame_img_path: {args.frame_img_path} \\n \\\n", "    \")\n", "    if 1: # content\n", "        print(f'|===> get content  \\n \\\n", "            cwd: {os.getcwd()} \\n \\\n", "            content_frame: {args.frame_img_path} \\n \\\n", "        ')                \n", "        img = onfile.path_cv_pil(args.frame_img_path)\n", "        img = ondata.pil_resize(img, ps=args.content_size)\n", "        img = onformat.pil_to_dnua(img)\n", "        print(f\"|===> nnani: content \\n \\\n", "            args.frame_img_path: {args.frame_img_path} \\n \\\n", "            args.content_imgs_dir: {args.content_imgs_dir} \\n \\\n", "            img shape: {np.shape(img)} \\n \\\n", "        \")\n", "        content_frame = img\n", "        if args.visual > 1:\n", "            onplot.pil_show_nua(content_frame)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    if 1: #   style images\n", "        style_imgs = onfile.names_to_nuas_with_tf(args.style_imgs_files, args.style_imgs_dir, args,)\n", "        print(f\"|===> nnani: styles \\n \\\n", "            args.style_imgs_files: {args.style_imgs_files} \\n \\\n", "            args.style_imgs_dir: {args.style_imgs_dir} \\n \\\n", "            shapes: {[str(np.shape(style_imgs[i])) for i,img in enumerate(style_imgs)]} \\n \\\n", "        \")\n", "        if 0 and args.visual:\n", "            print(f'|---> vis styles')\n", "            onplot.pil_show_nuas(style_imgs, [\"[   .   ] style_imgs\"])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    if 1: # input shape\n", "        print(f'|===> input shape  \\n \\\n", "            cwd: {os.getcwd()} \\n \\\n", "            args.video: {args.video} \\n \\\n", "            args.frame_first_type: {args.frame_first_type} \\n \\\n", "            frame: {frame} \\n \\\n", "        ')                    \n", "        input_img = get_input_image(\n", "            args.frame_first_type, \n", "            content_frame, \n", "            style_imgs, \n", "            init_img=None, \n", "            frame=frame,  \n", "            args=args\n", "        )\n", " \n", "    print(f'|===> nnani  \\n \\\n", "        cwd: {os.getcwd()} \\n \\\n", "        content_filename: {content_filename} \\n \\\n", "        args.frame_content_frmt: {args.frame_content_frmt} \\n \\\n", "        content_frame shape: {np.shape(content_frame)} \\n \\\n", "        args.style_imgs: ({len(args.style_imgs_files)}) {args.style_imgs_files} \\n \\\n", "        style_imgs shapes: {[np.shape(img) for img in style_imgs]} \\n \\\n", "        args.video_file: {args.video_file} \\n \\\n", "        args.video_output_dir: {args.video_output_dir} \\n \\\n", "        args.video_frames_dir: {args.video_frames_dir} \\n \\\n", "        args.frame_start/frame_end: ({num_frames}) {args.frame_start} : {args.frame_end} \\n \\\n", "        args.input_img shape: {np.shape(input_img)} \\n \\\n", "    ')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    if 1: # model\n", "        b,w,h,c = np.shape(input_img)\n", "        input_shape = (w,h,c)   \n", "        print(f\"|===> nnani model \\n \\\n", "            cwd: {os.getcwd()} \\n \\\n", "            input_shape: {input_shape} \\n \\\n", "            args.video_input_path: {args.video_input_path} \\n \\\n", "            args.img_output_dir: {args.img_output_dir} \\n \\\n", "        \")\n", "        model = GAN(input_shape = input_shape, args = args,)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    if 1: # fit\n", "        print(f\"|===> nnani fit \\n \\\n", "            cwd: {os.getcwd()} \\n \\\n", "            args.video_styled_dir: {args.video_styled_dir} \\n \\\n", "            args.img_output_dir: {args.img_output_dir} \\n \\\n", "        \")\n", "        args.max_iterations = args.frame_iterations\n", "        for frame in range(args.frame_start, args.frame_end+1):\n", "            print(f'|===> RENDERING VIDEO FRAME ({args.frame_first_type}): {frame}/{args.frame_end} ----\\n')\n", "            if frame == args.frame_start:\n", "                print(f\"|...> frame_start input_img type: {type(input_img)}\")\n", "                input_img = get_input_image(\n", "                    init_type=args.frame_first_type, \n", "                    content_img=content_frame, \n", "                    style_imgs=style_imgs, \n", "                    init_img=None, \n", "                    frame=frame,  \n", "                    args=args\n", "                )\n", "            else:\n", "                print(f\"|...> other_frame input_img type: {type(input_img)}\")\n", "                input_img = get_input_image(  # (1, 1080, 1440, 3) <class 'numpy.ndarray'>\n", "                    init_type=args.frame_init_type, #\n", "                    content_img=content_frame, \n", "                    style_imgs=style_imgs, \n", "                    init_img=None, \n", "                    frame=frame,  \n", "                    args=args\n", "                )\n", "            input_img = onimg.tf_resize_nua(input_img, args=args)\n", "            print(f\"|===> fit input image \\n \\\n", "                cwd: {os.getcwd()} \\n \\\n", "                input_img shape: {np.shape(input_img)} \\n \\\n", "            \")\n", "            model.fit( \n", "                input_img, content_frame, style_imgs,\n", "                frame = frame,                \n", "                args = args,\n", "            )\n", "    if 0: # render stylized video\n", "        \n", "        os.chdir(args.code_dir) # _e_ not std\n", "        print(f\"|===> nnani render stylized video \\n \\\n", "            cwd: {os.getcwd()} \\n \\\n", "            video: {args.video} \\n \\\n", "        \")\n", "        cmd = f'python neural_style.py --video \\\n", "        --video_input_dir \"{args.video_frames_dir}\" \\\n", "        --style_imgs_dir \"{args.style_imgs_dir}\" \\\n", "        --style_imgs {args.style_imgs_files[0]} \\\n", "        --frame_end {args.frame_end} \\\n", "        --max_size {args.max_size} \\\n", "        --verbose'\n", "        print(cmd)\n", "        \n", "    if 1: # gen video\n", "        fps = 6\n", "        maxTime = 9 # seconds\n", "        frameCount = 0\n", "        time = 0\n", "        nframes = int( maxTime*fps )\n", "        qsegs = 7\n", "        qcells = qsegs * qsegs\n", "        fps=10\n", "        video_output_path = os.path.join(args.video_output_dir, 'v.mp4')\n", "        gif_output_path = os.path.join(args.video_output_dir, 'v.gif')\n", "        print(f'|===> nnani render stylized video \\n \\\n", "            from args.video_frames_dir: {args.video_frames_dir} \\n \\\n", "            to video_output_path: {video_output_path} \\n \\\n", "        ')\n\n", "        #onvid.frames_to_video(args.video_styled_dir, video_output_path, fps)\n", "        onvid.folder_to_gif(args.video_styled_dir, gif_output_path)\n", "        \n", "#   ******************\n", "#\n", "#   MAIN\n", "#\n", "#   ******************\n", "def main():\n", "    parser = argparse.ArgumentParser(description='Run \"python %(prog)s <subcommand> --help\" for subcommand help.')\n", "    onutil.dodrive()\n", "    ap = getap()\n", "    for p in ap:\n", "        cls = type(ap[p])\n", "        parser.add_argument('--'+p, type=cls, default=ap[p])\n", "    cmds = [key for key in globals() if key.startswith(\"nn\")]\n", "    primecmd = ap[\"primecmd\"]\n", "        \n", "    # ---------------------------------------------------------------\n", "    #   add subparsers\n", "    #\n", "    subparsers = parser.add_subparsers(help='subcommands', dest='command') # command - subparser\n", "    for cmd in cmds:\n", "        subparser = subparsers.add_parser(cmd, help='cmd')  # add subcommands\n", "    \n", "    subparsers_actions = [action for action in parser._actions\n", "        if isinstance(action, argparse._SubParsersAction)] # retrieve subparsers from parser\n", "  \n", "    for subparsers_action in subparsers_actions:  # add common       \n", "        for choice, subparser in subparsers_action.choices.items(): # get all subparsers and print help\n", "            for p in {}:  # subcommand args dict\n", "                cls = type(ap[p])\n", "                subparser.add_argument('--'+p, type=cls, default=ap[p])\n\n", "    # get args to pass to nn cmds\n", "    if onutil.incolab():\n", "        args = parser.parse_args('') #  defaults as args\n", "    else:\n", "        args = parser.parse_args() #  parse_arguments()\n", "    kwargs = vars(args)\n", "    subcmd = kwargs.pop('command')      \n", "    if subcmd is None:\n", "        print (f\"Missing subcommand. set to default {primecmd}\")\n", "        subcmd = primecmd\n", "    \n", "    for name in cmds:\n", "        if (subcmd == name):\n", "            print(f'|===> call {name}')\n", "            globals()[name](args, kwargs) # pass args to nn cmd"]}, {"cell_type": "markdown", "metadata": {}, "source": ["--------------------------------------------------------------<br>\n", "python base/base.py nninfo"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if __name__ == \"__main__\":\n", "    print(\"|===>\", __name__)\n", "    main()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["--------------------------------------------------------------"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}