{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# -*- coding: utf-8 -*-\n", "# \n", "# # Copyright (c) 2019, NVIDIA Corporation. All rights reserved.\n", "#\n", "import os\n", "import io\n", "from io import StringIO\n", "import time\n", "import argparse\n", "import functools\n", "import errno\n", "import scipy\n", "import scipy.io\n", "import requests\n", "import zipfile\n", "import random\n", "import datetime\n", "#\n", "from functools import partial\n", "from importlib import import_module\n", "#\n", "import logging\n", "logging.getLogger('tensorflow').setLevel(logging.ERROR)\n", "#\n", "import numpy as np\n", "from numpy import *\n", "#\n", "import math\n", "from math import floor, log2\n", "from random import random\n", "from pylab import *\n", "from IPython.core.display import display\n", "import PIL\n", "from PIL import Image\n", "PIL.Image.MAX_IMAGE_PIXELS = 933120000\n", "#\n", "import scipy.ndimage as pyimg\n", "import cv2\n", "import imageio\n", "import glob\n", "import matplotlib as mpl\n", "import matplotlib.pyplot as plt \n", "import matplotlib.image as mgimg\n", "import matplotlib.animation as anim\n", "mpl.rcParams['figure.figsize'] = (12,12)\n", "mpl.rcParams['axes.grid'] = False\n", "#\n", "import shutil\n", "import gdown\n", "#\n", "import sys\n", "#\n", "import tensorflow as tf \n", "from tensorflow.keras import initializers, regularizers, constraints\n", "from tensorflow.keras import backend as K\n", "from tensorflow.keras import layers\n", "from tensorflow.keras.layers import Layer, InputSpec\n", "from tensorflow.keras.layers import BatchNormalization, Activation, ZeroPadding2D, UpSampling2D, Conv2D\n", "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout, LeakyReLU\n", "from tensorflow.keras.models import Sequential, Model\n", "from tensorflow.keras.optimizers import Adam\n", "from tensorflow.python.keras.utils import conv_utils\n", "#\n", "from tensorflow.keras.layers import Lambda\n", "from tensorflow.keras.layers import add\n", "from tensorflow.keras.layers import AveragePooling2D\n", "from tensorflow.keras.initializers import VarianceScaling\n", "from tensorflow.keras.models import clone_model\n", "from tensorflow.keras.models import model_from_json\n", "#\n", "from absl import app\n", "from absl import flags\n", "from absl import logging\n", "#\n", "tf.get_logger().setLevel('ERROR')\n", "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n", "#\n", "print(f'|===> {tf.__version__}')\n", "#\n", "if 1: # get base.py from github\n", "    cwd = os.getcwd()\n", "    base_path = os.path.join(cwd, 'base.py')\n", "    if not os.path.exists(base_path):\n", "        base_file = 'base.py'\n", "        urlfolder = 'https://raw.githubusercontent.com/sifbuilder/pylon/master/'\n", "        url = f'{urlfolder}{base_file}'\n", "        print(f\"|===> nnimg: get base file \\n \\\n", "            urlfolder: {urlfolder} \\n \\\n", "            url: {url} \\n \\\n", "            base_path: {base_path} \\n \\\n", "        \")\n", "        tofile = tf.keras.utils.get_file(f'{base_path}', origin=url, extract=True)\n", "    else:\n", "        print(f\"|===> base in cwd {cwd}\")\n", "#\n", "#\n", "#   FUNS\n", "#\n", "#\n", "# check if base.Onpyon is defined\n", "try:\n", "    var = Onpyon()\n", "except NameError:\n", "    sys.path.append('../')  # if called from eon, modules are in parallel folder\n", "    sys.path.append('./')  #  if called from dnns, modules are in folder\n", "    from base import *\n", "#\n", "onutil = Onutil()\n", "onplot = Onplot()\n", "onformat = Onformat()\n", "onfile = Onfile()\n", "onvid = Onvid()\n", "onimg = Onimg()\n", "ondata = Ondata()\n", "onset = Onset()\n", "onrecord = Onrecord()\n", "ontree = Ontree()\n", "onvgg = Onvgg()\n", "onlllyas = Onlllyas()\n", "#\n", "#\n", "#   CONTEXT\n", "#\n", "#\n", "def getap():\n", "    cp = {\n", "        \"primecmd\": 'nnmodel',\n", "        \"MNAME\": \"microsoft\",\n", "        \"AUTHOR\": \"microsoft\",\n", "        \"PROJECT\": \"msconfig\",\n", "        \"GITPOD\": \"ConfigNet\",\n", "        \"DATASET\": \"confignet\",\n", "        \"GDRIVE\": 1,            # mount gdrive: gdata, gwork    \n", "        \"TRAINDO\": 1,      \n", "        \"MAKEGIF\": 1,      \n", "        \"RUNGIF\": 0,      \n", "        \"CLEARTMP\": 0,      \n", "        \"REGET\": 0,             # get again data \n", "        \"ING\": 1,               # ckpt in gwork\n", "        \"MODITEM\": \"\",          # will look into module\n", "        \"RESETCODE\": 0,\n", "        \"LOCALDATA\": 0,\n", "        \"LOCALMODELS\": 0,\n", "        \"LOCALLAB\": 1,\n", "        \"grel_infix\": '../..',            # relative path to content \n", "        \"net_prefix\": '//enas/hdrive',     \n", "        \"gdrive_prefix\": '/content/drive/My Drive',     \n", "        \"gcloud_prefix\": '/content',     \n", "    }\n", "    local_prefix = os.path.abspath('')\n", "    try:\n", "            local_prefix = os.path.dirname(os.path.realpath(__file__)) # script dir\n", "    except:\n", "            pass\n", "    cp[\"local_prefix\"] = local_prefix\n", "    \n", "    hp = {\n", "        \"verbose\": 1, # [0,n]\n", "        \"visual\": 1, # [0,n]\n\n", "        # train\n", "        \"batch_size\": 1,\n", "        \"img_width\": 256,\n", "        \"img_height\": 256,\n", "        \"buffer_size\": 1000,\n", "        \"input_channels\": 3,\n", "        \"output_channels\": 3,\n", "        \"max_epochs\": 200,\n", "        \"n_iterations\": 10, # iters for snapshot\n\n", "        # dataset.py args\n", "        \"input_folder\": './input/',\n", "        \"output_folder\": './output/',\n", "        \"keep_folder\": 0,\n", "        \"process_type\": 'resize',\n", "        \"blur_type\": \"\", # [\"\",\"gaussian\",\"median\"]\n", "        \"blur_amount\": 1,\n", "        \"max_size\": 256,\n", "        \"height\": 256,\n", "        \"width\": 256,\n", "        \"shift_y\": 0,\n", "        \"v_align\": 'center',\n", "        \"h_align\": 'center',\n", "        \"shift_x\": 0,\n", "        \"scale\": 2.0,\n", "        \"direction\": 'AtoB',\n", "        \"border_type\": 'stretch',\n", "        \"border_color\": '255,255,255',\n", "        \"mirror\": 0,\n", "        \"rotate\": 0,\n", "        \"file_extension\": 'png',\n\n", "        # var\n", "        \"name\": 0, # use counter\n", "        \"keep_name\": 0, # _e_\n", "        \"numbered\": 1, # _e_\n", "        \"zfill\": 4, # zfill name counter\n", "    }\n", "    ap = {}\n", "    for key in cp.keys():\n", "        ap[key] = cp[key]\n", "    for key in hp.keys():\n", "        ap[key] = hp[key]\n", "    return ap\n", "#\n", "def getxp(cp):\n", "    yp={}\n", "    xp={}\n", "    for key in cp.keys():\n", "        xp[key] = cp[key]\n", "    tree = ontree.tree(cp)\n", "    for key in tree.keys():\n", "        xp[key] = tree[key]\n", "    for key in yp.keys():\n", "        xp[key] = yp[key]\n", "   \n", "    return xp\n", "#\n", "#\n", "#   NETS\n", "#\n", "#\n", "#\n", "#\n", "#   FUNS\n", "#\n", "#\n", "#\n", "#\n", "#   CMDS\n", "#\n", "#\n", "#\n", "#   nnmodel\n", "#\n", "def nnmodel(args, kwargs):\n", "    args = onutil.pargs(vars(args))\n", "    xp = getxp(vars(args))\n", "    args = onutil.pargs(xp)    \n", "    onutil.ddict(vars(args), 'args')\n", "    print(f'|---> nnmodel: {args.PROJECT}:   \\n \\\n", "        args.DATASET:    {args.DATASET} \\n \\\n", "    ')\n", "    if 1: # config\n", "        args.height = args.img_height\n", "        args.width = args.img_width\n", "        args.buffer_size = args.buffer_size\n", "        args.batch_size = args.batch_size\n", "        args.input_channels = args.input_channels\n", "        args.input_shape = [args.height, args.width, args.input_channels]\n", "        if 0:\n", "            ''' copy org to same data folder'''\n", "            args.patts = ['*in.png', '*re.png']\n", "        else:\n", "            ''' will separate images in data'''\n", "            args.patts = ['*.png', '*.png']\n", "    if args.verbose: print(f\"|---> nnleonardo config:   \\n \\\n", "        args.max_epochs:            {args.max_epochs}, \\n \\\n", "        args.output_channels:\t{args.output_channels} \\n \\\n", "        args.height: \t\t\t{args.height} \\n \\\n", "        args.width: \t\t\t{args.width} \\n \\\n", "        args.input_channels: \t{args.input_channels} \\n \\\n", "        args.buffer_size: \t\t{args.buffer_size} \\n \\\n", "        args.batch_size: \t\t{args.batch_size} \\n \\\n", "        args.input_shape: \t\t{args.input_shape} \\n \\\n", "        args.patts:     \t\t{args.patts}, \\n \\\n", "    \")\n", "    if 0: # conda\n", "        onutil.conda()\n", " \n", "    if 1: # git\n", "        onutil.get_git(args.AUTHOR, args.GITPOD, args.proj_dir)\n", "    if 1: # tree\n", "        args.models_dir = os.path.join(args.proj_dir, \"models\")\n", "        os.makedirs(args.data_dir, exist_ok=True)\n", "        os.makedirs(args.models_dir, exist_ok=True)\n", "    if args.verbose: print(f\"|===> tree: {args.PROJECT}:   \\n \\\n", "        cwd:     \t\t\t\t{os.getcwd()} \\n \\\n", "        args.dataorg_dir: {args.dataorg_dir} \\n \\\n", "        args.data_dir: {args.data_dir} \\n \\\n", "        args.models_dir: {args.models_dir} \\n \\\n", "        args.dataorg_dir:     {args.dataorg_dir} \\n \\\n", "        args.ckpt_dir:  {args.ckpt_dir} \\n \\\n", "        args.logs_dir:        {args.logs_dir} \\n \\\n", "        args.tmp_dir:        {args.tmp_dir} \\n \\\n", "        args.verbose:         {args.verbose}, \\n \\\n", "        args.visual:          {args.visual}, \\n \\\n", "    \")\n", "    #\n", "    #from confignet import ConfigNet, LatentGAN, FaceImageNormalizer\n", "    #def process_images(image_path: str, resolution: int) -> List[np.ndarray]:\n", "    #    '''Load the input images and normalize them'''\n", "    #    if os.path.isfile(image_path):\n", "    #        img = cv2.imread(image_path)\n", "    #        img = FaceImageNormalizer.normalize_individual_image(img, (resolution, resolution))\n", "    #        return [img]\n", "    #    elif os.path.isdir(image_path):\n", "    #        FaceImageNormalizer.normalize_dataset_dir(image_path, pre_normalize=True,\n", "    #                                                output_image_shape=(resolution, resolution), write_done_file=False)\n", "    #        normalized_image_dir = os.path.join(image_path, \"normalized\")\n", "    #        image_paths = glob.glob(os.path.join(normalized_image_dir, \"*.png\"))\n", "    #        max_images = 200\n", "    #        image_paths = image_paths[:max_images]\n", "    #        if len(image_paths) == 0:\n", "    #            raise ValueError(\"No images in input directory\")\n", "    #        imgs = []\n", "    #        for path in image_paths:\n", "    #            imgs.append(cv2.imread(path))\n", "    #        return imgs\n", "    #    else:\n", "    #        raise ValueError(\"Image path is neither directory nor file\")\n", "    #\n", "    if 1: # models.zip\n", "        os.chdir(args.proj_dir)\n", "        if args.verbose: print(f\"|===> models :   \\n \\\n", "            cwd:     \t\t\t\t{os.getcwd()} \\n \\\n", "        \")\n", "        import urllib.request\n", "        local_tar_path = ''\n", "        tree_root = None\n", "        local_tar_path = os.path.join(args.proj_dir, 'models.zip')\n", "        url = 'https://github.com/microsoft/ConfigNet/releases/download/v1.0.0/models.zip'\n", "        if not os.path.exists(local_tar_path):\n", "            print(f'|... urlretrieve: {url} to {args.local_tar_path}')\n", "            filename, headers = urllib.request.urlretrieve(url, filename=local_tar_path)\n", "        if os.listdir(args.models_dir) == 0:\n", "            print(f'|... tunzip: {local_tar_path} to {args.proj_dir}') # tree_root: models \n", "            import zipfile\n", "            with zipfile.ZipFile(local_tar_path, 'r') as zip_ref:\n", "                zip_ref.extractall(args.proj_dir)\n\n", "    # openface - https://github.com/microsoft/ConfigNet/tree/main/setup/download_deps.py\n", "    setup_dir = os.path.join(args.proj_dir, 'setup')\n", "    os.chdir(setup_dir)\n", "    if args.verbose: print(f\"|===> setup :   \\n \\\n", "        cwd:     \t\t\t\t{os.getcwd()} \\n \\\n", "    \")\n\n", "    # openface - https://github.com/microsoft/ConfigNet/tree/main/setup/download_models.py\n", "    import subprocess\n", "    OPENFACE = \"https://github.com/TadasBaltrusaitis/OpenFace/releases/download/OpenFace_2.2.0/OpenFace_2.2.0_win_x64.zip\"\n", "    #include_dir_path = os.path.abspath(os.path.dirname(__file__))\n", "    #cwd = os.getcwd()\n", "    #os.chdir(include_dir_path)\n", "    third_party_dir = os.path.join(\"..\", \"3rd_party\")\n", "    openface_filename = os.path.basename(OPENFACE)\n", "    openface_dirname = os.path.splitext(openface_filename)[0]\n", "    openface_local_path = os.path.join(third_party_dir, openface_dirname)\n", "    if args.verbose: print(f\"|---> openface:  \\n \\\n", "        cwd:                 {os.getcwd()} \\n \\\n", "        openface_dirname:    {openface_dirname} \\n \\\n", "        openface_filename:   {openface_filename} \\n \\\n", "        openface_local_path: {openface_local_path} \\n \\\n", "    \")\n", "    if not os.path.exists(openface_local_path):\n", "        print('|... Downloading OpenFace')\n", "        response = requests.get(OPENFACE)\n", "        with open(openface_filename, \"wb\") as fp:\n", "            fp.write(response.content)\n", "        print(\"|... Extracting OpenFace\")\n", "        os.makedirs(third_party_dir, exist_ok=True)\n", "        with zipfile.ZipFile(openface_filename, \"r\") as zip_ref:\n", "            zip_ref.extractall(third_party_dir)\n", "        print(\"|... Downloading patch experts\")\n", "        os.chdir(openface_local_path)\n", "        subprocess.run([r'powershell.exe', '-ExecutionPolicy', 'Unrestricted', './download_models.ps1'], cwd=os.getcwd())\n", "    # \n", "    os.chdir(args.proj_dir)   \n", "    imgs_dir = os.path.join(args.proj_dir, 'assets')\n", "    imgs_dir = os.path.join(args.gdata, 'threefaces', 'stock_photo1.jpg')\n", "    cmd = f'python evaluation/confignet_demo.py --image_path \"{imgs_dir}\"'\n", "    setup_dir = os.path.join(args.proj_dir, '')\n", "    os.chdir(setup_dir)\n", "    if args.verbose: print(f\"|---> confignet_demo :   \\n \\\n", "        cwd:  {os.getcwd()} \\n \\\n", "        cmd:  {cmd} \\n \\\n", "    \")\n", "    os.system(cmd)\n", "#\n", "#\n", "#\n", "#   MAIN\n", "#\n", "#\n", "def main():\n", "    parser = argparse.ArgumentParser(description='Run \"python %(prog)s <subcommand> --help\" for subcommand help.')\n", "    onutil.dodrive()\n", "    ap = getap()\n", "    for p in ap:\n", "        cls = type(ap[p])\n", "        parser.add_argument('--'+p, type=cls, default=ap[p])\n", "    cmds = [key for key in globals() if key.startswith(\"nn\")]\n", "    primecmd = ap[\"primecmd\"]\n", "        \n", "    # ---------------------------------------------------------------\n", "    #   add subparsers\n", "    #\n", "    subparsers = parser.add_subparsers(help='subcommands', dest='command') # command - subparser\n", "    for cmd in cmds:\n", "        subparser = subparsers.add_parser(cmd, help='cmd')  # add subcommands\n", "    \n", "    subparsers_actions = [action for action in parser._actions\n", "        if isinstance(action, argparse._SubParsersAction)] # retrieve subparsers from parser\n", "  \n", "    for subparsers_action in subparsers_actions:  # add common       \n", "        for choice, subparser in subparsers_action.choices.items(): # get all subparsers and print help\n", "            for p in {}:  # subcommand args dict\n", "                cls = type(ap[p])\n", "                subparser.add_argument('--'+p, type=cls, default=ap[p])\n\n", "    # get args to pass to nn cmds\n", "    if onutil.incolab():\n", "        args = parser.parse_args('') #  defaults as args\n", "    else:\n", "        args = parser.parse_args() #  parse_arguments()\n", "    kwargs = vars(args)\n", "    subcmd = kwargs.pop('command')      \n", "    if subcmd is None:\n", "        print (f\"Missing subcommand. set to default {primecmd}\")\n", "        subcmd = primecmd\n", "    \n", "    for name in cmds:\n", "        if (subcmd == name):\n", "            print(f'|===> call {name}')\n", "            globals()[name](args, kwargs) # pass args to nn cmd\n", "#\n", "#\n", "#\n", "# python base/base.py nninfo\n", "if __name__ == \"__main__\":\n", "    print(\"|===>\", __name__)\n", "    main()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}